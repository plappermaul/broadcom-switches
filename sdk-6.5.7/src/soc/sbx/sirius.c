/*
 * $Id: sirius.c,v 1.476.18.2 Broadcom SDK $
 * $Copyright: (c) 2016 Broadcom.
 * Broadcom Proprietary and Confidential. All rights reserved.$
 *
 * SIRIUS SOC Initialization implementation
 */

#include <shared/bsl.h>
#include <assert.h>
#include <soc/drv.h>
#include <soc/mem.h>
#include <soc/i2c.h>
#include <soc/error.h>
#include <soc/counter.h>
#include <soc/higig.h>
#include <soc/ipoll.h>
#include <soc/phyctrl.h>
#include <soc/sbx/sbx_drv.h>
#include <soc/sbx/sirius.h>
#include <soc/sbx/sirius_counter.h>
#include <soc/sbx/sbx_util.h>
#include <soc/phy/ddr23.h>
#include <soc/sbx/sirius_ddr23.h>
#include <soc/sbx/sbFabCommon.h>

#include <bcm_int/sbx/error.h>
#include <bcm_int/sbx/stack.h>
#include <bcm_int/sbx/state.h>
#include <bcm_int/sbx/fabric.h>
#include <bcm_int/sbx/port.h>
#include <bcm_int/sbx/mbcm.h>
#include <bcm_int/sbx/sirius.h>
#include <bcm_int/sbx_dispatch.h>

#include <bcm/error.h>
#include <bcm/types.h>
#include <bcm/port.h>
#include <bcm/fabric.h>

#include <soc/sbx/link.h>
#include <sal/appl/sal.h>
#include <sal/compiler.h>

    /* set property  sirius_init_timeout_in_usec = 40000000        */
    /* set property  sirius_rate_delta_mode      = 1               */
    /* set property  sirius_qs_ager_tick_cycles  = 800             */
    /* set property  sirius_qs_ager_queue_last  = 0x1ff            */

#ifdef BCM_SIRIUS_SUPPORT

#ifdef  SIRIUS_UNIT
#undef  SIRIUS_UNIT
#endif
#define SIRIUS_UNIT (pInitParams->unit)

#if 0 /* normally this should be left zero */
#define SIR_EVERB(stuff)      LOG_DEBUG(BSL_LS_SOC_COMMON, stuff)
#else /* 0 -- normally this should be left zero */
#define SIR_EVERB(stuff)
#endif /* 0 -- normally this should be left zero */

typedef struct sirius_reg_info1_s {
    uint32 reg;
    uint32 fld0;
} sirius_reg_info1_t;

typedef struct sirius_reg_info2_s {
    uint32 reg;
    uint16 fld0;
    uint16 fld1;
} sirius_reg_info2_t;

typedef struct sirius_tdm_table_entry_info_s {
    uint16 intf;
    uint16 sop;
    uint16 end;
} sirius_tdm_table_entry_info_t;

soc_sbx_sirius_state_t *_soc_sbx_sirius_state[SOC_MAX_NUM_DEVICES];

static int _sirius_init_timeout = 0;

static siriusIngressShaperInfo_t    *shaper_info[SOC_MAX_NUM_DEVICES];

static int sirius_age_thresh_field[32] =
{
    AGE_THRESH_QUEUE0f, AGE_THRESH_QUEUE1f, AGE_THRESH_QUEUE2f, AGE_THRESH_QUEUE3f,
    AGE_THRESH_QUEUE4f, AGE_THRESH_QUEUE5f, AGE_THRESH_QUEUE6f, AGE_THRESH_QUEUE7f,
    AGE_THRESH_QUEUE8f, AGE_THRESH_QUEUE9f, AGE_THRESH_QUEUE10f, AGE_THRESH_QUEUE11f,
    AGE_THRESH_QUEUE12f, AGE_THRESH_QUEUE13f, AGE_THRESH_QUEUE14f, AGE_THRESH_QUEUE15f,
    AGE_THRESH_QUEUE16f, AGE_THRESH_QUEUE17f, AGE_THRESH_QUEUE18f, AGE_THRESH_QUEUE19f,
    AGE_THRESH_QUEUE20f, AGE_THRESH_QUEUE21f, AGE_THRESH_QUEUE22f, AGE_THRESH_QUEUE23f,
    AGE_THRESH_QUEUE24f, AGE_THRESH_QUEUE25f, AGE_THRESH_QUEUE26f, AGE_THRESH_QUEUE27f,
    AGE_THRESH_QUEUE28f, AGE_THRESH_QUEUE29f, AGE_THRESH_QUEUE30f, AGE_THRESH_QUEUE31f
};

static const sirius_reg_info1_t  queue_depth_reg[16] =
{
    { Q_DEPTH_THRESH0r, Q_DEPTH_THRESH0f },
    { Q_DEPTH_THRESH1r, Q_DEPTH_THRESH1f },
    { Q_DEPTH_THRESH2r, Q_DEPTH_THRESH2f },
    { Q_DEPTH_THRESH3r, Q_DEPTH_THRESH3f },
    { Q_DEPTH_THRESH4r, Q_DEPTH_THRESH4f },
    { Q_DEPTH_THRESH5r, Q_DEPTH_THRESH5f },
    { Q_DEPTH_THRESH6r, Q_DEPTH_THRESH6f },
    { Q_DEPTH_THRESH7r, Q_DEPTH_THRESH7f },
    { Q_DEPTH_THRESH8r, Q_DEPTH_THRESH8f },
    { Q_DEPTH_THRESH9r, Q_DEPTH_THRESH9f },
    { Q_DEPTH_THRESH10r, Q_DEPTH_THRESH10f },
    { Q_DEPTH_THRESH11r, Q_DEPTH_THRESH11f },
    { Q_DEPTH_THRESH12r, Q_DEPTH_THRESH12f },
    { Q_DEPTH_THRESH13r, Q_DEPTH_THRESH13f },
    { Q_DEPTH_THRESH14r, Q_DEPTH_THRESH14f },
    { Q_DEPTH_THRESH15r, Q_DEPTH_THRESH15f }
};

static const sirius_reg_info2_t  ager_thresh_reg[16] =
{
    { AGER_THRESH_0r, AGER_PROFILE0_THRESH0f, AGER_PROFILE0_THRESH1f },
    { AGER_THRESH_1r, AGER_PROFILE1_THRESH0f, AGER_PROFILE1_THRESH1f },
    { AGER_THRESH_2r, AGER_PROFILE2_THRESH0f, AGER_PROFILE2_THRESH1f },
    { AGER_THRESH_3r, AGER_PROFILE3_THRESH0f, AGER_PROFILE3_THRESH1f },
    { AGER_THRESH_4r, AGER_PROFILE4_THRESH0f, AGER_PROFILE4_THRESH1f },
    { AGER_THRESH_5r, AGER_PROFILE5_THRESH0f, AGER_PROFILE5_THRESH1f },
    { AGER_THRESH_6r, AGER_PROFILE6_THRESH0f, AGER_PROFILE6_THRESH1f },
    { AGER_THRESH_7r, AGER_PROFILE7_THRESH0f, AGER_PROFILE7_THRESH1f },
    { AGER_THRESH_8r, AGER_PROFILE8_THRESH0f, AGER_PROFILE8_THRESH1f },
    { AGER_THRESH_9r, AGER_PROFILE9_THRESH0f, AGER_PROFILE9_THRESH1f },
    { AGER_THRESH_10r, AGER_PROFILE10_THRESH0f, AGER_PROFILE10_THRESH1f },
    { AGER_THRESH_11r, AGER_PROFILE11_THRESH0f, AGER_PROFILE11_THRESH1f },
    { AGER_THRESH_12r, AGER_PROFILE12_THRESH0f, AGER_PROFILE12_THRESH1f },
    { AGER_THRESH_13r, AGER_PROFILE13_THRESH0f, AGER_PROFILE13_THRESH1f },
    { AGER_THRESH_14r, AGER_PROFILE14_THRESH0f, AGER_PROFILE14_THRESH1f },
    { AGER_THRESH_15r, AGER_PROFILE15_THRESH0f, AGER_PROFILE15_THRESH1f }
};

static const unsigned int predFields[10][5] =
{
    {PRED0_FIELD_OFFSETf, PRED0_METAf, PRED0_RANGEf, PRED0_LO_MASKf, PRED0_HI_DATAf},
    {PRED1_FIELD_OFFSETf, PRED1_METAf, PRED1_RANGEf, PRED1_LO_MASKf, PRED1_HI_DATAf},
    {PRED2_FIELD_OFFSETf, PRED2_METAf, PRED2_RANGEf, PRED2_LO_MASKf, PRED2_HI_DATAf},
    {PRED3_FIELD_OFFSETf, PRED3_METAf, PRED3_RANGEf, PRED3_LO_MASKf, PRED3_HI_DATAf},
    {PRED4_FIELD_OFFSETf, PRED4_METAf, PRED4_RANGEf, PRED4_LO_MASKf, PRED4_HI_DATAf},
    {PRED5_FIELD_OFFSETf, PRED5_METAf, PRED5_RANGEf, PRED5_LO_MASKf, PRED5_HI_DATAf},
    {PRED6_FIELD_OFFSETf, PRED6_METAf, PRED6_RANGEf, PRED6_LO_MASKf, PRED6_HI_DATAf},
    {PRED7_FIELD_OFFSETf, PRED7_METAf, PRED7_RANGEf, PRED7_LO_MASKf, PRED7_HI_DATAf},
    {PRED8_FIELD_OFFSETf, PRED8_METAf, PRED8_RANGEf, PRED8_LO_MASKf, PRED8_HI_DATAf},
    {PRED9_FIELD_OFFSETf, PRED9_METAf, PRED9_RANGEf, PRED9_LO_MASKf, PRED9_HI_DATAf}
};

static const unsigned int predRegs[10][2] =
{
    {RB_PRED_CONFIG0r, RB_PRED_CONFIG3r},
    {RB_PRED_CONFIG0r, RB_PRED_CONFIG4r},
    {RB_PRED_CONFIG0r, RB_PRED_CONFIG5r},
    {RB_PRED_CONFIG0r, RB_PRED_CONFIG6r},
    {RB_PRED_CONFIG1r, RB_PRED_CONFIG7r},
    {RB_PRED_CONFIG1r, RB_PRED_CONFIG8r},
    {RB_PRED_CONFIG1r, RB_PRED_CONFIG9r},
    {RB_PRED_CONFIG1r, RB_PRED_CONFIG10r},
    {RB_PRED_CONFIG2r, RB_PRED_CONFIG11r},
    {RB_PRED_CONFIG2r, RB_PRED_CONFIG12r}
};

static const unsigned int cosMapRegs[64][2] =
{
    {RB_COS_MAP_TABLE_0r, COS_MAP_0f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_1f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_2f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_3f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_4f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_5f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_6f},
    {RB_COS_MAP_TABLE_0r, COS_MAP_7f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_8f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_9f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_10f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_11f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_12f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_13f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_14f},
    {RB_COS_MAP_TABLE_1r, COS_MAP_15f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_16f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_17f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_18f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_19f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_20f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_21f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_22f},
    {RB_COS_MAP_TABLE_2r, COS_MAP_23f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_24f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_25f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_26f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_27f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_28f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_29f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_30f},
    {RB_COS_MAP_TABLE_3r, COS_MAP_31f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_32f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_33f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_34f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_35f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_36f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_37f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_38f},
    {RB_COS_MAP_TABLE_4r, COS_MAP_39f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_40f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_41f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_42f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_43f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_44f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_45f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_46f},
    {RB_COS_MAP_TABLE_5r, COS_MAP_47f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_48f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_49f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_50f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_51f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_52f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_53f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_54f},
    {RB_COS_MAP_TABLE_6r, COS_MAP_55f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_56f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_57f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_58f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_59f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_60f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_61f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_62f},
    {RB_COS_MAP_TABLE_7r, COS_MAP_63f},
};

static const unsigned int queueSegRegs[7][2] =
{
    {RB_SEG_BASE_1_2r, SEGMENT_BASE_1f},
    {RB_SEG_BASE_1_2r, SEGMENT_BASE_2f},
    {RB_SEG_BASE_3_4r, SEGMENT_BASE_3f},
    {RB_SEG_BASE_3_4r, SEGMENT_BASE_4f},
    {RB_SEG_BASE_5_6r, SEGMENT_BASE_5f},
    {RB_SEG_BASE_5_6r, SEGMENT_BASE_6f},
    {RB_SEG_BASE_7r, SEGMENT_BASE_7f},
};


static int _soc_sirius_hw_init( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_step0( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_step1( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_step2( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_cleanup( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_rb( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_qm( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_qs( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_tx( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_ci( uint32 ci, siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_sc_sf( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_cs( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_ts( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_fr( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_eb( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_ep( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_es( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_fd( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_ff( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_xp( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_bp( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_hc( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_cmic( siriusInitParams_t *pInitParams);
static int _soc_sirius_hw_init_xmac( siriusInitParams_t *pInitParams);
static void _soc_sirius_init_default_params(siriusInitParams_t *pInitParams);

static int _soc_sirius_mdio_hc_cl22_read(int unit, uint32 uPhyAddr, uint32 uRegAddr, uint32 *pReadData);
static int _soc_sirius_mdio_hc_cl22_write(int unit, uint32 uPhyAddr, uint32 uRegAddr, uint32 uData);
static int soc_sirius_init_si_step0(int unit, uint nSi, int force_speed, int lane_mode, siriusInitParams_t *pInitParams);
static int soc_sirius_init_si_step1(int unit, uint nSi, siriusInitParams_t *pInitParams);

typedef enum {
    _SOC_ERROR_INFO_TYPE_GENERIC,
    _SOC_ERROR_INFO_TYPE_ECC_CORRECTED,
    _SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED,
    _SOC_ERROR_INFO_TYPE_NUM
} _soc_error_info_type_t;

typedef struct _soc_error_info_s {
    _soc_error_info_type_t  type;             /* error type */
    soc_mem_t               mem;              /* error memory table */
    soc_reg_t               enable_reg;       /* error enable register */
    soc_field_t             enable_field;     /* error enable field */
    soc_reg_t               status_reg;       /* error status register */
    soc_field_t             status_field;     /* error status field */
    soc_reg_t               mask_reg;         /* error mask register */
    soc_field_t             mask_field;       /* error mask field */
    soc_reg_t               force_reg;        /* error force register */
    soc_field_t             force_field;      /* error force field */
    soc_reg_t               info_reg;         /* error info register, such as ECC address */
    soc_field_t             info_field;       /* error info field */
    char                    *msg;             /* message for this error */
} _soc_error_info_t;

typedef struct _soc_error_block_info_s {
    _soc_error_info_t       *info;
    int32                   num_intr;
    soc_port_t              port;
    char                    *block_msg;             /* message for this error group */
} _soc_error_block_info_t;

STATIC _soc_error_info_t _soc_sirius_ci_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     CI_ERRORr, MISSED_REFRESHf,
     CI_ERROR_MASKr, MISSED_REFRESH_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "CI: Missed refresh error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CI_ECC_DEBUGr, WFIFO_CTL_ENABLE_ECCf, 
     CI_ERRORr, WFIFO_CTL_CORRECTED_ERRORf,
     CI_ERROR_MASKr, WFIFO_CTL_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     CI_ECC_STATUSr, WFIFO_CTL_ERROR_ADDRESSf,
     "CI: WFIFO_CTL Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     CI_ECC_DEBUGr, WFIFO_CTL_ENABLE_ECCf, 
     CI_ERRORr, WFIFO_CTL_UNCORRECTED_ERRORf,
     CI_ERROR_MASKr, WFIFO_CTL_UNCORRECTED_ERROR_DISINTf,
     CI_ECC_DEBUGr, WFIFO_CTL_FORCE_UNCORRECTABLE_ERRORf,
     CI_ECC_STATUSr, WFIFO_CTL_ERROR_ADDRESSf,
     "CI: WFIFO_CTL Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     CI_ERRORr, WB_OVERFLOWf,
     CI_ERROR_MASKr, WB_OVERFLOW_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "CI: Write FIFO overflows error"
    },
};
STATIC _soc_error_info_t _soc_sirius_cmic_error_info[] = {
    /* reported in CMIC_IRQ_STAT */
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDr,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "reported in CMIC_IRQ_STAT"
    }
};
STATIC _soc_error_info_t _soc_sirius_bp_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP7_DP_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP7_DP_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP7 datapath fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP7_FC_SIZE_ERRORf,
     BP_ERROR_MASKr, XP7_FC_SIZE_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP7 received message size was different than the expected size error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP7_FC_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP7_FC_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP7 flow control fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP6_DP_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP6_DP_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP6 datapath fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP6_FC_SIZE_ERRORf,
     BP_ERROR_MASKr, XP6_FC_SIZE_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP6 received message size was different than the expected size error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP6_FC_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP6_FC_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP6 flow control fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP5_DP_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP5_DP_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP5 datapath fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP5_FC_SIZE_ERRORf,
     BP_ERROR_MASKr, XP5_FC_SIZE_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP5 received message size was different than the expected size error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP5_FC_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP5_FC_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP5 flow control fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP4_DP_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP4_DP_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP4 datapath fifo overflow error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP4_FC_SIZE_ERRORf,
     BP_ERROR_MASKr, XP4_FC_SIZE_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP4 received message size was different than the expected size error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     BP_ERRORr, XP4_FC_FIFO_OVERFLOW_ERRORf,
     BP_ERROR_MASKr, XP4_FC_FIFO_OVERFLOW_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "BP: XP4 flow control fifo overflow error"
    },
    
};
STATIC _soc_error_info_t _soc_sirius_cs_error_info[] = {
    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_0_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK0_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK0_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_0_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS0r, BRICK0_PARITY_ERROR_ADDRESSf,
     "CS: Brick 0 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_1_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK1_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK1_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_1_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS0r, BRICK1_PARITY_ERROR_ADDRESSf,
     "CS: Brick 1 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_2_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK2_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK2_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_2_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS1r, BRICK2_PARITY_ERROR_ADDRESSf,
     "CS: Brick 2 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_3_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK3_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK3_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_3_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS1r, BRICK3_PARITY_ERROR_ADDRESSf,
     "CS: Brick 3 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_4_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK4_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK4_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_4_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS2r, BRICK4_PARITY_ERROR_ADDRESSf,
     "CS: Brick 4 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_5_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK5_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK5_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_5_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS2r, BRICK5_PARITY_ERROR_ADDRESSf,
     "CS: Brick 5 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_6_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK6_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK6_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_6_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS3r, BRICK6_PARITY_ERROR_ADDRESSf,
     "CS: Brick 6 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_7_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK7_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK7_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_7_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS3r, BRICK7_PARITY_ERROR_ADDRESSf,
     "CS: Brick 7 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_8_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK8_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK8_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_8_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS4r, BRICK8_PARITY_ERROR_ADDRESSf,
     "CS: Brick 8 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_9_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK9_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK9_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_9_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS4r, BRICK9_PARITY_ERROR_ADDRESSf,
     "CS: Brick 9 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_10_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK10_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK10_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_10_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS5r, BRICK10_PARITY_ERROR_ADDRESSf,
     "CS: Brick 10 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_11_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK11_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK11_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_11_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS5r, BRICK11_PARITY_ERROR_ADDRESSf,
     "CS: Brick 11 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_12_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK12_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK12_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_12_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS6r, BRICK12_PARITY_ERROR_ADDRESSf,
     "CS: Brick 12 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_13_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK13_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK13_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_13_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS6r, BRICK13_PARITY_ERROR_ADDRESSf,
     "CS: Brick 13 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_14_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK14_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK14_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_14_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS7r, BRICK14_PARITY_ERROR_ADDRESSf,
     "CS: Brick 14 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG0r, BRICK_15_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK15_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK15_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG0r, BRICK_15_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS7r, BRICK15_PARITY_ERROR_ADDRESSf,
     "CS: Brick 15 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_16_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK16_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK16_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_16_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS8r, BRICK16_PARITY_ERROR_ADDRESSf,
     "CS: Brick 16 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_17_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK17_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK17_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_17_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS8r, BRICK17_PARITY_ERROR_ADDRESSf,
     "CS: Brick 17 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_18_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK18_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK18_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_18_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS9r, BRICK18_PARITY_ERROR_ADDRESSf,
     "CS: Brick 18 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_19_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK19_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK19_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_19_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS9r, BRICK19_PARITY_ERROR_ADDRESSf,
     "CS: Brick 19 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_20_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK20_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK20_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_20_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS10r, BRICK20_PARITY_ERROR_ADDRESSf,
     "CS: Brick 20 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_21_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK21_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK21_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_21_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS10r, BRICK21_PARITY_ERROR_ADDRESSf,
     "CS: Brick 21 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_22_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK22_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK22_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_22_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS11r, BRICK22_PARITY_ERROR_ADDRESSf,
     "CS: Brick 22 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_23_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK23_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK23_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_23_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS11r, BRICK23_PARITY_ERROR_ADDRESSf,
     "CS: Brick 23 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_24_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK24_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK24_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_24_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS12r, BRICK24_PARITY_ERROR_ADDRESSf,
     "CS: Brick 24 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_25_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK25_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK25_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_25_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS12r, BRICK25_PARITY_ERROR_ADDRESSf,
     "CS: Brick 25 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_26_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK26_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK26_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_26_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS13r, BRICK26_PARITY_ERROR_ADDRESSf,
     "CS: Brick 26 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_27_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK27_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK27_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_27_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS13r, BRICK27_PARITY_ERROR_ADDRESSf,
     "CS: Brick 27 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_28_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK28_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK28_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_28_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS14r, BRICK28_PARITY_ERROR_ADDRESSf,
     "CS: Brick 28 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_29_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK29_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK29_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_29_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS14r, BRICK29_PARITY_ERROR_ADDRESSf,
     "CS: Brick 29 parity error"
    }, 
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_30_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK30_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK30_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_30_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS15r, BRICK30_PARITY_ERROR_ADDRESSf,
     "CS: Brick 30 parity error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     CS_PARITY_DEBUG1r, BRICK_31_ENABLE_PARITYf, 
     CS_PARITY_ERRORr, BRICK31_PARITY_ERRORf,
     CS_PARITY_ERROR_MASKr, BRICK31_PARITY_ERROR_DISINTf,
     CS_PARITY_DEBUG1r, BRICK_31_FORCE_PARITY_ERRORf, 
     CS_ECC_STATUS15r, BRICK31_PARITY_ERROR_ADDRESSf,
     "CS: Brick 31 parity error"
    }, 
};
STATIC _soc_error_info_t _soc_sirius_eb_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_GENERIC, CFAP_MEMm, 
     INVALIDr, INVALIDf, 
     EB_ERRORr, CFAP_MEM_FAILf,
     EB_ERROR_MASKr, CFAP_MEM_FAIL_DISINTf,
     INVALIDr, INVALIDf, 
     EB_CFAP_RD_PTRr, POINTERf, 
     "EB: CFAP memory stack error"
    },
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDm, 
     INVALIDr, INVALIDf, 
     EB_ERRORr, ENQ_NO_FREE_PTR_ERRORf,
     EB_ERROR_MASKr, ENQ_NO_FREE_PTR_ERROR_DISINTf,
     INVALIDr, INVALIDf, 
     INVALIDr, INVALIDf, 
     "EB: EnQ has no free cell pointer error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGING_CTR_MEMm, 
     EB_ECCP_DEBUG0r, CTR_ENABLE_PARITYf, 
     EB_ERRORr, CTR_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, CTR_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, CTR_FORCE_PARITY_ERRORf,
     EB_CTR_PARITY_STATUSr, ERROR_ADDRESSf, 
     "EB: Aging CTR uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGING_EXP_MEMm, 
     EB_ECCP_DEBUG0r, EXP_ENABLE_PARITYf, 
     EB_ERRORr, EXP_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, EXP_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, EXP_FORCE_PARITY_ERRORf,
     EB_EXP_PARITY_STATUSr, ERROR_ADDRESSf, 
     "EB: Aging EXP uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CCP_MEMm, 
     EB_ECCP_DEBUG0r, CCP_ENABLE_ECCf, 
     EB_ERRORr, CCP_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, CCP_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, CCP_FORCE_UNCORRECTABLE_ERRORf,
     EB_CCP_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CCP uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CFAP_MEMm, 
     EB_ECCP_DEBUG0r, CFAP_ENABLE_ECCf, 
     EB_ERRORr, CFAP_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, CFAP_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, CFAP_FORCE_UNCORRECTABLE_ERRORf,
     EB_CFAP_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CFAP uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CELL_DATA0_MEMm, 
     EB_ECCP_DEBUG0r, CELL_DATA_ENABLE_ECCf, 
     EB_ERRORr, CELL_DATA_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, CELL_DATA_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, CELL_DATA_FORCE_UNCORRECTABLE_ERRORf,
     EB_CELL_DATA_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CELL_DATA uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CELL_HDR_MEMm, 
     EB_ECCP_DEBUG0r, CELL_HDR_ENABLE_ECCf, 
     EB_ERRORr, CELL_HDR_UNCORRECTED_ERRORf,
     EB_ERROR_MASKr, CELL_HDR_UNCORRECTED_ERROR_DISINTf,
     EB_ECCP_DEBUG1r, CELL_HDR_FORCE_UNCORRECTABLE_ERRORf,
     EB_CELL_HDR_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CELL_HDR uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CCP_MEMm, 
     EB_ECCP_DEBUG0r, CCP_ENABLE_ECCf, 
     EB_ERRORr, CCP_CORRECTED_ERRORf,
     EB_ERROR_MASKr, CCP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf, 
     EB_CCP_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CCP corrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CFAP_MEMm, 
     EB_ECCP_DEBUG0r, CFAP_ENABLE_ECCf, 
     EB_ERRORr, CFAP_CORRECTED_ERRORf,
     EB_ERROR_MASKr, CFAP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf, 
     EB_CFAP_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CFAP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CELL_DATA0_MEMm, 
     EB_ECCP_DEBUG0r, CELL_DATA_ENABLE_ECCf, 
     EB_ERRORr, CELL_DATA_CORRECTED_ERRORf,
     EB_ERROR_MASKr, CELL_DATA_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf, 
     EB_CELL_DATA_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CELL_DATA corrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CELL_HDR_MEMm, 
     EB_ECCP_DEBUG0r, CELL_HDR_ENABLE_ECCf, 
     EB_ERRORr, CELL_HDR_CORRECTED_ERRORf,
     EB_ERROR_MASKr, CELL_HDR_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf, 
     EB_CELL_HDR_ECC_STATUSr, ECC_ERROR_ADDRESSf, 
     "EB: CELL_HDR corrected ECC error"
    },    
};
STATIC _soc_error_info_t _soc_sirius_ep_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     EP_ECC_DEBUGr, EP_XP_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_XP_BUFFER_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_XP_BUFFER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_XP_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_XP_BUFFER Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm,
     EP_ECC_DEBUGr, EP_XP_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_XP_BUFFER_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_XP_BUFFER_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_XP_BUFFER_FORCE_UNCORRECTABLE_ERRORf, 
     EP_XP_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_XP_BUFFER Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     EP_ECC_DEBUGr, EP_REQP_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_REQP_BUFFER_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_REQP_BUFFER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_REQP_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_REQP_BUFFER Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm,
     EP_ECC_DEBUGr, EP_REQP_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_REQP_BUFFER_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_REQP_BUFFER_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_REQP_BUFFER_FORCE_UNCORRECTABLE_ERRORf, 
     EP_REQP_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_REQP_BUFFER Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     EP_ECC_DEBUGr, EP_CM_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_CM_BUFFER_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_CM_BUFFER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_CM_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_CM_BUFFER Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm,
     EP_ECC_DEBUGr, EP_CM_BUFFER_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_CM_BUFFER_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_CM_BUFFER_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_CM_BUFFER_FORCE_UNCORRECTABLE_ERRORf, 
     EP_CM_BUFFER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_CM_BUFFER Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EP_DEST_PORT_MAPm, 
     EP_ECC_DEBUGr, EP_DEST_PORT_MAP_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_DEST_PORT_MAP_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_DEST_PORT_MAP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_DEST_PORT_MAP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_DEST_PORT_MAP Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EP_DEST_PORT_MAPm,
     EP_ECC_DEBUGr, EP_DEST_PORT_MAP_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_DEST_PORT_MAP_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_DEST_PORT_MAP_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_DEST_PORT_MAP_FORCE_UNCORRECTABLE_ERRORf, 
     EP_DEST_PORT_MAP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_DEST_PORT_MAP Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EP_OI2QB_MAPm, 
     EP_ECC_DEBUGr, EP_OI2QB_MAP_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_OI2QB_MAP_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_OI2QB_MAP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_OI2QB_MAP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_OI2QB_MAP Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EP_OI2QB_MAPm,
     EP_ECC_DEBUGr, EP_OI2QB_MAP_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_OI2QB_MAP_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_OI2QB_MAP_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_OI2QB_MAP_FORCE_UNCORRECTABLE_ERRORf, 
     EP_OI2QB_MAP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_OI2QB_MAP Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EP_CLASS_RESOLUTIONm, 
     EP_ECC_DEBUGr, EP_CLASS_RESOLUTION_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_CLASS_RESOLUTION_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_CLASS_RESOLUTION_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_CLASS_RESOLUTION_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_CLASS_RESOLUTION Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EP_CLASS_RESOLUTIONm,
     EP_ECC_DEBUGr, EP_CLASS_RESOLUTION_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_CLASS_RESOLUTION_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_CLASS_RESOLUTION_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_CLASS_RESOLUTION_FORCE_UNCORRECTABLE_ERRORf, 
     EP_CLASS_RESOLUTION_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_CLASS_RESOLUTION Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EP_STATS_CTRLm, 
     EP_ECC_DEBUGr, EP_STATS_CTRL_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_STATS_CTRL_CORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_STATS_CTRL_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     EP_STATS_CTRL_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_STATS_CTRL Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EP_STATS_CTRLm,
     EP_ECC_DEBUGr, EP_STATS_CTRL_ENABLE_ECCf, 
     EP_ECC_ERRORr, EP_STATS_CTRL_UNCORRECTED_ERRORf,
     EP_ECC_ERROR_MASKr, EP_STATS_CTRL_UNCORRECTED_ERROR_DISINTf,
     EP_ECC_DEBUGr, EP_STATS_CTRL_FORCE_UNCORRECTABLE_ERRORf, 
     EP_STATS_CTRL_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "EP: EP_STATS_CTRL Uncorrected ECC error"
    },
};
STATIC _soc_error_info_t _soc_sirius_es_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FLOW_CONTROL_BASE_TABLEm, 
     ES_ECC_DEBUG0r, FC_BASE_ENABLE_ECCf, 
     ES_ECC_ERRORr, FC_BASE_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FC_BASE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS10r, ERROR_ADDRESSf,
     "ES: Flow control base table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FLOW_CONTROL_BASE_TABLEm, 
     ES_ECC_DEBUG0r, FC_BASE_ENABLE_ECCf, 
     ES_ECC_ERRORr, FC_BASE_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FC_BASE_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FC_BASE_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS10r, ERROR_ADDRESSf,
     "ES: Flow control base table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CHANNEL_SHAPER_TABLEm, 
     ES_ECC_DEBUG0r, CHN_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, CHN_SHAPER_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, CHN_SHAPER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS0r, ERROR_ADDRESSf,
     "ES: Channel shaper table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CHANNEL_SHAPER_TABLEm, 
     ES_ECC_DEBUG0r, CHN_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, CHN_SHAPER_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, CHN_SHAPER_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, CHN_SHAPER_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS0r, ERROR_ADDRESSf,
     "ES: Channel shaper table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SUBPORT_SHAPER_TABLEm, 
     ES_ECC_DEBUG0r, SPT_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, SPT_SHAPER_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, SPT_SHAPER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS1r, ERROR_ADDRESSf,
     "ES: Subport shaper table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SUBPORT_SHAPER_TABLEm, 
     ES_ECC_DEBUG0r, SPT_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, SPT_SHAPER_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, SPT_SHAPER_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, SPT_SHAPER_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS1r, ERROR_ADDRESSf,
     "ES: Subport shaper base table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FIFO_SHAPER_TABLE_3m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER3_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER3_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS5r, ERROR_ADDRESSf,
     "ES: Fifo shaper 3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FIFO_SHAPER_TABLE_3m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER3_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER3_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER3_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FIFO_SHAPER3_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS5r, ERROR_ADDRESSf,
     "ES: Fifo shaper 3 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FIFO_SHAPER_TABLE_2m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER2_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER2_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS4r, ERROR_ADDRESSf,
     "ES: Fifo shaper 2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FIFO_SHAPER_TABLE_2m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER2_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER2_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER2_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FIFO_SHAPER2_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS4r, ERROR_ADDRESSf,
     "ES: Fifo shaper 2 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FIFO_SHAPER_TABLE_1m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER1_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER1_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS3r, ERROR_ADDRESSf,
     "ES: Fifo shaper 1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FIFO_SHAPER_TABLE_1m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER1_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER1_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER1_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FIFO_SHAPER1_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS3r, ERROR_ADDRESSf,
     "ES: Fifo shaper 1 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FIFO_SHAPER_TABLE_0m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER0_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER0_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS2r, ERROR_ADDRESSf,
     "ES: Fifo shaper 0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FIFO_SHAPER_TABLE_0m, 
     ES_ECC_DEBUG0r, FIFO_SHAPER0_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_SHAPER0_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_SHAPER0_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FIFO_SHAPER0_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS2r, ERROR_ADDRESSf,
     "ES: Fifo shaper 0 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, GROUP_MEMBER_TABLEm, 
     ES_ECC_DEBUG0r, GROUP_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, GROUP_SHAPER_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, GROUP_SHAPER_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS6r, ERROR_ADDRESSf,
     "ES: Group member table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, GROUP_MEMBER_TABLEm, 
     ES_ECC_DEBUG0r, GROUP_SHAPER_ENABLE_ECCf, 
     ES_ECC_ERRORr, GROUP_SHAPER_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, GROUP_SHAPER_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, GROUP_SHAPER_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS6r, ERROR_ADDRESSf,
     "ES: Group member table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CHANNEL_WERR_TABLEm, 
     ES_ECC_DEBUG0r, CHN_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, CHN_WERR_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, CHN_WERR_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS7r, ERROR_ADDRESSf,
     "ES: Channel WERR table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CHANNEL_WERR_TABLEm, 
     ES_ECC_DEBUG0r, CHN_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, CHN_WERR_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, CHN_WERR_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, CHN_WERR_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS7r, ERROR_ADDRESSf,
     "ES: Channel WERR table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SUBPORT_WERR_TABLEm, 
     ES_ECC_DEBUG0r, SPT_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, SPT_WERR_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, SPT_WERR_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS8r, ERROR_ADDRESSf,
     "ES: Subport WERR table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SUBPORT_WERR_TABLEm, 
     ES_ECC_DEBUG0r, SPT_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, SPT_WERR_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, SPT_WERR_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, SPT_WERR_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS8r, ERROR_ADDRESSf,
     "ES: Subport WERR table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FIFO_WERR_TABLEm, 
     ES_ECC_DEBUG0r, FIFO_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_WERR_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_WERR_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS10r, ERROR_ADDRESSf,
     "ES: Fifo WERR table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FIFO_WERR_TABLEm, 
     ES_ECC_DEBUG0r, FIFO_WERR_ENABLE_ECCf, 
     ES_ECC_ERRORr, FIFO_WERR_UNCORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FIFO_WERR_UNCORRECTED_ERROR_DISINTf,
     ES_ECC_DEBUG1r, FIFO_WERR_FORCE_UNCORRECTABLE_ERRORf,
     ES_ECC_STATUS9r, ERROR_ADDRESSf,
     "ES: Fifo WERR table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FLOW_CONTROL_BASE_TABLEm, 
     ES_ECC_DEBUG0r, FC_BASE_ENABLE_ECCf, 
     ES_ECC_ERRORr, FC_BASE_CORRECTED_ERRORf,
     ES_ECC_ERROR_MASKr, FC_BASE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     ES_ECC_STATUS9r, ERROR_ADDRESSf,
     "ES: Flow control base table Corrected ECC error"
    },
};
STATIC _soc_error_info_t _soc_sirius_fd_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EG_FD_MDBm, 
     FD_ECC_DEBUGr, MDB_ENABLE_ECCf, 
     FD_ECC_ERRORr, MDB_B_CORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, MDB_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FD_MDB_B_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: MDB_B table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EG_FD_MDBm, 
     FD_ECC_DEBUGr, MDB_ENABLE_ECCf, 
     FD_ECC_ERRORr, MDB_B_UNCORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, MDB_B_UNCORRECTED_ERROR_DISINTf,
     FD_ECC_DEBUGr, MDB_FORCE_UNCORRECTABLE_ERRORf,
     FD_MDB_B_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: MDB_B table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EG_FD_MDBm, 
     FD_ECC_DEBUGr, MDB_ENABLE_ECCf, 
     FD_ECC_ERRORr, MDB_A_CORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, MDB_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FD_MDB_A_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: MDB_A table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EG_FD_MDBm, 
     FD_ECC_DEBUGr, MDB_ENABLE_ECCf, 
     FD_ECC_ERRORr, MDB_A_UNCORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, MDB_A_UNCORRECTED_ERROR_DISINTf,
     FD_ECC_DEBUGr, MDB_FORCE_UNCORRECTABLE_ERRORf,
     FD_MDB_A_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: MDB_A table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EG_FD_SVTm, 
     FD_ECC_DEBUGr, SVT_ENABLE_ECCf, 
     FD_ECC_ERRORr, SVT_CORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, SVT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FD_SVT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: SVT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EG_FD_SVTm, 
     FD_ECC_DEBUGr, SVT_ENABLE_ECCf, 
     FD_ECC_ERRORr, SVT_UNCORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, SVT_UNCORRECTED_ERROR_DISINTf,
     FD_ECC_DEBUGr, SVT_FORCE_UNCORRECTABLE_ERRORf,
     FD_SVT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: SVT table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EG_FD_FCTm, 
     FD_ECC_DEBUGr, FCT_ENABLE_ECCf, 
     FD_ECC_ERRORr, FCT_CORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, FCT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FD_FCT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: FCT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EG_FD_FCTm, 
     FD_ECC_DEBUGr, FCT_ENABLE_ECCf, 
     FD_ECC_ERRORr, FCT_UNCORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, FCT_UNCORRECTED_ERROR_DISINTf,
     FD_ECC_DEBUGr, FCT_FORCE_UNCORRECTABLE_ERRORf,
     FD_FCT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: FCT table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EG_FD_GMTm, 
     FD_ECC_DEBUGr, GMT_ENABLE_ECCf, 
     FD_ECC_ERRORr, GMT_CORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, GMT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FD_GMT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: GMT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EG_FD_GMTm, 
     FD_ECC_DEBUGr, GMT_ENABLE_ECCf, 
     FD_ECC_ERRORr, GMT_UNCORRECTED_ERRORf,
     FD_ECC_ERROR_MASKr, GMT_UNCORRECTED_ERROR_DISINTf,
     FD_ECC_DEBUGr, GMT_FORCE_UNCORRECTABLE_ERRORf,
     FD_GMT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "FD: GMT table Uncorrected ECC error"
    },    
};
STATIC _soc_error_info_t _soc_sirius_ff_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_FC_MEM_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_FC_MEM_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_FC_MEM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS12r, ERROR_ADDRESSf,
     "FF: Fifo cache Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_FC_MEM_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_FC_MEM_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_FC_MEM_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_FC_MEM_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS12r, ERROR_ADDRESSf,
     "FF: Fifo cache Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_CONTROL_MEM_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_CONTROL_MEM_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_CONTROL_MEM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS11r, ERROR_ADDRESSf,
     "FF: MVR pointer Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_CONTROL_MEM_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_CONTROL_MEM_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_CONTROL_MEM_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_CONTROL_MEM_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS11r, ERROR_ADDRESSf,
     "FF: MVR pointer Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE10_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE10_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE10_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS10r, ERROR_ADDRESSf,
     "FF: Deferral Queue10 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE10_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE10_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE10_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE10_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS10r, ERROR_ADDRESSf,
     "FF: Deferral Queue10 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE9_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE9_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE9_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS9r, ERROR_ADDRESSf,
     "FF: Deferral Queue9 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE9_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE9_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE9_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE9_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS9r, ERROR_ADDRESSf,
     "FF: Deferral Queue9 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE8_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE8_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE8_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS8r, ERROR_ADDRESSf,
     "FF: Deferral Queue8 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE8_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE8_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE8_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE8_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS8r, ERROR_ADDRESSf,
     "FF: Deferral Queue8 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE7_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE7_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE7_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS7r, ERROR_ADDRESSf,
     "FF: Deferral Queue7 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE7_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE7_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE7_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE7_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS7r, ERROR_ADDRESSf,
     "FF: Deferral Queue7 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE6_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE6_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE6_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS6r, ERROR_ADDRESSf,
     "FF: Deferral Queue6 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE6_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE6_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE6_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE6_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS6r, ERROR_ADDRESSf,
     "FF: Deferral Queue6 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE5_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE5_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE5_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS5r, ERROR_ADDRESSf,
     "FF: Deferral Queue5 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE5_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE5_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE5_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE5_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS5r, ERROR_ADDRESSf,
     "FF: Deferral Queue5 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE4_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE4_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE4_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS4r, ERROR_ADDRESSf,
     "FF: Deferral Queue4 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE4_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE4_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE4_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE4_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS4r, ERROR_ADDRESSf,
     "FF: Deferral Queue4 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE3_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE3_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS3r, ERROR_ADDRESSf,
     "FF: Deferral Queue3 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE3_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE3_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE3_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE3_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS3r, ERROR_ADDRESSf,
     "FF: Deferral Queue3 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE2_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE2_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS2r, ERROR_ADDRESSf,
     "FF: Deferral Queue2 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE2_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE2_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE2_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE2_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS2r, ERROR_ADDRESSf,
     "FF: Deferral Queue2 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE1_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE1_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS1r, ERROR_ADDRESSf,
     "FF: Deferral Queue1 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE1_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE1_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE1_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE1_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS1r, ERROR_ADDRESSf,
     "FF: Deferral Queue1 Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE0_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE0_CORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     FFM_ECC_STATUS0r, ERROR_ADDRESSf,
     "FF: Deferral Queue0 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FFM_ECC_DEBUG0r, FF_DEFERAL_QUEUE0_ENABLE_ECCf, 
     FFM_ECC_ERRORr, FF_DEFERAL_QUEUE0_UNCORRECTED_ERRORf,
     FFM_ECC_ERROR_MASKr, FF_DEFERAL_QUEUE0_UNCORRECTED_ERROR_DISINTf,
     FFM_ECC_DEBUG1r, FF_DEFERAL_QUEUE0_FORCE_UNCORRECTABLE_ERRORf, 
     FFM_ECC_STATUS0r, ERROR_ADDRESSf,
     "FF: Deferral Queue0 Uncorrected ECC error"
    },    
};
STATIC _soc_error_info_t _soc_sirius_fr_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_UPPER_B_CORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_UPPER_B_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_UPPER_B_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer upper B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_UPPER_B_UNCORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_UPPER_B_UNCORRECTED_ERROR_DINSTf,
     FR_ECC_DEBUGr, FR_SF_BUFFER_FORCE_UNCORRECTABLE_ERRORf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_UPPER_B_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer upper B Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_UPPER_A_CORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_UPPER_A_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_UPPER_A_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer upper A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_UPPER_A_UNCORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_UPPER_A_UNCORRECTED_ERROR_DINSTf,
     FR_ECC_DEBUGr, FR_SF_BUFFER_FORCE_UNCORRECTABLE_ERRORf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_UPPER_A_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer upper A Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_LOWER_B_CORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_LOWER_B_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_LOWER_B_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer lower B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_LOWER_B_UNCORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_LOWER_B_UNCORRECTED_ERROR_DINSTf,
     FR_ECC_DEBUGr, FR_SF_BUFFER_FORCE_UNCORRECTABLE_ERRORf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_LOWER_B_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer lower B Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_LOWER_A_CORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_LOWER_A_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_LOWER_A_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer lower a Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_SF_BUFFER_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_SF_BUFFER_LOWER_A_UNCORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_SF_BUFFER_LOWER_A_UNCORRECTED_ERROR_DINSTf,
     FR_ECC_DEBUGr, FR_SF_BUFFER_FORCE_UNCORRECTABLE_ERRORf,
     FR_ECC_STATUS0r, FR_SF_BUFFER_LOWER_A_ECC_ERROR_ADDRESSf,
     "FR: Store and Forward Buffer lower a Uncorrected ECC error"
    },    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_DMT_MEM_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_DMT_MEM_CORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_DMT_MEM_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     FR_ECC_STATUS1r, FR_DMT_MEM_ECC_ERROR_ADDRESSf,
     "FR: Domain Mapping Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     FR_ECC_DEBUGr, FR_DMT_MEM_ENABLE_ECCf, 
     FR_ECC_ERROR0r, FR_DMT_MEM_UNCORRECTED_ERRORf,
     FR_ECC_ERROR0_MASKr, FR_DMT_MEM_UNCORRECTED_ERROR_DINSTf,
     FR_ECC_DEBUGr, FR_DMT_MEM_FORCE_UNCORRECTABLE_ERRORf,
     FR_ECC_STATUS1r, FR_DMT_MEM_ECC_ERROR_ADDRESSf,
     "FR: Domain Mapping Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_otpc_error_info[] = {
    /* N/A */
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDr,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "N/A"
    }
};
STATIC _soc_error_info_t _soc_sirius_qma_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     QMA_ECC_DEBUG0r, RBENQR_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RBENQR_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RBENQR_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_RBENQR_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: RB Enqueue Request FIFO Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     QMA_ECC_DEBUG0r, RBENQR_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RBENQR_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RBENQR_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, RBENQR_FORCE_UNCORRECTABLE_ERRORf,
     QMA_RBENQR_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: RB Enqueue Request FIFO Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_C_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_C_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_RANDGEN_ECC_STATUSr, MEM_C_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition C Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_C_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_C_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, RANDGEN_C_FORCE_UNCORRECTABLE_ERRORf,
     QMA_RANDGEN_ECC_STATUSr, MEM_C_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition C Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_B_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_RANDGEN_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_B_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_B_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, RANDGEN_B_FORCE_UNCORRECTABLE_ERRORf,
     QMA_RANDGEN_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition B Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_A_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_RANDGEN_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, RANDGENm, 
     QMA_ECC_DEBUG0r, RANDGEN_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, RANDGEN_A_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, RANDGEN_A_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, RANDGEN_A_FORCE_UNCORRECTABLE_ERRORf,
     QMA_RANDGEN_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMA: Physical partition A Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, WRED_AVG_QUEUE_LENGTHm, 
     QMA_ECC_DEBUG0r, QAVG_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QAVG_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QAVG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_WRED_AVG_QUEUE_LENGTH_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: WRED_AVG_QUEUE_LENGTH database Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, WRED_AVG_QUEUE_LENGTHm, 
     QMA_ECC_DEBUG0r, QAVG_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QAVG_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QAVG_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, QAVG_FORCE_UNCORRECTABLE_ERRORf,
     QMA_WRED_AVG_QUEUE_LENGTH_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: WRED_AVG_QUEUE_LENGTH database Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, WRED_STATEm, 
     QMA_ECC_DEBUG0r, WREDSTATE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, WREDSTATE_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, WREDSTATE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_VOQ_WRED_STATE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: VOQ_WRED_STATE database Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, WRED_STATEm, 
     QMA_ECC_DEBUG0r, WREDSTATE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, WREDSTATE_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, WREDSTATE_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, WREDSTATE_FORCE_UNCORRECTABLE_ERRORf,
     QMA_VOQ_WRED_STATE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: VOQ_WRED_STATE database Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, WRED_CURVEm, 
     QMA_ECC_DEBUG0r, WREDCURVE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, WREDCURVE_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, WREDCURVE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_WREDCURVE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: WRED_CURVE Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, WRED_CURVEm, 
     QMA_ECC_DEBUG0r, WREDCURVE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, WREDCURVE_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, WREDCURVE_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, WREDCURVE_FORCE_UNCORRECTABLE_ERRORf,
     QMA_WREDCURVE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: WRED_CURVE Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, Q_MAX_BUFFSm, 
     QMA_ECC_DEBUG0r, MBUFFS_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, MBUFFS_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, MBUFFS_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_Q_MAX_BUFFS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: Q_MAX_BUFFS Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, Q_MAX_BUFFSm, 
     QMA_ECC_DEBUG0r, MBUFFS_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, MBUFFS_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, MBUFFS_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, MBUFFS_FORCE_UNCORRECTABLE_ERRORf,
     QMA_Q_MAX_BUFFS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: Q_MAX_BUFFS Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, Q_MIN_BUFFSm, 
     QMA_ECC_DEBUG0r, GBUFFS_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, GBUFFS_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, GBUFFS_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_Q_MIN_BUFFS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_BUFFS Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, Q_MIN_BUFFSm, 
     QMA_ECC_DEBUG0r, GBUFFS_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, GBUFFS_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, GBUFFS_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, GBUFFS_FORCE_UNCORRECTABLE_ERRORf,
     QMA_Q_MIN_BUFFS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_BUFFS Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QBUFFSPROFILEm, 
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QBUFFSPROFILE_B_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QBUFFSPROFILE_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_QBUFFSPROFILE_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_MAX_PROFILE B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QBUFFSPROFILEm, 
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QBUFFSPROFILE_B_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QBUFFSPROFILE_B_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_FORCE_UNCORRECTABLE_ERRORf,
     QMA_QBUFFSPROFILE_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_MAX_PROFILE Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QBUFFSPROFILEm, 
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QBUFFSPROFILE_A_CORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QBUFFSPROFILE_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMA_QBUFFSPROFILE_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_MAX_PROFILE Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QBUFFSPROFILEm, 
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_ENABLE_ECCf, 
     QMA_ECC_ERROR0r, QBUFFSPROFILE_A_UNCORRECTED_ERRORf,
     QMA_ECC_ERROR0_MASKr, QBUFFSPROFILE_A_UNCORRECTED_ERROR_DISINTf,
     QMA_ECC_DEBUG0r, QBUFFSPROFILE_FORCE_UNCORRECTABLE_ERRORf,
     QMA_QBUFFSPROFILE_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMA: Q_MIN_MAX_PROFILE Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_qmb_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_111_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_111_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_D_ECC_STATUSr, MEM_111_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 111 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_111_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_111_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_D_ECC_STATUSr, MEM_111_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 111 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_110_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_110_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_D_ECC_STATUSr, MEM_110_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 110 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_110_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_110_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_D_ECC_STATUSr, MEM_110_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 110 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_101_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_101_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_C_ECC_STATUSr, MEM_101_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 101 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_101_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_101_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_C_ECC_STATUSr, MEM_101_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 101 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_100_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_100_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_C_ECC_STATUSr, MEM_100_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 100 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_100_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_100_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_C_ECC_STATUSr, MEM_100_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 100 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_011_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_011_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_B_ECC_STATUSr, MEM_011_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 011 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_011_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_011_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_B_ECC_STATUSr, MEM_011_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 011 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_010_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_010_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_B_ECC_STATUSr, MEM_010_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 010 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_010_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_010_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_B_ECC_STATUSr, MEM_010_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 010 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_001_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_001_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_A_ECC_STATUSr, MEM_001_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 001 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_001_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_001_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_A_ECC_STATUSr, MEM_001_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 001 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_000_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_000_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_BUFFER_LIST_A_ECC_STATUSr, MEM_000_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 000 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_LISTm, 
     QMB_ECC_DEBUG0r, BUFFERLIST_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, BUFFERLIST_000_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, BUFFERLIST_000_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, BUFFERLIST_FORCE_UNCORRECTABLE_ERRORf,
     QMB_BUFFER_LIST_A_ECC_STATUSr, MEM_000_ECC_ERROR_ADDRESSf,
     "QMB: Bufferlist 000 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, LLA_TRANSm, 
     QMB_ECC_DEBUG0r, LLATRANS_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, LLATRANS_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, LLATRANS_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_LLA_TRANS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: LLA_TRANS Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, LLA_TRANSm, 
     QMB_ECC_DEBUG0r, LLATRANS_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, LLATRANSE_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, LLATRANSE_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, LLATRANS_FORCE_UNCORRECTABLE_ERRORf,
     QMB_LLA_TRANS_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: LLA_TRANS Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FLUSH_PENDINGm, 
     QMB_ECC_DEBUG0r, FLUSHPENDING_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, FLUSHPENDING_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, FLUSHPENDING_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_FLUSH_PENDING_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: FLUSH_PENDING Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FLUSH_PENDINGm, 
     QMB_ECC_DEBUG0r, FLUSHPENDING_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, FLUSHPENDING_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, FLUSHPENDING_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, FLUSHPENDING_FORCE_UNCORRECTABLE_ERRORf,
     QMB_FLUSH_PENDING_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: FLUSH_PENDING Uncorrected ECC error"
    },      

    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TAIL_LLAm, 
     QMB_ECC_DEBUG0r, TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, TAIL_LLA_B_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, TAIL_LLA_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_TAIL_LLA_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: TAIL_LLA part B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TAIL_LLAm, 
     QMB_ECC_DEBUG0r, TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, TAIL_LLA_B_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, TAIL_LLA_B_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, TAIL_LLA_FORCE_UNCORRECTABLE_ERRORf,
     QMB_TAIL_LLA_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: TAIL_LLA part B Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TAIL_LLAm, 
     QMB_ECC_DEBUG0r, TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, TAIL_LLA_A_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, TAIL_LLA_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_TAIL_LLA_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: TAIL_LLA part A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TAIL_LLAm, 
     QMB_ECC_DEBUG0r, TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, TAIL_LLA_A_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, TAIL_LLA_A_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, TAIL_LLA_FORCE_UNCORRECTABLE_ERRORf,
     QMB_TAIL_LLA_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: TAIL_LLA part A Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, HEAD_LLAm, 
     QMB_ECC_DEBUG0r, HEAD_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, HEAD_LLA_B_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, HEAD_LLA_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_HEAD_LLA_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: HEAD_LLA part B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, HEAD_LLAm, 
     QMB_ECC_DEBUG0r, HEAD_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, HEAD_LLA_B_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, HEAD_LLA_B_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, HEAD_LLA_FORCE_UNCORRECTABLE_ERRORf,
     QMB_HEAD_LLA_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: HEAD_LLA part B Uncorrected ECC error"
    },      

    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, HEAD_LLAm, 
     QMB_ECC_DEBUG0r, HEAD_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, HEAD_LLA_A_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, HEAD_LLA_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_HEAD_LLA_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: HEAD_LLA part A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, HEAD_LLAm, 
     QMB_ECC_DEBUG0r, HEAD_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, HEAD_LLA_A_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, HEAD_LLA_A_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, HEAD_LLA_FORCE_UNCORRECTABLE_ERRORf,
     QMB_HEAD_LLA_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: HEAD_LLA part A Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, ALLOCBUFFSCNT_B_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, ALLOCBUFFSCNT_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ALLOCBUFFSCNT_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: ALLOCBUFFSCNT part B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, ALLOCBUFFSCNT_B_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, ALLOCBUFFSCNT_B_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ALLOCBUFFSCNT_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMB: ALLOCBUFFSCNT part B Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, ALLOCBUFFSCNT_A_CORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, ALLOCBUFFSCNT_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ALLOCBUFFSCNT_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: ALLOCBUFFSCNT part A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR0r, ALLOCBUFFSCNT_A_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR0_MASKr, ALLOCBUFFSCNT_A_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ALLOCBUFFSCNT_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ALLOCBUFFSCNT_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMB: ALLOCBUFFSCNT part A Uncorrected ECC error"
    },      

    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, STATSCFGm, 
     QMB_ECC_DEBUG0r, STATSCFG_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, STATSCFG_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, STATSCFG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_STATSCFG_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: Statistics Config Database Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, STATSCFGm, 
     QMB_ECC_DEBUG0r, STATSCFG_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, STATSCFG_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, STATSCFG_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, STATSCFG_FORCE_UNCORRECTABLE_ERRORf,
     QMB_STATSCFG_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: Statistics Config Database Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SLQ_COUNTERm, 
     QMB_ECC_DEBUG0r, SLQ_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, SLQ_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, SLQ_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_SLQ_COUNTER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: SLQ counter Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SLQ_COUNTERm, 
     QMB_ECC_DEBUG0r, SLQ_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, SLQ_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, SLQ_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, SLQ_FORCE_UNCORRECTABLE_ERRORf,
     QMB_SLQ_COUNTER_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: SLQ counter Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TC_FREE_POOLm, 
     QMB_ECC_DEBUG0r, TC_FP_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, TC_FP_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, TC_FP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_TC_FP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: Tag Controller Free Pool Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TC_FREE_POOLm, 
     QMB_ECC_DEBUG0r, TC_FP_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, TC_FP_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, TC_FP_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, TC_FP_FORCE_UNCORRECTABLE_ERRORf,
     QMB_TC_FP_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: Tag Controller Free Pool Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     QMB_ECC_DEBUG0r, ENQD_FIFO_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ENQD_FIFO_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ENQD_FIFO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ENQD_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ENQD FIFO Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     QMB_ECC_DEBUG0r, ENQD_FIFO_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ENQD_FIFO_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ENQD_FIFO_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ENQD_FIFO_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ENQD_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ENQD FIFO Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     QMB_ECC_DEBUG0r, ENQR_FIFO_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ENQR_FIFO_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ENQR_FIFO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ENQR_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ENQR FIFO Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     QMB_ECC_DEBUG0r, ENQR_FIFO_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ENQR_FIFO_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ENQR_FIFO_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ENQR_FIFO_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ENQR_FIFO_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ENQR FIFO Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ECONTEXT_TAIL_LLAm, 
     QMB_ECC_DEBUG0r, ECONTEXT_TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_TAIL_LLA_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_TAIL_LLA_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ECONTEXT_TAIL_LLA_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ECONTEXT_TAIL_LLA database Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ECONTEXT_TAIL_LLAm, 
     QMB_ECC_DEBUG0r, ECONTEXT_TAIL_LLA_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_TAIL_LLA_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_TAIL_LLA_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ECONTEXT_TAIL_LLA_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ECONTEXT_TAIL_LLA_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ECONTEXT_TAIL_LLA database Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ECONTEXT_INFLIGHTBUFFCNTm, 
     QMB_ECC_DEBUG0r, ECONTEXT_INFLIGHTBUFFCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_INFLIGHTBUFFCNT_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_INFLIGHTBUFFCNT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ECONTEXT_INFLIGHTBUFFCNT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ECONTEXT_INFLIGHTBUFFCNT Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ECONTEXT_INFLIGHTBUFFCNTm, 
     QMB_ECC_DEBUG0r, ECONTEXT_INFLIGHTBUFFCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_INFLIGHTBUFFCNT_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_INFLIGHTBUFFCNT_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ECONTEXT_INFLIGHTBUFFCNT_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ECONTEXT_INFLIGHTBUFFCNT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB: ECONTEXT_INFLIGHTBUFFCNT Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ECONTEXT_ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ECONTEXT_ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_ALLOCBUFFSCNT_CORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_ALLOCBUFFSCNT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMB_ECONTEXT_ALLOCBUFFSCNT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB:  ECONTEXT_ALLOCBUFFSCNT Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ECONTEXT_ALLOCBUFFSCNTm, 
     QMB_ECC_DEBUG0r, ECONTEXT_ALLOCBUFFSCNT_ENABLE_ECCf, 
     QMB_ECC_ERROR1r, ECONTEXT_ALLOCBUFFSCNT_UNCORRECTED_ERRORf,
     QMB_ECC_ERROR1_MASKr, ECONTEXT_ALLOCBUFFSCNT_UNCORRECTED_ERROR_DISINTf,
     QMB_ECC_DEBUG0r, ECONTEXT_ALLOCBUFFSCNT_FORCE_UNCORRECTABLE_ERRORf,
     QMB_ECONTEXT_ALLOCBUFFSCNT_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMB:  ECONTEXT_ALLOCBUFFSCNT Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_qmc_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, RATE_DELTA_MAXm, 
     QMC_ECC_DEBUGr, RDELTA_ENABLE_ECCf, 
     QMC_ECC_ERRORr, RDELTA_CORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, RDELTA_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMC_RATE_DELTA_MAX_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: RATE_DELTA_MAX Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, RATE_DELTA_MAXm, 
     QMC_ECC_DEBUGr, RDELTA_ENABLE_ECCf, 
     QMC_ECC_ERRORr, RDELTA_UNCORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, RDELTA_UNCORRECTED_ERROR_DISINTf,
     QMC_ECC_DEBUGr, RDELTA_FORCE_UNCORRECTABLE_ERRORf,
     QMC_RATE_DELTA_MAX_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: RATE_DELTA_MAX Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BUFFER_AGEm, 
     QMC_ECC_DEBUGr, BUFFAGE_ENABLE_ECCf, 
     QMC_ECC_ERRORr, BUFFAGE_CORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, BUFFAGE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMC_BUFFER_AGE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: BUFFER_AGE Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BUFFER_AGEm, 
     QMC_ECC_DEBUGr, BUFFAGE_ENABLE_ECCf, 
     QMC_ECC_ERRORr, BUFFAGE_UNCORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, BUFFAGE_UNCORRECTED_ERROR_DISINTf,
     QMC_ECC_DEBUGr, BUFFAGE_FORCE_UNCORRECTABLE_ERRORf,
     QMC_BUFFER_AGE_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: BUFFER_AGE Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, VOQ_CONFIGm, 
     QMC_ECC_DEBUGr, VOQCONFIG_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQCONFIG_CORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQCONFIG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMC_VOQ_CONFIG_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: VOQ_CONFIG Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, VOQ_CONFIGm, 
     QMC_ECC_DEBUGr, VOQCONFIG_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQCONFIG_UNCORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQCONFIG_UNCORRECTED_ERROR_DISINTf,
     QMC_ECC_DEBUGr, VOQCONFIG_FORCE_UNCORRECTABLE_ERRORf,
     QMC_VOQ_CONFIG_ECC_STATUSr, ECC_ERROR_ADDRESSf,
     "QMC: VOQ_CONFIG Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, VOQ_ARRIVALSm, 
     QMC_ECC_DEBUGr, VOQARRIVALS_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQARRIVALS_B_CORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQARRIVALS_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMC_VOQ_ARRIVALS_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMC: VOQ_ARRIVALS part B Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, VOQ_ARRIVALSm, 
     QMC_ECC_DEBUGr, VOQARRIVALS_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQARRIVALS_B_UNCORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQARRIVALS_B_UNCORRECTED_ERROR_DISINTf,
     QMC_ECC_DEBUGr, VOQARRIVALS_FORCE_UNCORRECTABLE_ERRORf,
     QMC_VOQ_ARRIVALS_ECC_STATUSr, MEM_B_ECC_ERROR_ADDRESSf,
     "QMC: VOQ_ARRIVALS part B Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, VOQ_ARRIVALSm, 
     QMC_ECC_DEBUGr, VOQARRIVALS_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQARRIVALS_A_CORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQARRIVALS_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QMC_VOQ_ARRIVALS_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMC: VOQ_ARRIVALS part A Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, VOQ_ARRIVALSm, 
     QMC_ECC_DEBUGr, VOQARRIVALS_ENABLE_ECCf, 
     QMC_ECC_ERRORr, VOQARRIVALS_A_UNCORRECTED_ERRORf,
     QMC_ECC_ERROR_MASKr, VOQARRIVALS_A_UNCORRECTED_ERROR_DISINTf,
     QMC_ECC_DEBUGr, VOQARRIVALS_FORCE_UNCORRECTABLE_ERRORf,
     QMC_VOQ_ARRIVALS_ECC_STATUSr, MEM_A_ECC_ERROR_ADDRESSf,
     "QMC: VOQ_ARRIVALS part A Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_qsa_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CALENDARm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL1_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBCAL1_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBCAL1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_CALENDAR_ECC_STATUSr, DBCAL1_ECC_ERROR_ADDRESSf,
     "QSA: CALENDAR database 1 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CALENDARm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL1_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBCAL1_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBCAL1_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_CALENDAR_ECC_STATUSr, DBCAL1_ECC_ERROR_ADDRESSf,
     "QSA: CALENDAR database 1 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CALENDARm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL0_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBCAL0_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBCAL0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_CALENDAR_ECC_STATUSr, DBCAL0_ECC_ERROR_ADDRESSf,
     "QSA: CALENDAR database 0 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CALENDARm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL0_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBCAL0_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBCAL0_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBCAL0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_CALENDAR_ECC_STATUSr, DBCAL0_ECC_ERROR_ADDRESSf,
     "QSA: CALENDAR database 0 Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_TS_1_HIm,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH1_ENABLE_ECCf,
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEH1_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEH1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEH_ECC_STATUSr, DBAGEH1_ECC_ERROR_ADDRESSf,
     "QSA: AGER high 1 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_TS_1_HIm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH1_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEH1_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEH1_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEH_ECC_STATUSr, DBAGEH1_ECC_ERROR_ADDRESSf,
     "QSA: AGER high 1 Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_TS_0_HIm,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH0_ENABLE_ECCf,
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEH0_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEH0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEH_ECC_STATUSr, DBAGEH0_ECC_ERROR_ADDRESSf,
     "QSA: AGER high 0 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_TS_0_HIm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH0_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEH0_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEH0_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEH0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEH_ECC_STATUSr, DBAGEH0_ECC_ERROR_ADDRESSf,
     "QSA: AGER high 0 Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_TS_1_LOm,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL1_ENABLE_ECCf,
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEL1_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEL1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEL_ECC_STATUSr, DBAGEL1_ECC_ERROR_ADDRESSf,
     "QSA: AGER low 1 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_TS_1_LOm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL1_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEL1_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEL1_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEL_ECC_STATUSr, DBAGEL1_ECC_ERROR_ADDRESSf,
     "QSA: AGER low 1 Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_TS_0_LOm,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL0_ENABLE_ECCf,
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEL0_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEL0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEL_ECC_STATUSr, DBAGEL0_ECC_ERROR_ADDRESSf,
     "QSA: AGER low 0 Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_TS_0_LOm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL0_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEL0_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEL0_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEL0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEL_ECC_STATUSr, DBAGEL0_ECC_ERROR_ADDRESSf,
     "QSA: AGER low 0 Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_FLAGSm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEFLAGS_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEFLAGS_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEFLAGS_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEFLAGS_ECC_STATUSr, DBAGEFLAGS_ECC_ERROR_ADDRESSf,
     "QSA: AGER flags Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_FLAGSm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEFLAGS_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEFLAGS_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEFLAGS_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEFLAGS_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEFLAGS_ECC_STATUSr, DBAGEFLAGS_ECC_ERROR_ADDRESSf,
     "QSA: AGER flags Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_EVENTm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEEVENT_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEEVENT_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEEVENT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGEEVENT_ECC_STATUSr, DBAGEEVENT_ECC_ERROR_ADDRESSf,
     "QSA: AGER event Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_EVENTm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEEVENT_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGEEVENT_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGEEVENT_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGEEVENT_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGEEVENT_ECC_STATUSr, DBAGEEVENT_ECC_ERROR_ADDRESSf,
     "QSA: AGER event Uncorrected ECC error"
    },   
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, AGER_THRESHOLDm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGETHRESH_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGETHRESH_CORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGETHRESH_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_AGETHRESH_ECC_STATUSr, DBAGETHRESH_ECC_ERROR_ADDRESSf,
     "QSA: AGER thresh Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, AGER_THRESHOLDm, 
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGETHRESH_ENABLE_ECCf, 
     QSA_CALENDAR_AGER_ECC_ERRORr, DBAGETHRESH_UNCORRECTED_ERRORf,
     QSA_CALENDAR_AGER_ECC_ERROR_MASKr, DBAGETHRESH_UNCORRECTED_ERROR_DISINTf,
     QSA_CALENDAR_AGER_ECC_DEBUGr, DBAGETHRESH_FORCE_UNCORRECTABLE_ERRORf,
     QSA_AGETHRESH_ECC_STATUSr, DBAGETHRESH_ECC_ERROR_ADDRESSf,
     "QSA: AGER thresh Uncorrected ECC error"
    },   
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, ESET_TO_NODE_TYPEm, 
     QSA_QPP_ECC_DEBUGr, DBE2NT_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBE2NT_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBE2NT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_E2NT_ECC_STATUSr, DBE2NT_ECC_ERROR_ADDRESSf,
     "QSA: Eset to node type table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, ESET_TO_NODE_TYPEm, 
     QSA_QPP_ECC_DEBUGr, DBE2NT_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBE2NT_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBE2NT_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBE2NT_FORCE_UNCORRECTABLE_ERRORf,
     QSA_E2NT_ECC_STATUSr, DBE2NT_ECC_ERROR_ADDRESSf,
     "QSA: Eset to node type table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QDEPTH_THRESH1m, 
     QSA_QPP_ECC_DEBUGr, DBQTHRESH1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQTHRESH1_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQTHRESH1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QTHRESH_ECC_STATUSr, DBQTHRESH1_ECC_ERROR_ADDRESSf,
     "QSA: Queue depth threshold 1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QDEPTH_THRESH1m, 
     QSA_QPP_ECC_DEBUGr, DBQTHRESH1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQTHRESH1_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQTHRESH1_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQTHRESH1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QTHRESH_ECC_STATUSr, DBQTHRESH1_ECC_ERROR_ADDRESSf,
     "QSA: Queue depth threshold 1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QDEPTH_THRESH0m, 
     QSA_QPP_ECC_DEBUGr, DBQTHRESH0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQTHRESH0_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQTHRESH0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QTHRESH_ECC_STATUSr, DBQTHRESH0_ECC_ERROR_ADDRESSf,
     "QSA: Queue depth threshold 0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QDEPTH_THRESH0m, 
     QSA_QPP_ECC_DEBUGr, DBQTHRESH0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQTHRESH0_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQTHRESH0_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQTHRESH0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QTHRESH_ECC_STATUSr, DBQTHRESH0_ECC_ERROR_ADDRESSf,
     "QSA: Queue depth threshold 0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TIMESLOT_BURST_SIZE_BYTESm, 
     QSA_QPP_ECC_DEBUGr, DBTSBSB_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBTSBSB_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBTSBSB_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_TSTB_ECC_STATUSr, DBTSBSB_ECC_ERROR_ADDRESSf,
     "QSA: TIMESLOT_BURST_SIZE_BYTES table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TIMESLOT_BURST_SIZE_BYTESm, 
     QSA_QPP_ECC_DEBUGr, DBTSBSB_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBTSBSB_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBTSBSB_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBTSBSB_FORCE_UNCORRECTABLE_ERRORf,
     QSA_TSTB_ECC_STATUSr, DBTSBSB_ECC_ERROR_ADDRESSf,
     "QSA: TIMESLOT_BURST_SIZE_BYTES table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BURST_SIZE_PER_ESETm, 
     QSA_QPP_ECC_DEBUGr, DBBSE_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBBSE_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBBSE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_BSE_ECC_STATUSr, DBBSE_ECC_ERROR_ADDRESSf,
     "QSA: BURST_SIZE_PER_ESET table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BURST_SIZE_PER_ESETm, 
     QSA_QPP_ECC_DEBUGr, DBBSE_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBBSE_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBBSE_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBBSE_FORCE_UNCORRECTABLE_ERRORf,
     QSA_BSE_ECC_STATUSr, DBBSE_ECC_ERROR_ADDRESSf,
     "QSA: BURST_SIZE_PER_ESET table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BURST_SIZE_PER_NODEm, 
     QSA_QPP_ECC_DEBUGr, DBBSN_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBBSN_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBBSN_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_BSN_ECC_STATUSr, DBBSN_ECC_ERROR_ADDRESSf,
     "QSA: BURST_SIZE_PER_NODE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BURST_SIZE_PER_NODEm, 
     QSA_QPP_ECC_DEBUGr, DBBSN_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBBSN_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBBSN_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBBSN_FORCE_UNCORRECTABLE_ERRORf,
     QSA_BSN_ECC_STATUSr, DBBSN_ECC_ERROR_ADDRESSf,
     "QSA: BURST_SIZE_PER_NODE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SYSPORT_TO_NODEm, 
     QSA_QPP_ECC_DEBUGr, DBS2N_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBS2N_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBS2N_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_S2N_ECC_STATUSr, DBS2N_ECC_ERROR_ADDRESSf,
     "QSA: SYSPORT_TO_NODE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SYSPORT_TO_NODEm, 
     QSA_QPP_ECC_DEBUGr, DBS2N_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBS2N_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBS2N_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBS2N_FORCE_UNCORRECTABLE_ERRORf,
     QSA_S2N_ECC_STATUSr, DBS2N_ECC_ERROR_ADDRESSf,
     "QSA: SYSPORT_TO_NODE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_TO_SC_3m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC3_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC3_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_Q2SC1_ECC_STATUSr, DBQ2SC3_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_TO_SC_3m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC3_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC3_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC3_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQ2SC3_FORCE_UNCORRECTABLE_ERRORf,
     QSA_Q2SC1_ECC_STATUSr, DBQ2SC3_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_3 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_TO_SC_2m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC2_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC2_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_Q2SC1_ECC_STATUSr, DBQ2SC2_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_TO_SC_2m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC2_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC2_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC2_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQ2SC2_FORCE_UNCORRECTABLE_ERRORf,
     QSA_Q2SC1_ECC_STATUSr, DBQ2SC2_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_2 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_TO_SC_1m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC1_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_Q2SC0_ECC_STATUSr, DBQ2SC1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_TO_SC_1m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC1_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC1_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQ2SC1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_Q2SC0_ECC_STATUSr, DBQ2SC1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_TO_SC_0m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC0_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_Q2SC0_ECC_STATUSr, DBQ2SC0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_TO_SC_0m, 
     QSA_QPP_ECC_DEBUGr, DBQ2SC0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQ2SC0_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQ2SC0_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQ2SC0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_Q2SC0_ECC_STATUSr, DBQ2SC0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_TO_SC_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_STATE_HIm, 
     QSA_QPP_ECC_DEBUGr, DBQSTATE1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQSTATE1_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQSTATE1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QSTATE_ECC_STATUSr, DBQSTATE1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_STATE_HI table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_STATE_HIm, 
     QSA_QPP_ECC_DEBUGr, DBQSTATE1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQSTATE1_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQSTATE1_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQSTATE1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QSTATE_ECC_STATUSr, DBQSTATE1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_STATE_HI table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_STATE_LOm, 
     QSA_QPP_ECC_DEBUGr, DBQSTATE0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQSTATE0_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQSTATE0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QSTATE_ECC_STATUSr, DBQSTATE0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_STATE_LO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_STATE_LOm, 
     QSA_QPP_ECC_DEBUGr, DBQSTATE0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQSTATE0_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQSTATE0_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQSTATE0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QSTATE_ECC_STATUSr, DBQSTATE0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_STATE_LO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_PARAMETER_HIm, 
     QSA_QPP_ECC_DEBUGr, DBQPARAMS1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQPARAMS1_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQPARAMS1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QPARAMS_ECC_STATUSr, DBQPARAMS1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_PARAMETER_HI table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_PARAMETER_HIm, 
     QSA_QPP_ECC_DEBUGr, DBQPARAMS1_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQPARAMS1_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQPARAMS1_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQPARAMS1_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QPARAMS_ECC_STATUSr, DBQPARAMS1_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_PARAMETER_HI table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_PARAMETER_LOm, 
     QSA_QPP_ECC_DEBUGr, DBQPARAMS0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQPARAMS0_CORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQPARAMS0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSA_QPARAMS_ECC_STATUSr, DBQPARAMS0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_PARAMETER_LO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_PARAMETER_LOm, 
     QSA_QPP_ECC_DEBUGr, DBQPARAMS0_ENABLE_ECCf, 
     QSA_QPP_ECC_ERRORr, DBQPARAMS0_UNCORRECTED_ERRORf,
     QSA_QPP_ECC_ERROR_MASKr, DBQPARAMS0_UNCORRECTED_ERROR_DISINTf,
     QSA_QPP_ECC_DEBUGr, DBQPARAMS0_FORCE_UNCORRECTABLE_ERRORf,
     QSA_QPARAMS_ECC_STATUSr, DBQPARAMS0_ECC_ERROR_ADDRESSf,
     "QSA: QUEUE_PARAMETER_LO table Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_qsb_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, PUPFIFO_HIm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_HI_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPUPFIFO_HI_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPUPFIFO_HI_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_PUP1_ECC_STATUSr, DBPUPFIFO_HI_ECC_ERROR_ADDRESSf,
     "QSB: PUPFIFO_HI table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, PUPFIFO_HIm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_HI_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPUPFIFO_HI_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPUPFIFO_HI_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_HI_FORCE_UNCORRECTABLE_ERRORf,
     QSB_PUP1_ECC_STATUSr, DBPUPFIFO_HI_ECC_ERROR_ADDRESSf,
     "QSB: PUPFIFO_HI table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, PUPFIFO_LOm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_LO_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPUPFIFO_LO_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPUPFIFO_LO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_PUP1_ECC_STATUSr, DBPUPFIFO_LO_ECC_ERROR_ADDRESSf,
     "QSB: PUPFIFO_LO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, PUPFIFO_LOm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_LO_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPUPFIFO_LO_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPUPFIFO_LO_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPUPFIFO_LO_FORCE_UNCORRECTABLE_ERRORf,
     QSB_PUP1_ECC_STATUSr, DBPUPFIFO_LO_ECC_ERROR_ADDRESSf,
     "QSB: PUPFIFO_LO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, LEAFNODE_TO_QUEUEm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLN2Q_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBLN2Q_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBLN2Q_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_GGP_ECC_STATUSr, DBLN2Q_ECC_ERROR_ADDRESSf,
     "QSB: LEAFNODE_TO_QUEUE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, LEAFNODE_TO_QUEUEm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLN2Q_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBLN2Q_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBLN2Q_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLN2Q_FORCE_UNCORRECTABLE_ERRORf,
     QSB_GGP_ECC_STATUSr, DBLN2Q_ECC_ERROR_ADDRESSf,
     "QSB: LEAFNODE_TO_QUEUE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SYSPORT_TO_QUEUEm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBS2Q_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBS2Q_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBS2Q_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_GGP_ECC_STATUSr, DBS2Q_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_TO_QUEUE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SYSPORT_TO_QUEUEm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBS2Q_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBS2Q_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBS2Q_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBS2Q_FORCE_UNCORRECTABLE_ERRORf,
     QSB_GGP_ECC_STATUSr, DBS2Q_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_TO_QUEUE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, LAST_SENTm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLASTSENT_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBLASTSENT_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBLASTSENT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_PUP0_ECC_STATUSr, DBLASTSENT_ECC_ERROR_ADDRESSf,
     "QSB: LAST_SENT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, LAST_SENTm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLASTSENT_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBLASTSENT_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBLASTSENT_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBLASTSENT_FORCE_UNCORRECTABLE_ERRORf,
     QSB_PUP0_ECC_STATUSr, DBLASTSENT_ECC_ERROR_ADDRESSf,
     "QSB: LAST_SENT table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SYSPORT_PRI_HIm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPH_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBSPPH_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBSPPH_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SPP_ECC_STATUSr, DBSPPH_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_PRI_HI table Corrected ECC error"
    },
    
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SYSPORT_PRI_HIm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPH_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBSPPH_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBSPPH_UNCORRECTED_ERRORf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPH_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SPP_ECC_STATUSr, DBSPPH_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_PRI_HI table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SYSPORT_PRI_LOm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPL_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBSPPL_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBSPPL_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SPP_ECC_STATUSr, DBSPPL_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_PRI_LO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SYSPORT_PRI_LOm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPL_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBSPPL_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBSPPL_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBSPPL_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SPP_ECC_STATUSr, DBSPPL_ECC_ERROR_ADDRESSf,
     "QSB: SYSPORT_PRI_LO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, PRI_LUTm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPLUT_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPLUT_CORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPLUT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_PLUT_ECC_STATUSr, DBPLUT_ECC_ERROR_ADDRESSf,
     "QSB: PRI_LUT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, PRI_LUTm, 
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPLUT_ENABLE_ECCf, 
     QSB_SPP_GGP_PUP_ECC_ERRORr, DBPLUT_UNCORRECTED_ERRORf,
     QSB_SPP_GGP_PUP_ECC_ERROR_MASKr, DBPLUT_UNCORRECTED_ERROR_DISINTf,
     QSB_SPP_PUP_GGP_ECC_DEBUGr, DBPLUT_FORCE_UNCORRECTABLE_ERRORf,
     QSB_PLUT_ECC_STATUSr, DBPLUT_ECC_ERROR_ADDRESSf,
     "QSB: PRI_LUT table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_STATE_STARVINGm, 
     QSB_BAA_ECC_DEBUGr, DBBAASTATESTARVING_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAASTATESTARVING_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAASTATESTARVING_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA0_ECC_STATUSr, DBBAASTATESTARVING_ECC_ERROR_ADDRESSf,
     "QSB: BAA_STATE_STARVING table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_STATE_STARVINGm, 
     QSB_BAA_ECC_DEBUGr, DBBAASTATESTARVING_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAASTATESTARVING_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAASTATESTARVING_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAASTATESTARVING_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA0_ECC_STATUSr, DBBAASTATESTARVING_ECC_ERROR_ADDRESSf,
     "QSB: BAA_STATE_STARVING table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_STATE_HUNGRYm, 
     QSB_BAA_ECC_DEBUGr, DBBAASTATEHUNGRY_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAASTATEHUNGRY_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAASTATEHUNGRY_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA0_ECC_STATUSr, DBBAASTATEHUNGRY_ECC_ERROR_ADDRESSf,
     "QSB: BAA_STATE_HUNGRY table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_STATE_HUNGRYm, 
     QSB_BAA_ECC_DEBUGr, DBBAASTATEHUNGRY_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAASTATEHUNGRY_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAASTATEHUNGRY_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAASTATEHUNGRY_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA0_ECC_STATUSr, DBBAASTATEHUNGRY_ECC_ERROR_ADDRESSf,
     "QSB: BAA_STATE_HUNGRY table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_EVENTm, 
     QSB_BAA_ECC_DEBUGr, DBBAAEVENT_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAAEVENT_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAAEVENT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA0_ECC_STATUSr, DBBAAEVENT_ECC_ERROR_ADDRESSf,
     "QSB: BAA_EVENT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_EVENTm, 
     QSB_BAA_ECC_DEBUGr, DBBAAEVENT_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAAEVENT_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAAEVENT_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAAEVENT_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA0_ECC_STATUSr, DBBAAEVENT_ECC_ERROR_ADDRESSf,
     "QSB: BAA_EVENT table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_BUCKET_3m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED3_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA1_ECC_STATUSr, DBBAACRED3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_BUCKET_3m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED3_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED3_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAACRED3_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA1_ECC_STATUSr, DBBAACRED3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_3 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_BUCKET_2m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED2_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA1_ECC_STATUSr, DBBAACRED2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_BUCKET_2m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED2_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED2_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAACRED2_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA1_ECC_STATUSr, DBBAACRED2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_2 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_BUCKET_1m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED1_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA2_ECC_STATUSr, DBBAACRED1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_BUCKET_1m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED1_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED1_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAACRED1_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA2_ECC_STATUSr, DBBAACRED1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_BUCKET_0m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED0_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA2_ECC_STATUSr, DBBAACRED0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_BUCKET_0m, 
     QSB_BAA_ECC_DEBUGr, DBBAACRED0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAACRED0_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAACRED0_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAACRED0_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA2_ECC_STATUSr, DBBAACRED0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_BUCKET_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_B3m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB3_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA3_ECC_STATUSr, DBBAALEAKB3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_B3m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB3_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB3_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB3_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA3_ECC_STATUSr, DBBAALEAKB3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B3 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_B2m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB2_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA3_ECC_STATUSr, DBBAALEAKB2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_B2m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB2_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB2_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB2_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA3_ECC_STATUSr, DBBAALEAKB2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B2 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_B1m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB1_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA4_ECC_STATUSr, DBBAALEAKB1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_B1m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB1_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB1_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB1_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA4_ECC_STATUSr, DBBAALEAKB1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B1 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_B0m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB0_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA4_ECC_STATUSr, DBBAALEAKB0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_B0m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKB0_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKB0_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKB0_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA4_ECC_STATUSr, DBBAALEAKB0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_B0 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_A3m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA3_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA5_ECC_STATUSr, DBBAALEAKA3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_A3m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA3_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA3_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA3_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA3_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA5_ECC_STATUSr, DBBAALEAKA3_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A3 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_A2m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA2_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA5_ECC_STATUSr, DBBAALEAKA2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_A2m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA2_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA2_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA2_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA2_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA5_ECC_STATUSr, DBBAALEAKA2_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A2 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_A1m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA1_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA6_ECC_STATUSr, DBBAALEAKA1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_A1m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA1_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA1_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA1_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA1_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA6_ECC_STATUSr, DBBAALEAKA1_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A1 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, BAA_LEAK_A0m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA0_CORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_BAA6_ECC_STATUSr, DBBAALEAKA0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, BAA_LEAK_A0m, 
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA0_ENABLE_ECCf, 
     QSB_BAA_ECC_ERRORr, DBBAALEAKA0_UNCORRECTED_ERRORf,
     QSB_BAA_ECC_ERROR_MASKr, DBBAALEAKA0_UNCORRECTED_ERROR_DISINTf,
     QSB_BAA_ECC_DEBUGr, DBBAALEAKA0_FORCE_UNCORRECTABLE_ERRORf,
     QSB_BAA6_ECC_STATUSr, DBBAALEAKA0_ECC_ERROR_ADDRESSf,
     "QSB: BAA_LEAK_A0 table Uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_STATEm, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERSTATE_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERSTATE_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERSTATE_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER0_ECC_STATUSr, DBSHAPERSTATE_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_STATE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_STATEm, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERSTATE_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERSTATE_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERSTATE_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERSTATE_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER0_ECC_STATUSr, DBSHAPERSTATE_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_STATE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_EVENTm, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPEREVENT_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPEREVENT_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPEREVENT_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER0_ECC_STATUSr, DBSHAPEREVENT_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_EVENT table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_EVENTm, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPEREVENT_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPEREVENT_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPEREVENT_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPEREVENT_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER0_ECC_STATUSr, DBSHAPEREVENT_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_EVENT table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_BUCKET_3m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED3_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED3_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER1_ECC_STATUSr, DBSHAPERCRED3_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_BUCKET_3m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED3_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED3_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED3_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED3_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER1_ECC_STATUSr, DBSHAPERCRED3_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_3 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_BUCKET_2m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED2_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED2_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER1_ECC_STATUSr, DBSHAPERCRED2_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_BUCKET_2m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED2_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED2_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED2_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED2_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER1_ECC_STATUSr, DBSHAPERCRED2_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_2 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_BUCKET_1m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED1_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED1_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER2_ECC_STATUSr, DBSHAPERCRED1_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_BUCKET_1m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED1_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED1_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED1_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED1_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER2_ECC_STATUSr, DBSHAPERCRED1_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_BUCKET_0m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED0_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED0_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER2_ECC_STATUSr, DBSHAPERCRED0_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_BUCKET_0m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED0_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERCRED0_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERCRED0_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERCRED0_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER2_ECC_STATUSr, DBSHAPERCRED0_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_BUCKET_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_LEAK_3m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK3_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK3_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK3_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER3_ECC_STATUSr, DBSHAPERLEAK3_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_3 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_LEAK_3m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK3_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK3_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK3_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK3_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER3_ECC_STATUSr, DBSHAPERLEAK3_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_3 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_LEAK_2m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK2_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK2_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER3_ECC_STATUSr, DBSHAPERLEAK2_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_2 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_LEAK_2m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK2_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK2_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK2_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK2_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER3_ECC_STATUSr, DBSHAPERLEAK2_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_2 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_LEAK_1m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK1_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK1_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER4_ECC_STATUSr, DBSHAPERLEAK1_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_LEAK_1m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK1_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK1_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK1_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK1_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER4_ECC_STATUSr, DBSHAPERLEAK1_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, SHAPER_LEAK_0m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK0_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK0_CORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     QSB_SHAPER4_ECC_STATUSr, DBSHAPERLEAK0_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, SHAPER_LEAK_0m, 
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK0_ENABLE_ECCf, 
     QSB_SHAPER_ECC_ERRORr, DBSHAPERLEAK0_UNCORRECTED_ERRORf,
     QSB_SHAPER_ECC_ERROR_MASKr, DBSHAPERLEAK0_UNCORRECTED_ERROR_DISINTf,
     QSB_SHAPER_ECC_DEBUGr, DBSHAPERLEAK0_FORCE_UNCORRECTABLE_ERRORf,
     QSB_SHAPER4_ECC_STATUSr, DBSHAPERLEAK0_ECC_ERROR_ADDRESSf,
     "QSB: SHAPER_LEAK_0 table Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_rb_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, EDCLOOKUP_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, EDCLOOKUP_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS6r, EDCLOOKUP_ECC_ERROR_ADDRESS_Bf,
     "RB: EDC_LOOKUP table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, EDCLOOKUP_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, EDCLOOKUP_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, EDCLOOKUP_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS6r, EDCLOOKUP_ECC_ERROR_ADDRESS_Bf,
     "RB: EDC_LOOKUP table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, EDCLOOKUP_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, EDCLOOKUP_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS6r, EDCLOOKUP_ECC_ERROR_ADDRESS_Af,
     "RB: EDC_LOOKUP table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, EDCLOOKUP_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, EDCLOOKUP_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, EDCLOOKUP_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS6r, EDCLOOKUP_ECC_ERROR_ADDRESS_Af,
     "RB: EDC_LOOKUP table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_ERESPFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQRESPFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQRESPFIFO_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQRESPFIFO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS6r, IDP1_ENQRESPFIFO_ECC_ERROR_ADDRESSf,
     "RB: IDP1_ERESPFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_ERESPFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQRESPFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQRESPFIFO_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQRESPFIFO_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_ENQRESPFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS6r, IDP1_ENQRESPFIFO_ECC_ERROR_ADDRESSf,
     "RB: IDP1_ERESPFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_ERESPFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQRESPFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQRESPFIFO_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQRESPFIFO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS6r, IDP0_ENQRESPFIFO_ECC_ERROR_ADDRESSf,
     "RB: IDP0_ERESPFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_ERESPFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQRESPFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQRESPFIFO_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQRESPFIFO_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_ENQRESPFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS6r, IDP0_ENQRESPFIFO_ECC_ERROR_ADDRESSf,
     "RB: IDP0_ERESPFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQREQFIFO_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQREQFIFO_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS4r, IDP1_ENQREQFIFO_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_EREQFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQREQFIFO_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQREQFIFO_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS4r, IDP1_ENQREQFIFO_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_EREQFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQREQFIFO_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQREQFIFO_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS4r, IDP1_ENQREQFIFO_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_EREQFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_ENQREQFIFO_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_ENQREQFIFO_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_ENQREQFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS4r, IDP1_ENQREQFIFO_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_EREQFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQREQFIFO_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQREQFIFO_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS5r, IDP0_ENQREQFIFO_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_EREQFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQREQFIFO_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQREQFIFO_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS5r, IDP0_ENQREQFIFO_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_EREQFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQREQFIFO_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQREQFIFO_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS5r, IDP0_ENQREQFIFO_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_EREQFIFO table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_EREQFIFOm, 
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_ENQREQFIFO_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_ENQREQFIFO_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_ENQREQFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS5r, IDP0_ENQREQFIFO_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_EREQFIFO table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP1_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO1_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO1_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS3r, IDP1_DFIFO1_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_DFIFO_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP1_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO1_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO1_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_DFIFO1_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS3r, IDP1_DFIFO1_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_DFIFO_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP1_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO1_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO1_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS3r, IDP1_DFIFO1_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_DFIFO_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP1_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO1_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO1_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_DFIFO1_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS3r, IDP1_DFIFO1_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_DFIFO_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP1_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO0_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO0_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS2r, IDP1_DFIFO0_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_DFIFO_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP1_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO0_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO0_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_DFIFO0_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS2r, IDP1_DFIFO0_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP1_DFIFO_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP1_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP1_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO0_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO0_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS2r, IDP1_DFIFO0_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_DFIFO_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP1_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP1_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP1_DFIFO0_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP1_DFIFO0_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP1_DFIFO0_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS2r, IDP1_DFIFO0_ECC_ERROR_ADDRESS_Af,
     "RB: IDP1_DFIFO_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP0_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO1_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO1_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS1r, IDP0_DFIFO1_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_DFIFO_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP0_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO1_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO1_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_DFIFO1_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS1r, IDP0_DFIFO1_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_DFIFO_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP0_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO1_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO1_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS1r, IDP0_DFIFO1_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_DFIFO_1 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_DFIFO_1m, 
     RB_ECC_DEBUGr, IDP0_DFIFO1_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO1_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO1_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_DFIFO1_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS1r, IDP0_DFIFO1_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_DFIFO_1 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP0_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO0_B_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO0_B_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS0r, IDP0_DFIFO0_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_DFIFO_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP0_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO0_B_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO0_B_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_DFIFO0_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS0r, IDP0_DFIFO0_ECC_ERROR_ADDRESS_Bf,
     "RB: IDP0_DFIFO_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, IDP0_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP0_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO0_A_CORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO0_A_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS0r, IDP0_DFIFO0_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_DFIFO_0 table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, IDP0_DFIFO_0m, 
     RB_ECC_DEBUGr, IDP0_DFIFO0_ENABLE_ECCf, 
     RB_ECC_ERROR_0r, IDP0_DFIFO0_A_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_0_MASKr, IDP0_DFIFO0_A_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, IDP0_DFIFO0_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS0r, IDP0_DFIFO0_ECC_ERROR_ADDRESS_Af,
     "RB: IDP0_DFIFO_0 table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, FRAME_PARSINGm, 
     RB_ECC_DEBUGr, RECORDLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, RECORDLOOKUP_CORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, RECORDLOOKUP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS2r, RECORDLOOKUP_ECC_ERROR_ADDRESSf,
     "RB: FRAME_PARSING table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, FRAME_PARSINGm, 
     RB_ECC_DEBUGr, RECORDLOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, RECORDLOOKUP_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, RECORDLOOKUP_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, RECORDLOOKUP_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS2r, RECORDLOOKUP_ECC_ERROR_ADDRESSf,
     "RB: FRAME_PARSING table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TYPE_RESOLUTION_TABLEm, 
     RB_ECC_DEBUGr, TYPELOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, TYPELOOKUP_CORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, TYPELOOKUP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS0r, TYPELOOKUP_ECC_ERROR_ADDRESSf,
     "RB: TYPE_RESOLUTION_TABLE table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TYPE_RESOLUTION_TABLEm, 
     RB_ECC_DEBUGr, TYPELOOKUP_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, TYPELOOKUP_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, TYPELOOKUP_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, TYPELOOKUP_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS0r, TYPELOOKUP_ECC_ERROR_ADDRESSf,
     "RB: TYPE_RESOLUTION_TABLE table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCRTNFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, EDCRTNFIFO_CORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, EDCRTNFIFO_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS4r, EDCRTNFIFO_ECC_ERROR_ADDRESSf,
     "RB: EDC TAG return fifo table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, EDC_LOOKUPm, 
     RB_ECC_DEBUGr, EDCRTNFIFO_ENABLE_ECCf, 
     RB_ECC_ERROR_1r, EDCRTNFIFO_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, EDCRTNFIFO_UNCORRECTED_ERROR_DISINTf,
     RB_ECC_DEBUGr, EDCRTNFIFO_FORCE_UNCORRECTABLE_ERRORf,
     RB_ECC_STATUS4r, EDCRTNFIFO_ECC_ERROR_ADDRESSf,
     "RB: EDC TAG return fifo table Uncorrected ECC error"
    },
    
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_MAPm, 
     INVALIDr, INVALIDf,
     RB_ECC_ERROR_1r, QMAP1_CORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, QMAP1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS7r, QMAP1_ECC_ERROR_ADDRESSf,
     "RB: QUEUE_MAP table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_MAPm, 
     INVALIDr, INVALIDf,
     RB_ECC_ERROR_1r, QMAP1_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, QMAP1_UNCORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS7r, QMAP1_ECC_ERROR_ADDRESSf,
     "RB: QUEUE_MAP table Uncorrected ECC error"
    },      
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, QUEUE_MAPm, 
     INVALIDr, INVALIDf,
     RB_ECC_ERROR_1r, QMAP0_CORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, QMAP0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS7r, QMAP0_ECC_ERROR_ADDRESSf,
     "RB: QUEUE_MAP table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, QUEUE_MAPm, 
     INVALIDr, INVALIDf,
     RB_ECC_ERROR_1r, QMAP0_UNCORRECTED_ERRORf,
     RB_ECC_ERROR_1_MASKr, QMAP0_UNCORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     RB_ECC_STATUS7r, QMAP0_ECC_ERROR_ADDRESSf,
     "RB: QUEUE_MAP table Uncorrected ECC error"
    },      
};
STATIC _soc_error_info_t _soc_sirius_sc_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     SC_ECC_DEBUGr, SC_PRI_UPD_ECC_ENABLEf, 
     SC_ECC_ERROR0r, SC_PRI_UPD_CORRECTED_ERRORf,
     SC_ECC_ERROR0_MASKr, SC_PRI_UPD_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     SC_ECC_STATUS0r, SC_PRI_UPD_ECC_ERROR_ADDRESSf,
     "SC: Priority update table Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     SC_ECC_DEBUGr, SC_PRI_UPD_ECC_ENABLEf, 
     SC_ECC_ERROR0r, SC_PRI_UPD_UNCORRECTED_ERRORf,
     SC_ECC_ERROR0_MASKr, SC_PRI_UPD_UNCORRECTED_ERROR_DISINTf,
     SC_ECC_DEBUGr, SC_PRI_UPD_FORCE_UNCORRECTABLE_ERRORf,
     SC_ECC_STATUS0r, SC_PRI_UPD_ECC_ERROR_ADDRESSf,
     "SC: Priority update table Uncorrected ECC error"
    },       
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_ODD_ENABLE_ECCf, 
     SC_TOP_SI_ECC_ERRORr, TXFIFO_ODD_CORRECTED_ERRORf,
     SC_TOP_SI_ECC_ERROR_MASKr, TXFIFO_ODD_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     SC_TOP_SI_ECC_STATUSr, TXFIFO_ODD_ECC_ERROR_ADDRESSf,
     "SC: TXFIFO odd Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_ODD_ENABLE_ECCf, 
     SC_TOP_SI_ECC_ERRORr, TXFIFO_ODD_UNCORRECTED_ERRORf,
     SC_TOP_SI_ECC_ERROR_MASKr, TXFIFO_ODD_UNCORRECTED_ERROR_DINSTf,
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_ODD_FORCE_UNCORRECTABLE_ERRORf,
     SC_TOP_SI_ECC_STATUSr, TXFIFO_ODD_ECC_ERROR_ADDRESSf,
     "SC: TXFIFO odd Uncorrected ECC error"
    },           
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_EVEN_ENABLE_ECCf, 
     SC_TOP_SI_ECC_ERRORr, TXFIFO_EVEN_CORRECTED_ERRORf,
     SC_TOP_SI_ECC_ERROR_MASKr, TXFIFO_EVEN_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     SC_TOP_SI_ECC_STATUSr, TXFIFO_EVEN_ECC_ERROR_ADDRESSf,
     "SC: TXFIFO even Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_EVEN_ENABLE_ECCf, 
     SC_TOP_SI_ECC_ERRORr, TXFIFO_EVEN_UNCORRECTED_ERRORf,
     SC_TOP_SI_ECC_ERROR_MASKr, TXFIFO_EVEN_UNCORRECTED_ERROR_DINSTf,
     SC_TOP_SI_ECC_DEBUGr, TXFIFO_EVEN_FORCE_UNCORRECTABLE_ERRORf,
     SC_TOP_SI_ECC_STATUSr, TXFIFO_EVEN_ECC_ERROR_ADDRESSf,
     "SC: TXFIFO even Uncorrected ECC error"
    },           
};
STATIC _soc_error_info_t _soc_sirius_sf_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     SI_ECC_DEBUGr, TXFIFO_ODD_ENABLE_ECCf, 
     SI_ECC_ERRORr, TXFIFO_ODD_CORRECTED_ERRORf,
     SI_ECC_ERROR_MASKr, TXFIFO_ODD_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     SI_ECC_STATUSr, TXFIFO_ODD_ECC_ERROR_ADDRESSf,
     "SF: TXFIFO odd Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     SI_ECC_DEBUGr, TXFIFO_ODD_ENABLE_ECCf, 
     SI_ECC_ERRORr, TXFIFO_ODD_UNCORRECTED_ERRORf,
     SI_ECC_ERROR_MASKr, TXFIFO_ODD_UNCORRECTED_ERROR_DINSTf,
     SI_ECC_DEBUGr, TXFIFO_ODD_FORCE_UNCORRECTABLE_ERRORf,
     SI_ECC_STATUSr, TXFIFO_ODD_ECC_ERROR_ADDRESSf,
     "SF: TXFIFO odd Uncorrected ECC error"
    },           
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, INVALIDm, 
     SI_ECC_DEBUGr, TXFIFO_EVEN_ENABLE_ECCf, 
     SI_ECC_ERRORr, TXFIFO_EVEN_CORRECTED_ERRORf,
     SI_ECC_ERROR_MASKr, TXFIFO_EVEN_CORRECTED_ERROR_DINSTf,
     INVALIDr, INVALIDf,
     SI_ECC_STATUSr, TXFIFO_EVEN_ECC_ERROR_ADDRESSf,
     "SF: TXFIFO even Corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, INVALIDm, 
     SI_ECC_DEBUGr, TXFIFO_EVEN_ENABLE_ECCf, 
     SI_ECC_ERRORr, TXFIFO_EVEN_UNCORRECTED_ERRORf,
     SI_ECC_ERROR_MASKr, TXFIFO_EVEN_UNCORRECTED_ERROR_DINSTf,
     SI_ECC_DEBUGr, TXFIFO_EVEN_FORCE_UNCORRECTABLE_ERRORf,
     SI_ECC_STATUSr, TXFIFO_EVEN_ECC_ERROR_ADDRESSf,
     "SF: TXFIFO even Uncorrected ECC error"
    },           
};
STATIC _soc_error_info_t _soc_sirius_ts_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_N2m, 
     TS_ECC_DEBUG0r, L2_N2_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N2_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS7r, L2_N2_ECC_ERROR_ADDRESSf,
     "TS: L2_N2 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_N2m, 
     TS_ECC_DEBUG0r, L2_N2_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N2_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N2_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_N2_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS7r, L2_N2_ECC_ERROR_ADDRESSf,
     "TS: L2_N2 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_N1m, 
     TS_ECC_DEBUG0r, L2_N1_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N1_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS7r, L2_N1_ECC_ERROR_ADDRESSf,
     "TS: L2_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_N1m, 
     TS_ECC_DEBUG0r, L2_N1_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N1_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N1_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_N1_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS7r, L2_N1_ECC_ERROR_ADDRESSf,
     "TS: L2_N1 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_N0m, 
     TS_ECC_DEBUG0r, L2_N0_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N0_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS6r, L2_N0_ECC_ERROR_ADDRESSf,
     "TS: L2_N0 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_N0m, 
     TS_ECC_DEBUG0r, L2_N0_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_N0_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_N0_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_N0_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS6r, L2_N0_ECC_ERROR_ADDRESSf,
     "TS: L2_N0 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_BPm, 
     TS_ECC_DEBUG0r, L2_BP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_BP_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_BP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS6r, L2_BP_ECC_ERROR_ADDRESSf,
     "TS: L2_BP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_BPm, 
     TS_ECC_DEBUG0r, L2_BP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_BP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_BP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_BP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS6r, L2_BP_ECC_ERROR_ADDRESSf,
     "TS: L2_BP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_BKm, 
     TS_ECC_DEBUG0r, L2_BK_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_BK_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_BK_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS5r, L2_BK_ECC_ERROR_ADDRESSf,
     "TS: L2_BK corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_BKm, 
     TS_ECC_DEBUG0r, L2_BK_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_BK_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_BK_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_BK_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS5r, L2_BK_ECC_ERROR_ADDRESSf,
     "TS: L2_BK uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_NGm, 
     TS_ECC_DEBUG0r, L2_NG_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_NG_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_NG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS5r, L2_NG_ECC_ERROR_ADDRESSf,
     "TS: L2_NG corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_NGm, 
     TS_ECC_DEBUG0r, L2_NG_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_NG_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_NG_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_NG_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS5r, L2_NG_ECC_ERROR_ADDRESSf,
     "TS: L2_NG uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L2_NMm, 
     TS_ECC_DEBUG0r, L2_NM_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_NM_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_NM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS4r, L2_NM_ECC_ERROR_ADDRESSf,
     "TS: L2_NM corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L2_NMm, 
     TS_ECC_DEBUG0r, L2_NM_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L2_NM_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L2_NM_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L2_NM_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS4r, L2_NM_ECC_ERROR_ADDRESSf,
     "TS: L2_NM uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_N2m, 
     TS_ECC_DEBUG0r, L1_N2_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N2_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS4r, L1_N2_ECC_ERROR_ADDRESSf,
     "TS: L1_N2 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_N2m, 
     TS_ECC_DEBUG0r, L1_N2_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N2_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N2_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_N2_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS4r, L1_N2_ECC_ERROR_ADDRESSf,
     "TS: L1_N2 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_N1m, 
     TS_ECC_DEBUG0r, L1_N1_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N1_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS3r, L1_N1_ECC_ERROR_ADDRESSf,
     "TS: L1_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_N1m, 
     TS_ECC_DEBUG0r, L1_N1_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N1_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N1_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_N1_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS3r, L1_N1_ECC_ERROR_ADDRESSf,
     "TS: L1_N1 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_N0m, 
     TS_ECC_DEBUG0r, L1_N0_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N0_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS3r, L1_N0_ECC_ERROR_ADDRESSf,
     "TS: L1_N0 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_N0m, 
     TS_ECC_DEBUG0r, L1_N0_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_N0_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_N0_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_N0_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS3r, L1_N0_ECC_ERROR_ADDRESSf,
     "TS: L1_N0 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_BPm, 
     TS_ECC_DEBUG0r, L1_BP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_BP_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_BP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS2r, L1_BP_ECC_ERROR_ADDRESSf,
     "TS: L1_BP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_BPm, 
     TS_ECC_DEBUG0r, L1_BP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_BP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_BP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_BP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS2r, L1_BP_ECC_ERROR_ADDRESSf,
     "TS: L1_BP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_BKm, 
     TS_ECC_DEBUG0r, L1_BK_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_BK_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_BK_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS2r, L1_BK_ECC_ERROR_ADDRESSf,
     "TS: L1_BK corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_BKm, 
     TS_ECC_DEBUG0r, L1_BK_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_BK_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_BK_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_BK_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS2r, L1_BK_ECC_ERROR_ADDRESSf,
     "TS: L1_BK uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_NGm, 
     TS_ECC_DEBUG0r, L1_NG_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_NG_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_NG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS1r, L1_NG_ECC_ERROR_ADDRESSf,
     "TS: L1_NG corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_NGm, 
     TS_ECC_DEBUG0r, L1_NG_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_NG_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_NG_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_NG_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS1r, L1_NG_ECC_ERROR_ADDRESSf,
     "TS: L1_NG uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L1_NMm, 
     TS_ECC_DEBUG0r, L1_NM_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_NM_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_NM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS1r, L1_NM_ECC_ERROR_ADDRESSf,
     "TS: L1_NM corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L1_NMm, 
     TS_ECC_DEBUG0r, L1_NM_ENABLE_ECCf, 
     TS_ECC_ERROR0r, L1_NM_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, L1_NM_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, L1_NM_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS1r, L1_NM_ECC_ERROR_ADDRESSf,
     "TS: L1_NM uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, LF_QPm, 
     TS_ECC_DEBUG0r, LF_QP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, LF_QP_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, LF_QP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS0r, LF_QP_ECC_ERROR_ADDRESSf,
     "TS: LF_QP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, LF_QPm, 
     TS_ECC_DEBUG0r, LF_QP_ENABLE_ECCf, 
     TS_ECC_ERROR0r, LF_QP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, LF_QP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, LF_QP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS0r, LF_QP_ECC_ERROR_ADDRESSf,
     "TS: LF_QP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, LF_QDm, 
     TS_ECC_DEBUG0r, LF_QD_ENABLE_ECCf, 
     TS_ECC_ERROR0r, LF_QD_CORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, LF_QD_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS0r, LF_QD_ECC_ERROR_ADDRESSf,
     "TS: LF_QD corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, LF_QDm, 
     TS_ECC_DEBUG0r, LF_QD_ENABLE_ECCf, 
     TS_ECC_ERROR0r, LF_QD_UNCORRECTED_ERRORf,
     TS_ECC_ERROR0_MASKr, LF_QD_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG0r, LF_QD_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS0r, LF_QD_ECC_ERROR_ADDRESSf,
     "TS: LF_QD uncorrected ECC error"
    },

    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_N2m, 
     TS_ECC_DEBUG1r, L4_N2_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N2_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS12r, L4_N2_ECC_ERROR_ADDRESSf,
     "TS: L4_N2 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_N2m, 
     TS_ECC_DEBUG1r, L4_N2_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N2_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N2_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_N2_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS12r, L4_N2_ECC_ERROR_ADDRESSf,
     "TS: L4_N2 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_N1m, 
     TS_ECC_DEBUG1r, L4_N1_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N1_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS12r, L4_N1_ECC_ERROR_ADDRESSf,
     "TS: L4_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_N1m, 
     TS_ECC_DEBUG1r, L4_N1_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N1_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N1_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_N1_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS12r, L4_N1_ECC_ERROR_ADDRESSf,
     "TS: L4_N1 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_N0m, 
     TS_ECC_DEBUG1r, L4_N0_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N0_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS11r, L4_N0_ECC_ERROR_ADDRESSf,
     "TS: L4_N0 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_N0m, 
     TS_ECC_DEBUG1r, L4_N0_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_N0_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_N0_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_N0_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS11r, L4_N0_ECC_ERROR_ADDRESSf,
     "TS: L4_N0 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_BPm, 
     TS_ECC_DEBUG1r, L4_BP_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_BP_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_BP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS11r, L4_BP_ECC_ERROR_ADDRESSf,
     "TS: L4_BP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_BPm, 
     TS_ECC_DEBUG1r, L4_BP_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_BP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_BP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_BP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS11r, L4_BP_ECC_ERROR_ADDRESSf,
     "TS: L4_BP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_BKm, 
     TS_ECC_DEBUG1r, L4_BK_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_BK_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_BK_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS11r, L4_BK_ECC_ERROR_ADDRESSf,
     "TS: L4_BK corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_BKm, 
     TS_ECC_DEBUG1r, L4_BK_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_BK_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_BK_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_BK_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS11r, L4_BK_ECC_ERROR_ADDRESSf,
     "TS: L4_BK uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_NGm, 
     TS_ECC_DEBUG1r, L4_NG_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_NG_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_NG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS10r, L4_NG_ECC_ERROR_ADDRESSf,
     "TS: L4_NG corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_NGm, 
     TS_ECC_DEBUG1r, L4_NG_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_NG_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_NG_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_NG_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS10r, L4_NG_ECC_ERROR_ADDRESSf,
     "TS: L4_NG uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L4_NMm, 
     TS_ECC_DEBUG1r, L4_NM_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_NM_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_NM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS10r, L4_NM_ECC_ERROR_ADDRESSf,
     "TS: L4_NM corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L4_NMm, 
     TS_ECC_DEBUG1r, L4_NM_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L4_NM_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L4_NM_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L4_NM_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS10r, L4_NM_ECC_ERROR_ADDRESSf,
     "TS: L4_NM uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_N2m, 
     TS_ECC_DEBUG1r, L3_N2_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N2_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N2_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS10r, L3_N2_ECC_ERROR_ADDRESSf,
     "TS: L3_N2 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_N2m, 
     TS_ECC_DEBUG1r, L3_N2_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N2_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N2_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_N2_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS10r, L3_N2_ECC_ERROR_ADDRESSf,
     "TS: L3_N2 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_N1m, 
     TS_ECC_DEBUG1r, L3_N1_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N1_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS9r, L3_N1_ECC_ERROR_ADDRESSf,
     "TS: L3_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_N1m, 
     TS_ECC_DEBUG1r, L3_N1_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N1_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N1_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_N1_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS9r, L3_N1_ECC_ERROR_ADDRESSf,
     "TS: L3_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_N0m, 
     TS_ECC_DEBUG1r, L3_N0_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N0_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS9r, L3_N0_ECC_ERROR_ADDRESSf,
     "TS: L3_N0 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_N0m, 
     TS_ECC_DEBUG1r, L3_N0_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_N0_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_N0_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_N0_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS9r, L3_N0_ECC_ERROR_ADDRESSf,
     "TS: L3_N0 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_BPm, 
     TS_ECC_DEBUG1r, L3_BP_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_BP_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_BP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS9r, L3_BP_ECC_ERROR_ADDRESSf,
     "TS: L3_BP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_BPm, 
     TS_ECC_DEBUG1r, L3_BP_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_BP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_BP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_BP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS9r, L3_BP_ECC_ERROR_ADDRESSf,
     "TS: L3_BP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_BKm, 
     TS_ECC_DEBUG1r, L3_BK_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_BK_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_BK_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS8r, L3_BK_ECC_ERROR_ADDRESSf,
     "TS: L3_BK corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_BKm, 
     TS_ECC_DEBUG1r, L3_BK_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_BK_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_BK_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_BK_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS8r, L3_BK_ECC_ERROR_ADDRESSf,
     "TS: L3_BK uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_NGm, 
     TS_ECC_DEBUG1r, L3_NG_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_NG_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_NG_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS8r, L3_NG_ECC_ERROR_ADDRESSf,
     "TS: L3_NG corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_NGm, 
     TS_ECC_DEBUG1r, L3_NG_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_NG_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_NG_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_NG_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS8r, L3_NG_ECC_ERROR_ADDRESSf,
     "TS: L3_NG uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L3_NMm, 
     TS_ECC_DEBUG1r, L3_NM_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_NM_CORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_NM_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS8r, L3_NM_ECC_ERROR_ADDRESSf,
     "TS: L3_NM corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L3_NMm, 
     TS_ECC_DEBUG1r, L3_NM_ENABLE_ECCf, 
     TS_ECC_ERROR1r, L3_NM_UNCORRECTED_ERRORf,
     TS_ECC_ERROR1_MASKr, L3_NM_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG1r, L3_NM_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS8r, L3_NM_ECC_ERROR_ADDRESSf,
     "TS: L3_NM uncorrected ECC error"
    },

    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L5_N1m, 
     TS_ECC_DEBUG2r, L5_N1_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_N1_CORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_N1_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS13r, L5_N1_ECC_ERROR_ADDRESSf,
     "TS: L5_N1 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L5_N1m, 
     TS_ECC_DEBUG2r, L5_N1_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_N1_UNCORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_N1_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG2r, L5_N1_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS13r, L5_N1_ECC_ERROR_ADDRESSf,
     "TS: L5_N1 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L5_N0m, 
     TS_ECC_DEBUG2r, L5_N0_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_N0_CORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_N0_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS13r, L5_N0_ECC_ERROR_ADDRESSf,
     "TS: L5_N0 corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L5_N0m, 
     TS_ECC_DEBUG2r, L5_N0_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_N0_UNCORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_N0_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG2r, L5_N0_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS13r, L5_N0_ECC_ERROR_ADDRESSf,
     "TS: L5_N0 uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L5_BPm, 
     TS_ECC_DEBUG2r, L5_BP_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_BP_CORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_BP_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS13r, L5_BP_ECC_ERROR_ADDRESSf,
     "TS: L5_BP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L5_BPm, 
     TS_ECC_DEBUG2r, L5_BP_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_BP_UNCORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_BP_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG2r, L5_BP_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS13r, L5_BP_ECC_ERROR_ADDRESSf,
     "TS: L5_BP uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, L5_BKm, 
     TS_ECC_DEBUG2r, L5_BK_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_BK_CORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_BK_CORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TS_ECC_STATUS13r, L5_BK_ECC_ERROR_ADDRESSf,
     "TS: L5_BK corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, L5_BKm, 
     TS_ECC_DEBUG2r, L5_BK_ENABLE_ECCf, 
     TS_ECC_ERROR2r, L5_BK_UNCORRECTED_ERRORf,
     TS_ECC_ERROR2_MASKr, L5_BK_UNCORRECTED_ERROR_DISINTf,
     TS_ECC_DEBUG2r, L5_BK_FORCE_UNCORRECTABLE_ERRORf,
     TS_ECC_STATUS13r, L5_BK_ECC_ERROR_ADDRESSf,
     "TS: L5_BK uncorrected ECC error"
    }
};
STATIC _soc_error_info_t _soc_sirius_tx_error_info[] = {
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TX_SFI_CFIFOm, 
     TX_ECC_DEBUGr, SFI_CBUFFER_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, SFI_CBUFFER_B_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, SFI_CBUFFER_B_UNCORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TX_ECC_STATUS0r, SFI_CBUFFER_B_ECC_ERROR_ADDRESSf,
     "TX: SFI Cbuffer B corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TX_SFI_CFIFOm, 
     TX_ECC_DEBUGr, SFI_CBUFFER_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, SFI_CBUFFER_B_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, SFI_CBUFFER_B_UNCORRECTED_ERROR_DISINTf,
     TX_ECC_DEBUGr, SFI_CBUFFER_FORCE_UNCORRECTABLE_ERRORf,
     TX_ECC_STATUS0r, SFI_CBUFFER_B_ECC_ERROR_ADDRESSf,
     "TX: SFI Cbuffer B uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, TX_SFI_CFIFOm, 
     TX_ECC_DEBUGr, SFI_CBUFFER_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, SFI_CBUFFER_A_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, SFI_CBUFFER_A_UNCORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TX_ECC_STATUS0r, SFI_CBUFFER_A_ECC_ERROR_ADDRESSf,
     "TX: SFI Cbuffer A corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, TX_SFI_CFIFOm, 
     TX_ECC_DEBUGr, SFI_CBUFFER_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, SFI_CBUFFER_A_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, SFI_CBUFFER_A_UNCORRECTED_ERROR_DISINTf,
     TX_ECC_DEBUGr, SFI_CBUFFER_FORCE_UNCORRECTABLE_ERRORf,
     TX_ECC_STATUS0r, SFI_CBUFFER_A_ECC_ERROR_ADDRESSf,
     "TX: SFI Cbuffer A uncorrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_CORRECTED, CBLOCK_MOD_LOOKUPm, 
     TX_ECC_DEBUGr, CBLOCKS_MOD_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, CBLOCKS_MOD_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, CBLOCKS_MOD_UNCORRECTED_ERROR_DISINTf,
     INVALIDr, INVALIDf,
     TX_ECC_STATUS0r, CBLOCKS_MOD_ECC_ERROR_ADDRESSf,
     "TX: CBLOCK_MOD_LOOKUP corrected ECC error"
    },
    {_SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED, CBLOCK_MOD_LOOKUPm, 
     TX_ECC_DEBUGr, CBLOCKS_MOD_ENABLE_ECCf, 
     TX_ECC_ERROR_0r, CBLOCKS_MOD_UNCORRECTED_ERRORf,
     TX_ECC_ERROR_0_MASKr, CBLOCKS_MOD_UNCORRECTED_ERROR_DISINTf,
     TX_ECC_DEBUGr, CBLOCKS_MOD_FORCE_UNCORRECTABLE_ERRORf,
     TX_ECC_STATUS0r, CBLOCKS_MOD_ECC_ERROR_ADDRESSf,
     "TX: CBLOCK_MOD_LOOKUP uncorrected ECC error"
    },
};
STATIC _soc_error_info_t _soc_sirius_xp_error_info[] = {
    /* XPORT ECC errors not handled for now */
    {_SOC_ERROR_INFO_TYPE_GENERIC, INVALIDr,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     INVALIDr, INVALIDf,
     "XPORT:  ECC error not implemented"
    }
};

STATIC _soc_error_block_info_t _soc_sirius_block_info[] = {
    {_soc_sirius_bp_error_info,  COUNTOF(_soc_sirius_bp_error_info), REG_PORT_ANY, "BP" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 0, "CI0" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 1, "CI1" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 2, "CI2" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 3, "CI3" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 4, "CI4" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 5, "CI5" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 6, "CI6" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 7, "CI7" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 8, "CI8" },
    {_soc_sirius_ci_error_info,  COUNTOF(_soc_sirius_ci_error_info), 9, "CI9" },
    {_soc_sirius_cmic_error_info,COUNTOF(_soc_sirius_cmic_error_info), REG_PORT_ANY, "CMIC" },
    {_soc_sirius_cs_error_info,  COUNTOF(_soc_sirius_cs_error_info), REG_PORT_ANY, "CS" },
    {_soc_sirius_eb_error_info,  COUNTOF(_soc_sirius_eb_error_info), REG_PORT_ANY, "EB" },
    {_soc_sirius_ep_error_info,  COUNTOF(_soc_sirius_ep_error_info), REG_PORT_ANY, "EP" },
    {_soc_sirius_es_error_info,  COUNTOF(_soc_sirius_es_error_info), REG_PORT_ANY, "ES" },
    {_soc_sirius_fd_error_info,  COUNTOF(_soc_sirius_fd_error_info), REG_PORT_ANY, "FD" },
    {_soc_sirius_ff_error_info,  COUNTOF(_soc_sirius_ff_error_info), REG_PORT_ANY, "FF" },
    {_soc_sirius_fr_error_info,  COUNTOF(_soc_sirius_fr_error_info), REG_PORT_ANY, "FR" },
    {_soc_sirius_otpc_error_info,COUNTOF(_soc_sirius_otpc_error_info),REG_PORT_ANY, "OTPC" },
    {_soc_sirius_qma_error_info, COUNTOF(_soc_sirius_qma_error_info),REG_PORT_ANY, "QMA" },
    {_soc_sirius_qmb_error_info, COUNTOF(_soc_sirius_qmb_error_info),REG_PORT_ANY, "QMB" },
    {_soc_sirius_qmc_error_info, COUNTOF(_soc_sirius_qmc_error_info),REG_PORT_ANY, "QMC" },
    {_soc_sirius_qsa_error_info, COUNTOF(_soc_sirius_qsa_error_info),REG_PORT_ANY, "QSA" },
    {_soc_sirius_qsb_error_info, COUNTOF(_soc_sirius_qsb_error_info),REG_PORT_ANY, "QSB" },
    {_soc_sirius_rb_error_info,  COUNTOF(_soc_sirius_rb_error_info), REG_PORT_ANY, "RB" },
    {_soc_sirius_sc_error_info,  COUNTOF(_soc_sirius_sc_error_info), REG_PORT_ANY, "SC" },
    {_soc_sirius_sf_error_info,  COUNTOF(_soc_sirius_sf_error_info), REG_PORT_ANY, "SF" },
    {_soc_sirius_ts_error_info,  COUNTOF(_soc_sirius_ts_error_info), REG_PORT_ANY, "TS" },
    {_soc_sirius_tx_error_info,  COUNTOF(_soc_sirius_tx_error_info), REG_PORT_ANY, "TX" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 0, "XP0" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 1, "XP1" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 2, "XP2" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 3, "XP3" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 4, "XP4" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 5, "XP5" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 6, "XP6" },
    {_soc_sirius_xp_error_info,  COUNTOF(_soc_sirius_xp_error_info), 7, "XP7" }
};

soc_error_t
soc_sirius_modid_set(int unit, int node)
{
  uint32 regval = 0;

  SOC_IF_ERROR_RETURN(READ_TX_CONFIG0r(unit, &regval));
  soc_reg_field_set(unit, TX_CONFIG0r, &regval, SOURCE_NODEf, node); 
  SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG0r(unit, regval));

  return SOC_E_NONE;
}


void
soc_sirius_isr(void *_unit)
{

}

void
soc_sirius_ecc_enable(int unit, int enable) {
    soc_reg_t enable_reg, mask_reg, status_reg, info_reg;
    soc_field_t enable_field, mask_field, status_field, info_field;
    int block, error;
    _soc_error_info_t *error_info;
    uint32 regval = 0;
    soc_port_t port;
    int16 index, index_max = 1;
    int rv;

    for (block = 0; block < COUNTOF(_soc_sirius_block_info); block++) {
	port = _soc_sirius_block_info[block].port;
	error_info = _soc_sirius_block_info[block].info;

	for (error = 0; error < _soc_sirius_block_info[block].num_intr; error++, error_info++) {
	    /* enable */
	    enable_reg = error_info->enable_reg;
	    enable_field = error_info->enable_field;	    
	    if ( (enable_reg != INVALIDr) &&
		 (enable_field != INVALIDf) ) {
                if ((enable_reg == SI_ECC_DEBUGr) || (enable_reg == SC_TOP_SI_ECC_DEBUGr)) index_max = 12;
                for (index=0; index < index_max; index++) {
                    rv = (soc_reg32_read(unit, soc_reg_addr(unit, enable_reg,
                                                            port, index), &regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to enable ECC\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                    soc_reg_field_set(unit, enable_reg, &regval, enable_field, enable);
                    rv = (soc_reg32_write(unit, soc_reg_addr(unit, enable_reg,
                                                             port, index), regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to enable ECC\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                }
	    }

	    /* mask */
	    mask_reg = error_info->mask_reg;
	    mask_field = error_info->mask_field;
	    if ( (mask_reg != INVALIDr) &&
		 (mask_field != INVALIDf) ) {
                if ((mask_reg == SI_ECC_ERROR_MASKr) || (mask_reg == SC_TOP_SI_ECC_ERROR_MASKr)) index_max = 12;
                
                for (index=0; index < index_max; index++) {
                    rv = (soc_reg32_read(unit, soc_reg_addr(unit, mask_reg,
							port, index), &regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to read ECC mask\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                    soc_reg_field_set(unit, mask_reg, &regval, mask_field, enable?0:1);
                    rv = (soc_reg32_write(unit, soc_reg_addr(unit, mask_reg,
                                                             port, index), regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to setup ECC mask\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                }
	    }

	    /* status */
	    status_reg = error_info->status_reg;
	    status_field = error_info->status_field;
            if ( (status_reg != INVALIDr) &&
		 (status_field != INVALIDf) ) {
		regval = 0; 
            if ((status_reg == SI_ECC_ERRORr) || (status_reg == SC_TOP_SI_ECC_ERRORr)) index_max = 12;
                for (index=0; index < index_max; index++) {
                    rv = (soc_reg32_read(unit, soc_reg_addr(unit, status_reg,
                                                            port, index), &regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to clear ECC status\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                    soc_reg_field_set(unit, status_reg, &regval, status_field, 1);
                    rv = (soc_reg32_write(unit, soc_reg_addr(unit, status_reg,
                                                             port, index), regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to clear ECC status\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                }
	    }

	    /* info bits */
	    info_reg = error_info->info_reg;
	    info_field = error_info->info_field;	    
	    if ( (info_reg != INVALIDr) &&
		 (info_field != INVALIDf) ) {
                if ((info_reg == SI_ECC_STATUSr) || (info_reg == SC_TOP_SI_ECC_STATUSr)) index_max = 12;
                for (index=0; index < index_max; index++) {
                    regval = 0;
                    rv = (soc_reg32_read(unit, soc_reg_addr(unit, info_reg,
                                                             port, 0), &regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to clear ECC info\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                    soc_reg_field_set(unit, info_reg, &regval, info_field, 0);
                    rv = (soc_reg32_write(unit, soc_reg_addr(unit, info_reg,
                                                             port, 0), regval));
                    if (rv != SOC_E_NONE) {
                        LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to clear ECC info\n"), 
                                   unit, error_info->msg));
                        continue;
                    }
                }
            }
	}
    }
}

void
soc_sirius_block_error(void *unit_vp, void *d1, void *d2,
		       void *d3, void *d4)
{
    int unit = PTR_TO_INT(unit_vp);
    int block = PTR_TO_INT(d1);
    uint32 regval = 0;
    int error, ecc_addr;
    _soc_error_info_t *error_info;
    soc_port_t port;
    int rv;
    int32 handled = FALSE;
    soc_reg_t status_reg, info_reg;
    soc_field_t status_field, info_field;

    if (block >= COUNTOF(_soc_sirius_block_info)) {
	LOG_INFO(BSL_LS_SOC_INTR,
                 (BSL_META_U(unit,
                             "soc_intr unit %d: interrupt from unsupported block %d\n"),
                  unit, block));
	return;
    }
    
    error_info = _soc_sirius_block_info[block].info;
    
    for (error = 0; error < _soc_sirius_block_info[block].num_intr; error++, error_info++) {
	port =  _soc_sirius_block_info[block].port;
	status_reg = error_info->status_reg;
	status_field = error_info->status_field;
	info_reg = error_info->info_reg;
	info_field = error_info->info_field;

	if ( (status_reg != INVALIDr) &&
	     (status_field != INVALIDf) ) {
	    rv = (soc_reg32_read(unit, soc_reg_addr(unit, status_reg,
						    port, 0), &regval));
	    if (rv != SOC_E_NONE) {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d %s failed to read ECC status\n"), 
                           unit, error_info->msg));
		continue;
	    }
	    if (soc_reg_field_get(unit, status_reg, regval, status_field) == 0) {
		continue;
	    }
	} else {
	    continue;
	}

	/* assuming error bits are w1tc, clear the error */
	regval = 0;
	soc_reg_field_set(unit, status_reg, &regval, status_field, 1);
	rv = (soc_reg32_write(unit, soc_reg_addr(unit, status_reg,
						 port, 0), regval));
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d %s failed to clear ECC error\n"), 
                       unit, error_info->msg));
	    break;
	} else {
	    handled = TRUE;
	}

	/* report error infor */
	switch (error_info->type) {
	    case _SOC_ERROR_INFO_TYPE_GENERIC:
		LOG_INFO(BSL_LS_SOC_INTR,
                         (BSL_META_U(unit,
                                     "unit %d %s asserted\n"),
                          unit, error_info->msg));
		break;
	    case _SOC_ERROR_INFO_TYPE_ECC_CORRECTED:
	    case _SOC_ERROR_INFO_TYPE_ECC_UNCORRECTED:
		if ( (info_reg != INVALIDr) &&
		     (info_field != INVALIDf) ) {
		    /* get and clear the ECC error address */
		    rv = (soc_reg32_read(unit, soc_reg_addr(unit, info_reg,
							    port, 0), &regval));
		    if (rv != SOC_E_NONE) {
			LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to get ECC error address \n"), 
                                   unit, error_info->msg));
		    }
		    ecc_addr = soc_reg_field_get(unit, info_reg, regval, info_field);
		    soc_reg_field_set(unit, info_reg, &regval, info_field, 0);
		    rv = (soc_reg32_write(unit, soc_reg_addr(unit, info_reg, port, 0), regval));
		    if (rv != SOC_E_NONE) {
			LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META_U(unit,
                                              "unit %d %s failed to clear ECC error address \n"), 
                                   unit, error_info->msg));
		    }
		    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d %s at address 0x%x\n"), 
                               unit, error_info->msg, ecc_addr));
		} else {
		    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d %s asserted\n"), unit, error_info->msg));
		}
		break;
	    default:
		LOG_INFO(BSL_LS_SOC_INTR,
                         (BSL_META_U(unit,
                                     "soc_intr unit %d: unsupported interrupt type from block %d\n"),
                          unit, block));
		break;
	}
    }

    if (handled) {
	/* reenable block interrupt once done with analysis */
	if (block < 32) {
	    soc_intr_block_lo_enable(unit, (1<<block));
	} else {
	    soc_intr_block_hi_enable(unit, (1<<(block-32)));
	}
    } else {
	LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d unsupported interrupts from block %d, disabling interrupt from this block \n"), 
                   unit, block));
    }
}


int
soc_sirius_config_linkdriver(int unit, int nLink, sbLinkDriverConfig_t *pLinkDriverConfig)
{

    sbLinkSpecificDriverConfig_t specificConfig;
    sbFabStatus_t status;
    uint32 uPhyAddr;
    uint32 uLaneAddr;
    bcm_port_t port = 0;
    uint16     full_speed = 0;

    SOC_IF_ERROR_RETURN(soc_sirius_serdes_phyaddr(unit, nLink, &uPhyAddr, &uLaneAddr));

    if ( nLink < 0 || nLink >= SB_FAB_DEVICE_SIRIUS_NUM_SERIALIZERS ) {
        LOG_ERROR(BSL_LS_SOC_FABRIC,
                  (BSL_META_U(unit,
                              "Bad link(%d) requested for SIRIUS."
                              " Valid range is [0,%d)\n"), nLink,
                   SB_FAB_DEVICE_SIRIUS_NUM_SERIALIZERS));
        return SB_FAB_STATUS_BAD_LINK_ID;
    }

    status = GetLinkSpecificConfig((sbFabUserDeviceHandle_t)unit, nLink, pLinkDriverConfig, &specificConfig);
    if ( status != SB_FAB_STATUS_OK ) {
        LOG_ERROR(BSL_LS_SOC_FABRIC,
                  (BSL_META_U(unit,
                              "Could not get link specific configuration"
                              " for link(%d)\n"),nLink));
        return status;
    }

    if  ((SOC_SBX_CFG_SIRIUS(unit)->uSerdesAbility[nLink] == 
          SOC_PORT_ABILITY_SFI) ||
	 
	 ((SOC_SBX_CFG_SIRIUS(unit)->uSerdesAbility[nLink] == 
	   SOC_PORT_ABILITY_SCI) &&
	  (SOC_SBX_CFG(unit)->uSerdesSpeed < 6250))
	 ) 
      {

        /* We are running at 1/2 speed 3.125G */
	/* Override nPreemphasisPre */
	specificConfig.u.hypercore.equalization.nPreemphasisPre = 0;
        full_speed = 0;
    } else {
	/*
         * We are running at full speed 6.25G 
         * Set high bit in value to indicate to program TX0_TX_BR_DRIVER
         */
	full_speed = 0x8000;
    }
        

    /*
     * Now that we have the data, etc. program the correct link config and 
     * we're done 
     */
    SOC_IF_ERROR_RETURN(soc_sirius_si_to_port(unit, nLink, &port));
    SOC_IF_ERROR_RETURN
        (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_PREEMPHASIS,
         specificConfig.u.hypercore.equalization.nPremphasisPost|full_speed));
    SOC_IF_ERROR_RETURN
        (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_DRIVER_CURRENT,
         specificConfig.u.hypercore.strength.nIDriver|full_speed));
    SOC_IF_ERROR_RETURN
       (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_PRE_DRIVER_CURRENT,
         specificConfig.u.hypercore.strength.nIPreDriver|full_speed));
    SOC_IF_ERROR_RETURN
        (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_PRE_PREEMPHASIS,
         specificConfig.u.hypercore.equalization.nPreemphasisPre|full_speed));

    return SB_FAB_STATUS_OK;
}

/*
 * soc_sirius_init - Fill in defaults for hardware settings, then pick up SOC params
 *                   from input structure/properties, fill in hardware init
 *                   structure with corresponding values, then call hwSiriusInit
 *   NOTE:   called from sbx_drv.c after that picks up some soc properties
 */
int
soc_sirius_init(int unit, soc_sbx_config_t *cfg)
{
    int rv = SOC_E_NONE;
    siriusInitParams_t *hwSiriusInitParams_sp;
    soc_control_t       *soc;
    soc_sbx_control_t   *sbx;
    sbLinkThresholdConfig_t linkThresholdConfig;
    bcm_port_t port;
    int link;
    int status;

    if (!SOC_UNIT_VALID(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "soc_init: unit %d not valid\n"), unit));
        return SOC_E_UNIT;
    }

    soc = SOC_CONTROL(unit);
    sbx = SOC_SBX_CONTROL(unit);

    if (!(soc->soc_flags & SOC_F_ATTACHED)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "soc_init: unit %d not attached\n"), unit));
        return(SOC_E_UNIT);
    }

    /* Setup Sirius HW init parameters based on config */
    hwSiriusInitParams_sp = sal_alloc(sizeof(siriusInitParams_t), "Sirius_init_st");
    if (hwSiriusInitParams_sp == NULL) {
        return SOC_E_MEMORY;
    }

    sal_memset(hwSiriusInitParams_sp, 0 ,sizeof(siriusInitParams_t));

    hwSiriusInitParams_sp->unit = unit;
    hwSiriusInitParams_sp->reset = cfg->reset_ul;
    hwSiriusInitParams_sp->bResetOnly = FALSE;

    hwSiriusInitParams_sp->clearDdr = sbx->sbx_functions.sirius_ddr_clear;

    _soc_sirius_init_default_params(hwSiriusInitParams_sp);

    /* If the port is sfi or sfi_sci, make sure link status is handled */
    for (link = 0; link < SB_FAB_DEVICE_SIRIUS_LINKS; link++) {
	rv = soc_sirius_si_to_port(unit, link, &port);
	if (rv != SOC_E_NONE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "Sirius hardware init failed\n")));
	    sal_free(hwSiriusInitParams_sp);
	    return rv;
	}

	if( soc_property_port_get(unit,  port, spn_PORT_IS_SFI, 0) ){
	    hwSiriusInitParams_sp->sc.uLinkStatusRemap[link] = link;
	} else {
	    hwSiriusInitParams_sp->sc.uLinkStatusRemap[link] = 0x1f;
	}
    }

    /* All non-SCI serializers will be brought up in the SOC layer to allow
     * for proper serdes bring up.  They will all be forced low, until
     * enabled by bcm_port_enable
     */
    status = GetLinkThresholdConfig(SOC_SBX_CFG(unit)->uLinkThresholdIndex,
				    &linkThresholdConfig);
    if (status == SB_FAB_STATUS_OK) {
       hwSiriusInitParams_sp->uSiLsThreshold = linkThresholdConfig.uLsThreshold;
       hwSiriusInitParams_sp->uSiLsWindow = linkThresholdConfig.uLsWindowIn256Clocks;
    } else {
        LOG_ERROR(BSL_LS_SOC_FABRIC,
                  (BSL_META_U(unit,
                              "Sirius uLinkThresholdIndex(%d) initialization "
			      "parameter not initialized correctly."
			      " Should be [0,100]\n"),
                   SOC_SBX_CFG(unit)->uLinkThresholdIndex));
    }

    rv = _soc_sirius_hw_init(hwSiriusInitParams_sp);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Sirius hardware init failed\n")));
        sal_free(hwSiriusInitParams_sp);
        return (rv);
    }

    /* Initialize SOC link control module */
    
    soc_linkctrl_init(unit, &soc_linkctrl_driver_sbx);

    /* start sw ddr23 training if enabled */
    if (!SAL_BOOT_BCMSIM) {
        soc_sbx_sirius_sw_ddr23_train_init(unit,hwSiriusInitParams_sp);
    }

    sal_free(hwSiriusInitParams_sp);

    if (soc_property_get(unit, spn_PARITY_ENABLE, FALSE)) {
	soc_sirius_ecc_enable(unit, TRUE);
    } else {
	soc_sirius_ecc_enable(unit, FALSE);
    }

    return rv;
}

/*
 * Function:
 *     soc_sirius_state_cleanup
 * Purpose:
 *     Cleanup and free all resources allocated during device specific
 *     initialization routine.
 * Parameters:
 *     unit - Device number
 * Returns:
 *     (nothing)
 * Notes:
 *     Assumes valid unit, soc control.
 */
void
soc_sirius_state_cleanup(int unit)
{
    soc_sbx_sirius_state_t *state;
    soc_sbx_sirius_predicate_parser_rule_t *ppRuleCurr;
    soc_sbx_sirius_predicate_parser_rule_t *ppRuleNext;

    if (__soc_sbx_sirius_state_init) {
        
        state = SOC_SBX_SIRIUS_STATE(unit);
        SOC_SBX_SIRIUS_STATE(unit) = NULL;
        if (state) {
            ppRuleNext = state->ingressRuleHead;
            while (ppRuleNext) {
                ppRuleCurr = ppRuleNext;
                ppRuleNext = ppRuleCurr->next;
                sal_free(ppRuleCurr);
            }
            ppRuleNext = state->egressRuleHead;
            while (ppRuleNext) {
                ppRuleCurr = ppRuleNext;
                ppRuleNext = ppRuleCurr->next;
                sal_free(ppRuleCurr);
            }
            sal_free(state);
        } /* if (state) */
    } /* if (__soc_sbx_sirius_state_init) */
}

/*
 * Function:
 *     soc_sirius_detach
 * Purpose:
 *     Cleanup and free all resources allocated during device specific
 *     initialization routine.
 * Parameters:
 *     unit - Device number
 * Returns:
 *     SOC_E_NONE - Success
 *     SOC_E_XXX  - Failure
 * Notes:
 *     Assumes valid unit, soc control.
 */
int
soc_sirius_detach(int unit)
{
    unsigned int index;
    soc_driver_t *driver;
    soc_sbx_config_t *sbx;
    soc_sbx_sirius_config_t *sir;

    /* if state information has been set up, tear it down */
    if (SOC_CONTROL(unit)) {
        /* SOC_CONTROL exists; get rid of parts */
        if (SOC_DRIVER(unit)) {
            /* SOC_DRIVER exists; get rid of parts */
            driver = SOC_DRIVER(unit);
            if (driver->port_info) {
                sal_free(driver->port_info);
                driver->port_info = NULL;
            }
        } /* if (SOC_DRIVER(unit)) */
        if (SOC_SBX_CFG(unit)) {
            /* SOC_SBX_CFG exists; get rid of parts */
            sbx = SOC_SBX_CFG(unit);
            if (SOC_SBX_CFG_SIRIUS(unit)) {
                /* SOC_SBX_CFG_SIRIUS exists; get rid of parts */
                sir = SOC_SBX_CFG_SIRIUS(unit);
                if (sir->cs.gbl_stats) {
                    sal_free(sir->cs.gbl_stats);
                    sir->cs.gbl_stats = NULL;
                }
                if (sir->cs.slq_stats) {
                    sal_free(sir->cs.slq_stats);
                    sir->cs.slq_stats = NULL;
                }
                for (index = 0; index < FD_DROP_TYPE_COUNT; index++) {
                    if (sir->cs.fd_drop[index]) {
                        sal_free(sir->cs.fd_drop[index]);
                        sir->cs.fd_drop[index] = NULL;
                    }
                }
                if (sir->cs.fifo_dma_rbuf_begin) {
                    soc_cm_sfree(unit, sir->cs.fifo_dma_rbuf_begin);
                    sir->cs.fifo_dma_rbuf_begin = NULL;
                    sir->cs.fifo_dma_rbuf_read_ptr = NULL;
                    sir->cs.fifo_dma_rbuf_end = NULL;
                }
                if (sir->cs.slq_stats) {
                    sal_free(sir->cs.slq_stats);
                    sir->cs.slq_stats = NULL;
                }
                if (sir->cs.slq_stats) {
                    sal_free(sir->cs.slq_stats);
                    sir->cs.slq_stats = NULL;
                }
                if (sir->cs.slq_stats) {
                    sal_free(sir->cs.slq_stats);
                    sir->cs.slq_stats = NULL;
                }
                if (sir->cs.slq_stats) {
                    sal_free(sir->cs.slq_stats);
                    sir->cs.slq_stats = NULL;
                }
                if (sir->lMcAggrLock) {
                    sal_mutex_destroy(sir->lMcAggrLock);
                    sir->lMcAggrLock = NULL;
                }
            } /* if (SOC_SBX_CFG_SIRIUS(unit)) */
            if (sbx->custom_stats) {
                sal_free(sbx->custom_stats);
                sbx->custom_stats = NULL;
            }
        } /* if (SOC_SBX_CFG(unit)) */
    } /* if (SOC_CONTROL(unit)) */
    soc_sirius_state_cleanup(unit);
    soc_sbx_connect_deinit(unit);

#if 0
    if (sirius_mem_info[unit]) {
        sal_free(sirius_mem_info[unit]);
        sirius_mem_free[unit] = NULL;
    }
#endif

    return SOC_E_NONE;
}

/*
 * Function:
 *     soc_reset_bcm88230_a0
 * Purpose:
 *     reset sirius and bringup cmic interface only for register and memory access
 * Parameters:
 *     unit - Device number
 * Returns:
 *     SOC_E_NONE - Success
 *     SOC_E_XXX  - Failure
 * Notes:
 *     Assumes valid unit, soc control.
 */
int
soc_sirius_reset(int unit)
{
    int rv = SOC_E_NONE;
    siriusInitParams_t *hwSiriusInitParams_sp;
    soc_control_t       *soc;

    if (!SOC_UNIT_VALID(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "soc_init: unit %d not valid\n"), unit));
        return SOC_E_UNIT;
    }

    soc = SOC_CONTROL(unit);

    if (!(soc->soc_flags & SOC_F_ATTACHED)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "soc_init: unit %d not attached\n"), unit));
        return(SOC_E_UNIT);
    }

    /* Setup Sirius HW init parameters based on config */
    hwSiriusInitParams_sp = sal_alloc(sizeof(siriusInitParams_t), "Sirius_init_st");
    if (hwSiriusInitParams_sp == NULL) {
        return SOC_E_MEMORY;
    }

    sal_memset(hwSiriusInitParams_sp, 0 ,sizeof(siriusInitParams_t));

    hwSiriusInitParams_sp->unit = unit;
    hwSiriusInitParams_sp->reset = TRUE;
    hwSiriusInitParams_sp->bResetOnly = TRUE;

    rv = _soc_sirius_hw_init(hwSiriusInitParams_sp);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Sirius hardware reset failed\n")));
    }

    sal_free(hwSiriusInitParams_sp);

    return rv;
}

int
soc_sirius_port_info_config(int unit, int drv_dev_id, int dev_id)
{
    int                 i, port, hg, pno, blk;
    soc_info_t          *si;
    int                 total_ports = 0, total_hg_ports = 0;
    soc_port_info_t     *port_info;
    soc_driver_t        *driver;
    static soc_port_info_t *default_port_info = NULL;
    int                 hg_min, hg_max;
    int                 bTmeMode = 0;

    si     = &SOC_INFO(unit);
    driver = SOC_DRIVER(unit);

    /*=========================================================
     * Alloc new port info structure
     *=========================================================*/
    if (default_port_info == NULL) {
        default_port_info = driver->port_info;
    }

    /* Load port mapping into 'port_info' and 'block_info' device driver */
    /* free old array if its not the default */
    if (driver->port_info &&
        (driver->port_info != default_port_info))
    {
        sal_free(driver->port_info);
        driver->port_info = NULL;
    }

    /* set defaults first */
    driver->port_info = default_port_info;

    bTmeMode = soc_property_get(unit, spn_QE_TME_MODE, 0);
    total_hg_ports = SB_FAB_DEVICE_SIRIUS_NUM_HG_PORTS;
    total_ports = (SB_FAB_DEVICE_SIRIUS_NUM_HG_PORTS        + /* HG ports, upto 8 */
		   1                                        + /* CPU port */
		   SB_FAB_DEVICE_SIRIUS_SFI_LINKS           + /* SFI port, upto 28 */
		   SB_FAB_DEVICE_SIRIUS_SCI_LINKS           + /* SCI port, upto 2 */
		   SB_FAB_DEVICE_SIRIUS_NUM_REQUEUE_PORTS   + /* Requeue port, upto 2*/
		   1);                                        /* end of list entry */

    port_info = sal_alloc((sizeof(soc_port_info_t) * total_ports),
                          "sirius_port_info");
    if (port_info == NULL) {
        return SOC_E_MEMORY;
    }

    /* init port info to the 'end of list' entry */
    for (port=0; port<total_ports; port++) {
        port_info[port].blk     = -1;
        port_info[port].bindex  = -1;
    }

    driver->port_info = port_info;

    /*=========================================================
     * port info blk and bindex
     *=========================================================*/
    /* HG Interface Ports */
    port = 0;
    for (hg = 0; hg < total_hg_ports; hg++, port++) {
         port_info[port].blk    = soc_sbx_block_find(unit, SOC_BLK_GXPORT, hg);
         port_info[port].bindex = 0;
    }

    /* CPU Port */
    port_info[port].blk    = soc_sbx_block_find(unit, SOC_BLK_CMIC, 0);
    port_info[port].bindex = -1;
    port++;

    /* SFI/SCI Ports */
    if ((dev_id != BCM56613_DEVICE_ID &&
         dev_id != BCM56931_DEVICE_ID &&
         dev_id != BCM56936_DEVICE_ID &&
         dev_id != BCM88231_DEVICE_ID &&
         dev_id != BCM88236_DEVICE_ID) && 
        (bTmeMode != SOC_SBX_QE_MODE_TME_BYPASS) && (bTmeMode != SOC_SBX_QE_MODE_TME)) {
	/* SFI & SCI Ports maps
	 * SCI 0-1   (i = 22-23) ports in SOC_BLK_SC_TOP block, block index 0-1
	 * SFI 0-9   (i = 0 - 9) ports in SOC_BLK_SC_TOP block, block index 2-11
	 * SFI 10-21 (i = 10-21) ports in SOC_BLK_SF_TOP block, block index 0-11
	 */
	for (i=0; i<(SB_FAB_DEVICE_SIRIUS_SFI_LINKS + SB_FAB_DEVICE_SIRIUS_SCI_LINKS); i++, port++) {
	    if ( (i < 10) || (i >= SB_FAB_DEVICE_SIRIUS_SFI_LINKS) ) {
		port_info[port].blk    = soc_sbx_block_find(unit, SOC_BLK_SC_TOP, 0);
		if (i < 10) {
		    port_info[port].bindex = i+2;
		} else {
		    port_info[port].bindex = i-SB_FAB_DEVICE_SIRIUS_SFI_LINKS;
		}
	    } else {
		port_info[port].blk    = soc_sbx_block_find(unit, SOC_BLK_SF_TOP, 0);
		port_info[port].bindex = i-10;
	    }
	}
    } /* if dev_id != BCM56613_DEVICE_ID */

    /* Requeue Ports */
    for (i=0; i<SB_FAB_DEVICE_SIRIUS_NUM_REQUEUE_PORTS; i++, port++) {
	port_info[port].blk    = soc_sbx_block_find(unit, SOC_BLK_EP, 0);
	port_info[port].bindex = i;
    }

    /*=========================================================
     * Add port into pbmp
     *=========================================================*/
    for (blk = 0; blk < SOC_MAX_NUM_BLKS; blk++) {
        si->block_port[blk] = REG_PORT_ANY;
    }

    /* hg ports */
    hg_min = 0;
    hg_max = hg_min + total_hg_ports - 1;

    for (port = hg_min; port <= hg_max; port++) {
        si->port_type[port] = SOC_BLK_GXPORT;
	if ( (dev_id == BCM88239_DEVICE_ID) && (port >= (hg_min + 4)) ) {
	    /* BCM88239 only support 2 higig ports */
	    continue;
	}

        if ( port >= (hg_min + 4) ) {
	    if (((soc_property_get(unit, spn_QE_TME_MODE,      \
                                  SOC_SBX_CFG(unit)->bTmeMode) \
                                            == SOC_SBX_QE_MODE_FIC) ||
             (soc_property_get(unit, spn_QE_TME_MODE,      \
                                  SOC_SBX_CFG(unit)->bTmeMode) \
                                            == SOC_SBX_QE_MODE_HYBRID))) {
                /* fic/hybrid mode only use first 4 hg ports */
                continue;
            }
        }

        pno = port - hg_min;
        si->port_offset[port] = pno;
        if ( (blk = soc_sbx_block_find(unit, SOC_BLK_GXPORT, pno)) < 0) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "HG port %d not found\n"), port));
            return SOC_E_INTERNAL;
        }
        si->block_valid[blk] += 1;
        if (si->block_port[blk] < 0) {
            si->block_port[blk] = port;
        }
        SOC_PBMP_PORT_ADD(si->block_bitmap[blk], port);
        if (!SAL_BOOT_BCMSIM && (soc_property_get(unit, spn_PBMP_XPORT_XE, 0) || soc_property_get(unit, spn_DIAG_HG_AS_XE, 0))) {
            /* emulator might use hg as 10G port */
            SBX_ADD_PORT(xe, port);
            SBX_ADD_PORT(ether, port);
	    sal_snprintf(SOC_PORT_NAME(unit,port),
			 sizeof(si->port_name[port]),
			 "xe%d", pno);
	    si->port_speed_max[port] = 10000;
        } else if (!SAL_BOOT_BCMSIM && (soc_property_get(unit, spn_PBMP_XPORT_GE, 0) || soc_property_get(unit, spn_DIAG_HG_AS_GE, 0))) {
            /* emulator might use hg as GE port */
            SBX_ADD_PORT(ge, port);
            SBX_ADD_PORT(ether, port);
	    sal_snprintf(SOC_PORT_NAME(unit,port),
			 sizeof(si->port_name[port]),
			 "ge%d", pno);
	    si->port_speed_max[port] = 2500;
        } else {
            /* all other case use hg as higig interfaces */
            SBX_ADD_PORT(st, port);
            SBX_ADD_PORT(hg, port);
            SOC_HG2_ENABLED_PORT_ADD(unit, port);
	    sal_snprintf(SOC_PORT_NAME(unit,port),
			 sizeof(si->port_name[port]),
			 "hg%d", pno);
	    si->port_speed_max[port] = 25000;
        }
        SBX_ADD_PORT(port,port);
	SBX_ADD_PORT(gx, port);
        SBX_ADD_PORT(all,port);
    }
    if (!SAL_BOOT_BCMSIM && (soc_property_get(unit, spn_PBMP_XPORT_XE, 0) || soc_property_get(unit, spn_DIAG_HG_AS_XE, 0))) {
        /* emulator might use hg as 10G port */
        si->xe.min = hg_min;
        si->xe.max = hg_max;
    } else if (!SAL_BOOT_BCMSIM && (soc_property_get(unit, spn_PBMP_XPORT_GE, 0) || soc_property_get(unit, spn_DIAG_HG_AS_GE, 0))) {
        /* emulator might use hg as GE port */
        si->ge.min = hg_min;
        si->ge.max = hg_max;
    } else {
        /* all other case use hg as higig interfaces */
        si->hg.min = hg_min;
        si->hg.max = hg_max;
    }

    /* cpu port */
    si->ipic_port = -1;
    si->cmic_port = port;
    si->cmic_block = SOC_BLK_CMIC;
    si->port_type[port] = SOC_BLK_CMIC;
    SOC_PBMP_PORT_ADD((si->cmic_bitmap), port);
    SBX_ADD_PORT(all, port);
    sal_snprintf(SOC_PORT_NAME(unit,port),
                 sizeof(si->port_name[port]),
                 "cpu");
    port++;

    /* default to have 22 sfi ports and 2 sci ports
     */
#define _SIRIUS_DEFAULT_NUM_SFI_PORTS (22)
#define _SIRIUS_DEFAULT_NUM_SCI_PORTS (2)
    si->sfi.min = port;
    si->sfi.max = si->sfi.min + SB_FAB_DEVICE_SIRIUS_NUM_SERIALIZERS - 1;
    for (port = si->sfi.min; port < (si->sfi.min + _SIRIUS_DEFAULT_NUM_SFI_PORTS); port++) {
        if (dev_id != BCM56613_DEVICE_ID &&
            dev_id != BCM88231_DEVICE_ID &&
            dev_id != BCM88236_DEVICE_ID &&
            dev_id != BCM56931_DEVICE_ID &&
            dev_id != BCM56936_DEVICE_ID &&
	    (bTmeMode != SOC_SBX_QE_MODE_TME_BYPASS) && (bTmeMode != SOC_SBX_QE_MODE_TME)) {
	    SBX_ADD_PORT(sfi,port);
	    SBX_ADD_PORT(port,port);
	    SBX_ADD_PORT(all,port);
	} /* dev_id != BCM56613_DEVICE_ID */
	if (port < si->sfi.min + 10) {
	    si->port_type[port] = SOC_BLK_SC_TOP; /* sfi port 0-9 are in SC_TOP block */
	} else {
	    si->port_type[port] = SOC_BLK_SF_TOP; /* sfi port 10-21 are in SF_TOP block */
	}
	/* use port_offset to identify serdes number */
	SOC_PORT_OFFSET(unit, port) = port - si->sfi.min + _SIRIUS_DEFAULT_NUM_SCI_PORTS;
	sal_snprintf(SOC_PORT_NAME(unit,port),
		     sizeof(si->port_name[port]),
		     "sfi%d", (port - si->sfi.min));
    }

    si->sci.min = si->sfi.min;
    si->sci.max = si->sfi.max;
    for (port = si->sfi.min + _SIRIUS_DEFAULT_NUM_SFI_PORTS; port <= si->sci.max; port++) {
        if (dev_id != BCM56613_DEVICE_ID &&
            dev_id != BCM88231_DEVICE_ID &&
            dev_id != BCM88236_DEVICE_ID &&
            dev_id != BCM56931_DEVICE_ID &&
            dev_id != BCM56936_DEVICE_ID &&
	    (bTmeMode != SOC_SBX_QE_MODE_TME_BYPASS) && (bTmeMode != SOC_SBX_QE_MODE_TME)) {
	    SBX_ADD_PORT(sci,port);
	    SBX_ADD_PORT(port,port);
	    SBX_ADD_PORT(all,port);
	} /* dev_id != BCM56613_DEVICE_ID */
	si->port_type[port] = SOC_BLK_SC_TOP;
	/* use port_offset to identify serdes number */
	SOC_PORT_OFFSET(unit, port) = port - si->sfi.min - _SIRIUS_DEFAULT_NUM_SFI_PORTS;
	sal_snprintf(SOC_PORT_NAME(unit,port),
		     sizeof(si->port_name[port]),
		     "sci%d", (port - si->sci.min - _SIRIUS_DEFAULT_NUM_SFI_PORTS));
    }

    if (SOC_SBX_QE_MODE_FIC != soc_property_get(unit, spn_QE_TME_MODE, 0)) {
        /* requeue ports */
        si->req.min = port; /* because it was initialised to zero and never set */
        for (i=0; i<SB_FAB_DEVICE_SIRIUS_NUM_REQUEUE_PORTS; i++, port++) {
            SBX_ADD_PORT(req,port);
            SBX_ADD_PORT(port,port);
            SBX_ADD_PORT(all,port);
            si->port_type[port] = SOC_BLK_EP;
            SOC_PORT_OFFSET(unit, port) = i;
            sal_snprintf(SOC_PORT_NAME(unit,port), sizeof(si->port_name[port]), "req%d", i);
        }
    }

    si->port_num = port;

    return SOC_E_NONE;
}


/* Static functions for hw init
 * The hw init is splited into 3 steps in case some block requires multi-step
 * bring up. If certain blocks require multi-step bringup, split the function
 * and put it into corresponding hw_init_stepx calls.
 */
static int
_soc_sirius_hw_init( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init called.\n")));

    rv = _soc_sirius_hw_init_step0(pInitParams);
    if (rv != SOC_E_NONE) {
        return rv;
    }

    rv = _soc_sirius_hw_init_step1(pInitParams);
    if (rv != SOC_E_NONE) {
        return rv;
    }

    rv = _soc_sirius_hw_init_step2(pInitParams);
    if (rv != SOC_E_NONE) {
        return rv;
    }

    if( pInitParams->bCleanUp ) {
        rv = _soc_sirius_hw_init_cleanup(pInitParams);
        if (rv != SOC_E_NONE) {
            return rv;
        }
    }

    return rv;
}

static int
_soc_sirius_hw_init_step0( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    soc_control_t       *soc;
    soc_persist_t       *sop;
    soc_mem_t           mem;
    uint regval;
    soc_timeout_t timeout;
    uint32 nInitDone = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init step 0 called.\n")));

    rv = _soc_sirius_hw_init_cmic(pInitParams);
    if (rv != SOC_E_NONE) {
        return rv;
    }


    if (pInitParams->bResetOnly) {
	return rv;
    }


    /*
     * Must initialize EP before Xport
     */
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ep enable called.\n")));

    SOC_IF_ERROR_RETURN(READ_EP_CONFIGr(SIRIUS_UNIT, &regval));
    soc_reg_field_set(SIRIUS_UNIT, EP_CONFIGr, &regval, SOFT_RESETf, 0);
    if (SOC_SBX_CFG(SIRIUS_UNIT)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) {
        soc_reg_field_set(SIRIUS_UNIT, EP_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 1);
    } else {
        soc_reg_field_set(SIRIUS_UNIT, EP_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 0);
    }
    SOC_IF_ERROR_RETURN(WRITE_EP_CONFIGr(SIRIUS_UNIT, regval));

    SOC_IF_ERROR_RETURN(READ_EP_CONFIGr(SIRIUS_UNIT, &regval));
    soc_reg_field_set(SIRIUS_UNIT, EP_CONFIGr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_EP_CONFIGr(SIRIUS_UNIT, regval));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        soc_timeout_init(&timeout, _sirius_init_timeout,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_EP_CONFIGr(SIRIUS_UNIT, &regval));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT,EP_CONFIGr,regval,INIT_DONEf);
            if (nInitDone)
                break;
        }
    }

    /*
     * Must initialize BP before Xport
     */
    rv = _soc_sirius_hw_init_bp(pInitParams);
    if (rv != SOC_E_NONE) {
        return rv;
    }

    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(SIRIUS_UNIT, &regval));
    if (SOC_SBX_CFG(SIRIUS_UNIT)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) {
        soc_reg_field_set(SIRIUS_UNIT, ES_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 1);
    } 
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(SIRIUS_UNIT, regval));

    /* A bunch of stuff that I don't know where to put
     */

    /*
     * Update saved chip state to reflect values after reset.
     */
    soc = SOC_CONTROL(SIRIUS_UNIT);
    sop = SOC_PERSIST(SIRIUS_UNIT);

    soc->soc_flags &= SOC_F_RESET;

    sop->debugMode = 0;
    soc->gbpMemSize = 0;                /* Set when sized later */
    soc->gbpBanks = 0;
    soc->gbpDDR = 0;
    soc->gbpWidth = 0;
    soc->gbpFullEnable = 0;
    soc->gbpFullTime = 0;
    soc->pciParityDPC = 0;
    soc->pciFatalDPC = 0;

    /*
     * Initialize memory table status.
     */
    for (mem = 0; mem < NUM_SOC_MEM; mem++) {
        if (SOC_MEM_IS_VALID(SIRIUS_UNIT, mem)) {
            sal_memset(sop->memState[mem].count, 0,
                       sizeof (sop->memState[mem].count));

            /* Disable caching, if enabled */
            (void)soc_mem_cache_set(SIRIUS_UNIT, mem, MEM_BLOCK_ALL, FALSE);
        }
    }

    return rv;
}

#define SIRIUS_TREAD_EN_START (0xE)
#define SIRIUS_TREAD_EN_END   (0x9)

static int
_soc_sirius_hw_init_step1( siriusInitParams_t *pInitParams)
{
    int status = SOC_E_NONE;
    int32 unit = (int32) pInitParams->unit;
    uint32 i, tread_en;
    uint32 tread_en_start=0;
    uint32 tread_en_end=0;
    int user_tread_en=0;
    uint32 ci_train_errors = 0;
    uint8  ci_train_failed = FALSE;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init step 1 called.\n")));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        status = _soc_sirius_hw_init_xp(pInitParams);
        if (status != SOC_E_NONE) {
            return status;
        }
    }

    if (pInitParams->bResetOnly) {
        /* if reset only, don't need to bring up ci interface and other blocks */
        return status;
    }

    if (!SAL_BOOT_BCMSIM && soc_property_get(unit, spn_DIAG_EMULATOR_PARTIAL_INIT, 0)) {
        status = _soc_sirius_hw_init_sc_sf(pInitParams);
        if (status != SOC_E_NONE) {
            return status;
        }
    }

    for (i = 0; i < pInitParams->uDdr3NumMemories; i++) {

      /* use the soc property if it exists */
      user_tread_en = soc_property_port_get(unit,i,spn_SIRIUS_DDR3_TREAD_ENB,-1);
      if (user_tread_en >= 0 ) {
	tread_en_start = user_tread_en;
	tread_en_end   = user_tread_en;
      } else {
	tread_en_start = SIRIUS_TREAD_EN_START;
	tread_en_end   = SIRIUS_TREAD_EN_END;
      }

	for (tread_en = tread_en_start; tread_en >= tread_en_end; tread_en--) {

	    /* train the tread_en */
	    pInitParams->ci[i].read_enb = tread_en;

	    status =_soc_sirius_hw_init_ci(i,pInitParams);
	    if (status != SOC_E_NONE) {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("CI%d bringup returned (%s)\n"), i, bcm_errmsg(status)));
	    }

	    LOG_VERBOSE(BSL_LS_SOC_COMMON,
	                (BSL_META("Training ci%d tread_en %d.\n"),
	                 i, tread_en));

	    if (!SAL_BOOT_QUICKTURN && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
  	        status = soc_sirius_ci_ddr_verify(unit, i);

		if (status == SOC_E_NONE) {
		    /* passed functional tests, move on to next ci */
		    LOG_VERBOSE(BSL_LS_SOC_COMMON,
		                (BSL_META("Training ci%d tread_en %d OK.\n"),
		                 i, tread_en));
		    break;
		} else {
		    LOG_VERBOSE(BSL_LS_SOC_COMMON,
		                (BSL_META("Training ci%d tread_en %d failed.\n"),
		                 i, tread_en));
		    ci_train_errors++;
		}
	    }
	}

	if (!SAL_BOOT_BCMSIM && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
	  if (ci_train_errors == (tread_en_start - tread_en_end)+1) {
	    LOG_CLI((BSL_META("CI%d had DDR training failures on tread_en values\n"), i));
	    ci_train_failed = TRUE;
	  }
	}
	ci_train_errors = 0;
    }

    /* exit if one or more CI interfaces had failures */
    if (ci_train_failed) {
      return SOC_E_INIT;
    }

    /* only configure xport and ddr interface if runing on emulator only */
    if (!SAL_BOOT_BCMSIM && soc_property_get(unit, spn_DIAG_EMULATOR_PARTIAL_INIT, 0)) {
        soc_sbx_sirius_config_t *sir = SOC_SBX_CFG_SIRIUS(pInitParams->unit);

	SHR_BITSET(sir->property, DIAG_EMULATOR_PARTIAL_INIT);
        /*
         * In order to validate the cs DMA, the emulator needs to
         * initialize the CS block to create the DMA ring buffer
         * and set both s/w and h/w ptrs to the same DMA-able buffer.
         */
        status = _soc_sirius_hw_init_cs(pInitParams);
        if (status != SOC_E_NONE) {
            return status;
        }
	/*
	 * Initialize Flags for system verification use.
	 */
        for (i=0; i<8; i++) {
          sir->type_res_flags[PRED_TYPE_RB][i*2] |= (PRED_TYPE_FLAGS_INTF |
                                                     PRED_TYPE_FLAGS_UC);

          sir->type_res_flags[PRED_TYPE_RB][i*2+1] |= (PRED_TYPE_FLAGS_INTF |
                                                       PRED_TYPE_FLAGS_MC);

          sir->type_res_flags[PRED_TYPE_EP][i*2]  |= (PRED_TYPE_FLAGS_INTF |
                                                      PRED_TYPE_FLAGS_UC);

          sir->type_res_flags[PRED_TYPE_EP][i*2+1] |= (PRED_TYPE_FLAGS_INTF |
                                                       PRED_TYPE_FLAGS_MC);
        }
        return SOC_E_NONE;
    }

    status = _soc_sirius_hw_init_qs(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_tx(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_qm(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_rb(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_cs(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_ts(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_sc_sf(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_fr(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_eb(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_es(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_ep(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_fd(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_ff(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_hc(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }

    status = _soc_sirius_hw_init_xmac(pInitParams);
    if (status != SOC_E_NONE) {
        return status;
    }
    return status;
}

static int
_soc_sirius_hw_init_step2( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32 unit = (int32) pInitParams->unit;
    uint32  regval = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init step 2 called.\n")));

    /* passthru_mode_enable need to be toggled here to enable e2ecc processing
     * may not be the best place here but should be the safest place
     */
    if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) {
	SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
        soc_reg_field_set(unit, ES_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 0);
	SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

	sal_usleep(100);

        soc_reg_field_set(unit, ES_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 1);
	SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));
    } 


    return rv;
}

static int
_soc_sirius_hw_init_cleanup( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init cleanup called.\n")));

    return rv;
}

/*
 *  Builds the type_res_flags values based upon the current layout of the type
 *  resolution or class resolution table.  This assumes the internal state for
 *  the predicates is up-to-date and so that must be correct before calling.
 *
 *  Note this does not manipulate the SHARED bit.
 *
 *  This needs to be called to update the type_res_flags at any point where the
 *  interfaces or multicast bit state affected by a predicate would change, or
 *  whenever the mapping between predicates and actions would change.
 */
static int
_soc_sirius_update_type_res_flags(int unit, int ingress)
{
    static const unsigned int ingressField[16] = {TYPE0f, TYPE1f, TYPE2f, TYPE3f,
                                                  TYPE4f, TYPE5f, TYPE6f, TYPE7f,
                                                  TYPE8f, TYPE9f, TYPE10f, TYPE11f,
                                                  TYPE12f, TYPE13f, TYPE14f, TYPE15f};
    static const unsigned int egressField[16] = {VALUE0f, VALUE1f, VALUE2f, VALUE3f,
                                                 VALUE4f, VALUE5f, VALUE6f, VALUE7f,
                                                 VALUE8f, VALUE9f, VALUE10f, VALUE11f,
                                                 VALUE12f, VALUE13f, VALUE14f, VALUE15f};
    union {
        type_resolution_table_entry_t ingressBuffer[1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)];
        ep_class_resolution_entry_t egressBuffer[1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)];
    } u;
    uint32 type_res_temp[SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS];
    uint32 field;
    uint32 current;
    const unsigned int *fields;
    uint8 *buffer;
    unsigned int mem;
    unsigned int index;
    unsigned int offset;
    unsigned int size;
    unsigned int stage;
    int result = SOC_E_NONE;

    if (ingress) {
        fields = &(ingressField[0]);
        mem = TYPE_RESOLUTION_TABLEm;
        size = sizeof(type_resolution_table_entry_t);
        buffer = (uint8*)(&(u.ingressBuffer[0]));
        stage = 0;
    } else {
        fields = &(egressField[0]);
        mem = EP_CLASS_RESOLUTIONm;
        size = sizeof(ep_class_resolution_entry_t);
        buffer = (uint8*)(&(u.egressBuffer[0]));
        stage = 2;
    }
    /* get the mapping table */
    for (index = 0;
         (SOC_E_NONE == result) &&
         (index < (1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)));
         index++) {
        result = soc_mem_read(unit,
                              mem,
                              MEM_BLOCK_ANY,
                              index,
                              &(buffer[size * index]));
    } /* for (all rows in the memory) */
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unable to read unit %d %s predicate->parser"
                            " map: %d (%s)\n"),
                   unit,
                   ingress?"ingress":"egress",
                 result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    /* initially assume a parser sees no frames */
    for (index = 0;
         index < SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS;
         index++) {
        type_res_temp[index] = 0;
    }
    /*
     *  For every possible combination of predicate states, add in the frames
     *  that would match that combination of predicate states to the parser
     *  selected by that combination of predicate states.
     */
    for (index = 0;
         index < (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES);
         index++) {
        field = soc_mem_field32_get(unit,
                                    mem,
                                    &(buffer[size * (index >> 4)]),
                                    fields[index & 0xF]);
        current = PRED_TYPE_FLAGS_ALL_BITS;
        for (offset = 0;
             offset < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES;
             offset++) {
            if (index & (1 << offset)) {
                current &= SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[stage][offset];
            } else {
                current &= SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[stage + 1][offset];
            }
        }
        if (PRED_TYPE_FLAGS_INTF_ANY & current) {
            /* at least one interface hits this parser by this rule */
            type_res_temp[field] |= current;
        }
    } /* for (all possible predicate vector values) */
    for (index = 0;
         index < SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS;
         index++) {
        SIR_EVERB((SIR_MSG1("unit %d %s parser %2d flags = %08X\n"),
                   unit,
                   ingress?"ingress":"egress",
                   index,
                   type_res_temp[index]));
        SOC_SBX_CFG_SIRIUS(unit)->type_res_flags[stage >> 1][index] = type_res_temp[index];
    }
    return result;
}

/*
 *  Allocate a predicate
 */
int
soc_sirius_predicate_allocate(int unit,
                               uint32 flags,
                               unsigned int *predId)
{
    uint16 *preds;
    uint16 *predsSdk;
    unsigned int pid;

    if (!predId) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predId pointer must not be NULL\n")));
        return SOC_E_PARAM;
    }
    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    pid = *predId;
    if (((SIRIUS_PREDICATE_FLAGS_INGRESS | SIRIUS_PREDICATE_FLAGS_EGRESS) ==
         (flags & (SIRIUS_PREDICATE_FLAGS_INGRESS |
                   SIRIUS_PREDICATE_FLAGS_EGRESS))) ||
        (0 == (flags & (SIRIUS_PREDICATE_FLAGS_INGRESS |
                        SIRIUS_PREDICATE_FLAGS_EGRESS)))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate must be either ingress or egress"
                              " on unit %d\n"),
                   unit));
        return SOC_E_PARAM;
    }
    if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) {
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPreds);
        predsSdk = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPredsSdk);
        pid -= SIRIUS_PREDICATE_OFFSET_INGRESS;
    } else { /* if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->egressPreds);
        predsSdk = &(SOC_SBX_SIRIUS_STATE(unit)->egressPredsSdk);
        pid -= SIRIUS_PREDICATE_OFFSET_EGRESS;
    } /* if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) */
    if (flags & SIRIUS_PREDICATE_FLAGS_WITH_ID) {
        /* caller specified ID */
        /* coverity[unsigned_compare] */
        if ((0 > pid) || (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES <= pid)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%d is invalid %s predicate ID on unit %d\n"),
                       *predId,
                       (flags & SIRIUS_PREDICATE_FLAGS_INGRESS)?"ingress":"egress",
                       unit));
            return SOC_E_PARAM;
        }
        if (flags & SIRIUS_PREDICATE_FLAGS_REPLACE) {
            if (0 == ((*preds) & (1 << pid))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predicate %d not in use; can't"
                                      " replace it\n"),
                           unit,
                           *predId));
                return SOC_E_NOT_FOUND;
            }
            if (flags & SIRIUS_PREDICATE_FLAGS_SDK) {
                if (0 == ((*predsSdk) & (1 << pid))) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d predicate %d not in use by SDK;"
                                          " can't replace it\n"),
                               unit,
                               *predId));
                    return SOC_E_EXISTS;
                }
            } else { /* if (flags & SIRIUS_PREDICATE_FLAGS_SDK) */
                if ((*predsSdk) & (1 << pid)) {
                    LOG_WARN(BSL_LS_SOC_COMMON,
                             (BSL_META_U(unit,
                                         "unit %d predicate %d in use by SDK"
                                         " directly replaced by application\n"),
                              unit,
                              *predId));
                }
            } /* if (flags & SIRIUS_PREDICATE_FLAGS_SDK) */
        } else { /* if (flags & SIRIUS_PREDICATE_FLAGS_REPLACE) */
            if (0 != ((*preds) & (1 << pid))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predicate %d is already in use;"
                                      " must replace it\n"),
                           unit,
                           *predId));
                return SOC_E_EXISTS;
            }
        } /* if (flags & SIRIUS_PREDICATE_FLAGS_REPLACE) */
    } else { /* if (flags & SIRIUS_PREDICATE_FLAGS_WITH_ID) */
        /* caller did not specify ID */
        if (flags & SIRIUS_PREDICATE_FLAGS_REPLACE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d requires WITH_ID with REPLACE\n"),
                       unit));
            return SOC_E_PARAM;
        }
        for (pid = 0; SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES > pid; pid++) {
            if (0 == ((*preds) & (1 << pid))) {
                /* found an available one */
                break;
            }
        }
        if (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES <= pid) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d has no available %s predicate\n"),
                       unit,
                       (flags & SIRIUS_PREDICATE_FLAGS_INGRESS)?"ingress":"egress"));
            return SOC_E_RESOURCE;
        }
    } /* if (flags & SIRIUS_PREDICATE_FLAGS_WITH_ID) */
    (*preds) |= (1 << pid);
    if (flags & SIRIUS_PREDICATE_FLAGS_SDK) {
        /* owned by SDK */
        (*predsSdk) |= (1 << pid);
    } else {
        /* not owned by SDK */
        (*predsSdk) &= ~(1 << pid);
    }
    if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) {
        *predId = pid + SIRIUS_PREDICATE_OFFSET_INGRESS;
    } else { /* if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) */
        *predId = pid + SIRIUS_PREDICATE_OFFSET_EGRESS;
    } /* if (flags & SIRIUS_PREDICATE_FLAGS_INGRESS) */
    return SOC_E_NONE;
}

/*
 *  Return a predicate to the free set.
 */
int
soc_sirius_predicate_free(int unit,
                          unsigned int predId)
{
    uint16 *preds;
    uint16 *predsSdk;
    int *refs;
    unsigned int pid = predId;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }

    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
        ((SIRIUS_PREDICATE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates ingress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPreds);
        predsSdk = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPredsSdk);
        refs = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPredRefs[0]);
        predId -= SIRIUS_PREDICATE_OFFSET_INGRESS;
    } else if ((SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) &&
               ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates egress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->egressPreds);
        predsSdk = &(SOC_SBX_SIRIUS_STATE(unit)->egressPredsSdk);
        refs = &(SOC_SBX_SIRIUS_STATE(unit)->egressPredRefs[0]);
        predId -= SIRIUS_PREDICATE_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate ID %d is not valid on unit %d\n"),
                   predId,
                   unit));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*preds) & (1 << predId))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate %d is not in use\n"),
                   unit,
                   pid));
        return SOC_E_NOT_FOUND;
    }
    if (0 != refs[predId]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate %d is still being referenced\n"),
                   unit,
                   pid));
        return SOC_E_FULL;
    }
    (*preds) &= ~(1 << predId);
    (*predsSdk) &= ~(1 << predId);
    return SOC_E_NONE;
}

/*
 *  Check whether a predicate is in use
 */
int
soc_sirius_predicate_check(int unit,
                           unsigned int predId)
{
    uint16 *preds;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
        ((SIRIUS_PREDICATE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates ingress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPreds);
        predId -= SIRIUS_PREDICATE_OFFSET_INGRESS;
    } else if ((SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) &&
               ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates egress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->egressPreds);
        predId -= SIRIUS_PREDICATE_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate ID %d is not valid on unit %d\n"),
                   predId,
                   unit));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*preds) & (1 << predId))) {
        /* this predicate is not allocated */
        return SOC_E_EMPTY;
    } else {
        /* this predicate is allocated */
        return SOC_E_FULL;
    }
}

/*
 *  Check whether a predicate is in use by the SDK
 */
int
soc_sirius_predicate_check_sdk(int unit,
                               unsigned int predId)
{
    uint16 *preds;

    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
        ((SIRIUS_PREDICATE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates ingress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPredsSdk);
        predId -= SIRIUS_PREDICATE_OFFSET_INGRESS;
    } else if ((SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) &&
               ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates egress */
        preds = &(SOC_SBX_SIRIUS_STATE(unit)->egressPredsSdk);
        predId -= SIRIUS_PREDICATE_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate ID %d is not valid on unit %d\n"),
                   predId,
                   unit));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*preds) & (1 << predId))) {
        /* this predicate is not allocated */
        return SOC_E_EMPTY;
    } else {
        /* this predicate is allocated */
        return SOC_E_FULL;
    }
}

/*
 *  Get the next existing predicate, given a current one (any very large value
 *  for current will fetch the first predicate).
 */
int
soc_sirius_predicate_next(int unit,
                          unsigned int current,
                          unsigned int *next)
{
    int result = SOC_E_NOT_FOUND;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!next) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "next pointer must not be NULL\n")));
        return SOC_E_PARAM;
    }
    do {
        /* figure out next predicate to examine */
        if (current >= ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                         SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) * 2)) {
            /* very large number; go to first ingress predicate */
            current = SIRIUS_PREDICATE_OFFSET_INGRESS;
#if (0 != SIRIUS_PREDICATE_OFFSET_INGRESS)
        } else if (current < SIRIUS_PREDICATE_OFFSET_INGRESS) {
            /* below ingress; go to first ingress predicate */
            current = SIRIUS_PREDICATE_OFFSET_INGRESS;
#endif /* (0 != SIRIUS_PREDICATE_OFFSET_INGRESS) */
        } else if (
#if (0 != SIRIUS_PREDICATE_OFFSET_INGRESS)
                   (current >= SIRIUS_PREDICATE_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_PREDICATE_OFFSET_INGRESS) */
                   (current < ((SIRIUS_PREDICATE_OFFSET_INGRESS - 1) +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES))) {
            /* within ingress; look at next ingress */
            current++;
        } else if (current < SIRIUS_PREDICATE_OFFSET_EGRESS) {
            /* last ingress/between ingress and egress; go to first egress */
            current = SIRIUS_PREDICATE_OFFSET_EGRESS;
        } else if ((current >= SIRIUS_PREDICATE_OFFSET_EGRESS) &&
                   (current < ((SIRIUS_PREDICATE_OFFSET_EGRESS - 1) +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES))) {
            /* within egress; look at next egress */
            current++;
        } else {
            /* at/after end of egress but not large enough to wrap */
            break;
        }
        if (
#if (0 != SIRIUS_PREDICATE_OFFSET_INGRESS)
            (current >= SIRIUS_PREDICATE_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_PREDICATE_OFFSET_INGRESS) */
            (current < (SIRIUS_PREDICATE_OFFSET_INGRESS +
                        SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES))) {
            /* check ingress  */
            if (SOC_SBX_SIRIUS_STATE(unit)->ingressPreds & (1 <<
                                                            (current -
                                                             SIRIUS_PREDICATE_OFFSET_INGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        } else  if ((current >= SIRIUS_PREDICATE_OFFSET_EGRESS) &&
                    (current < (SIRIUS_PREDICATE_OFFSET_EGRESS +
                                SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES))) {
            if (SOC_SBX_SIRIUS_STATE(unit)->egressPreds & (1 <<
                                                           (current -
                                                            SIRIUS_PREDICATE_OFFSET_EGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        }
    } while ((SOC_E_NOT_FOUND == result));
    if (SOC_E_NONE == result) {
        *next = current;
    }
    return result;
}

/*
 *  Configure a predicate.
 *
 *  This also updates the predicate info flags, kept in the unit configuration
 *  struct, SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags.  These flags reflect the
 *  various PRED_TYPE_* flags that are used by the central statistics code to
 *  deal with what kind of frames go to which parsers.
 *
 *  pred_info_flags[0][pred] = frames that match ingress [pred] TRUE state
 *  pred_info_flags[1][pred] = frames that match ingress [pred] FALSE state
 *  pred_info_flags[2][pred] = frames that match egress [pred] TRUE state
 *  pred_info_flags[3][pred] = frames that match egress [pred] FALSE state
 *
 *  These data are used elsewhere in the code to update the type_res_flags so
 *  the central statistics code can figure out what is going on.  Note that
 *  nothing around here actually forces CS updates; the application is expected
 *  to configure its predicates, actions, and predicate_action rules before
 *  setting up statistics.
 */
int
soc_sirius_predicate_set(int unit,
                         unsigned int predId,
                         unsigned int offset,
                         int meta,
                         int range,
                         unsigned int low_mask,
                         unsigned int high_data)
{
    ep_predictive_ranging_entry_t predicate;
    uint32 regval = 0;
    unsigned int pred = predId;
    unsigned int index = 4;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((!meta) && (0x3F < offset)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d fraem offset must be < 64 bytes\n"),
                   unit));
        return SOC_E_PARAM;
    }
    if ((low_mask > 0xFFFF) ||
        (high_data > 0xFFFF)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate comparisons limited to 16b\n"),
                   unit));
        return SOC_E_PARAM;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
        ((SIRIUS_PREDICATE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        if (meta && (0 < offset)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d ingress does not support metadatum %d\n"),
                       unit,
                       offset));
            return SOC_E_PARAM;
        }
        /* predicate ID indicates ingress */
        predId -= SIRIUS_PREDICATE_OFFSET_INGRESS;
        result = soc_reg32_read(unit,
                                soc_reg_addr(unit,
                                             predRegs[predId][0],
                                             REG_PORT_ANY,
                                             0),
                                &regval);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to access unit %d ingress predicate %d:"
                                  " %d (%s)\n"),
                       unit,
                       predId + SIRIUS_PREDICATE_OFFSET_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        }
        soc_reg_field_set(unit,
                          predRegs[predId][0],
                          &regval,
                          predFields[predId][0],
                          offset);
        soc_reg_field_set(unit,
                          predRegs[predId][0],
                          &regval,
                          predFields[predId][1],
                          !(!meta));
        soc_reg_field_set(unit,
                          predRegs[predId][0],
                          &regval,
                          predFields[predId][2],
                          !(!range));
        result = soc_reg32_write(unit,
                                 soc_reg_addr(unit,
                                              predRegs[predId][0],
                                              REG_PORT_ANY,
                                              0),
                                 regval);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d ingress predicate %d:"
                                  " %d (%s)\n"),
                       unit,
                       predId + SIRIUS_PREDICATE_OFFSET_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        } /* (SOC_E_NONE == result) */
        regval = 0;
        soc_reg_field_set(unit,
                          predRegs[predId][1],
                          &regval,
                          predFields[predId][3],
                          low_mask);
        soc_reg_field_set(unit,
                          predRegs[predId][1],
                          &regval,
                          predFields[predId][4],
                          high_data);
        result = soc_reg32_write(unit,
                                 soc_reg_addr(unit,
                                              predRegs[predId][1],
                                              REG_PORT_ANY,
                                              0),
                                 regval);
        if (SOC_E_NONE == result) {
            /* assume all types of frames can hit & miss this predicate */
            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] = PRED_TYPE_FLAGS_ALL_BITS;
            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] = PRED_TYPE_FLAGS_ALL_BITS;
            /* eliminate frames based upon analysis of the predicate */
            if (!meta) {
                /* data from the frame header will be considered */
                if (!range) {
                    /* specific bit values will be considered */
                    if ((0x00 == offset) && (low_mask & 0x0010)) {
                        /* predicate includes multicast bit */
                        if (high_data & 0x0010) {
                            /* predicate TRUE when MC set, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~PRED_TYPE_FLAGS_UC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~PRED_TYPE_FLAGS_MC);
                        } else {
                            /* predicate TRUE when MC clear, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~PRED_TYPE_FLAGS_MC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~PRED_TYPE_FLAGS_UC);
                        }
                    }
                    if ((0x01 == offset) && (low_mask & 0x1000)) {
                        /* predicate includes multicast bit */
                        if (high_data & 0x1000) {
                            /* predicate TRUE when MC set, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~PRED_TYPE_FLAGS_UC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~PRED_TYPE_FLAGS_MC);
                        } else {
                            /* predicate TRUE when MC clear, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~PRED_TYPE_FLAGS_MC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~PRED_TYPE_FLAGS_UC);
                        }
                    }
                } /* if (!range) */
            } else { /* if (!meta) */
                /* metadata will be considered */
                if (range) {
                    /* a range of values will be considered */
                    if (0 == offset) {
                        /* interface number will be considered */
                        for (index = 0;
                             index < 7;
                             index++) {
                            if ((low_mask > index) || (high_data < index)) {
                                /* predicate is false for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            } else {
                                /* predicate is true for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            }
                        }
                    }
                } else { /* if (range) */
                    /* specific bit values will be considered */
                    if (0 == offset) {
                        /* interface number will be considered */
                        for (index = 0;
                             index < 7;
                             index++) {
                            if ((low_mask & index) != high_data) {
                                /* predicate is false for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[0][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            } else {
                                /* predicate is true for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[1][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            }
                        }
                    }
                } /* if (range) */
            } /* if (!meta) */
        } else { /* (SOC_E_NONE == result) */
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d ingress predicate %d:"
                                  " %d (%s)\n"),
                       unit,
                       predId + SIRIUS_PREDICATE_OFFSET_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        } /* (SOC_E_NONE == result) */
        index = 0;
    } else if ((SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) &&
               ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates egress */
        if (meta && ((5 < offset) ||
                     (1 > offset))) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress does not support metadatum %d\n"),
                       unit,
                       offset));
            return SOC_E_PARAM;
        }
        predId -= SIRIUS_PREDICATE_OFFSET_EGRESS;
        sal_memset(&predicate, 0, sizeof(predicate));
        if (meta) {
            soc_mem_field32_set(unit,
                                EP_PREDICTIVE_RANGINGm,
                                &predicate,
                                FIELD_OFFSETf,
                                0);
            soc_mem_field32_set(unit,
                                EP_PREDICTIVE_RANGINGm,
                                &predicate,
                                META_SELf,
                                offset);
        } else {
            soc_mem_field32_set(unit,
                                EP_PREDICTIVE_RANGINGm,
                                &predicate,
                                FIELD_OFFSETf,
                                offset);
            soc_mem_field32_set(unit,
                                EP_PREDICTIVE_RANGINGm,
                                &predicate,
                                META_SELf,
                                0);
        }
        soc_mem_field32_set(unit,
                            EP_PREDICTIVE_RANGINGm,
                            &predicate,
                            RANGEf,
                            !(!range));
        soc_mem_field32_set(unit,
                            EP_PREDICTIVE_RANGINGm,
                            &predicate,
                            HI_DATAf,
                            high_data);
        soc_mem_field32_set(unit,
                            EP_PREDICTIVE_RANGINGm,
                            &predicate,
                            LO_MASKf,
                            low_mask);
        result = WRITE_EP_PREDICTIVE_RANGINGm(unit,
                                              MEM_BLOCK_ALL,
                                              predId,
                                              &predicate);
        if (SOC_E_NONE == result) {
            /* assume all types of frames can hit & miss this predicate */
            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] = PRED_TYPE_FLAGS_ALL_BITS;
            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] = PRED_TYPE_FLAGS_ALL_BITS;
            /* eliminate frames based upon analysis of the predicate */
            if (!meta) {
                /* data from the frame header will be considered */
                if (!range) {
                    /* specific bit values will be considered */
                    if ((0x01 == offset) && (low_mask & 0x0008)) {
                        /* predicate includes multicast bit */
                        if (high_data & 0x0008) {
                            /* predicate TRUE when MC set, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~PRED_TYPE_FLAGS_UC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~PRED_TYPE_FLAGS_MC);
                        } else {
                            /* predicate TRUE when MC clear, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~PRED_TYPE_FLAGS_MC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~PRED_TYPE_FLAGS_UC);
                        }
                    }
                    if ((0x02 == offset) && (low_mask & 0x0800)) {
                        /* predicate includes multicast bit */
                        if (high_data & 0x0800) {
                            /* predicate TRUE when MC set, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~PRED_TYPE_FLAGS_UC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~PRED_TYPE_FLAGS_MC);
                        } else {
                            /* predicate TRUE when MC clear, false otherwise */
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~PRED_TYPE_FLAGS_MC);
                            SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~PRED_TYPE_FLAGS_UC);
                        }
                    }
                } /* if (!range) */
            } else { /* if (!meta) */
                /* metadata will be considered */
                if (range) {
                    /* a range of values will be considered */
                    if (ep_intf_num == offset) {
                        /* interface number will be considered */
                        for (index = 0;
                             index < 7;
                             index++) {
                            if ((low_mask > index) || (high_data < index)) {
                                /* predicate is false for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            } else {
                                /* predicate is true for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            }
                        }
                    }
                } else { /* if (range) */
                    /* specific bit values will be considered */
                    if (ep_intf_num == offset) {
                        /* interface number will be considered */
                        for (index = 0;
                             index < 7;
                             index++) {
                            if ((low_mask & index) != high_data) {
                                /* predicate is false for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[2][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            } else {
                                /* predicate is true for this interface */
                                SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[3][predId] &= (~(1 << (index + PRED_TYPE_FLAGS_IF_SHIFT)));
                            }
                        }
                    }
                } /* if (range) */
            } /* if (!meta) */
        } else { /* (SOC_E_NONE == result) */
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d egress predicate %d:"
                                  " %d (%s)\n"),
                       unit,
                       predId + SIRIUS_PREDICATE_OFFSET_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        } /* (SOC_E_NONE == result) */
        index = 2;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate ID %d is not valid on unit %d\n"),
                   predId,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    if (index < 3) {
        SIR_EVERB((BSL_META("unit %d %sgress predicate %d [%s:%d,%s:%04X/%04X]"
                            "->[%08X/%08X] write: %d (%s)\n"),
                   unit,
                   (pred < SIRIUS_PREDICATE_OFFSET_EGRESS)?"in":"e",
                   predId,
                   meta?"META":"FRAME",
                   offset,
                   range?"RANGE":"MASK",
                   low_mask,
                   high_data,
                   SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[index][predId],
                   SOC_SBX_CFG_SIRIUS(unit)->pred_info_flags[index+1][predId],
                   result,
                   _SHR_ERRMSG(result)));
    }
    return _soc_sirius_update_type_res_flags(unit,
                                             pred < SIRIUS_PREDICATE_OFFSET_EGRESS);
}

/*
 *  Configure a predicate that the SDK should own
 */
int
soc_sirius_predicate_set_sdk(int unit,
                             unsigned int predId,
                             unsigned int offset,
                             int meta,
                             int range,
                             unsigned int low_mask,
                             unsigned int high_data)
{
    if (SOC_E_FULL != soc_sirius_predicate_check_sdk(unit, predId)) {
        /* this predicate is not allocated to the SDK */
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate %d is not allocated to SDK\n"),
                   unit,
                   predId));
        return SOC_E_NOT_FOUND;
    }
    return soc_sirius_predicate_set(unit,
                                    predId,
                                    offset,
                                    meta,
                                    range,
                                    low_mask,
                                    high_data);
}

/*
 *  Get a predicate's configuration
 */
int
soc_sirius_predicate_get(int unit,
                         unsigned int predId,
                         unsigned int *offset,
                         int *meta,
                         int *range,
                         unsigned int *low_mask,
                         unsigned int *high_data)
{
    ep_predictive_ranging_entry_t predicate;
    uint32 regval0 = 0;
    uint32 regval1 = 0;

    if ((!offset) ||
        (!meta) ||
        (!range) ||
        (!low_mask) ||
        (!high_data)) {
        /* all out params are required */
        return BCM_E_PARAM;
    }
    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }

    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
        ((SIRIUS_PREDICATE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates ingress */
        predId -= SIRIUS_PREDICATE_OFFSET_INGRESS;
        SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
                                           soc_reg_addr(unit,
                                                        predRegs[predId][0],
                                                        REG_PORT_ANY,
                                                        0),
                                           &regval0));
        SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
                                           soc_reg_addr(unit,
                                                        predRegs[predId][1],
                                                        REG_PORT_ANY,
                                                        0),
                                           &regval1));
        *offset = soc_reg_field_get(unit,
                                    predRegs[predId][0],
                                    regval0,
                                    predFields[predId][0]);
        *meta = soc_reg_field_get(unit,
                                  predRegs[predId][0],
                                  regval0,
                                  predFields[predId][1]);
        *range = soc_reg_field_get(unit,
                                   predRegs[predId][0],
                                   regval0,
                                   predFields[predId][2]);
        *low_mask = soc_reg_field_get(unit,
                                      predRegs[predId][1],
                                      regval1,
                                      predFields[predId][3]);
        *high_data = soc_reg_field_get(unit,
                                       predRegs[predId][1],
                                       regval1,
                                       predFields[predId][4]);
    } else if ((SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) &&
               ((SIRIUS_PREDICATE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES) > predId)) {
        /* predicate ID indicates egress */
        predId -= SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(READ_EP_PREDICTIVE_RANGINGm(unit,
                                                        MEM_BLOCK_ANY,
                                                        predId,
                                                        &predicate));
        *meta = soc_mem_field32_get(unit,
                                    EP_PREDICTIVE_RANGINGm,
                                    &predicate,
                                    META_SELf);
        if (0 == *meta) {
            *offset = soc_mem_field32_get(unit,
                                          EP_PREDICTIVE_RANGINGm,
                                          &predicate,
                                          FIELD_OFFSETf);
            *meta = FALSE;
        } else {
            *offset = *meta;
            *meta = TRUE;
        }
        *range = soc_mem_field32_get(unit,
                                     EP_PREDICTIVE_RANGINGm,
                                     &predicate,
                                     RANGEf);
        *high_data = soc_mem_field32_get(unit,
                                         EP_PREDICTIVE_RANGINGm,
                                         &predicate,
                                         HI_DATAf);
        *low_mask = soc_mem_field32_get(unit,
                                        EP_PREDICTIVE_RANGINGm,
                                        &predicate,
                                        LO_MASKf);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "predicate ID %d is not valid on unit %d\n"),
                   predId,
                   unit));
        return SOC_E_NOT_FOUND;
    }

    return SOC_E_NONE;
}


/*
 *  Clear any ingress predicates that are not in use.
 */
static int
soc_sirius_ingress_predicates_clear_unused(int unit)
{
    unsigned int idx;
    soc_sbx_sirius_state_t *sir = SOC_SBX_SIRIUS_STATE(unit);

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    for (idx = 0; idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES; idx++) {
        if (0 == (sir->ingressPreds & (1 << idx))) {
            /* this one is not in use */
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_set(unit,
                                                         idx + SIRIUS_PREDICATE_OFFSET_INGRESS,
                                                         0x00,
                                                         FALSE,
                                                         FALSE,
                                                         0x0000,
                                                         0xFFFF));
        }
    } /* for (all ingress predicates) */
    return SOC_E_NONE;
}

/*
 *  Clear any egress predicates that are not in use.
 */
static int
soc_sirius_egress_predicates_clear_unused(int unit)
{
    unsigned int idx;
    soc_sbx_sirius_state_t *sir = SOC_SBX_SIRIUS_STATE(unit);

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    for (idx = 0; idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES; idx++) {
        if (0 == (sir->egressPreds & (1 << idx))) {
            /* this one is not in use */
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_set(unit,
                                                         idx + SIRIUS_PREDICATE_OFFSET_EGRESS,
                                                         0x00,
                                                         FALSE,
                                                         FALSE,
                                                         0x0000,
                                                         0xFFFF));
        }
    } /* for (all ingress predicates) */
    return SOC_E_NONE;
}

/*
 *  Unlike the BCM flavour of this, this one takes hardware port index only,
 *  and does not parse GPORTs for read or write value.
 */
int
soc_sirius_port_control_default_queue_access(int unit,
                                             int write,
                                             unsigned int portIndex,
                                             int *value)
{
    uint32 regVal = 0;
    soc_reg_t regId;
    soc_field_t fieldId;
    int rv;

    switch (portIndex) {
    case 0:
        /* CPU */
        regId = RB_DEF_Q_IX_0r;
        fieldId = IF0_DEF_Q_INDEXf;
        break;
    case 1:
        /* HiGig 0 */
        regId = RB_DEF_Q_IX_0r;
        fieldId = IF1_DEF_Q_INDEXf;
        break;
    case 2:
        /* HiGig 1 */
        regId = RB_DEF_Q_IX_1r;
        fieldId = IF2_DEF_Q_INDEXf;
        break;
    case 3:
        /* HiGig 2 */
        regId = RB_DEF_Q_IX_1r;
        fieldId = IF3_DEF_Q_INDEXf;
        break;
    case 4:
        /* HiGig 3 */
        regId = RB_DEF_Q_IX_2r;
        fieldId = IF4_DEF_Q_INDEXf;
        break;
    case 5:
        /* requeue 0 */
        regId = RB_DEF_Q_IX_2r;
        fieldId = IF5_DEF_Q_INDEXf;
        break;
    case 6:
        /* requeue 0 */
        regId = RB_DEF_Q_IX_3r;
        fieldId = IF6_DEF_Q_INDEXf;
        break;
    default:
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d port index %d not valid for default queue\n"),
                   unit,
                   portIndex));
        return SOC_E_PORT;
    }
    rv = soc_reg32_read(unit,
                        soc_reg_addr(unit, regId, REG_PORT_ANY, 0),
                        &regVal);
    if (SOC_E_NONE == rv) {
        if (write) {
            if ((*value) & (~0xFFFF)) {
                LOG_WARN(BSL_LS_SOC_COMMON,
                         (BSL_META_U(unit,
                                     "queue ID %08X bits %08X were ignored\n"),
                          *value,
                          (*value) & (~0xFFFF)));
            }
            soc_reg_field_set(unit, regId, &regVal, fieldId, (*value) & 0xFFFF);
            rv = soc_reg32_write(unit,
                                 soc_reg_addr(unit, regId, REG_PORT_ANY, 0),
                                 regVal);
        } else { /* if (write) */
            *value = soc_reg_field_get(unit, regId, regVal, fieldId);
        } /* if (write) */
    } /* if (SOC_E_NONE == rv) */
    if (SOC_E_NONE != rv) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to %s default queue for unit %d port %d"
                              " (value %08X): %d (%s)\n"),
                   write?"write":"read",
                   unit,
                   portIndex,
                   *value,
                   rv,
                   _SHR_ERRMSG(rv)));
    }
    return rv;
}

/*
 *  Calling this will tear down any existing configuration and replace it
 *  according to the current settings.  Probably very disruptive to traffic,
 *  and so should only be invoked as part of initial configuration.
 *
 *  Note that the multicast predicate is common, despite the fact that SBX
 *  native parsers don't use it.  This is because other features do use it, and
 *  so it has to be forced to be present, just as the interface number
 *  predicates have to be forced to be presentin XGS mode (since some
 *  additional features will use them).
 *
 *  WARNING: This sets up the SDK flags and SDK honours them everywhere *but*
 *  here.  Here, it explicitly destroys all ingress resources associated with
 *  the ingress processing -- predicate_action rules, actions, predicates,
 *  queue_map blocks -- even if they were owned by the application.  The
 *  application must (re)establish its ingress processing after making any call
 *  that would result in this function being invoked (such as changing the
 *  encapsulation / header format).
 *
 *  NOTE: IDs are not kept here; they have specific values that are published
 *  in other header files and referenced here WITH_ID during setup so other
 *  features know what belongs to base SDK functionality.
 *
 *  At this point, the COS map is the same between XGS and SBX modes, so this
 *  function does not tear it down or set it up.  Maybe in the future...?
 *
 *  Predicates in XGS mode:
 *    0 = interface number bit 0 (common code)
 *    1 = interface number bit 1 (common code)
 *    2 = interface number bit 2 (common code)
 *    3 = multicast (!unicast) (common code)
 *    4 = frame is destined for remote CPU port
 *    5 = extended header valid set in frame header
 *    6 =
 *    7 =
 *    8 =
 *    9 =
 *
 *  Predicates in SBX mode:
 *    0 = interface number bit 0 (common code)
 *    1 = interface number bit 1 (common code)
 *    2 = interface number bit 2 (common code)
 *    3 = multicast (!unicast) (common code)
 *    4 =
 *    5 =
 *    6 = DP[0] is set in frame header
 *    7 = DP[1] is set in frame header
 *    8 = frame OI is >= 8192
 *    9 =
 *
 *  Queue map segments in XGS mode:
 *    1 = unicast (14b, 16K entries)
 *    2 = multicast (14b, 16k entries)
 *    3 =
 *    4 =
 *    5 =
 *    6 =
 *    7 =
 *
 *  Queue map segments in SBX mode:
 *    1 =
 *    2 =
 *    3 =
 *    4 = requeue (16b, 64k entries) (only in hybrid mode)
 *    5 =
 *    6 =
 *    7 =
 *
 *  Frame parsers in XGS mode:
 *     0 = unicast frames
 *     1 = multicast frames
 *     2 = frames destined for a remote CPU
 *     3 =
 *     4 =
 *     5 =
 *     6 =
 *     7 =
 *     8 =
 *     9 =
 *    10 =
 *    11 =
 *    12 =
 *    13 =
 *    14 =
 *    15 = invalid or diagnostic mode
 *
 *  Frame parsers in SBX mode:
 *     0 = ingress DP0 frames
 *     1 = ingress DP1 frames
 *     2 = ingress DP2 frames
 *     3 = ingress DP3 frames
 *     4 = TB requeue DP0 frames
 *     5 = TB requeue DP1 frames
 *     6 = TB requeue DP2 frames
 *     7 = TB requeue DP3 frames
 *     8 = LB requeue DP0 frames
 *     9 = LB requeue DP1 frames
 *    10 = LB requeue DP2 frames
 *    11 = LB requeue DP3 frames
 *    12 =
 *    13 =
 *    14 =
 *    15 = invalid or diagnostic mode
 */
int
soc_sirius_hw_update_trt(uint32 unit)
{
    int rv = SOC_E_NONE;
    soc_sirius_parser_info_t parser;
    uint32 idx = 0;
    uint32 regval = 0;
    uint8 use_default_dp=1, hdr_fmt = 0;
    unsigned int predId;
    unsigned int parserId;
    soc_sirius_predicate_parser_rule_t predParserMap0;
    soc_sirius_predicate_parser_rule_t predParserMap1;
    unsigned int predParserId;
    unsigned int qselId;
    unsigned int next;
    int queueId;
    soc_reg_t reg0, reg1;

    /* get rid of the existing ingress processing configuration */
    predParserId = SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS - 1;
    do {
        rv = soc_sirius_predicate_parser_map_get_next(unit,
                                                      predParserId,
                                                      &next,
                                                      &predParserMap0);
        if (SOC_E_NONE == rv) {
            /* got next predicate_parser rule */
            predParserId = next;
            if (predParserMap0.flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
                /* predicate_parser rule is ingress, destroy it */
                rv = soc_sirius_predicate_parser_map_delete(unit, predParserId);
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
    parserId = SIRIUS_PARSER_OFFSET_INGRESS - 1;
    do {
        rv = soc_sirius_parser_next(unit, parserId, &next);
        if (SOC_E_NONE == rv) {
            parserId = next;
            rv = soc_sirius_parser_get(unit, parserId, &parser);
            if (SOC_E_NONE == rv) {
                /* got next parser */
                if (parser.ingress.flags & SIRIUS_PARSER_FLAGS_INGRESS) {
                    /* parser is ingress, destroy it */
                    rv = soc_sirius_parser_free(unit, parserId);
                }
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
    qselId = SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS - 1;
    do {
        rv = soc_sirius_queue_map_block_next(unit, qselId, &next);
        if (SOC_E_NONE == rv) {
            /* got next queue_map block */
            qselId = next;
#ifdef SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS

            if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS <= qselId) &&
                (SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS > qselId)) {
#endif /* def SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS */
                /* queue_map block is ingress, destroy it */
                rv = soc_sirius_queue_map_block_free(unit, qselId);
#ifdef SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS
            }
#endif /* def SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS */
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
    predId = SIRIUS_PREDICATE_OFFSET_INGRESS - 1;
    do {
        rv = soc_sirius_predicate_next(unit, predId, &next);
        if (SOC_E_NONE == rv) {
            /* got next predicate_parser rule */
            predId = next;
            /* coverity[unsigned_compare] */
            if ((SIRIUS_PREDICATE_OFFSET_INGRESS <= predId) &&
                (SIRIUS_PREDICATE_OFFSET_EGRESS > predId)) {
                /* parser is ingress, destroy it */
                rv = soc_sirius_predicate_free(unit, predId);
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);

    if (SOC_SBX_IF_PROTOCOL_XGS == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        /* XGS mode configuration of queue segments */
        qselId = (_SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST +
                  SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_queue_map_block_allocate(unit,
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS |
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID |
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK,
                                                                0,
                                                                16384,
                                                                &qselId));
        qselId = (_SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST +
                  SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_queue_map_block_allocate(unit,
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS |
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID |
                                                                SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK,
                                                                0,
                                                                16384,
                                                                &qselId));
    } else if (SOC_SBX_IF_PROTOCOL_SBX == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        /* SBX mode configuration of queue segments */
        if (SOC_SBX_QE_MODE_HYBRID == SOC_SBX_CFG(unit)->bTmeMode) {
            qselId = (_SIRIUS_I_QUEUE_MAP_SEG_SBX_RQ +
                      SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
            SOC_IF_ERROR_RETURN(soc_sirius_queue_map_block_allocate(unit,
                                                                    SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS |
                                                                    SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID |
                                                                    SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK,
                                                                    0,
                                                                    65536,
                                                                    &qselId));
        }
    }
    /* at this point, all is well */
    rv = SOC_E_NONE;

    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
	/* configure XGS mode predicates */
	/*
	 * Set the remote CPU mod/port bit patterns to 0xFFFF temporarily.
	 * The actual mod/port is set through the stack port mapping API.
	 */
	predId = _SIRIUS_I_PRED_XGS_RCPU + SIRIUS_PREDICATE_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
							  SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
							  &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         0x02,
                                                         FALSE,
                                                         FALSE,
                                                         0xFFFF,
                                                         0xFFFF));
	/* EHV on HG header */
	predId = _SIRIUS_I_PRED_XGS_EHV + SIRIUS_PREDICATE_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
							  SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
							  &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         0x06,
                                                         FALSE,
                                                         FALSE,
                                                         0x0020,
                                                         0x0020));
    } else if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {
	/* configure SBX mode predicates */
	/* DP[0] in pkt HDR (SBX ONLY) */
	
	predId = _SIRIUS_I_PRED_SBX_DP0 + SIRIUS_PREDICATE_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
							  SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
							  &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         0x08,
                                                         FALSE,
                                                         FALSE,
                                                         0x4000,
                                                         0x4000));

	/* DP[1] in pkt HDR (SBX ONLY) */
	
	predId = _SIRIUS_I_PRED_SBX_DP1 + SIRIUS_PREDICATE_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
							  SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
							  &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         0x08,
                                                         FALSE,
                                                         FALSE,
                                                         0x8000,
                                                         0x8000));

	/* OI in pkt >= 8192 (SBX ONLY) */
	predId = _SIRIUS_I_PRED_SBX_NTB + SIRIUS_PREDICATE_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
							  SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
							  &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         0x02,
                                                         FALSE,
                                                         TRUE,
                                                         0x2000,
                                                         0xFFFF));
    } else {
	/* bogus configuration -- neither XGS nor SBX mode */
	return SOC_E_INTERNAL;
    }
    /* configure the shared predicates */
    /* bits 2..0 of the interface number */
    predId = _SIRIUS_I_PRED_ALL_IF0 + SIRIUS_PREDICATE_OFFSET_INGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
						      SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                      SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                      SIRIUS_PREDICATE_FLAGS_SDK,
						      &predId));
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                     predId,
                                                     0x00,
                                                     TRUE,
                                                     FALSE,
                                                     0x0001,
                                                     0x0001));
    predId = _SIRIUS_I_PRED_ALL_IF1 + SIRIUS_PREDICATE_OFFSET_INGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
						      SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                      SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                      SIRIUS_PREDICATE_FLAGS_SDK,
						      &predId));
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                     predId,
                                                     0x00,
                                                     TRUE,
                                                     FALSE,
                                                     0x0002,
                                                     0x0002));
    predId = _SIRIUS_I_PRED_ALL_IF2;
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
						      SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                      SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                      SIRIUS_PREDICATE_FLAGS_SDK,
						      &predId));
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                     predId,
                                                     0x00,
                                                     TRUE,
                                                     FALSE,
                                                     0x0004,
                                                     0x0004));
    /* multicast (!unicast) */
    predId = _SIRIUS_I_PRED_ALL_MC + SIRIUS_PREDICATE_OFFSET_INGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
						      SIRIUS_PREDICATE_FLAGS_INGRESS |
                                                      SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                      SIRIUS_PREDICATE_FLAGS_SDK,
						      &predId));
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                     _SIRIUS_I_PRED_ALL_MC,
                                                     0x00,
                                                     FALSE,
                                                     FALSE,
                                                     0x0010,
                                                     0x0010));
    /* clear out unused predicates */
    SOC_IF_ERROR_RETURN(soc_sirius_ingress_predicates_clear_unused(unit));
    /* set up global ingress invalid parser (also used for diag mode) */
    sal_memset(&parser, 0x00, sizeof(parser));
    parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
                            SIRIUS_PARSER_FLAGS_SDK |
                            SIRIUS_PARSER_FLAGS_WITH_ID |
                            SIRIUS_PARSER_FLAGS_QUEUE_DEFAULT);
    parserId = _SIRIUS_I_PARSER_ALL_INVALID + SIRIUS_PARSER_OFFSET_INGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                   parser.ingress.flags,
                                                   &parserId));
    SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit, parserId, &parser));
    /* set up SBX mode frame parsers */
    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
	/*
	 * Configure FRAME_PARSING table to match unicast and multicast
	 * HGX headers for queue selection, USE_DEFAULT_INDEX=0 qid_index
	 * generated from extracted fields within the first 40 bytes of the
	 * packet.
	 */

	/* Configure frame parser for HGX Unicast */
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
				SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_USE_COS_MAP |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.cos_byte = 1;
	parser.ingress.queue_byte0 = 3;
	parser.ingress.queue_length0 = 7;
	parser.ingress.queue_byte1 = 2;
	parser.ingress.queue_length1 = 7;
	parser.ingress.segmentSel = (_SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST +
				     SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
	parser.ingress.dp = -1;
	parser.ingress.ecn = -1;
	if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
	    /* point to Source Mod/Port field in Higig2 header */
	    parser.ingress.stat_length0 = 15;
	    parser.ingress.stat_byte0 = 5;
	    parser.ingress.stat_bit0 = 0;
	}

	parserId = _SIRIUS_I_PARSER_XGS_UNICAST + SIRIUS_PARSER_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
						       parser.ingress.flags,
						       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));
	/* Configure frame parser for HGX Multicast */
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
				SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_USE_COS_MAP |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.cos_byte = 1;
	parser.ingress.queue_byte0 = 3;
	parser.ingress.queue_length0 = 14;
	parser.ingress.segmentSel = (_SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST +
				     SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
	parser.ingress.dp = -1;
	parser.ingress.ecn = -1;
	if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
	    /* point to Source Mod/Port field in Higig2 header */
	    parser.ingress.stat_length0 = 15;
	    parser.ingress.stat_byte0 = 5;
	    parser.ingress.stat_bit0 = 0;
	}

	parserId = _SIRIUS_I_PARSER_XGS_MULTICAST + SIRIUS_PARSER_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
						       parser.ingress.flags,
						       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));
	/*
	 * Configure frame parsing record for HG2 Remote CPU port
	 * QUEUE_MAP table is not used
	 * queue_tag field in Extended HG header specifies the actual queue
	 */
	
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
				SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_USE_TAG_OFFSET |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.dp = -1;
	parser.ingress.ecn = -1;
	if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
	    /* point to Source Mod/Port field in Higig2 header */
	    parser.ingress.stat_length0 = 15;
	    parser.ingress.stat_byte0 = 5;
	    parser.ingress.stat_bit0 = 0;
	}

	parserId = _SIRIUS_I_PARSER_XGS_REMOTE_CPU + SIRIUS_PARSER_OFFSET_INGRESS;
	SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
						       parser.ingress.flags,
						       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));
	/* configure the rules linking predicates to parsers */
	/*
	 *  Note that these rules, like the parsers and predicates that
	 *  support them, are not meant to be torn down.  Since the user
	 *  does not need to know their ID, and we will not be tearing them
	 *  down, we don't care about their IDs.
	 *
	 *  Their priority has been chosen so the user can add rules at
	 *  higher and lower priority, but tending to bias the priority
	 *  toward low, as we will also add higher priority rules that are
	 *  set up and torn down via the steering APIs and maybe others.
	 *
	 *  Note that the unicast and multicast parsers do not overlap, and
	 *  so can be installed at the same priority with impunity.
	 *  However, the remove CPU parser overlaps both unicast and
	 *  multicast, and must override, so its priority must be higher.
	 *
	 *  In the past, we also had a default.  That's dropped now because
	 *  the table is configured assuming a default fill.
	 */
	/* unicast */
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.parser = _SIRIUS_I_PARSER_XGS_UNICAST + SIRIUS_PARSER_OFFSET_INGRESS;
	predParserMap0.priority = 8;
	predParserMap0.predMask = _SIRIUS_I_PRED_ALL_MC_BIT;
	predParserMap0.predState = 0;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								&predParserMap0,
								&predParserId));
	/* multicast */
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.parser = _SIRIUS_I_PARSER_XGS_MULTICAST + SIRIUS_PARSER_OFFSET_INGRESS;
	predParserMap0.priority = 8;
	predParserMap0.predMask = _SIRIUS_I_PRED_ALL_MC_BIT;
	predParserMap0.predState = _SIRIUS_I_PRED_ALL_MC_BIT;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								&predParserMap0,
								&predParserId));
	/* remote CPU */
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.parser = _SIRIUS_I_PARSER_XGS_REMOTE_CPU + SIRIUS_PARSER_OFFSET_INGRESS;
	predParserMap0.priority = 12;
	predParserMap0.predMask = _SIRIUS_I_PRED_XGS_RCPU_BIT | _SIRIUS_I_PRED_XGS_EHV_BIT;
	predParserMap0.predState = _SIRIUS_I_PRED_XGS_RCPU_BIT | _SIRIUS_I_PRED_XGS_EHV_BIT;
	SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								&predParserMap0,
								&predParserId));
    } /* if (using XGS encapsulation) */
    /* set up SBX mode frame parsers */
    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {
	/*
	 * If control_fabric_header_custom, disable default dp
	 */
	if (SOC_SBX_CONTROL(unit)->state == NULL) {
	    hdr_fmt = BCM_PORT_CONTROL_FABRIC_HEADER_88230;
	} else {
	    hdr_fmt = SOC_SBX_STATE(unit)->port_state->fabric_header_format;
	}

	if (hdr_fmt == BCM_PORT_CONTROL_FABRIC_HEADER_CUSTOM) {
	    use_default_dp = 0;
	} else if (hdr_fmt == BCM_PORT_CONTROL_FABRIC_HEADER_88230) {
	    use_default_dp = 1;
	} else {
	    return SOC_E_INTERNAL;
	}

	/*
	 * set drop enable on hg interfaces only
	 */
	SOC_IF_ERROR_RETURN(READ_RB_TWO_BYTE_DROP_CONFIG0r(unit, &regval));
	soc_reg_field_set(unit, RB_TWO_BYTE_DROP_CONFIG0r, &regval, IF0_2BYTE_DROP_ENABLEf, 1);
	soc_reg_field_set(unit, RB_TWO_BYTE_DROP_CONFIG0r, &regval, IF1_2BYTE_DROP_ENABLEf, 1);
	soc_reg_field_set(unit, RB_TWO_BYTE_DROP_CONFIG0r, &regval, IF2_2BYTE_DROP_ENABLEf, 1);
	soc_reg_field_set(unit, RB_TWO_BYTE_DROP_CONFIG0r, &regval, IF3_2BYTE_DROP_ENABLEf, 1);
	soc_reg_field_set(unit, RB_TWO_BYTE_DROP_CONFIG0r, &regval, IF4_2BYTE_DROP_ENABLEf, 1);
	SOC_IF_ERROR_RETURN(WRITE_RB_TWO_BYTE_DROP_CONFIG0r(unit, regval));

	/* Configure frame parsing records for SBX ingress */
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
				SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_LENGTH_ADJUST |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.queue_byte0 = 3;
	parser.ingress.queue_length0 = 16;
	parser.ingress.ecn = -1;
	if (!use_default_dp) {
	    parser.ingress.dp = -1;
	}
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	sal_memset(&predParserMap1, 0x00, sizeof(predParserMap1));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.priority = 8;
	predParserMap0.predMask = _SIRIUS_I_PRED_ALL_IF2_BIT | _SIRIUS_I_PRED_SBX_DP_BITS;
	predParserMap1.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap1.priority = 8;
	predParserMap1.predMask = _SIRIUS_I_PRED_ALL_IF_BITS | _SIRIUS_I_PRED_SBX_DP_BITS;
	for (idx = 0; idx < 4; idx++) {
	    /* configure the parser */
	    if (use_default_dp) {
		parser.ingress.dp = idx;
	    }
	    if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
		/* point to SID field in SBX header */
		parser.ingress.stat_length0 = 15;
		parser.ingress.stat_byte0 = 5;
		parser.ingress.stat_bit0 = 0;
	    }

	    parserId = _SIRIUS_I_PARSER_SBX_INGRESS_DP0 + idx + SIRIUS_PARSER_OFFSET_INGRESS;
	    SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
							   parser.ingress.flags,
							   &parserId));
            SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                          parserId,
                                                          &parser));
	    /* link the predicate to the parser */
	    /*
	     *  Need interface 0..4; this requires two rules to map.  The
	     *  first rule covers interfaces 0..3 (IF bit 2 = 0), and the
	     *  second rule covers interface 4 (if bits 2..0 = 100).  In
	     *  both rules, we also specify the proper DP predicates.
	     */
	    predParserMap0.parser = parserId;
	    predParserMap1.parser = parserId;
	    switch (idx) {
                case 0:
                    predParserMap0.predState = 0;
                    predParserMap1.predState = _SIRIUS_I_PRED_ALL_IF2_BIT;
                    break;
                case 1:
                    predParserMap0.predState = _SIRIUS_I_PRED_SBX_DP0_BIT;
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT);
                    break;
                case 2:
                    predParserMap0.predState = _SIRIUS_I_PRED_SBX_DP1_BIT;
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT);
                    break;
                default:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT);
	    }
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap0,
								    &predParserId));
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap1,
								    &predParserId));
	}

	/* Configure frame parsing records for SBX TB Requeue */
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
                                SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.queue_byte0 = 5;
	parser.ingress.queue_length0 = 16;
	parser.ingress.ecn = -1;
	if (!use_default_dp) {
	    parser.ingress.dp = -1;
	}
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	sal_memset(&predParserMap1, 0x00, sizeof(predParserMap1));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.priority = 8;
	predParserMap0.predMask = (_SIRIUS_I_PRED_ALL_IF_BITS |
				   _SIRIUS_I_PRED_SBX_DP_BITS |
				   _SIRIUS_I_PRED_SBX_NTB_BIT);
	predParserMap1.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap1.priority = 8;
	predParserMap1.predMask = (_SIRIUS_I_PRED_ALL_IF_BITS |
				   _SIRIUS_I_PRED_SBX_DP_BITS |
				   _SIRIUS_I_PRED_SBX_NTB_BIT);
	for (idx = 0; idx < 4; idx++) {
	    if (use_default_dp) {
		parser.ingress.dp = idx;
	    }
	    if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
		/* point to SID field in SBX header */
		parser.ingress.stat_length0 = 15;
		parser.ingress.stat_byte0 = 5;
		parser.ingress.stat_bit0 = 0;
	    }

	    parserId = _SIRIUS_I_PARSER_SBX_TB_REQ_DP0 + idx + SIRIUS_PARSER_OFFSET_INGRESS;
	    SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
							   parser.ingress.flags,
							   &parserId));
            SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                          parserId,
                                                          &parser));
	    /* link the predicate to the parser */
	    /*
	     *  Need interface 5,6; this requires two rules to map.  The
	     *  first rule covers interface 5 (IF bits 2..0 = 101), and the
	     *  second rule covers interface 6 (if bits 2..0 = 110). In
	     *  both rules, we also specify the proper DP predicates.
	     */
	    predParserMap0.parser = parserId;
	    predParserMap1.parser = parserId;
	    switch (idx) {
                case 0:
                    predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                case 1:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                case 2:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                default:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
	    }
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap0,
								    &predParserId));
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap1,
								    &predParserId));
	}

	/* Configure frame parsing records for SBX LB Requeue */
	sal_memset(&parser, 0x00, sizeof(parser));
	parser.ingress.flags = (SIRIUS_PARSER_FLAGS_INGRESS |
				SIRIUS_PARSER_FLAGS_WITH_ID |
                                SIRIUS_PARSER_FLAGS_USE_COS_MAP |
                                SIRIUS_PARSER_FLAGS_SDK);
	parser.ingress.segmentSel = (_SIRIUS_I_QUEUE_MAP_SEG_SBX_RQ +
				     SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
	parser.ingress.queue_byte0 = 3;
	parser.ingress.queue_length0 = 16;
	parser.ingress.cos_byte = 9;
	parser.ingress.cos_bit = 2;
	parser.ingress.ecn = -1;
	if (!use_default_dp) {
	    parser.ingress.dp = -1;
	}
	sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
	sal_memset(&predParserMap1, 0x00, sizeof(predParserMap1));
	predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap0.priority = 8;
	predParserMap0.predMask = (_SIRIUS_I_PRED_ALL_IF_BITS |
				   _SIRIUS_I_PRED_SBX_DP_BITS |
				   _SIRIUS_I_PRED_SBX_NTB_BIT);
	predParserMap1.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
	predParserMap1.priority = 8;
	predParserMap1.predMask = (_SIRIUS_I_PRED_ALL_IF_BITS |
				   _SIRIUS_I_PRED_SBX_DP_BITS |
				   _SIRIUS_I_PRED_SBX_NTB_BIT);
	for (idx = 0; idx < 4; idx++) {
	    if (use_default_dp) {
		parser.ingress.dp = idx;
	    }
	    if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
		/* point to SID field in SBX header */
		parser.ingress.stat_length0 = 15;
		parser.ingress.stat_byte0 = 5;
		parser.ingress.stat_bit0 = 0;
	    }

	    parserId = _SIRIUS_I_PARSER_SBX_LB_REQ_DP0 + idx + SIRIUS_PARSER_OFFSET_INGRESS;
	    SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
							   parser.ingress.flags,
							   &parserId));
            SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                          parserId,
                                                          &parser));
	    /* link the predicate to the parser */
	    /*
	     *  Need interface 5,6; this requires two rules to map.  The
	     *  first rule covers interface 5 (IF bits 2..0 = 101), and the
	     *  second rule covers interface 6 (if bits 2..0 = 110). In
	     *  both rules, we also specify the proper DP predicates.
	     */
	    predParserMap0.parser = parserId;
	    predParserMap1.parser = parserId;
	    switch (idx) {
                case 0:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                case 1:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                case 2:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
                    break;
                default:
                    predParserMap0.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF0_BIT);
                    predParserMap1.predState = (_SIRIUS_I_PRED_SBX_NTB_BIT |
                                                _SIRIUS_I_PRED_SBX_DP1_BIT |
                                                _SIRIUS_I_PRED_SBX_DP0_BIT |
                                                _SIRIUS_I_PRED_ALL_IF2_BIT |
                                                _SIRIUS_I_PRED_ALL_IF1_BIT);
	    }
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap0,
								    &predParserId));
	    SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
								    &predParserMap1,
								    &predParserId));
	}
    } /* if (using SBX encapsulation) */
    /* clear unused parsers */
    SOC_IF_ERROR_RETURN(soc_sirius_parser_clear_unused_ingress(unit));

    /*
     *  No matter which mode, any interfaces set up in diagnostic mode need to
     *  be put into diagnostic mode at this time.  Note that we do not
     *  configure queues automatically; the application must set that up if it
     *  wants diagnostic mode to forward frames.
     */
    
    /* First, ensure default queues are all the default drop queue */
    for (idx = 0, queueId = SIRIUS_Q_BASE_INVALID;
         idx < SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES;
         idx++) {
        SOC_IF_ERROR_RETURN(soc_sirius_port_control_default_queue_access(unit,
                                                                         TRUE,
                                                                         idx,
                                                                         &queueId));
    } /* for (all interfaces) */
    /*
     *  For each interface in diagnostic mode:
     *
     *    Set diagnostic mode (rb_config)
     *    Set configured header for insertion (rb_if#_nohead_fields_[0|1])
     *    Add predicate->action rule mapping interface to diag parser
     */
    for (idx = 0;
         idx < SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES;
         idx++) {
        if ((SOC_SBX_CFG_SIRIUS(unit)->if_diag_mode[idx]) & 0x01) {
            /* interface is configured in diagnostic mode */
            SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
                                               soc_reg_addr(unit,
                                                            RB_CONFIGr,
                                                            REG_PORT_ANY,
                                                            0),
                                               &regval));
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
            predParserMap0.parser = _SIRIUS_I_PARSER_ALL_INVALID +
                                    SIRIUS_PARSER_OFFSET_INGRESS;
            predParserMap0.priority = 32; /* orverride other SDK mapping */
            predParserMap0.predMask = _SIRIUS_I_PRED_ALL_IF_BITS;
            switch (idx) {
            case 0:
                predParserMap0.predState = 0; /* no bits set*/
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF0_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF0_NOHEAD_FIELDS_0r;
                reg1 = RB_IF0_NOHEAD_FIELDS_1r;
                break;
            case 1:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF0_BIT;
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF1_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF1_NOHEAD_FIELDS_0r;
                reg1 = RB_IF1_NOHEAD_FIELDS_1r;
                break;
            case 2:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF1_BIT;
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF2_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF2_NOHEAD_FIELDS_0r;
                reg1 = RB_IF2_NOHEAD_FIELDS_1r;
                break;
            case 3:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF0_BIT |
                                            _SIRIUS_I_PRED_ALL_IF1_BIT);
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF3_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF3_NOHEAD_FIELDS_0r;
                reg1 = RB_IF3_NOHEAD_FIELDS_1r;
                break;
            case 4:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF2_BIT;
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF4_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF4_NOHEAD_FIELDS_0r;
                reg1 = RB_IF4_NOHEAD_FIELDS_1r;
                break;
            case 5:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF0_BIT |
                                            _SIRIUS_I_PRED_ALL_IF2_BIT);
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF5_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF5_NOHEAD_FIELDS_0r;
                reg1 = RB_IF5_NOHEAD_FIELDS_1r;
                break;
            case 6:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF1_BIT |
                                            _SIRIUS_I_PRED_ALL_IF2_BIT);
                soc_reg_field_set(unit,
                                  RB_CONFIGr,
                                  &regval,
                                  IF6_DIAGNOSTIC_MODEf,
                                  1);
                reg0 = RB_IF6_NOHEAD_FIELDS_0r;
                reg1 = RB_IF6_NOHEAD_FIELDS_1r;
                break;
            /* coverity[dead_error_begin] */
            default:
                /* should never get here */
                return SOC_E_INTERNAL;
            } /* switch (idx) */
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
                                                soc_reg_addr(unit,
                                                             RB_CONFIGr,
                                                             REG_PORT_ANY,
                                                             0),
                                                regval));
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
                                                soc_reg_addr(unit,
                                                             reg0,
                                                             REG_PORT_ANY,
                                                             0),
                                                SOC_SBX_CFG_SIRIUS(unit)->if_diag_nohead[idx][0]));
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
                                                soc_reg_addr(unit,
                                                             reg1,
                                                             REG_PORT_ANY,
                                                             0),
                                                SOC_SBX_CFG_SIRIUS(unit)->if_diag_nohead[idx][1]));
        } /* if (interface is in diagnostic mode */
    } /* for (all interfaces) */

    return rv;
}

/*
 * If the destMod and destPort are valid, then program the frame parsing
 * predicate. */
int
soc_sirius_rb_higig2_remote_cpu_config(int unit, int32 destMod, int32 destPort, int32 nQueue)
{
    int32 rv = SOC_E_NONE;

    if ( (destMod != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         (destPort != SOC_SIRIUS_API_PARAM_NO_CHANGE) ) {
        if (SOC_E_FULL == soc_sirius_predicate_check_sdk(unit,
                                                         _SIRIUS_I_PRED_XGS_RCPU +
                                                         SIRIUS_PREDICATE_OFFSET_INGRESS)) {
            /* SDK owns this predicate; update it */
            /*
             * Set the remote CPU mod/port bit patterns to module and port, with
             * module in high byte and port in low byte, and all bits matter, but
             * only set it if the SDK still owns the predicate.
             */
            rv = soc_sirius_predicate_set_sdk(unit,
                                              _SIRIUS_I_PRED_XGS_RCPU +
                                              SIRIUS_PREDICATE_OFFSET_INGRESS,
                                              0x02,
                                              FALSE,
                                              FALSE,
                                              0xFFFF,
                                              (((destMod & 0xFF) << 8) |
                                               (destPort & 0xFF)));
        }
    }
#if 0 
    /*
     * nQueue not used. As current mechanism does not use QUEUE_MAP table.
     * Queue is picked directly from the HG extension header when EHV is set.
     */
    COMPILER_REFERENCE(nQueue);
#endif 
    return rv;
}

/* write the queue map table for higig2 headers */
/* index is dest_modid[6:0]dest_pid[5:0]        */
int
soc_sirius_rb_higig2_header_unicast_queue_map_config(int unit, uint32 uDestNode, uint32 uDestPort, int32 nQueue)
{
    uint32 nIndex;
    int cos_map_nbr = _SIRIUS_I_COS_PROFILE_GENERAL;
    bcm_sbx_cosq_queue_state_t     *p_qstate = NULL;
    bcm_sbx_cosq_bw_group_state_t  *p_bwstate;
    int32                           bw_group = 0;

    if (SOC_E_FULL == soc_sirius_queue_map_block_check_sdk(unit,
                                                           _SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST +
                                                           SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)) {
        /* SDK owns _SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST; update it */
        
        nIndex = uDestNode << 7 | uDestPort;

        /* update cos map */
        if (nQueue != SIRIUS_Q_BASE_INVALID) {
            p_qstate = (bcm_sbx_cosq_queue_state_t*)SOC_SBX_STATE(unit)->queue_state;
            p_qstate = &p_qstate[nQueue];
            bw_group = p_qstate->bw_group;
            p_bwstate = (bcm_sbx_cosq_bw_group_state_t*)SOC_SBX_STATE(unit)->bw_group_state;
            p_bwstate = &p_bwstate[bw_group];
            cos_map_nbr = p_bwstate->cos_map;
        }

        return soc_sirius_queue_map_block_entry_set_sdk(unit,
                                                        _SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST +
                                                        SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                                                        nIndex,
                                                        cos_map_nbr +
                                                        SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS,
                                                        nQueue);
    } else {
        /* application owns _SIRIUS_I_QUEUE_MAP_SEG_XGS_UNICAST; ignore it */
        return SOC_E_NONE;
    }
}

int
soc_sirius_rb_higig2_header_multicast_queue_map_config(int unit, int32 nMcGroup, int32 nQueue)
{
    uint32 nIndex;
    int cos_map_nbr = _SIRIUS_I_COS_PROFILE_GENERAL;
    bcm_sbx_cosq_queue_state_t     *p_qstate = NULL;
    bcm_sbx_cosq_bw_group_state_t  *p_bwstate;
    int32                           bw_group = 0;

    if (SOC_E_FULL == soc_sirius_queue_map_block_check_sdk(unit,
                                                           _SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST +
                                                           SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)) {
        /* SDK owns _SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST; update it */
        /* there are only 16K entries for MC, so groups will wrap */
        nIndex = nMcGroup & 16383;

        /* update cos map */
        if (nQueue != SIRIUS_Q_BASE_INVALID) {
            p_qstate = (bcm_sbx_cosq_queue_state_t*)SOC_SBX_STATE(unit)->queue_state;
            p_qstate = &p_qstate[nQueue];
            bw_group = p_qstate->bw_group;
            p_bwstate = (bcm_sbx_cosq_bw_group_state_t*)SOC_SBX_STATE(unit)->bw_group_state;
            p_bwstate = &p_bwstate[bw_group];
            cos_map_nbr = p_bwstate->cos_map;
        }

        return soc_sirius_queue_map_block_entry_set_sdk(unit,
                                                        _SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST +
                                                        SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                                                        nIndex,
                                                        cos_map_nbr +
                                                        SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS,
                                                        nQueue);
    } else {
        /* application owns _SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST; ignore it */
        return SOC_E_NONE;
    }
}

int
soc_sirius_rb_higig2_header_multicast_queue_map_read(int unit, int32 nMcGroup, int32 *nQueue)
{
    int rv = SOC_E_NONE;
    unsigned int cosProfile;
    unsigned int queue;
    uint32 nIndex;

    /* there are only 16K entries for MC, so groups will wrap */
    nIndex = nMcGroup & 16383;
    rv = soc_sirius_queue_map_block_entry_get(unit,
                                              _SIRIUS_I_QUEUE_MAP_SEG_XGS_MULTICAST +
                                              SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                                              nIndex,
                                              &cosProfile,
                                              &queue);
    if (SOC_E_NONE == rv) {
        *nQueue = queue;
    }
    return rv;
}

static int
_soc_sirius_hw_init_rb( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32  unit = (int32) pInitParams->unit;
    type_resolution_table_entry_t type_entry;
    queue_map_entry_t queue_map_entry;
    uint32 idx = 0;
    uint32 regval = 0, port = 0;
    uint64 val64 = COMPILER_64_INIT(0,0);
    frame_parsing_entry_t fp_entry;
    edc_lookup_entry_t edc_entry;


    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "Sirius hardware init rb called.\n")));

    /* Clear rb reset
     */
    regval = 0;
    soc_reg_field_set(unit, RB_SW_RESETr, &regval, SOFT_RESETf, 0x0);
    SOC_IF_ERROR_RETURN(WRITE_RB_SW_RESETr(unit, regval));

    /*
     * Initialize Predicate field offset to invalidate
     */
    regval = 0;
    SOC_IF_ERROR_RETURN(READ_RB_PRED_CONFIG0r(unit, &regval));
    soc_reg_field_set(unit, RB_PRED_CONFIG0r, &regval, PRED3_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG0r, &regval, PRED2_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG0r, &regval, PRED1_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG0r, &regval, PRED0_FIELD_OFFSETf, 0x3f);
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG0r(unit, regval));

    regval = 0;
    SOC_IF_ERROR_RETURN(READ_RB_PRED_CONFIG1r(unit, &regval));
    soc_reg_field_set(unit, RB_PRED_CONFIG1r, &regval, PRED7_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG1r, &regval, PRED6_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG1r, &regval, PRED5_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG1r, &regval, PRED4_FIELD_OFFSETf, 0x3f);
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG1r(unit, regval));

    regval = 0;
    SOC_IF_ERROR_RETURN(READ_RB_PRED_CONFIG2r(unit, &regval));
    soc_reg_field_set(unit, RB_PRED_CONFIG2r, &regval, PRED9_FIELD_OFFSETf, 0x3f);
    soc_reg_field_set(unit, RB_PRED_CONFIG2r, &regval, PRED8_FIELD_OFFSETf, 0x3f);
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG2r(unit, regval));

    regval = 0;
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG3r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG4r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG5r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG6r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG7r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG8r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG9r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG10r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG11r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_RB_PRED_CONFIG12r(unit, regval));

    /*
     * Clear Type Resolution table
     */
    sal_memset(&type_entry, 0, sizeof(type_resolution_table_entry_t));
    for (idx = 0; idx <= SOC_MEM_INFO(unit, TYPE_RESOLUTION_TABLEm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_TYPE_RESOLUTION_TABLEm(unit, MEM_BLOCK_ANY, idx, &type_entry));
    }

    /*
     *  Ensure the COS_PROFILEs we use are allocated
     */
    /*
     *  NOTE: idx is not kept here; the SDK assumes certain IDs for various
     *  objects and so we 'reserve' the objects specifying the ID to use.
     */
    idx = _SIRIUS_I_COS_PROFILE_GENERAL + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_cos_map_block_allocate(unit,
                                                          SIRIUS_COS_MAP_BLOCK_FLAGS_INGRESS |
                                                          SIRIUS_COS_MAP_BLOCK_FLAGS_WITH_ID |
                                                          SIRIUS_COS_MAP_BLOCK_FLAGS_SDK,
                                                          &idx));
    if (SOC_SBX_IF_PROTOCOL_SBX == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        /* ENCAPID profile is only used in SBX mode */
        idx = _SIRIUS_I_COS_PROFILE_ENCAPID + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_cos_map_block_allocate(unit,
                                                              SIRIUS_COS_MAP_BLOCK_FLAGS_INGRESS |
                                                              SIRIUS_COS_MAP_BLOCK_FLAGS_WITH_ID |
                                                              SIRIUS_COS_MAP_BLOCK_FLAGS_SDK,
                                                              &idx));
    }

    /*
     * Write queue map table to the highest queue number
     */
    if (!SAL_BOOT_QUICKTURN) {
        soc_mem_field32_set(unit, QUEUE_MAPm, &queue_map_entry, COS_PROFILEf, _SIRIUS_I_COS_PROFILE_GENERAL);
	soc_mem_field32_set(unit, QUEUE_MAPm, &queue_map_entry, QID_BASEf, SIRIUS_Q_BASE_INVALID);
	for (idx = 0; idx <= SOC_MEM_INFO(unit, QUEUE_MAPm).index_max; idx++) {
	    SOC_IF_ERROR_RETURN(WRITE_QUEUE_MAPm(unit, MEM_BLOCK_ANY, idx, &queue_map_entry));
	}
    } else {
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius init rb queue_map lookup table skipped.\n")));
    }

    /*
     * Clear frame parsing record map table
     * Configure FRAME_PARSING table to match unicast and multicast
     * HGX headers for queue selection
     */
    sal_memset(&fp_entry, 0, sizeof(frame_parsing_entry_t));
    for (idx = 0; idx <= SOC_MEM_INFO(unit, FRAME_PARSINGm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_FRAME_PARSINGm(unit, MEM_BLOCK_ANY, idx, &fp_entry));
    }

    /*
     * Clear EDC lookup table to 0, according PR25981
     */
    sal_memset(&edc_entry, 0, sizeof(edc_lookup_entry_t));
    for (idx = 0; idx <= SOC_MEM_INFO(unit, EDC_LOOKUPm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_EDC_LOOKUPm(unit, MEM_BLOCK_ANY, idx, &edc_entry));
    }

    /*
     *  Initial configuration of queue_map segment registers.
     */
    for (idx = 0; idx < SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS; idx++) {
        SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
                                           soc_reg_addr(unit,
                                                        queueSegRegs[idx][0],
                                                        REG_PORT_ANY,
                                                        0),
                                           &regval));
        soc_reg_field_set(unit,
                          queueSegRegs[idx][0],
                          &regval,
                          queueSegRegs[idx][1],
                          SIRIUS_Q_BASE_INVALID);
        SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
                                            soc_reg_addr(unit,
                                                         queueSegRegs[idx][0],
                                                         REG_PORT_ANY,
                                                         0),
                                            regval));
    }

    /*
     *  configure predicates, parsers, and so on...
     */
    rv = soc_sirius_hw_update_trt(unit);

    /*
     * 6 bits of cos, 4 from xgs/sbx header, lower 2 from queue map table cos_profile
     * (currently set to 0 for xgs and 1 for sbx)
     * Set unused profiles to default to XGS values
     */

    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_7f, 1);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_6f, 1);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_5f, 0);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_4f, 1);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_3f, 0);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_2f, 0);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_1f, 0);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_0f, 0);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_0r(unit, regval));

    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_15f, 3);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_14f, 3);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_13f, 1);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_12f, 3);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_11f, 2);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_10f, 2);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_9f,  1);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_8f,  2);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_1r(unit, regval));

    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_23f, 5);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_22f, 5);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_21f, 2);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_20f, 5);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_19f, 4);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_18f, 4);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_17f, 2);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_16f, 4);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_2r(unit, regval));

    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_31f, 7);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_30f, 7);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_29f, 3);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_28f, 7);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_27f, 6);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_26f, 6);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_25f, 3);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_24f, 6);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_3r(unit, regval));

    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_7f, 9);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_6f, 9);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_5f, 4);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_4f, 9);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_3f, 8);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_2f, 8);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_1f, 4);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_0r, &regval, COS_MAP_0f, 8);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_4r(unit, regval));
    
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_15f, 11);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_14f, 11);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_13f, 5);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_12f, 11);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_11f, 10);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_10f, 10);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_9f,  5);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_1r, &regval, COS_MAP_8f,  10);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_5r(unit, regval));
    
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_23f, 13);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_22f, 13);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_21f, 6);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_20f, 13);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_19f, 12);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_18f, 12);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_17f, 6);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_2r, &regval, COS_MAP_16f, 12);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_6r(unit, regval));
    
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_31f, 15);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_30f, 15);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_29f, 7);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_28f, 15);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_27f, 14);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_26f, 14);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_25f, 7);
    soc_reg_field_set(unit, RB_COS_MAP_TABLE_3r, &regval, COS_MAP_24f, 14);
    SOC_IF_ERROR_RETURN(WRITE_RB_COS_MAP_TABLE_7r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_CI_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, MAX_CIf, pInitParams->uDdr3NumMemories - 1);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, DRAM_PAGE_SIZEf, 0);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, NUM_COL_BITSf, pInitParams->uNumColBits);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, BUFFER_SIZEf, pInitParams->uBufferSize);
    SOC_IF_ERROR_RETURN(WRITE_RB_CI_CONFIGr(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP0r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_0f,
		      (0 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_1f,
		      (1 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_2f,
		      (2 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_3f,
		      (3 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_4f,
		      (4 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_5f,
		      (5 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_6f,
		      (6 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_7f,
		      (7 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP0r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP1r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_8f,
		      (8 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_9f,
		      (9 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_10f,
		      (10 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_11f,
		      (11 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_12f,
		      (12 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_13f,
		      (13 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_14f,
		      (14 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_15f,
		      (15 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP1r(unit, regval));
    
    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP2r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_16f,
		      (16 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_17f,
		      (17 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_18f,
		      (18 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_19f,
		      (19 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_20f,
		      (20 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_21f,
		      (21 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_22f,
		      (22 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_23f,
		      (23 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP2r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP3r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_24f,
		      (24 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_25f,
		      (25 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_26f,
		      (26 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_27f,
		      (27 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_28f,
		      (28 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_29f,
		      (29 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_30f,
		      (30 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_31f,
		      (31 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP3r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP4r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_32f,
		      (32 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_33f,
		      (33 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_34f,
		      (34 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_35f,
		      (35 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_36f,
		      (36 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_37f,
		      (37 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_38f,
		      (38 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_39f,
		      (39 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP4r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_RB_FIRST_CI_LOOKUP5r(unit, &regval));
    soc_reg_field_set(unit, RB_FIRST_CI_LOOKUP5r, &regval, CI_LOOKUP_40f,
		      (40 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_RB_FIRST_CI_LOOKUP5r(unit, regval));

    regval = 0;
    SOC_IF_ERROR_RETURN(READ_RB_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, RB_CONFIGr, &regval, ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_RB_CONFIGr(unit, regval));

    if (!SAL_BOOT_BCMSIM && (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX)) {
        uint64 uuOne = COMPILER_64_INIT(0,1);
	for (port=0; port < 8; port++) {
	    SOC_IF_ERROR_RETURN(READ_MAC_CTRLr(unit, port, &val64));
	    soc_reg64_field_set(unit, MAC_CTRLr, &val64, RUNT_51B_MODEf, uuOne);
	    SOC_IF_ERROR_RETURN(WRITE_MAC_CTRLr(unit, port, val64));
	}
    }

    /* 
     * HCFC config or SAFC config in RB?
     */

    return rv;
}

#define SIRIUS_QM_RANDOM_TABLE_INDEX_MAX 55

static uint32 sirius_qm_random_table_entries[SIRIUS_QM_RANDOM_TABLE_INDEX_MAX] = {
0x490a9a, 0x2044af, 0x02426b, 0x18f82b, 0x435cbd, 0x636fcc, 0x196142, 0x049ba9,
0x4079f1, 0x436be6, 0x5d91f8, 0x4f46e6, 0x7b6a2b, 0x6316fb, 0x7e7ef4, 0x319b92,
0x317bc2, 0x2a89e9, 0x7957fb, 0x1de939, 0x04996b, 0x63f66d, 0x7c9834, 0x33bb4b,
0x3a003d, 0x316527, 0x572c24, 0x2f4714, 0x0b55ac, 0x195393, 0x18f7b1, 0x42b9c3,
0x201d91, 0x483210, 0x6abc22, 0x276666, 0x25901f, 0x04c1dc, 0x035e1c, 0x14d3eb,
0x5acfee, 0x355315, 0x008ba5, 0x2bab1f, 0x477ff4, 0x33e2b9, 0x48c224, 0x4284b2,
0x32b985, 0x0f18a6, 0x7cb45e, 0x629730, 0x506259, 0x36259a, 0x5e1079};




/* Min Buffer Profile
 * buffer_profile * 1024 * bufferSize = number of bytes buffered for this profile
 */
#define SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX 32 /* though there are 512 entries, currently we are only using 32 */

static uint32 sirius_qm_min_buffer[SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX] = {
    /* 0      1       2       3       4       5       6       7       8       9      10      11      12     13      14      15 */
       0,     5,     10,     20,     30,     40,     50,     60,     70,     80,     90,    100,    110,   120,    130,    140,
     150,   200,    300,    400,    500,    600,    700,    800,    900,   1000,   2000,   3000,   4000,  5000,   6000,   7000
};

#if 0
static uint32 sirius_qm_max_buffer[SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX] = {
    /* 0      1       2       3       4       5       6       7       8       9      10      11      12     13      14      15 */
       0,    10,     20,     40,     60,     80,    100,    120,    140,    160,    180,    200,    220,   240,    260,    280,
     300,   400,    600,    800,   1000,   1200,   1400,   1600,   1800,   2000,   4000,   6000,   8000, 10000,  12000,  14000
};
#endif /* 0 */

int soc_sirius_qm_buffer_template_config(int unit, uint32 uMinBufferingInKbytes, uint32 uMaxBufferingInKbytes, uint32 *pTemplateId)
{
    uint32 uIndex;
    uint32 uBufferingForCurrentTemplateInKbytes;
    int32  nBufferSize;
    uint32 uRegValue;

    *pTemplateId = 0;

    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG1r(unit, &uRegValue));
    nBufferSize = (int32)(soc_reg_field_get(unit, QMA_CONFIG1r, uRegValue, BUFF_SIZEf));

    if ((nBufferSize != 5) && (nBufferSize !=10)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Invalid buffer size configured (%d)\n"),
                   nBufferSize*1024));
        return SOC_E_PARAM;
    }

    for (uIndex=0; uIndex < SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX; uIndex++) {

        uBufferingForCurrentTemplateInKbytes = sirius_qm_min_buffer[uIndex] * nBufferSize;

        if (uBufferingForCurrentTemplateInKbytes > uMinBufferingInKbytes) {
            break;
        }
    }
    LOG_ERROR(BSL_LS_SOC_COMMON,
              (BSL_META_U(unit,
                          "closest value without exceeding (%d)kbytes template(%d)"
                          " buffer size(%d)bytes\n"),
               uBufferingForCurrentTemplateInKbytes,
               uIndex, nBufferSize*1024));

    *pTemplateId = uIndex;
    return SOC_E_NONE;
}

int
soc_sirius_qm_queue_max_buffs_buf_entry_set(int unit, int32 template_id, uint32 max_buffs)
{
    int rv = SOC_E_NONE;
    q_max_buffs_entry_t qMaxBuffs;
    SOC_IF_ERROR_RETURN(READ_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));
    soc_mem_field32_set(unit, Q_MAX_BUFFSm, &qMaxBuffs, MAX_BUFFSf, max_buffs);
    SOC_IF_ERROR_RETURN(WRITE_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));

    return rv;
}

int
soc_sirius_qm_queue_max_buffs_entry_set(int unit, int32 template_id, uint32 gain, uint32 max_buffs)
{
    int rv = SOC_E_NONE;
    q_max_buffs_entry_t qMaxBuffs;
    SOC_IF_ERROR_RETURN(READ_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));
    soc_mem_field32_set(unit, Q_MAX_BUFFSm, &qMaxBuffs, GAINf, gain);
    soc_mem_field32_set(unit, Q_MAX_BUFFSm, &qMaxBuffs, MAX_BUFFSf, max_buffs);
    SOC_IF_ERROR_RETURN(WRITE_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));

    return rv;
}

int
soc_sirius_qm_queue_max_buffs_buf_entry_get(int unit, int32 template_id, uint32 *pmax_buffs)
{
    int rv = SOC_E_NONE;
    q_max_buffs_entry_t qMaxBuffs;

    SOC_IF_ERROR_RETURN(READ_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));
    *pmax_buffs = soc_mem_field32_get(unit, Q_MAX_BUFFSm, &qMaxBuffs, MAX_BUFFSf);

    return rv;
}

int
soc_sirius_qm_queue_max_buffs_entry_get(int unit, int32 template_id, uint32 *pgain, uint32 *pmax_buffs)
{
    int rv = SOC_E_NONE;
    q_max_buffs_entry_t qMaxBuffs;

    SOC_IF_ERROR_RETURN(READ_Q_MAX_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMaxBuffs));
    *pgain = soc_mem_field32_get(unit, Q_MAX_BUFFSm, &qMaxBuffs, GAINf);
    *pmax_buffs = soc_mem_field32_get(unit, Q_MAX_BUFFSm, &qMaxBuffs, MAX_BUFFSf);

    return rv;
}

int
soc_sirius_qm_queue_size_in_bufs_get(int unit, uint32 buff_sz, uint32 *nbr_bufs)
{
    int     rv = SOC_E_NONE;
    int32   nBufferSize;
    uint32  uRegValue;


    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG1r(unit, &uRegValue));
    nBufferSize = (int32)(soc_reg_field_get(unit, QMA_CONFIG1r, uRegValue, BUFF_SIZEf));
    (*nbr_bufs) = (buff_sz / (nBufferSize * 1024)) + ((buff_sz % (nBufferSize * 1024)) ? 1 : 0);

    return(rv);
} 

int
soc_sirius_qm_queue_size_get(int unit, uint32 nbr_buff, uint32 *buff_sz)
{
    int     rv = SOC_E_NONE;
    int32   nBufferSize;
    uint32  uRegValue;


    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG1r(unit, &uRegValue));
    nBufferSize = (int32)(soc_reg_field_get(unit, QMA_CONFIG1r, uRegValue, BUFF_SIZEf));
    (*buff_sz) = nbr_buff * (nBufferSize * 1024);

    return(rv);
} 


int
soc_sirius_qm_queue_max_buff_set(int unit, int32 template_id, uint32 max_buff_sz)
{
    int     rv = SOC_E_NONE;
    uint32  nBuffs;


    rv = soc_sirius_qm_queue_size_in_bufs_get(unit, max_buff_sz, &nBuffs);
    if (rv != SOC_E_NONE) {
        return(rv);
    }

    if (nBuffs <= 0) {
	nBuffs = 0x3ffff;
    }

    rv = soc_sirius_qm_queue_max_buffs_buf_entry_set(unit, template_id, nBuffs);

    return(rv);
}

int
soc_sirius_qm_queue_max_buff_get(int unit, int32 template_id, uint32 *pmax_buff_sz)
{
    int     rv = SOC_E_NONE;
    uint32  nBuffs;


    rv = soc_sirius_qm_queue_max_buffs_buf_entry_get(unit, template_id, &nBuffs);
    if (rv != SOC_E_NONE) {
        return(rv);
    }
    rv = soc_sirius_qm_queue_size_get(unit, nBuffs, pmax_buff_sz);

    return(rv);
}

int
soc_sirius_qm_queue_buffs_profile_entry_set(int unit, int32 queue, uint32 buffs_template, uint32 enable)
{
    int rv = SOC_E_NONE;
    qbuffsprofile_entry_t qBuffsProfile;

    SOC_IF_ERROR_RETURN(READ_QBUFFSPROFILEm(unit, MEM_BLOCK_ANY, queue, &qBuffsProfile));
    soc_mem_field32_set(unit, QBUFFSPROFILEm, &qBuffsProfile, BUFF_TEMPLATEf, buffs_template);
    soc_mem_field32_set(unit, QBUFFSPROFILEm, &qBuffsProfile, ENABLEf, enable);
    SOC_IF_ERROR_RETURN(WRITE_QBUFFSPROFILEm(unit, MEM_BLOCK_ANY, queue, &qBuffsProfile));

    return rv;
}

int
soc_sirius_qm_queue_buffs_profile_entry_get(int unit, int32 queue, uint32 *pbuffs_template, uint32 *penable)
{
    int rv = SOC_E_NONE;
    qbuffsprofile_entry_t qBuffsProfile;

    SOC_IF_ERROR_RETURN(READ_QBUFFSPROFILEm(unit, MEM_BLOCK_ANY, queue, &qBuffsProfile));
    *pbuffs_template = soc_mem_field32_get(unit, QBUFFSPROFILEm, &qBuffsProfile, BUFF_TEMPLATEf);
    *penable = soc_mem_field32_get(unit, QBUFFSPROFILEm, &qBuffsProfile, ENABLEf);

    return rv;
}

int
soc_sirius_qm_queue_min_buffs_entry_set(int unit, int32 template_id, uint32 guaranteed_buffs)
{
    int rv = SOC_E_NONE;
    q_min_buffs_entry_t qMinBuffs;

    SOC_IF_ERROR_RETURN(READ_Q_MIN_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMinBuffs));
    soc_mem_field32_set(unit, Q_MIN_BUFFSm, &qMinBuffs, MIN_BUFFSf, guaranteed_buffs);
    SOC_IF_ERROR_RETURN(WRITE_Q_MIN_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMinBuffs));
    return rv;
}

int
soc_sirius_qm_queue_min_buffs_entry_get(int unit, int32 template_id, uint32 *pguaranteed_buffs)
{
    int rv = SOC_E_NONE;
    q_min_buffs_entry_t qMinBuffs;

    SOC_IF_ERROR_RETURN(READ_Q_MIN_BUFFSm(unit, MEM_BLOCK_ANY, template_id, &qMinBuffs));
    *pguaranteed_buffs = soc_mem_field32_get(unit, Q_MIN_BUFFSm, &qMinBuffs, MIN_BUFFSf);
    return rv;
}

int
soc_sirius_qm_queue_min_buff_set(int unit, int32 template_id, uint32 min_buff_sz)
{
    int     rv = SOC_E_NONE;
    uint32  nBuffs;


    rv = soc_sirius_qm_queue_size_in_bufs_get(unit, min_buff_sz, &nBuffs);
    if (rv != SOC_E_NONE) {
        return(rv);
    }
    rv = soc_sirius_qm_queue_min_buffs_entry_set(unit, template_id, nBuffs);

    return(rv);
}

int
soc_sirius_qm_queue_min_buff_get(int unit, int32 template_id, uint32 *pmin_buff_sz)
{
    int     rv = SOC_E_NONE;
    uint32  nBuffs;


    rv = soc_sirius_qm_queue_min_buffs_entry_get(unit, template_id, &nBuffs);
    if (rv != SOC_E_NONE) {
        return(rv);
    }
    rv = soc_sirius_qm_queue_size_get(unit, nBuffs, pmin_buff_sz);

    return(rv);
}

static int
_soc_sirius_hw_init_qm( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue;
    wred_curve_entry_t wredCurve;
    rate_delta_max_entry_t rateDeltaMaxEntry;
    leafnode_to_queue_entry_t leafnodeToQueue;
    queue_to_sc_0_entry_t queueToSc;
    lla_trans_entry_t llaTrans;
    pfc_enq_src_port_lkup_entry_t QmPFCSrcPortLutEntry;
    soc_timeout_t timeout;
    int nTimeoutInUsec;
    int32 nIndex = 0;
    int32 nLla, nLla_9_6, nLla_5_1, nLla_0, nLla_9_7, nLla_6_1;
    int32 nLla_9_8, nLla_7_1, nLla_9_9, nLla_8_1;
    int32 nInitDone;
    int32 nDequeuePlaneMode;
#if 0
    int32 nTemplateId;
    int32 uGuaranteedBuffs;
    int32 uGain;
    int32 uMaxBuffs;
    int cos, is_allocated, template;
#endif /* 0 */
    uint32 wred_enable;
    uint32 qavg_enable;
    uint16 dev_id;
    uint8  rev_id;
    int rate_delta_mode = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init qm called.\n")));

    soc_cm_get_id(SIRIUS_UNIT, &dev_id, &rev_id);

    /* Clear software resets for each of the QM partitions
     */
    SOC_IF_ERROR_RETURN(READ_QMA_SW_RESETr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMA_SW_RESETr, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QMA_SW_RESETr(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMB_SW_RESETr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_SW_RESETr, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QMB_SW_RESETr(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMC_SW_RESETr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMC_SW_RESETr, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QMC_SW_RESETr(SIRIUS_UNIT, uRegValue));


    SOC_IF_ERROR_RETURN(READ_QMB_FL_DEBUG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG1r, &uRegValue, FREE_LIST_HEAD_PTRf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QMB_FL_DEBUG1r(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMB_FL_DEBUG2r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG2r, &uRegValue, FREE_LIST_TAIL_PTRf,
		      pInitParams->uMaxBuffer - 1);
    SOC_IF_ERROR_RETURN(WRITE_QMB_FL_DEBUG2r(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMB_FL_DEBUG3r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG3r, &uRegValue, FREE_LIST_DEPTHf,
		      pInitParams->uMaxBuffer);
    soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG3r, &uRegValue, FREE_LIST_INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMB_FL_DEBUG3r(SIRIUS_UNIT, uRegValue));


    /* Initialize the QM database.  For each partition the database initialization
     * is kicked off and then status polled until init done is returned.
     */
    /* A partition init */
    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMA_CONFIG0r, &uRegValue, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMA_CONFIG0r(SIRIUS_UNIT, uRegValue));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        nTimeoutInUsec = _sirius_init_timeout;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_QMA_CONFIG0r(SIRIUS_UNIT,&uRegValue));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT, QMA_CONFIG0r, uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("QM A init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* B partition init */
    if (SAL_BOOT_BCMSIM) {
        /* in BCMSIM environment, set the free list to 16k instead of 256k 
           to reduce the memory usage on the model */
        SOC_IF_ERROR_RETURN(READ_QMB_FL_DEBUG3r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG3r, &uRegValue, 
                          FREE_LIST_DEPTHf, 0x4000);
        SOC_IF_ERROR_RETURN(WRITE_QMB_FL_DEBUG3r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_QMB_FL_DEBUG2r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QMB_FL_DEBUG2r, &uRegValue, 
                          FREE_LIST_TAIL_PTRf, (0x4000 -1));
        SOC_IF_ERROR_RETURN(WRITE_QMB_FL_DEBUG2r(SIRIUS_UNIT, uRegValue));
    }

    SOC_IF_ERROR_RETURN(READ_QMB_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG0r, &uRegValue, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMB_CONFIG0r(SIRIUS_UNIT, uRegValue));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        nTimeoutInUsec = _sirius_init_timeout * 10;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_QMB_CONFIG0r(SIRIUS_UNIT,&uRegValue));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT, QMB_CONFIG0r,uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("QM B init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* C partition init */
    SOC_IF_ERROR_RETURN(READ_QMC_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMC_CONFIG0r, &uRegValue, INITf, 1);
    /* disable this, when enabled, BAA will limit the amount of bandwidth it asks for 
     * based on ingress shaper config 
     */
    soc_reg_field_set(SIRIUS_UNIT, QMC_CONFIG0r, &uRegValue, QS_SHAPER_LIMIT_ENABLEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QMC_CONFIG0r(SIRIUS_UNIT, uRegValue));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        nTimeoutInUsec = _sirius_init_timeout;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_QMC_CONFIG0r(SIRIUS_UNIT,&uRegValue));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT, QMC_CONFIG0r,uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("QM C init done timeout\n")));
            return SOC_E_TIMEOUT;
        }
    }


    /* Initialize the maximum VOQ number
     */
    if (pInitParams->nMaxVoq > SB_FAB_DEVICE_SIRIUS_MAX_VOQ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("QM max VOQ is out of range\n")));
        return SOC_E_PARAM;
    }
    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMA_CONFIG1r, &uRegValue, VOQ_THRESHOLDf, pInitParams->nMaxVoq);
    SOC_IF_ERROR_RETURN(WRITE_QMA_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /* Set the size of the payload buffers
     */
    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMA_CONFIG1r, &uRegValue, BUFF_SIZEf,
		      pInitParams->uBufferSize);
    SOC_IF_ERROR_RETURN(WRITE_QMA_CONFIG1r(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMB_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG0r, &uRegValue, BUFF_SIZEf,
		      pInitParams->uBufferSize);
    SOC_IF_ERROR_RETURN(WRITE_QMB_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /* If we are in hybrid or tme mode, set the dequeue planes to be static.
     * If in FIC mode, set the dequeue plane to be dynamic regardless.
     */
    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) ||
        soc_feature(SIRIUS_UNIT, soc_feature_hybrid) ) {
        nDequeuePlaneMode = 1;
    }else {
        nDequeuePlaneMode = 0;
    }
    SOC_IF_ERROR_RETURN(READ_QMB_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG0r, &uRegValue, DEQUEUE_PLANE_MODEf, nDequeuePlaneMode);
    SOC_IF_ERROR_RETURN(WRITE_QMB_CONFIG0r(SIRIUS_UNIT, uRegValue));


    /* Set up random number memory table
     */
    for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, RANDGENm).index_max; nIndex++) {
      SOC_IF_ERROR_RETURN(WRITE_RANDGENm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &sirius_qm_random_table_entries[nIndex]));
    }

    /* Set up lla translation table */
    if (pInitParams->uDdr3NumMemories > 8) {
	/* 9 or 10 channels
	 *
	 * lla[9:6] = offset[9:1] % `NUMBER_OF_CI; // channel
	 * lla[5:1] = offset[9:1] / `NUMBER_OF_CI; //   block
	 * lla[  0] = offset[  0];                 //   index
	 */
	for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, LLA_TRANSm).index_max; nIndex++) {
	    
	    nLla_9_6  = ((nIndex & 0x3FE) >> 1) % pInitParams->uDdr3NumMemories; /* channel */
	    nLla_5_1  = ((nIndex & 0x3FE) >> 1) / pInitParams->uDdr3NumMemories; /* block */
	    nLla_0 =     nIndex & 0x1;              /* index */
	    
	    nLla = (nLla_9_6 << 6) | (nLla_5_1 << 1) | nLla_0;
	    soc_mem_field32_set(SIRIUS_UNIT, LLA_TRANSm, &llaTrans, LLA_OFFSETf, nLla);
	    SOC_IF_ERROR_RETURN(WRITE_LLA_TRANSm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &llaTrans));
	}
    } else if (pInitParams->uDdr3NumMemories > 4) {
	/* 5 to 8 channels
	 *
	 * lla[9:7] = offset[9:1] % `NUMBER_OF_CI; // channel
	 * lla[6:1] = offset[9:1] / `NUMBER_OF_CI; //   block
	 * lla[  0] = offset[  0];                 //   index
	 */
	for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, LLA_TRANSm).index_max; nIndex++) {
	    
	    nLla_9_7  = ((nIndex & 0x3FE) >> 1) % pInitParams->uDdr3NumMemories; /* channel */
	    nLla_6_1  = ((nIndex & 0x3FE) >> 1) / pInitParams->uDdr3NumMemories; /* block */
	    nLla_0 =     nIndex & 0x1;              /* index */
	    
	    nLla = (nLla_9_7 << 7) | (nLla_6_1 << 1) | nLla_0;
	    soc_mem_field32_set(SIRIUS_UNIT, LLA_TRANSm, &llaTrans, LLA_OFFSETf, nLla);
	    SOC_IF_ERROR_RETURN(WRITE_LLA_TRANSm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &llaTrans));
	}
    } else if (pInitParams->uDdr3NumMemories > 2) {
	/* 2 to 4 channels
	 *
	 * lla[9:8] = offset[9:1] % `NUMBER_OF_CI; // channel
	 * lla[7:1] = offset[9:1] / `NUMBER_OF_CI; //   block
	 * lla[  0] = offset[  0];                 //   index
	 */
	for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, LLA_TRANSm).index_max; nIndex++) {
	    
	    nLla_9_8  = ((nIndex & 0x3FE) >> 1) % pInitParams->uDdr3NumMemories; /* channel */
	    nLla_7_1  = ((nIndex & 0x3FE) >> 1) / pInitParams->uDdr3NumMemories; /* block */
	    nLla_0 =     nIndex & 0x1;              /* index */
	    
	    nLla = (nLla_9_8 << 8) | (nLla_7_1 << 1) | nLla_0;
	    soc_mem_field32_set(SIRIUS_UNIT, LLA_TRANSm, &llaTrans, LLA_OFFSETf, nLla);
	    SOC_IF_ERROR_RETURN(WRITE_LLA_TRANSm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &llaTrans));
	}
    } else {
	/* 1 to 2 channels
	 *
	 * lla[9:9] = offset[9:1] % `NUMBER_OF_CI; // channel
	 * lla[8:1] = offset[9:1] / `NUMBER_OF_CI; //   block
	 * lla[  0] = offset[  0];                 //   index
	 */
	for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, LLA_TRANSm).index_max; nIndex++) {
	    
	    nLla_9_9  = ((nIndex & 0x3FE) >> 1) % pInitParams->uDdr3NumMemories; /* channel */
	    nLla_8_1  = ((nIndex & 0x3FE) >> 1) / pInitParams->uDdr3NumMemories; /* block */
	    nLla_0 =     nIndex & 0x1;              /* index */
	    
	    nLla = (nLla_9_9 << 9) | (nLla_8_1 << 1) | nLla_0;
	    soc_mem_field32_set(SIRIUS_UNIT, LLA_TRANSm, &llaTrans, LLA_OFFSETf, nLla);
	    SOC_IF_ERROR_RETURN(WRITE_LLA_TRANSm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &llaTrans));
	}
    }

    /* Enable free buffer list
     */
    SOC_IF_ERROR_RETURN(READ_QMB_CONFIG3r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG3r, &uRegValue, FREE_LIST_ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMB_CONFIG3r(SIRIUS_UNIT, uRegValue));
    /*
     *  Initialise leafnode_to_queue mapping so invalid leaves point to queue SIRIUS_Q_BASE_INVALID
     */
    sal_memset(&(leafnodeToQueue), 0x00, sizeof(leafnodeToQueue));
    soc_mem_field32_set(SIRIUS_UNIT, LEAFNODE_TO_QUEUEm, &(leafnodeToQueue), LN2Q_BASE_QUEUEf, (SIRIUS_Q_BASE_INVALID >> 2));
    for (nIndex = SOC_MEM_INFO(SIRIUS_UNIT, LEAFNODE_TO_QUEUEm).index_min;
         nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, LEAFNODE_TO_QUEUEm).index_max;
         nIndex++) {
        SOC_IF_ERROR_RETURN(WRITE_LEAFNODE_TO_QUEUEm(SIRIUS_UNIT, MEM_BLOCK_ALL, nIndex, &(leafnodeToQueue)));
    }
    /*
     *  Initialise queue_to_leafnode mapping so invalid queue point to leaf SIRIUS_Q_BASE_INVALID
     */
    sal_memset(&(queueToSc), 0x00, sizeof(queueToSc));
    soc_mem_field32_set(SIRIUS_UNIT, QUEUE_TO_SC_0m, &(queueToSc), COSf, (SIRIUS_Q_BASE_INVALID & 0xF));
    soc_mem_field32_set(SIRIUS_UNIT, QUEUE_TO_SC_0m, &(queueToSc), SYSPORTf, (SIRIUS_Q_BASE_INVALID >> 4));
    for (nIndex = SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_0m).index_min;
         nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_0m).index_max;
         nIndex++) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_0m(SIRIUS_UNIT, MEM_BLOCK_ALL, nIndex, &(queueToSc)));
    }
    for (nIndex = SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_1m).index_min;
         nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_1m).index_max;
         nIndex++) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_1m(SIRIUS_UNIT, MEM_BLOCK_ALL, nIndex, &(queueToSc)));
    }
    for (nIndex = SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_2m).index_min;
         nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_2m).index_max;
         nIndex++) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_2m(SIRIUS_UNIT, MEM_BLOCK_ALL, nIndex, &(queueToSc)));
    }
    for (nIndex = SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_3m).index_min;
         nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, QUEUE_TO_SC_3m).index_max;
         nIndex++) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_3m(SIRIUS_UNIT, MEM_BLOCK_ALL, nIndex, &(queueToSc)));
    }
    /* Set up WRED tables to be off
     */
    for (nIndex=0; nIndex<=SOC_MEM_INFO(SIRIUS_UNIT, WRED_CURVEm).index_max; nIndex++) {

        SOC_IF_ERROR_RETURN(READ_WRED_CURVEm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &wredCurve));
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, PDROP_MAXf, 0x3);
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, TMAXf, 0xffff);
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, TECNf, 0xffff);
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, TMINf, 0xffff);
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, SCALEf, 0xf);
        soc_mem_field32_set(SIRIUS_UNIT, WRED_CURVEm, &wredCurve, SLOPEf, 0xfff);
        SOC_IF_ERROR_RETURN(WRITE_WRED_CURVEm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &wredCurve));
    }
    /* Set buffer aging settings - scaling factor/enable is also controlled via API bcm_switch_control_set()
     */
    SOC_IF_ERROR_RETURN(READ_QMC_AGER_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMC_AGER_CONFIG0r, &uRegValue, AGER_SCALING_FACTORf, 7);
    soc_reg_field_set(SIRIUS_UNIT, QMC_AGER_CONFIG0r, &uRegValue, AGER_ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMC_AGER_CONFIG0r(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_QMC_AGER_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    /* last_buffer_id[17:3] - drop ls 3 bits */
    soc_reg_field_set(SIRIUS_UNIT, QMC_AGER_CONFIG1r, &uRegValue, AGER_TAIL_BUFFERf,
		      (pInitParams->uMaxBuffer-1)>>3);
    
    soc_reg_field_set(SIRIUS_UNIT, QMC_AGER_CONFIG1r, &uRegValue, AGER_TAIL_QUEUEf, 0xffff);
    SOC_IF_ERROR_RETURN(WRITE_QMC_AGER_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /*
     * There are 64 rate delta max table entries which set a damping level
     * on the responsiveness of a queue to changes in bandwidth allocation.
     * Recommended setting between 10 and 20% of line rate.  Units are in
     * bytes/epoch.  The smaller the rate delta max, the slower the
     * responsiveness in bw allocation.
     *
     * TME mode - unused because bandwidth allocation not performed.
     */
        if (soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
        int32 nRateDeltaMaxInBytesPerEpoch = 0;

        for (nIndex=0; nIndex<SOC_MEM_INFO(SIRIUS_UNIT, RATE_DELTA_MAXm).index_max; nIndex++) {
            soc_mem_field32_set(SIRIUS_UNIT, RATE_DELTA_MAXm, &rateDeltaMaxEntry, RATE_MAX_DELTAf, nRateDeltaMaxInBytesPerEpoch);
            SOC_IF_ERROR_RETURN(WRITE_RATE_DELTA_MAXm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &rateDeltaMaxEntry));
        }
    }
    else {

        /*
         * Sample Calculation: - tune for sirius
         *
         * logical port rate 10Gbps.
         * rate 10%
         *
         * 632ns timeslot size in D-Mode 16401 byte epoch
         *
         * rate in b/s = x bytes/epoch * 1byte/8 bits * 1 epoch/16401 timeslots * 1 timeslot/632ns solve for x.
         * x bytes/epoch = (rate b/s) * 632ns/timeslot * 16401 timeslots/epoch * 1 byte/8 bits
         * x bytes/epoch = (rate b/s) * 1.295679x10^3
         * Set up the rate delta max table for D-Mode as follows:
         *
         * timeslot = 1065 ns
         * epoch size = 16433 timeslots
         * epoch (in ns) = 1065 * 16433
         * x rate (bits/sec)
         *   rate (bits/sec) = x
         *   rate (bits/nsec) = x/(10^9)
         *   rate (bits/epoch) = x/(10^9) * 1065 * 16433
         *   rate (bytes / epoch) = x * ((1065 * 16433) / ((10^9) * 8))
         *                        = x * .002186743125
         *
         */

        /*                                           10%       13%      17%      20%                          */
        int32 nRateDeltaMaxInBytesPerEpoch_mode0[64] = { 218,      283,     370,     436,           /*    1 Mb   */
                                                           437,      568,     742,     874,           /*    2 Mb   */
                                                           1093,     1420,    1858,    2186,          /*    5 Mb   */
                                                           1530,     1989,    2601,    3060,          /*    7 Mb   */
                                                           2186,     2841,    3716,    4372,          /*    10 Mb  */
                                                           4373,     5684,    7434,    8746,		  /*    20 Mb  */
                                                           10933,    14212,   18586,   21866,		  /*    50 Mb  */
                                                           15307,    19899,   26021,   30614,		  /*    70 Mb  */
                                                           21867,    28427,   37173,   43734,         /*   100 Mb  */
                                                           43734,    56854,   74347,   87468,	      /*   200 Mb  */
                                                           109337,   142138,  185872,  218674,	      /*   500 Mb  */
                                                           153072,   198993,  260222,  306144,	      /*   700 Mb  */
                                                           218764,   284393,  371898,  437528,        /*    1 Gb   */
                                                           437528,   568786,  743797,  875056,	      /*    2 Gb   */
                                                           1093821,  1421967, 1859495, 2187642,	      /*    5 Gb   */
                                                           2187643,  2843935, 3718993, 4375286};	  /*   10 Gb   */
        


        int32 nRateDeltaMaxInBytesPerEpoch_mode1[64] = {  1093,     1420,    1858,    2186,          /*    5 Mb   */
                                                            1530,     1989,    2601,    3060,          /*    7 Mb   */
                                                            2186,     2841,    3716,    4372,          /*    10 Mb  */
                                                            4373,     5684,    7434,    8746,          /*    20 Mb  */
                                                            10933,    14212,   18586,   21866,         /*    50 Mb  */
                                                            15307,    19899,   26021,   30614,         /*    70 Mb  */
                                                            21867,    28427,   37173,   43734,         /*   100 Mb  */
                                                            43734,    56854,   74347,   87468,         /*   200 Mb  */
                                                            109337,   142138,  185872,  218674,        /*   500 Mb  */
                                                            153072,   198993,  260222,  306144,        /*   700 Mb  */
                                                            218764,   284393,  371898,  437528,        /*    1 Gb   */
                                                            437528,   568786,  743797,  875056,        /*    2 Gb   */
                                                            1093821,  1421967, 1859495, 2187642,       /*    5 Gb   */
                                                            2187643,  2843935, 3718993, 4375286,       /*   10 Gb   */
                                                            4375286, 5687870,  7437986, 8450592,       /*   20 Gb   */
                                                            5469108, 7109838,  9297483, 10938215};     /*   25 Gb   */
        /* #endif  CSP 529938 */

        rate_delta_mode = soc_property_get(SIRIUS_UNIT, "sirius_rate_delta_mode", rate_delta_mode);


        for (nIndex=0; nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, RATE_DELTA_MAXm).index_max; nIndex++) {
            if (rate_delta_mode == 1) {
                soc_mem_field32_set(SIRIUS_UNIT, RATE_DELTA_MAXm, &rateDeltaMaxEntry, RATE_MAX_DELTAf, nRateDeltaMaxInBytesPerEpoch_mode1[nIndex]);
            } else {
                soc_mem_field32_set(SIRIUS_UNIT, RATE_DELTA_MAXm, &rateDeltaMaxEntry, RATE_MAX_DELTAf, nRateDeltaMaxInBytesPerEpoch_mode0[nIndex]);
            }
            SOC_IF_ERROR_RETURN(WRITE_RATE_DELTA_MAXm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &rateDeltaMaxEntry));
        }
    }


#if 0
    /*
     * Sirius buffer templates are no longer managed by the qbuf module due to local WRED
     * Since local WRED template uses same template pointer, make the queue min/max sizes part of
     * the WRED template and manage it there.
     */

    /*
     * Setup default buffer templates
     */
    rv = soc_sbx_qbuf_init(SIRIUS_UNIT);
    if (rv != SOC_E_NONE) {
        return(rv);
    }

    for (cos = 0; cos < SBX_MAX_FABRIC_COS; cos++) {
        rv = soc_sbx_qbuf_alloc(SIRIUS_UNIT, SOC_SBX_TEMPLATE_FIXED,
                                SOC_SBX_CFG(SIRIUS_UNIT)->bcm_cosq_priority_min_depth_bytes[cos],
                                SOC_SBX_CFG(SIRIUS_UNIT)->bcm_cosq_priority_max_depth_bytes[cos],
                                &is_allocated, &template);
        if (rv != SOC_E_NONE) {
            return(rv);
        }

        if (is_allocated == TRUE) {
            rv = soc_sirius_qm_queue_min_buff_set(SIRIUS_UNIT, template, 
                                 SOC_SBX_CFG(SIRIUS_UNIT)->bcm_cosq_priority_min_depth_bytes[cos]);
            if (rv != SOC_E_NONE) {
                return(rv);
            }

            rv = soc_sirius_qm_queue_max_buff_set(SIRIUS_UNIT, template,
                                SOC_SBX_CFG(SIRIUS_UNIT)->bcm_cosq_priority_max_depth_bytes[cos]);
            if (rv != SOC_E_NONE) {
                return(rv);
            }
        }
    }
    
    
    for (nTemplateId=0; nTemplateId<SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX; nTemplateId++) {
        if (nBufferSize==10) {
          uGuaranteedBuffs = sirius_qm_min_buffer[nTemplateId];
        }
        else {
          uGuaranteedBuffs = sirius_qm_min_buffer[nTemplateId] << 1;
        }
        rv = soc_sirius_qm_queue_min_buffs_entry_set(SIRIUS_UNIT, nTemplateId, uGuaranteedBuffs);
        if (rv) {
            return rv;
        }
    }

    for (nTemplateId=0; nTemplateId<SIRIUS_QM_Q_MIN_MAX_BUFFS_MAX; nTemplateId++) {

        if (nBufferSize==10) {
            uMaxBuffs= sirius_qm_max_buffer[nTemplateId];
        }
        else {
            uMaxBuffs = sirius_qm_max_buffer[nTemplateId] << 1;
        }

        uGain = 0;

        rv = soc_sirius_qm_queue_max_buffs_entry_set(SIRIUS_UNIT, nTemplateId, uGain, uMaxBuffs);
        if (rv) {
            return rv;
        }
    }
#endif /* 0 */

    /* enable flusher
     */
    SOC_IF_ERROR_RETURN(READ_QMB_CONFIG2r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG2r, &uRegValue, FLUSHER_ENABLEf, 1);
    if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {    
	soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG2r, &uRegValue, DEQR_SLOT_DELAYf, 0);
    } else {
	soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG2r, &uRegValue, DEQR_SLOT_DELAYf, 6);
    }
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG2r, &uRegValue, SC_LEN_FORMATf, 4);
    soc_reg_field_set(SIRIUS_UNIT, QMB_CONFIG2r, &uRegValue, ARRIVAL_UPDATE_ON_DROPf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMB_CONFIG2r(SIRIUS_UNIT, uRegValue));

    /* enable QM block
     */
    SOC_IF_ERROR_RETURN(READ_QMA_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMA_CONFIG0r, &uRegValue, ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QMA_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /*
     * Enable WRED
     */
    SOC_IF_ERROR_RETURN(READ_QMA_WRED_CONFIGr(SIRIUS_UNIT, &uRegValue));

    wred_enable = soc_reg_field_get(SIRIUS_UNIT, QMA_WRED_CONFIGr, uRegValue, WRED_ENABLEf);
    if (!soc_feature(SIRIUS_UNIT, soc_feature_standalone)) { /* FIC Queues */
	if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {
	    wred_enable |= 0x3;
	} else {
	    wred_enable |= 0x2;
	}
    } else {
	    wred_enable |= 0x1;
    }

    soc_reg_field_set(SIRIUS_UNIT, QMA_WRED_CONFIGr, &uRegValue, WRED_ENABLEf, wred_enable);
    SOC_IF_ERROR_RETURN(WRITE_QMA_WRED_CONFIGr(SIRIUS_UNIT, uRegValue));

    /* Enable Qavg */
    SOC_IF_ERROR_RETURN(READ_QMC_QAVG_CONFIG0r(SIRIUS_UNIT, &uRegValue));

    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) ||
	soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {
	qavg_enable = 0x1;
    } else {
	qavg_enable = 0x0;
    }

    soc_reg_field_set(SIRIUS_UNIT, QMC_QAVG_CONFIG0r, &uRegValue, QAVG_ENABLEf, qavg_enable);
    SOC_IF_ERROR_RETURN(WRITE_QMC_QAVG_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /* Max Arrival bytes */
    SOC_IF_ERROR_RETURN(READ_QMC_DC_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMC_DC_CONFIG0r, &uRegValue, MAX_ARRIVAL_BYTESf, 
              (pInitParams->uEpochSizeInNs/1000 * pInitParams->uQmMaxArrivalRateMbs/8));
    SOC_IF_ERROR_RETURN(WRITE_QMC_DC_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /* length sum adjustment */
    SOC_IF_ERROR_RETURN(READ_QMC_DC_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QMC_DC_CONFIG1r, &uRegValue, LENGTH_SUM_ADJUSTf,
              ((pInitParams->uQmMaxArrivalRateMbs * pInitParams->nMaxVoq * 6) /
                                       (SOC_SBX_CFG(SIRIUS_UNIT)->uClockSpeedInMHz * 8)));
    SOC_IF_ERROR_RETURN(WRITE_QMC_DC_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /* PFC config */
    if (soc_feature(SIRIUS_UNIT, soc_feature_source_port_priority_flow_control)) {
	/* source port/priority PFC */
	SOC_IF_ERROR_RETURN(READ_QM_PFC_CONFIG0r(SIRIUS_UNIT, &uRegValue));    
	soc_reg_field_set(SIRIUS_UNIT, QM_PFC_CONFIG0r, &uRegValue, SP_PG_ENABLEf, 1);
	soc_reg_field_set(SIRIUS_UNIT, QM_PFC_CONFIG0r, &uRegValue, BANK_SWITCH_TIMERf, 8);
	SOC_IF_ERROR_RETURN(WRITE_QM_PFC_CONFIG0r(SIRIUS_UNIT, uRegValue));

	/* source port ID generation, only care about lower 4 bits */
	SOC_IF_ERROR_RETURN(READ_QM_PFC_ENQ_SRC_PORT_LKUP_CFGr(SIRIUS_UNIT, &uRegValue));    
	soc_reg_field_set(SIRIUS_UNIT, QM_PFC_ENQ_SRC_PORT_LKUP_CFGr, &uRegValue,
			  SOURCE_ID_MASKf, 0xFFF0);
	SOC_IF_ERROR_RETURN(WRITE_QM_PFC_ENQ_SRC_PORT_LKUP_CFGr(SIRIUS_UNIT, uRegValue));

	/* user lower 4 bits of SID as source port ID */
	for (nIndex = 0; nIndex <= SOC_MEM_INFO(SIRIUS_UNIT, PFC_ENQ_SRC_PORT_LKUPm).index_max; nIndex++) {
	    soc_mem_field32_set(SIRIUS_UNIT, PFC_ENQ_SRC_PORT_LKUPm, &QmPFCSrcPortLutEntry, ENABLEf, 1);
	    soc_mem_field32_set(SIRIUS_UNIT, PFC_ENQ_SRC_PORT_LKUPm, &QmPFCSrcPortLutEntry, KEYf, nIndex);
	    SOC_IF_ERROR_RETURN(WRITE_PFC_ENQ_SRC_PORT_LKUPm(SIRIUS_UNIT, MEM_BLOCK_ANY, nIndex, &QmPFCSrcPortLutEntry));
	}
    }    

    return rv;
}

int
soc_sirius_qs_queue_parameter_set(int unit, int32 nQueue, int32 q_type, int32 hold_ts)
{
    int rv = SOC_E_NONE;
    int32 nTempQueue;
    queue_parameter_hi_entry_t queue_parameter_hi_entry;
    queue_parameter_lo_entry_t queue_parameter_lo_entry;

    if (nQueue < 32768) {
        SOC_IF_ERROR_RETURN(READ_QUEUE_PARAMETER_LOm(unit, MEM_BLOCK_ANY, nQueue, &queue_parameter_lo_entry));
        soc_mem_field32_set(unit, QUEUE_PARAMETER_LOm, &queue_parameter_lo_entry, HOLD_TSf, hold_ts);
        soc_mem_field32_set(unit, QUEUE_PARAMETER_LOm, &queue_parameter_lo_entry, QTYPEf, q_type);
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_PARAMETER_LOm(unit, MEM_BLOCK_ANY, nQueue, &queue_parameter_lo_entry));
    } else {
        nTempQueue = nQueue - 32768;
        SOC_IF_ERROR_RETURN(READ_QUEUE_PARAMETER_HIm(unit, MEM_BLOCK_ANY, nTempQueue, &queue_parameter_hi_entry));
        soc_mem_field32_set(unit, QUEUE_PARAMETER_HIm, &queue_parameter_hi_entry, HOLD_TSf, hold_ts);
        soc_mem_field32_set(unit, QUEUE_PARAMETER_HIm, &queue_parameter_hi_entry, QTYPEf, q_type);
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_PARAMETER_HIm(unit, MEM_BLOCK_ANY, nTempQueue, &queue_parameter_hi_entry));
    }
    return rv;
}

int
soc_sirius_qs_queue_parameter_get(int unit, int32 nQueue, int32 *q_type, int32 *hold_ts)
{
    int rv = SOC_E_NONE;
    int32 nTempQueue;
    queue_parameter_hi_entry_t queue_parameter_hi_entry;
    queue_parameter_lo_entry_t queue_parameter_lo_entry;

    if (nQueue < 32768) {
        SOC_IF_ERROR_RETURN(READ_QUEUE_PARAMETER_LOm(unit, MEM_BLOCK_ANY, nQueue, &queue_parameter_lo_entry));
        (*hold_ts) =
            soc_mem_field32_get(unit, QUEUE_PARAMETER_LOm, &queue_parameter_lo_entry, HOLD_TSf);
        (*q_type) =
            soc_mem_field32_get(unit, QUEUE_PARAMETER_LOm, &queue_parameter_lo_entry, QTYPEf);
    } else {
        nTempQueue = nQueue - 32768;
        SOC_IF_ERROR_RETURN(READ_QUEUE_PARAMETER_HIm(unit, MEM_BLOCK_ANY, nTempQueue, &queue_parameter_hi_entry));
        (*hold_ts) =
            soc_mem_field32_get(unit, QUEUE_PARAMETER_HIm, &queue_parameter_hi_entry, HOLD_TSf);
        (*q_type) =
            soc_mem_field32_get(unit, QUEUE_PARAMETER_HIm, &queue_parameter_hi_entry, QTYPEf);
    }
    return rv;
}


int
_soc_sirius_hw_init_qs_shaper(int unit, int32 nMaxVoq)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue;
    int32  nShapeInc;
    int32  nVoqShapeStart;
    int32  nVoqShapeEnd;
    int32  nLocalShapeStart;
    int32  nLocalShapeEnd;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "Sirius hardware init qs shaper called.\n")));
    /*
     * Setup shaper scheme - there are 16K maximum shapers
     * They can occur every 4th queue or be in a contiguous range (nShapeInc=0)
     * Divide these ranges up based upon mode:
     * FIC - vport - 0-nMaxVoq/4 can be shaped (every 4th queue)
     * FIC - vport legacy - 0-nMaxVoq can be shaped (every queue 16k queues max)
     * HYB - 0-nMaxVoq can be shaped (every 4th queue)
     * TME - 0-64k local shaped (every 4th queue)
     */
    nShapeInc = 1; /* increment every 4th queue */

    if (soc_feature(unit, soc_feature_standalone)) {
        nVoqShapeStart = 0;
        nVoqShapeEnd = 0;
        nLocalShapeStart = 0;
        nLocalShapeEnd = 64*1024 - 1;

    } else if (soc_feature(unit, soc_feature_hybrid)) {
        nShapeInc = 1; /* increment every 4th queue */
        nVoqShapeStart = 0;
        nVoqShapeEnd = nMaxVoq - 1;
        nLocalShapeStart = nMaxVoq;
        nLocalShapeEnd = 64*1024 - 1;

    }else {/* FIC */
        if (SOC_SBX_CFG(unit)->uFabricConfig == SOC_SBX_SYSTEM_CFG_VPORT_LEGACY ||
	    SOC_SBX_CFG(unit)->uFabricConfig == SOC_SBX_SYSTEM_CFG_VPORT_MIX ||
            SOC_SBX_CFG(unit)->uFabricConfig == SOC_SBX_SYSTEM_CFG_VPORT) {
            nShapeInc = 0;
        }
        nVoqShapeStart = 0;
        nVoqShapeEnd = nVoqShapeStart + nMaxVoq;
        nLocalShapeStart = 0;
        nLocalShapeEnd = 0;
    }
    /*
     * set local shaper values
     */
    SOC_IF_ERROR_RETURN(READ_SHAPER_QUEUE_LOCAL_RANGE_STARTr(unit, &uRegValue));
    soc_reg_field_set(unit, SHAPER_QUEUE_LOCAL_RANGE_STARTr, &uRegValue, INCf, nShapeInc);
    soc_reg_field_set(unit, SHAPER_QUEUE_LOCAL_RANGE_STARTr, &uRegValue, STARTQUEUEf, nLocalShapeStart);
    SOC_IF_ERROR_RETURN(WRITE_SHAPER_QUEUE_LOCAL_RANGE_STARTr(unit, uRegValue));

    SOC_IF_ERROR_RETURN(READ_SHAPER_QUEUE_LOCAL_RANGE_ENDr(unit, &uRegValue));
    soc_reg_field_set(unit, SHAPER_QUEUE_LOCAL_RANGE_ENDr, &uRegValue, ENDQUEUEf, nLocalShapeEnd);
    SOC_IF_ERROR_RETURN(WRITE_SHAPER_QUEUE_LOCAL_RANGE_ENDr(unit, uRegValue));

    /*
     * set fabric shaper values
     */
    SOC_IF_ERROR_RETURN(READ_SHAPER_QUEUE_FABRIC_RANGE_STARTr(unit, &uRegValue));
    soc_reg_field_set(unit, SHAPER_QUEUE_FABRIC_RANGE_STARTr, &uRegValue, INCf, nShapeInc);
    soc_reg_field_set(unit, SHAPER_QUEUE_FABRIC_RANGE_STARTr, &uRegValue, STARTQUEUEf, nVoqShapeStart);
    SOC_IF_ERROR_RETURN(WRITE_SHAPER_QUEUE_FABRIC_RANGE_STARTr(unit, uRegValue));

    SOC_IF_ERROR_RETURN(READ_SHAPER_QUEUE_FABRIC_RANGE_ENDr(unit, &uRegValue));
    soc_reg_field_set(unit, SHAPER_QUEUE_FABRIC_RANGE_ENDr, &uRegValue, ENDQUEUEf, nVoqShapeEnd);
    SOC_IF_ERROR_RETURN(WRITE_SHAPER_QUEUE_FABRIC_RANGE_ENDr(unit, uRegValue));

    /*
     * shaper queues are 0 to (2^13 + 2^13) = 16k)
     */
    SOC_IF_ERROR_RETURN(READ_SHAPER_LOOP_SIZEr(unit, &uRegValue));
    soc_reg_field_set(unit, SHAPER_LOOP_SIZEr, &uRegValue, SHAPE_LOOP_SIZE_EXP1f, 0xd);
    soc_reg_field_set(unit, SHAPER_LOOP_SIZEr, &uRegValue, SHAPE_LOOP_SIZE_EXP2f, 0xd);
    SOC_IF_ERROR_RETURN(WRITE_SHAPER_LOOP_SIZEr(unit, uRegValue));

    return rv;
}

static int
_soc_sirius_hw_init_qs_ager( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue;
    int cos;
    int template;
    int is_allocated;
    int hwValue, actValue;
#ifdef BCM_EASY_RELOAD_SUPPORT
    uint32 maxage[SBX_MAX_FABRIC_COS];
    uint32 minuse[SBX_MAX_FABRIC_COS];
    uint32 dataval;
#endif
    int tick_cycles = 3200;
    int queue_range_last = 0x7ff;
    
    tick_cycles = soc_property_get(SIRIUS_UNIT, "sirius_qs_ager_tick_cycles", tick_cycles);
    queue_range_last = soc_property_get(SIRIUS_UNIT, "sirius_qs_ager_queue_last", queue_range_last);

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init qs ager called.\n")));
    SOC_IF_ERROR_RETURN(READ_AGER_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, AGER_CONFIG0r, &uRegValue, TICK_CYCLESf, tick_cycles); /* 3200/400MHz=8usec */
    SOC_IF_ERROR_RETURN(WRITE_AGER_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /*
     * Set up ager profile settings
     * One profile is reserved for the calendar_profile, use the last, 15
     * Set up for all queues from 0 to 64k
     */
    SOC_IF_ERROR_RETURN(READ_AGER_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, AGER_CONFIG1r, &uRegValue, CALENDAR_PROFILEf, 15);
    soc_reg_field_set(SIRIUS_UNIT, AGER_CONFIG1r, &uRegValue, QUEUE_RANGE_FIRSTf, 0);
    soc_reg_field_set(SIRIUS_UNIT, AGER_CONFIG1r, &uRegValue, QUEUE_RANGE_LASTf, queue_range_last); /* 15:5 */
    SOC_IF_ERROR_RETURN(WRITE_AGER_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /*
     * Set up age event threshold to be 1/2 the total number of queues
     */
    SOC_IF_ERROR_RETURN(READ_AGER_EVENT_THRESHr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, AGER_EVENT_THRESHr, &uRegValue, EVENT_THRESHf,((64*1024)-1)/2);
    SOC_IF_ERROR_RETURN(WRITE_AGER_EVENT_THRESHr(SIRIUS_UNIT, uRegValue));


    /*
     * Set up ager profile
     * (set age0 and age1 to the same value for now)
     *
     * Also setup queue depth profiles
     */
    rv = soc_sbx_connect_init(SIRIUS_UNIT, SBX_MAX_FABRIC_COS, SBX_MAX_FABRIC_COS);
    if (rv != SOC_E_NONE) {
        return(rv);
    }

#ifdef BCM_EASY_RELOAD_SUPPORT
    if (SOC_IS_RELOADING(SIRIUS_UNIT)) {
        /* read the anemic utilisation template values. */
        for (template = 0;
             template < SBX_MAX_FABRIC_COS;
             template++) {
            SOC_IF_ERROR_RETURN(soc_reg32_read(SIRIUS_UNIT,
                                               soc_reg_addr(SIRIUS_UNIT,
                                                            queue_depth_reg[template].reg,
                                                            REG_PORT_ANY,
                                                            0),
                                               &uRegValue));
            dataval = soc_reg_field_get(SIRIUS_UNIT,
                                        queue_depth_reg[template].reg,
                                        uRegValue,
                                        queue_depth_reg[template].fld0);
            minuse[template] = dataval;
        }
        /* read the max age template values */
        for (template = 0;
             template < SBX_MAX_FABRIC_COS;
             template++) {
            SOC_IF_ERROR_RETURN(soc_reg32_read(SIRIUS_UNIT,
                                               soc_reg_addr(SIRIUS_UNIT,
                                                            ager_thresh_reg[template].reg,
                                                            REG_PORT_ANY,
                                                            0),
                                               &uRegValue));
            
            dataval = soc_reg_field_get(SIRIUS_UNIT,
                                        ager_thresh_reg[template].reg,
                                        uRegValue,
                                        ager_thresh_reg[template].fld0);
            maxage[template] = dataval;
        }
        /* commit the template values to the cache */
        SOC_IF_ERROR_RETURN(soc_sbx_connect_reload(SIRIUS_UNIT,
                                                   &(minuse[0]),
                                                   &(maxage[0])));
    }
#endif

    /* Allocate template reserved for TDM Calendar usage */
    /* The utilization for this template is 0, because   */
    /* this is required for the TDM age events to work.  */
    rv = soc_sirius_template_min_util_adjust(SIRIUS_UNIT,
                                             0,
                                             &hwValue);
    if (SOC_E_NONE != rv) {
        return rv;
    }
    rv = soc_sirius_template_min_util_recall(SIRIUS_UNIT,
                                             hwValue,
                                             &actValue);
    if (BCM_E_NONE != rv) {
        actValue = -1;
    }

    rv = soc_sbx_connect_min_util_alloc(SIRIUS_UNIT,
                                        SOC_SBX_CONN_FIXED,
                                        hwValue,
                                        &is_allocated,
                                        &template);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("Sirius hardware init, error allocating age"
                            " threshold template for TDM Calendar.\n")));
        return(rv);
    }
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("TDMcal min util set %3d%% -> template %2d,"
                          " hw %02X, actual %3d%%\n"),
                 0,
                 template,
                 hwValue,
                 actValue));


    rv = soc_sirius_template_min_util_set(SIRIUS_UNIT,
                                          template,
                                          hwValue);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("Sirius hardware init, error setting utilisation threshold"
                            " template for TDM calendar.\n")));
        return(rv);
    }

    SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util_tdm_calendar_template = template;

    rv = soc_sirius_template_max_age_adjust(SIRIUS_UNIT,
                                            0,
                                            &hwValue);
    if (SOC_E_NONE != rv) {
        return rv;
    }
    rv = soc_sirius_template_max_age_recall(SIRIUS_UNIT,
                                            hwValue,
                                            &actValue);
    if (BCM_E_NONE != rv) {
        actValue = -1;
    }

    rv = soc_sbx_connect_max_age_alloc(SIRIUS_UNIT,
                                       SOC_SBX_CONN_FIXED,
                                       hwValue,
                                       &is_allocated,
                                       &template);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("Sirius hardware init, error allocating age timeout"
                            " for TDM Calendar.\n")));
        return(rv);
    }
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("TDMcal max age  set %4d -> template %2d,"
                          " hw %02X, actual %4d\n"),
                 0,
                 template,
                 hwValue,
                 actValue));

    rv = soc_sirius_template_max_age_set(SIRIUS_UNIT,
                                         template,
                                         hwValue);
    if (rv != SOC_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("Sirius hardware init, error setting age timeout template"
                            " for TDM calendar.\n")));
        return(rv);
    }

    SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time_tdm_calendar_template = template;

    /* Allocate  default or soc property configured templates */
    for (cos = 0; cos < SBX_MAX_FABRIC_COS; cos++) {
        if (SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos] != -1) {
            rv = soc_sirius_template_min_util_adjust(SIRIUS_UNIT,
                                                     SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos],
                                                     &hwValue);
            if (SOC_E_NONE != rv) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("COS %2d min util %3d%% invalid\n"),
                           cos,
                           SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos]));
                return rv;
            }
            rv = soc_sirius_template_min_util_recall(SIRIUS_UNIT,
                                                     hwValue,
                                                     &actValue);
            if (BCM_E_NONE != rv) {
                actValue = -1;
            }

            rv = soc_sbx_connect_min_util_alloc(SIRIUS_UNIT,
                                                SOC_SBX_CONN_FIXED,
                                                hwValue,
                                                &is_allocated,
                                                &template);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("Unable to allocate template for COS %2d"
                                    " min util %3d%%\n"),
                           cos,
                           SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos]));
                return(rv);
            }
            LOG_VERBOSE(BSL_LS_SOC_COMMON,
                        (BSL_META("COS %2d min util set %3d%% -> template %2d,"
                                  " hw %02X, actual %3d%%\n"),
                         cos,
                         SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos],
                         template,
                         hwValue,
                         actValue));

            if (is_allocated) {
                rv = soc_sirius_template_min_util_set(SIRIUS_UNIT,
                                                      template,
                                                      hwValue);
                if (rv != SOC_E_NONE) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META("Unable to set template %d for COS %2d"
                                        " min util %3d%%\n"),
                               template,
                               cos,
                               SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util[cos]));
                    return(rv);
                }
            }

            /*
             *  Sirius hardware compensates for different timeslot size when
             *  going to different queues, so we set the same utilisation
             *  templates for local and remote destined queues.
             */
            SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util_template[cos] = template;
            SOC_SBX_CFG(SIRIUS_UNIT)->connect_min_util_remote_template[cos] = template;
        }

        if (SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos] != -1) {
            rv = soc_sirius_template_max_age_adjust(SIRIUS_UNIT,
                                                    SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos],
                                                    &hwValue);
            if (SOC_E_NONE != rv) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("COS %2d max_age %4d invalid\n"),
                           cos,
                           SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos]));
                return rv;
            }
            rv = soc_sirius_template_max_age_recall(SIRIUS_UNIT,
                                                    hwValue,
                                                    &actValue);
            if (BCM_E_NONE != rv) {
                actValue = -1;
            }

            rv = soc_sbx_connect_max_age_alloc(SIRIUS_UNIT,
                                               SOC_SBX_CONN_FIXED,
                                               hwValue,
                                               &is_allocated,
                                               &template);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("Unable to allocate template for COS %2d max age %4d\n"),
                           cos,
                           SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos]));
                return(rv);
            }
            LOG_VERBOSE(BSL_LS_SOC_COMMON,
                        (BSL_META("COS %2d max age  set %4d -> template %2d,"
                                  " hw %02X, actual %4d\n"),
                         cos,
                         SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos],
                         template,
                         hwValue,
                         actValue));

            if (is_allocated) {
                rv = soc_sirius_template_max_age_set(SIRIUS_UNIT,
                                                     template,
                                                     hwValue);
                if (rv != SOC_E_NONE) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META("Unable to configure template %d for COS %2d max age %4d\n"),
                               template,
                               cos,
                               SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time[cos]));
                    return(rv);
                }
            }

            SOC_SBX_CFG(SIRIUS_UNIT)->connect_max_age_time_template[cos] = template;
        }
    }

    return rv;

}
static int
_soc_sirius_hw_init_qs_timeslot_calendar(siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue;
    uint32 uCalIndex;
    calendar_entry_t calendarEntry;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init qs timeslot calendar called.\n")));
    /* Set calendar to 2048 entries, active calendar 0 */
    SOC_IF_ERROR_RETURN(READ_CALENDAR_CONFIGr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, TDM_START_CALENDARf,0x00);
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, CALENDAR_ACTIVE_IDf,0x00);
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, QUEUE_B_ENf,0);
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, QUEUE_A_ENf,0);
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, CAL_SIZEf,2047);
    soc_reg_field_set(SIRIUS_UNIT, CALENDAR_CONFIGr, &uRegValue, ENABLE_SWITCHOVERf,0);
    SOC_IF_ERROR_RETURN(WRITE_CALENDAR_CONFIGr(SIRIUS_UNIT, uRegValue));

    /* Write all entries = 0xfff8 to disable - means queue not valid */
    sal_memset(&calendarEntry, 0, sizeof(calendar_entry_t));
    soc_mem_field32_set(SIRIUS_UNIT, CALENDARm, &calendarEntry, TIMESLOTf, 0);
    soc_mem_field32_set(SIRIUS_UNIT, CALENDARm, &calendarEntry, CALENDAR_QUEUE1f, SIRIUS_Q_BASE_INVALID);
    soc_mem_field32_set(SIRIUS_UNIT, CALENDARm, &calendarEntry, CALENDAR_QUEUE0f, SIRIUS_Q_BASE_INVALID);

    for (uCalIndex = 0; uCalIndex <= SOC_MEM_INFO(SIRIUS_UNIT, CALENDAR0m).index_max; uCalIndex++ ) {

        SOC_IF_ERROR_RETURN(WRITE_CALENDAR0m(SIRIUS_UNIT, MEM_BLOCK_ANY, uCalIndex, &calendarEntry));
        SOC_IF_ERROR_RETURN(WRITE_CALENDAR1m(SIRIUS_UNIT, MEM_BLOCK_ANY, uCalIndex, &calendarEntry));

    }

    /* Set the TDM calendar q type to be 3 */
    SOC_IF_ERROR_RETURN(READ_QS_CALENDAR_TYPE_DECODEr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QS_CALENDAR_TYPE_DECODEr, &uRegValue, CALENDAR_TYPE_DECODEf, (1 << SIRIUS_Q_TYPE_TDM_CALENDAR));
    SOC_IF_ERROR_RETURN(WRITE_QS_CALENDAR_TYPE_DECODEr(SIRIUS_UNIT, uRegValue));

    return rv;
}

static int
_soc_sirius_hw_reconfigure_qs_priorities(siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uPri0RegValue;
    uint32 uPri1RegValue;
    int priority_mode = 0;

    /* read default priorities */
    SOC_IF_ERROR_RETURN(READ_SPP_PRIORITY0r(SIRIUS_UNIT, &uPri0RegValue));
    SOC_IF_ERROR_RETURN(READ_SPP_PRIORITY1r(SIRIUS_UNIT, &uPri1RegValue));

    /* modify priorities */
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, NOPRIf, 1); /* AB501 081010 ECO Fix CSP 338350*/
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, ANEMICf, 1);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, SATISFIEDf, 3);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, HUNGRYf, 8);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, HOLDf, 13);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, EFf, 14);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, SUPER_EFf, 14);
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uPri0RegValue, MAXPRIf, 15);

    priority_mode = soc_property_get(SIRIUS_UNIT, "sirius_priority_mode", priority_mode);

    if (priority_mode == 1) {
        /*  we have 8 Ingress MC CosQ model */
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP0f, 9);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP1f, 9);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP2f, 10);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP3f, 10);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP4f, 11); /*  Match Hungry Pri       */
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP5f, 11); /*         ,,              */
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP6f, 12); /*         ,,              */
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP7f, 12); /*  Higher than Hungry Pri */
    } else {
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP0f, 4);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP1f, 5);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP2f, 6);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP3f, 7);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP4f, 9);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP5f, 10);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP6f, 11);
        soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY1r, &uPri1RegValue, SP7f, 12);
    }
    /* write back priorities */
    SOC_IF_ERROR_RETURN(WRITE_SPP_PRIORITY0r(SIRIUS_UNIT, uPri0RegValue));
    SOC_IF_ERROR_RETURN(WRITE_SPP_PRIORITY1r(SIRIUS_UNIT, uPri1RegValue));

    return(rv);
}

static int
_soc_sirius_hw_init_qs_priority_lookup_addr_get(siriusInitParams_t *pInitParams,
                                                uint32 uPriLutAddr, uint32 *pPri, uint32 *pNextPri )
{
    uint32 bShaped;
    uint32 uQueueLength;
    uint32 uAnemicAged;
    uint32 uQueueType;
    uint32 uEfAged;
    uint32 uHungry;
    uint32 uStarving;
    uint32 uHold;
    uint32 uPktLength;
    uint32 uRegValue;
    uint32 uNoPri;
    uint32 uPriAnemic;
    uint32 uPriSatisfied;
    uint32 uPriHungry;
    uint32 uPriHold;
    uint32 uPriEf;
    uint32 uPriSuperEf;
    uint32 uPriMaxPri;
    uint32 uPriSp0;
    uint32 uPriSp1;
    uint32 uPriSp2;
    uint32 uPriSp3;
    uint32 uPriSp4;
    uint32 uPriSp5;
    uint32 uPriSp6;
    uint32 uPriSp7;
    uint32 uLocal;
    uint32 uLocalPriMaxPri;
    uint32 uLocalPriEf = 0;
    uint32 uLocalPriHold;
    uint32 uLocalPriSp0 = 0;
    uint32 uLocalPriSp1 = 0;
    uint32 uLocalPriSp2 = 0;
    uint32 uLocalPriSp3 = 0;
    uint32 uLocalPriSp4 = 0;
    uint32 uLocalPriSp5 = 0;
    uint32 uLocalPriSp6 = 0;
    uint32 uLocalPriSatisfiedRcpq0to1 = 0;
    uint32 uLocalPriSatisfiedRcpq2to3 = 0;
    uint32 uLocalPriSatisfiedRcpq4to5 = 0;
    uint32 uLocalPriSatisfiedRcpq6 = 0;
    uint32 uLocalPriStarving0 = 0;
    uint32 uLocalPriStarving1 = 0;
    uint32 uLocalPriStarving2 = 0;
    uint32 uLocalPriStarving3 = 0;
    uint32 uLocalPriHungry0 = 0;
    uint32 uLocalPriHungry1 = 0;
    uint32 uLocalPriHungry2 = 0;
    uint32 uLocalPriHungry3 = 0;
    uint32 uLocalPriSatisfied = 0;
    uint32 uLocalPriAnemic  = 0;
    uint32 uLocalPriAnemic_1 = 0;
    uint32 uLocalPriAnemic_2 = 0;
    uint32 uLocalPriAnemic_3 = 0;
    uint32 uLocalPriNoPri = 0;
    int32 unit = (int32) pInitParams->unit;
    uint16 dev_id;
    uint8  rev_id;
    int32 disable_starving = FALSE;

    soc_cm_get_id(unit, &dev_id, &rev_id);
    if ((rev_id == BCM88230_A0_REV_ID) ||
	(rev_id == BCM88230_B0_REV_ID)) {
	disable_starving = TRUE;
    }

    COMPILER_REFERENCE(uLocalPriMaxPri);
    COMPILER_REFERENCE(uLocalPriHold);
    COMPILER_REFERENCE(uLocalPriAnemic_1);

    SOC_IF_ERROR_RETURN(READ_SPP_PRIORITY0r(SIRIUS_UNIT, &uRegValue));

    uNoPri = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, NOPRIf) & 0xFE;/* AB501 081010 NOPRI=1 is '0' with ECO fix CSP 338350*/
    uPriAnemic = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, ANEMICf);
    uPriSatisfied = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, SATISFIEDf);
    uPriHungry = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, HUNGRYf);
    uPriHold = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, HOLDf);
    uPriEf = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, EFf);
    uPriSuperEf = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, SUPER_EFf);
    uPriMaxPri = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY0r, uRegValue, MAXPRIf);

    SOC_IF_ERROR_RETURN(READ_SPP_PRIORITY1r(SIRIUS_UNIT, &uRegValue));

    uPriSp0 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP0f);
    uPriSp1 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP1f);
    uPriSp2 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP2f);
    uPriSp3 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP3f);
    uPriSp4 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP4f);
    uPriSp5 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP5f);
    uPriSp6 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP6f);
    uPriSp7 = soc_reg_field_get(SIRIUS_UNIT, SPP_PRIORITY1r, uRegValue, SP7f);

    /* local pri don't go through the translation table */
    switch (SOC_SBX_CFG(unit)->local_template_id) {
	case SOC_SBX_QOS_TEMPLATE_TYPE0:
	    uLocalPriMaxPri = 15;
	    uLocalPriEf = 14;
	    uLocalPriHold = 13;
	    uLocalPriSp0 = 9;
	    uLocalPriSp1 = 10;
	    uLocalPriSp2 = 11;
	    uLocalPriSp3 = 12;
	    uLocalPriStarving0 = 6;
	    uLocalPriStarving1 = 7;
	    uLocalPriStarving2 = 8;
	    uLocalPriHungry0 = 3;
	    uLocalPriHungry1 = 4;
	    uLocalPriHungry2 = 5;
	    uLocalPriSatisfied = 2;
	    uLocalPriAnemic = 1;
	    uLocalPriNoPri = 0;
	    break;
	case SOC_SBX_QOS_TEMPLATE_TYPE1:
	    uLocalPriMaxPri = 15;
	    uLocalPriEf = 14;
	    uLocalPriHold = 13;
	    uLocalPriSp0 = 11;
	    uLocalPriSp1 = 12;
	    uLocalPriStarving0 = 7;
	    uLocalPriStarving1 = 8;
	    uLocalPriStarving2 = 9;
	    uLocalPriStarving3 = 10;
	    uLocalPriHungry0 = 3;
	    uLocalPriHungry1 = 4;
	    uLocalPriHungry2 = 5;
	    uLocalPriHungry3 = 6;
	    uLocalPriSatisfied = 2;
	    uLocalPriAnemic = 1;
	    uLocalPriNoPri = 0;
	    break;
        case SOC_SBX_QOS_TEMPLATE_TYPE2:
        case SOC_SBX_QOS_TEMPLATE_TYPE4:
	    uLocalPriMaxPri = 15;
	    uLocalPriEf = 14;
	    uLocalPriHold = 13;
        
        uLocalPriSp6 = 12;
        uLocalPriSatisfiedRcpq6 = 5;
        
        uLocalPriSp4 = 10;
        uLocalPriSp5 = 11;
        uLocalPriSatisfiedRcpq4to5 = 4;
        
        uLocalPriSp2 = 8;
        uLocalPriSp3 = 9;
        uLocalPriSatisfiedRcpq2to3 = 3;
        
        uLocalPriSp0 = 6;
        uLocalPriSp1 = 7;
        uLocalPriSatisfiedRcpq0to1 = 2;
	    uLocalPriSatisfied = 2;

        uLocalPriAnemic = 1;
        uLocalPriNoPri = 0;
        
	    break;
	case SOC_SBX_QOS_TEMPLATE_TYPE3:
	    uLocalPriMaxPri = 15;
	    uLocalPriEf = 14;
	    uLocalPriHold = 13;
	    uLocalPriSp0 = 9;
	    uLocalPriSp1 = 10;
	    uLocalPriSp2 = 11;
	    uLocalPriSp3 = 12;
	    uLocalPriStarving0 = 7;
	    uLocalPriStarving1 = 8;
	    uLocalPriHungry0 = 5;
	    uLocalPriHungry1 = 6;
	    uLocalPriSatisfied = 4;
	    uLocalPriAnemic_3 = 3;
	    uLocalPriAnemic_2 = 2;
	    uLocalPriAnemic_1 = 1;
            uLocalPriAnemic = 1;
	    uLocalPriNoPri = 0;
	    break;
	default:
	    return SOC_E_PARAM;
    }

    /* Kamino had a slightly different address word to the PriLUT ( from ka_qs_ri_tbli_pri.v)
     *     12  shaped
     *   11:9  q_len_in_ts
     *      8  anemic aged
     *    7:4  qtype     (4 bits)
     *      3  ef aged
     *      2  hungry
     *      1  hold
     *      0  head_pkt_len
     *Sirius PriLut Address =
     *     15  shaped
     *  14:12  q_len_in_ts  (range 0 to 4)
     *  11:10  age bits
     *    9:5  qtype     (5 bits)
     *    4:3  credit level { 00 : Starving (bucket depth < thresh 1),
     *                        01 : Hungry (thresh1 <= bucket depth < thesh 2),
     *                        11: Satisfied (thresh2 <= bucket depth),
     *                        10 : unused }
     *      2  hold_ts
     *    1:0  head_pkt_len_in_ts {  00: less than or equal to 1 Timeslot burst,
     *                               01: less than or equal to 2 Timeslot bursts,
     *                               10: less than or equal to 3
     */

    /*
     * old scheme
     *  bShaped       = 1'b0;  // prilut addr does not go this high
     *  uQueueLength  = uPriLutAddr[14:12]
     *  uAnemicAged   = uPriLutAddr[11:10]
     *  uQueueType    = uPriLutAddr[9:5]
     *  uEfAged       = uPriLutAddr[4]
     *  uHungry       = uPriLutAddr[4:3]
     *  uHold         = uPriLutAddr[2]
     *  uPktLength    = uPriLutAddr[1:0]
     */

    /* ken suggestions
     *  Just decode the bottom 4 bits of q_type from the address so default PriLUT has same priority for qtype {1, xxxx} and {0,xxxx}.
     *  Assign aged[1] = anemic aged, aged[0] = ef aged
     *  assign hungry = (credit level == 00);
     * assign head_pkt_len = (head_pkt_len_in_ts == 00)  00 means less than or equal to 1 Timeslot burst
     */
    bShaped          = 0;                                  /* prilut addr does not go this high */
    uQueueLength     = (uPriLutAddr & 0x7000) >> 12;         /* bits [14:12] */
    uAnemicAged      = (uPriLutAddr & 0x0400) >> 10;         /* bit  [10]  aged 0 */
    uQueueType       = (uPriLutAddr & 0x03E0) >> 5;          /* bits [8:5] reduced range of [3:0] was [4:0] */
    uEfAged          = (uPriLutAddr & 0x0800) >> 11;         /* bit [11]  aged 1 */
    if (uQueueType >= 16) {
	uLocal = TRUE;
    } else {
	uLocal = FALSE;
    }

    /* starving = 0 and hungry=1 - if we are either starving or hungry, set to
       hungry to match QE2000 */
    if (((uPriLutAddr & 0x0018) >> 3) == 0) { /* bits [4:3] */
        uStarving = 1;
	uHungry = 1;
    } else if (((uPriLutAddr & 0x0018) >> 3) == 1) {
	uStarving = 0;
	uHungry = 1;
    } else {
	uStarving = 0;
        uHungry = 0;
    }

    uHold            = (uPriLutAddr & 0x0004) >> 2;          /* [2] */
    uPktLength       =((uPriLutAddr & 0x0003) != 0) ? 1: 0; /* bits[1:0] */

    if (SOC_SBX_CFG(unit)->local_template_id == SOC_SBX_QOS_TEMPLATE_TYPE4) {
	/* Type 4 only support local queue and will use all the FIC queue type */ 
	
	/* Pri */
	if ( (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_EF   ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP0  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP1  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP2  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP3  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP4  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP5  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP6  ) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ0) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ1) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ2) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ3) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ4) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ5) ||
	     (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ6) ) {
	    /* force anemic pri to nopri */
	    uLocalPriAnemic = uLocalPriNoPri;
	}

	if ((uQueueLength == 0) || bShaped) {  /* pri doesnt get NOPRI for bShaped */
	    *pPri = uLocalPriNoPri;
	}
	else if (uQueueLength == 1 && !uAnemicAged) {
	    *pPri = uLocalPriAnemic;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_EF) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_EF)) {
	    (*pPri) = uLocalPriEf;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP0) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP0)) {
	    (*pPri) = uLocalPriSp0;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP1) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP1)) {
	    (*pPri) = uLocalPriSp1;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP2) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP2)) {
	    (*pPri) = uLocalPriSp2;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP3) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP3)) {
	    (*pPri) = uLocalPriSp3;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP4) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP4)) {
	    (*pPri) = uLocalPriSp4;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP5) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP5)) {
	    (*pPri) = uLocalPriSp5;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_SP6) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_SP6)) {
	    (*pPri) = uLocalPriSp6;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ0) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ0)) {
	    (*pPri) = uHungry ? uLocalPriSp0 : uLocalPriSatisfiedRcpq0to1;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ1) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ1)) {
	    (*pPri) = uHungry ? uLocalPriSp1 : uLocalPriSatisfiedRcpq0to1;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ2) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ2)) {
	    (*pPri) = uHungry ? uLocalPriSp2 : uLocalPriSatisfiedRcpq2to3;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ3) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ3)) {
	    (*pPri) = uHungry ? uLocalPriSp3 : uLocalPriSatisfiedRcpq2to3;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ4) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ4)) {
	    (*pPri) = uHungry ? uLocalPriSp4 : uLocalPriSatisfiedRcpq4to5;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ5) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ5)) {
	    (*pPri) = uHungry ? uLocalPriSp5 : uLocalPriSatisfiedRcpq4to5;
	}
	else if ((uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ6) ||
		 (uQueueType== SIRIUS_Q_TYPE_LOCAL_NOANEMIC_RCPQ6)) {
	    (*pPri) = uHungry ? uLocalPriSp6 : uLocalPriSatisfiedRcpq6;
	}
	else {
	    (*pPri) = uLocalPriSatisfied;
	}

	/* Next Pri */
	if (uQueueLength < 3 || bShaped) {
	    *pNextPri = uNoPri;
	} else if (uPktLength) {
	    *pNextPri = uPriMaxPri;
	} else if (uQueueLength == 3) {
	    *pNextPri = uLocalPriAnemic;
	} else if (uHold && uQueueLength > 3) {
	    *pNextPri = uPriHold;
	} else {
	    *pNextPri = *pPri;
	}
	return SOC_E_NONE;
    }


    /* Fic Current Pri  */
    if ((uQueueLength == 0) || bShaped) {  /* pri doesnt get NOPRI for bShaped */
	*pPri = uLocal ? uLocalPriNoPri : uNoPri;
    } else if (uQueueLength == 1 && !uAnemicAged) {
	*pPri = uLocal ? uLocalPriAnemic : uPriAnemic;
    } else if (uQueueType== SIRIUS_Q_TYPE_EF) {
	*pPri = uEfAged ? uPriSuperEf : uPriEf;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP7) {
	*pPri = uPriSp7;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP6) {
	*pPri = uPriSp6;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP5) {
	*pPri = uPriSp5;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP4) {
	*pPri = uPriSp4;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP3) {
	*pPri = uPriSp3;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP2) {
	*pPri = uPriSp2;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP1) {
	*pPri = uPriSp1;
    } else if (uQueueType== SIRIUS_Q_TYPE_SP0) {
	*pPri = uPriSp0;
    } else {
	/* Local Current Pri  */
	switch (SOC_SBX_CFG(unit)->local_template_id) {
	    case SOC_SBX_QOS_TEMPLATE_TYPE0:
		if (uQueueType== SIRIUS_Q_TYPE_LOCAL_EF) {
		    *pPri = uLocalPriEf;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP0) {
		    *pPri = uLocalPriSp0;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP1) {
		    *pPri = uLocalPriSp1;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP2) {
		    *pPri = uLocalPriSp2;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP3) {
		    *pPri = uLocalPriSp3;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP4) {
		    /* low cir AF0 queue type */
		    *pPri = (uHungry ? uLocalPriHungry0 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP5) {
		    /* low cir AF1 queue type */
		    *pPri = (uHungry ? uLocalPriHungry1 : uLocalPriSatisfied); 
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP6) {
		    /* low cir AF2 queue type */
		    *pPri = (uHungry ? uLocalPriHungry2 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF0) {
		    if (disable_starving) {
			/* high cir AF0 queue type */
			*pPri = uStarving?uLocalPriHungry0:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving0 : (uHungry?uLocalPriHungry0:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF1) {
		    if (disable_starving) {
			/* high cir AF1 queue type */
			*pPri = uStarving?uLocalPriHungry1:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving1 : (uHungry?uLocalPriHungry1:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF2) {
		    if (disable_starving) {
			/* high cir AF2 queue type */
			*pPri = uStarving?uLocalPriHungry2:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving2 : (uHungry?uLocalPriHungry2:uLocalPriSatisfied));
		    }
		} else if (uQueueType == SIRIUS_Q_TYPE_BE) {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		} else if (uHungry) {
		    *pPri = uPriHungry;
		} else {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		}
		break;
	    case SOC_SBX_QOS_TEMPLATE_TYPE1:
		if (uQueueType== SIRIUS_Q_TYPE_LOCAL_EF) {
		    *pPri = uLocalPriEf;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP0) {
		    *pPri = uLocalPriSp0;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP1) {
		    *pPri = uLocalPriSp1;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ0) {
		    *pPri = uHungry?uLocalPriSp0:uLocalPriSatisfied;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ1) {
		    *pPri = uHungry?uLocalPriSp1:uLocalPriSatisfied;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP4) {
		    /* low cir AF0 queue type */
		    *pPri = (uHungry ? uLocalPriHungry0 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP5) {
		    /* low cir AF1 queue type */
		    *pPri = (uHungry ? uLocalPriHungry1 : uLocalPriSatisfied); 
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP6) {
		    /* low cir AF2 queue type */
		    *pPri = (uHungry ? uLocalPriHungry2 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP7) {
		    /* low cir AF3 queue type */
		    *pPri = (uHungry ? uLocalPriHungry3 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF0) {
		    if (disable_starving) {
			/* high cir AF0 queue type */
			*pPri = uStarving?uLocalPriHungry0:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving0 : (uHungry?uLocalPriHungry0:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF1) {
		    if (disable_starving) {
			/* high cir AF1 queue type */
			*pPri = uStarving?uLocalPriHungry1:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving1 : (uHungry?uLocalPriHungry1:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF2) {
		    if (disable_starving) {
			/* high cir AF2 queue type */
			*pPri = uStarving?uLocalPriHungry2:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving2 : (uHungry?uLocalPriHungry2:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF3) {
		    if (disable_starving) {
			/* high cir AF3 queue type */
			*pPri = uStarving?uLocalPriHungry3:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving3 : (uHungry?uLocalPriHungry3:uLocalPriSatisfied));
		    }
		} else if (uQueueType == SIRIUS_Q_TYPE_BE) {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		} else if (uHungry) {
		    *pPri = uPriHungry;
		} else {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		}
		break;
            case SOC_SBX_QOS_TEMPLATE_TYPE2:
		if (uQueueType== SIRIUS_Q_TYPE_LOCAL_EF) {
		    (*pPri) = uLocalPriEf;
		}
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP0) {
		    (*pPri) = uLocalPriSp0;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP1) {
		    (*pPri) = uLocalPriSp1;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP2) {
		    (*pPri) = uLocalPriSp2;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP3) {
		    (*pPri) = uLocalPriSp3;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP4) {
		    (*pPri) = uLocalPriSp4;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP5) {
		    (*pPri) = uLocalPriSp5;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP6) {
		    (*pPri) = uLocalPriSp6;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ0) {
		    (*pPri) = uHungry ? uLocalPriSp0 : uLocalPriSatisfiedRcpq0to1;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ1) {
		    (*pPri) = uHungry ? uLocalPriSp1 : uLocalPriSatisfiedRcpq0to1;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ2) {
		    (*pPri) = uHungry ? uLocalPriSp2 : uLocalPriSatisfiedRcpq2to3;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ3) {
		    (*pPri) = uHungry ? uLocalPriSp3 : uLocalPriSatisfiedRcpq2to3;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ4) {
		    (*pPri) = uHungry ? uLocalPriSp4 : uLocalPriSatisfiedRcpq4to5;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ5) {
		    (*pPri) = uHungry ? uLocalPriSp5 : uLocalPriSatisfiedRcpq4to5;
                }
		else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_RCPQ6) {
		    (*pPri) = uHungry ? uLocalPriSp6 : uLocalPriSatisfiedRcpq6;
		}
		else if (uQueueType == SIRIUS_Q_TYPE_BE) {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		}
		else if (uHungry) {
		    *pPri = uPriHungry;
		}
		else {
		    *pPri = uLocal ? uLocalPriSatisfied : uPriSatisfied;
		}
	        break;
	    case SOC_SBX_QOS_TEMPLATE_TYPE3:
		if (uQueueLength == 2 && !uAnemicAged) {
		    *pPri = uLocalPriAnemic_2;
		} else if (uQueueLength == 3 && !uAnemicAged) {
		    *pPri = uLocalPriAnemic_3;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_EF) {
		    *pPri = uLocalPriEf;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP0) {
		    *pPri = uLocalPriSp0;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP1) {
		    *pPri = uLocalPriSp1;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP2) {
		    *pPri = uLocalPriSp2;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP3) {
		    *pPri = uLocalPriSp3;
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP4) {
		    /* low cir AF0 queue type */
		    *pPri = ( uHungry? uLocalPriHungry0 : uLocalPriSatisfied);
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_SP5) {
		    /* low cir AF1 queue type */
		    *pPri = ( uHungry? uLocalPriHungry1 : uLocalPriSatisfied); 
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF0) {
		    if (disable_starving) {
			/* high cir AF0 queue type */
			*pPri = uStarving?uLocalPriHungry0:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving0 : (uHungry?uLocalPriHungry0:uLocalPriSatisfied));
		    }
		} else if (uQueueType== SIRIUS_Q_TYPE_LOCAL_AF1) {
		    if (disable_starving) {
			/* high cir AF1 queue type */
			*pPri = uStarving?uLocalPriHungry1:uLocalPriSatisfied;
		    } else {
			*pPri = (uStarving ? uLocalPriStarving1 : (uHungry?uLocalPriHungry1:uLocalPriSatisfied));
		    }
		} else if (uQueueType == SIRIUS_Q_TYPE_BE) {
		    /* NOTE: this would only works for TME mode, not for hybrid */
		    *pPri = uLocalPriSatisfied;
		} else if (uHungry) {
		    *pPri = uPriHungry;
		} else {
		    *pPri = uLocalPriSatisfied;
		}
		break;
	    default:
		return SOC_E_PARAM;
	}
    }

    /* Next Pri */
    if ((uLocal || (uQueueType == SIRIUS_Q_TYPE_BE)) && 
	(SOC_SBX_CFG(unit)->local_template_id == SOC_SBX_QOS_TEMPLATE_TYPE3)) {
	/* reduce latency for local queue types */
	if (uQueueLength < 3 || bShaped) {
	    *pNextPri = uNoPri;
	} else if (uPktLength) {
	    *pNextPri = uPriMaxPri;
	} else if (uQueueLength == 3) {
	    *pNextPri = uLocal ? uLocalPriAnemic : uPriAnemic;
	} else if (uHold && uQueueLength > 3) {
	    *pNextPri = uPriHold;
	} else {
	    *pNextPri = *pPri;
	}
    } else {
	if (uQueueLength < 1 || bShaped) {
	    *pNextPri = uNoPri;
	} else if (uPktLength) {
	    *pNextPri = uPriMaxPri;
	} else if (uQueueLength < 3){
	    *pNextPri = uPriAnemic;
	} else if (uHold) {
	    *pNextPri = uPriHold;
	} else {
	    *pNextPri = *pPri;
	}
    }

    return SOC_E_NONE;
}
static int
_soc_sirius_hw_init_qs_priority_lookup_table(siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uPriLutAddr;
    uint32 uPri = 0, uNextPri = 0;
    pri_lut_entry_t priLutEntry;
    int32 unit = (int32) pInitParams->unit;
    uint32 uRegValue;

    if (SAL_BOOT_QUICKTURN) {
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius init qs priority lookup table skipped.\n")));
	return rv;
    } else {
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius init qs priority lookup table called.\n")));
    }

    for (uPriLutAddr = 0; uPriLutAddr <= SOC_MEM_INFO(unit, PRI_LUTm).index_max; uPriLutAddr++ ) {

        rv = _soc_sirius_hw_init_qs_priority_lookup_addr_get(pInitParams, uPriLutAddr, &uPri, &uNextPri );
        if (rv) {
            return rv;
        }
        soc_mem_field32_set(unit, PRI_LUTm, &priLutEntry, PRIf, uPri);
        soc_mem_field32_set(unit, PRI_LUTm, &priLutEntry, NEXT_PRIf, uNextPri);
        SOC_IF_ERROR_RETURN(WRITE_PRI_LUTm(unit, MEM_BLOCK_ANY, uPriLutAddr, &priLutEntry));
    }

    if (soc_feature(unit, soc_feature_standalone) ||
	soc_feature(unit, soc_feature_hybrid)) {
	SOC_IF_ERROR_RETURN(READ_GGI_CONFIG1r(unit, &uRegValue));
	switch (SOC_SBX_CFG(unit)->local_template_id) {
	    case SOC_SBX_QOS_TEMPLATE_TYPE0:
		soc_reg_field_set(unit, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x01F8);
		/*
		  uLocalPriStarving0 = 6;
		  uLocalPriStarving1 = 7;
		  uLocalPriStarving2 = 8;
		  uLocalPriHungry0 = 3;
		  uLocalPriHungry1 = 4;
		  uLocalPriHungry2 = 5;
		*/
		break;
	    case SOC_SBX_QOS_TEMPLATE_TYPE1:
		soc_reg_field_set(unit, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x07F8);
		/*
		  uLocalPriStarving0 = 7;
		  uLocalPriStarving1 = 8;
		  uLocalPriStarving2 = 9;
		  uLocalPriStarving3 = 10;
		  uLocalPriHungry0 = 3;
		  uLocalPriHungry1 = 4;
		  uLocalPriHungry2 = 5;
		  uLocalPriHungry3 = 6;
		*/
		break;
	    case SOC_SBX_QOS_TEMPLATE_TYPE2:
	    case SOC_SBX_QOS_TEMPLATE_TYPE4:
		soc_reg_field_set(unit, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x1FC0);
		/*
		  uLocalPriSp6 = 12;
		  uLocalPriSp4 = 10;
		  uLocalPriSp5 = 11;
		  uLocalPriSp2 = 8;
		  uLocalPriSp3 = 9;
		  uLocalPriSp0 = 6;
		  uLocalPriSp1 = 7;
		*/
		break;
	    case SOC_SBX_QOS_TEMPLATE_TYPE3:
		soc_reg_field_set(unit, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x01E0);
		/*
		  uLocalPriStarving0 = 7;
		  uLocalPriStarving1 = 8;
		  uLocalPriHungry0 = 5;
		  uLocalPriHungry1 = 6;
		*/
		break;
	    default:
		return SOC_E_PARAM;
	}
	SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG1r(unit, uRegValue));
    }

    return rv;
}

static int
_soc_sirius_hw_init_qs( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue;
    int32  nGrantScenario;
    int32  nTimeoutInUsec;
    int32  nInitDone;
    soc_timeout_t timeout;
    uint32 uClocksPerEpoch;
    int channel, index, burst_size, node_type, els;
    int channels, local_burst_size;
    uint16 dev_id;
    uint8  rev_id;
    int i;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init qs called.\n")));

    /* Clear QSA soft reset
     */
    SOC_IF_ERROR_RETURN(READ_QSA_SOFT_RESETr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QSA_SOFT_RESETr, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QSA_SOFT_RESETr(SIRIUS_UNIT, uRegValue));

    /* Clear QSB soft reset
     */
    SOC_IF_ERROR_RETURN(READ_QSB_SOFT_RESETr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QSB_SOFT_RESETr, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QSB_SOFT_RESETr(SIRIUS_UNIT, uRegValue));

    /* Punch phase sync
     */
    SOC_IF_ERROR_RETURN(READ_QSA_INITr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QSA_INITr, &uRegValue, QSA_PHASE_SYNCf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QSA_INITr(SIRIUS_UNIT, uRegValue));

    /* Init memories QSA
     */
    soc_reg_field_set(SIRIUS_UNIT, QSA_INITr, &uRegValue, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QSA_INITr(SIRIUS_UNIT, uRegValue));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        nTimeoutInUsec = _sirius_init_timeout;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_QSA_INITr(SIRIUS_UNIT,&uRegValue));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT, QSA_INITr,uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("QS A init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* Clear bit to resume operation
     */
    soc_reg_field_set(SIRIUS_UNIT, QSA_INITr, &uRegValue, INIT_DONEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QSA_INITr(SIRIUS_UNIT, uRegValue));

    /* Init memories QSB
     */
    soc_reg_field_set(SIRIUS_UNIT, QSB_INITr, &uRegValue, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QSB_INITr(SIRIUS_UNIT, uRegValue));

    if (!SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        nTimeoutInUsec = _sirius_init_timeout;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_QSB_INITr(SIRIUS_UNIT,&uRegValue));
            
            nInitDone = soc_reg_field_get(SIRIUS_UNIT, QSB_INITr,uRegValue, INIT_DONEf);

            if (nInitDone) {
                break;
            }
        }
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("QS B init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* Clear bit to resume operation
     */
    soc_reg_field_set(SIRIUS_UNIT, QSB_INITr, &uRegValue, INIT_DONEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_QSB_INITr(SIRIUS_UNIT, uRegValue));

    /*
     * Configuration for FIC template
     */
    if (pInitParams->spMode == SOC_SBX_SP_MODE_ACCOUNT_IN_BAG) {
        _soc_sirius_hw_reconfigure_qs_priorities(pInitParams);

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG1r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x0100);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG1r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG2r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG2r, &uRegValue, EF_GRANT_SQUELCHf, 0x4000);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG2r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG3r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG3r, &uRegValue, MAXPRIf, 0x8000);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG3r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG4r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG4r, &uRegValue, SUPER_EFf, 0x4000);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG4r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG5r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG5r, &uRegValue, EFf, 0x4000);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG5r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG6r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG6r, &uRegValue, HOLDf, 0x2000);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG6r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GG_EF_TYPE_DECODEr(SIRIUS_UNIT, &uRegValue));
	if (SOC_SBX_CFG(SIRIUS_UNIT)->bTmeMode != 0) {
	    soc_reg_field_set(SIRIUS_UNIT, GG_EF_TYPE_DECODEr, &uRegValue, EF_TYPE_DECODEf,
			      ((1<<SIRIUS_Q_TYPE_LOCAL_EF) | (1 << SIRIUS_Q_TYPE_EF)));
	} else {
	    soc_reg_field_set(SIRIUS_UNIT, GG_EF_TYPE_DECODEr, &uRegValue, EF_TYPE_DECODEf,
			      (1 << SIRIUS_Q_TYPE_EF));
	}
        SOC_IF_ERROR_RETURN(WRITE_GG_EF_TYPE_DECODEr(SIRIUS_UNIT, uRegValue));
    }
    else { /* SOC_SBX_SP_MODE_IN_BAG */
        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG1r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG1r, &uRegValue, HUNGRY_PRIf, 0x0008);
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG1r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GGI_CONFIG2r(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG2r, &uRegValue, EF_GRANT_SQUELCHf,
                                                                      0x2000 /* no SUPER-EF */ );
        SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG2r(SIRIUS_UNIT, uRegValue));

        SOC_IF_ERROR_RETURN(READ_GG_EF_TYPE_DECODEr(SIRIUS_UNIT, &uRegValue));
	if (SOC_SBX_CFG(SIRIUS_UNIT)->bTmeMode != 0) {
	    soc_reg_field_set(SIRIUS_UNIT, GG_EF_TYPE_DECODEr, &uRegValue, EF_TYPE_DECODEf,
			      ((1<<SIRIUS_Q_TYPE_LOCAL_EF) | (1 << SIRIUS_Q_TYPE_EF)));
	} else {
	    soc_reg_field_set(SIRIUS_UNIT, GG_EF_TYPE_DECODEr, &uRegValue, EF_TYPE_DECODEf,
			      (1 << SIRIUS_Q_TYPE_EF));
	}
        SOC_IF_ERROR_RETURN(WRITE_GG_EF_TYPE_DECODEr(SIRIUS_UNIT, uRegValue));
    }

    /* Enable ECO Fix */
    SOC_IF_ERROR_RETURN(READ_SPP_PRIORITY0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, SPP_PRIORITY0r, &uRegValue, NOPRIf, 1);
    SOC_IF_ERROR_RETURN(WRITE_SPP_PRIORITY0r(SIRIUS_UNIT, uRegValue));

    /* Init priority lookup table (PriLut)
     */
    rv = _soc_sirius_hw_init_qs_priority_lookup_table(pInitParams);
    if (rv) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unit%d init qs prilut failed\n"), SIRIUS_UNIT));
    }

    /* Set maximum VOQ
     */
    SOC_IF_ERROR_RETURN(READ_QS_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG1r, &uRegValue, LOCAL_BOUNDARYf, pInitParams->nMaxVoq);
    SOC_IF_ERROR_RETURN(WRITE_QS_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /* Set grant mode
     *  2'd0 = fabric_grant(plane A), local_grant(plane B)         ( 2 GRANT HYBRID MODE )
     *  2'd1 = fabric_grant(plane A), fabric_grant(plane B)
     *  2'd2 = local_grant(plane A),  local_grant(plane B)
     *  2'd3 = local_grant(plane B), fabric_grant(plane A), local_grant(plane B) ( 3 GRANT HYBRID MODE )
     *         mode 3 not supported in sirius A0
     */
    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {
        nGrantScenario = 2;
    }else if(soc_feature(SIRIUS_UNIT, soc_feature_hybrid) ) {
        nGrantScenario = 0;
    } else {
        nGrantScenario = 1;
    }

    SOC_IF_ERROR_RETURN(READ_GG_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, GG_CONFIG0r, &uRegValue, GRANT_SCENARIOf, nGrantScenario);
    SOC_IF_ERROR_RETURN(WRITE_GG_CONFIG0r(SIRIUS_UNIT, uRegValue));

    SOC_IF_ERROR_RETURN(READ_GGI_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG0r, &uRegValue, GRANT_SCENARIOf, nGrantScenario);
    SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG0r(SIRIUS_UNIT, uRegValue));


    /* BAA Config, Set VOQ range */
    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) ||
	soc_feature(SIRIUS_UNIT, soc_feature_hybrid))  {
	/* TME or Hybrid mode, use full queue range */
	SOC_IF_ERROR_RETURN(READ_BAA_QUEUE_RANGEr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, BAA_QUEUE_RANGEr, &uRegValue, STARTQUEUEf, 0);
	soc_reg_field_set(SIRIUS_UNIT, BAA_QUEUE_RANGEr, &uRegValue, ENDQUEUEf, 0xffff);
	SOC_IF_ERROR_RETURN(WRITE_BAA_QUEUE_RANGEr(SIRIUS_UNIT, uRegValue));
	
	/*
	 * baa queues are 0 to (2^15+ 2^15 = 64k)
	 * 1 << x + 1 << y = endqueue
	 */
	SOC_IF_ERROR_RETURN(READ_BAA_LOOP_SIZEr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, BAA_LOOP_SIZEr, &uRegValue, BAA_LOOP_SIZE_EXP1f, 0xf);
	soc_reg_field_set(SIRIUS_UNIT, BAA_LOOP_SIZEr, &uRegValue, BAA_LOOP_SIZE_EXP2f, 0xf);
	SOC_IF_ERROR_RETURN(WRITE_BAA_LOOP_SIZEr(SIRIUS_UNIT, uRegValue));
    } else {
	/* FIC mode, use VOQ only, 32K queues even though polaris only support 16K queues */
	SOC_IF_ERROR_RETURN(READ_BAA_QUEUE_RANGEr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, BAA_QUEUE_RANGEr, &uRegValue, STARTQUEUEf, 0);
	soc_reg_field_set(SIRIUS_UNIT, BAA_QUEUE_RANGEr, &uRegValue, ENDQUEUEf, 0x7fff);
	SOC_IF_ERROR_RETURN(WRITE_BAA_QUEUE_RANGEr(SIRIUS_UNIT, uRegValue));
	
	/*
	 * baa queues are 0 to (2^15+ 2^0 = 32k)
	 * 1 << x + 1 << y = endqueue
	 */
	SOC_IF_ERROR_RETURN(READ_BAA_LOOP_SIZEr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, BAA_LOOP_SIZEr, &uRegValue, BAA_LOOP_SIZE_EXP1f, 0xf);
	soc_reg_field_set(SIRIUS_UNIT, BAA_LOOP_SIZEr, &uRegValue, BAA_LOOP_SIZE_EXP2f, 0);
	SOC_IF_ERROR_RETURN(WRITE_BAA_LOOP_SIZEr(SIRIUS_UNIT, uRegValue));
    }

    /* Starving threshold and hungry threshold is set to be 1/2 so that bucket size won't
     * overflow for the large rate case
     * hungry_threshold must be >= starving_threshold
     */
    /*Following restriction is to resolve an issue with CIR accuracy in TME/Hybrid mode and
     *in Sirius A0 and B0. The issue does not apply to FIC mode and to Sirius C0*/
    soc_cm_get_id(SIRIUS_UNIT, &dev_id, &rev_id);
    SOC_IF_ERROR_RETURN(READ_BAA_CREDIT_THRESHr(SIRIUS_UNIT, &uRegValue));
    if ( ((rev_id == BCM88230_A0_REV_ID) ||
	 (rev_id == BCM88230_B0_REV_ID) )&&
         (soc_feature(SIRIUS_UNIT, soc_feature_standalone) ||
	soc_feature(SIRIUS_UNIT, soc_feature_hybrid)))  {
	soc_reg_field_set(SIRIUS_UNIT, BAA_CREDIT_THRESHr, &uRegValue, STARVING_THRESHf, 2);
	soc_reg_field_set(SIRIUS_UNIT, BAA_CREDIT_THRESHr, &uRegValue, HUNGRY_THRESHf, 6);
	SOC_IF_ERROR_RETURN(WRITE_BAA_CREDIT_THRESHr(SIRIUS_UNIT, uRegValue));

    } else {
	soc_reg_field_set(SIRIUS_UNIT, BAA_CREDIT_THRESHr, &uRegValue, STARVING_THRESHf, 1);
	soc_reg_field_set(SIRIUS_UNIT, BAA_CREDIT_THRESHr, &uRegValue, HUNGRY_THRESHf, 2);
	SOC_IF_ERROR_RETURN(WRITE_BAA_CREDIT_THRESHr(SIRIUS_UNIT, uRegValue));

	/* setup the ECO fix, always enable the min floor for hungry threshold and 
	 * set the floor to be 0x3FFFF (32K bytes), should be large enough compare to
	 * the timeslot burst size 
	 */
	SOC_IF_ERROR_RETURN(READ_BAA_EVENT_BLOCKr(SIRIUS_UNIT, &uRegValue));
	uRegValue |= (0x3 << 20); /* ECO enable bits */
	uRegValue |= (0x7 << 15); /* bit [19:15] set to 0x7 */
	SOC_IF_ERROR_RETURN(WRITE_BAA_EVENT_BLOCKr(SIRIUS_UNIT, uRegValue));	
    }


    rv = _soc_sirius_hw_init_qs_shaper(SIRIUS_UNIT, pInitParams->nMaxVoq);
    if (rv) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unit%d init qs shaper failed\n"), SIRIUS_UNIT));
    }

    rv = _soc_sirius_hw_init_qs_ager(pInitParams);
    if (rv) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unit%d init qs ager failed\n"), SIRIUS_UNIT));
    }

    /* If we are in hybrid or tme mode, set the dequeue planes to be static.
     * If in FIC mode, set the dequeue plane to be dynamic regardless.
     */
    SOC_IF_ERROR_RETURN(READ_GGI_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    if  (soc_feature(SIRIUS_UNIT, soc_feature_standalone) ||
         soc_feature(SIRIUS_UNIT, soc_feature_hybrid) ) {
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG0r, &uRegValue, GRANT_DYNAMICf, 0);
    }else {
        soc_reg_field_set(SIRIUS_UNIT, GGI_CONFIG0r, &uRegValue, GRANT_DYNAMICf, 1);
    }
    SOC_IF_ERROR_RETURN(WRITE_GGI_CONFIG0r(SIRIUS_UNIT, uRegValue));

    if  (!soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
        rv = _soc_sirius_hw_init_qs_timeslot_calendar(pInitParams);
        if (rv) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("unit%d init timeslot calendar\n"), SIRIUS_UNIT));
        }
    }

    /* Priority updates per timeslot, set to 0x28 (?)
     */
    SOC_IF_ERROR_RETURN(READ_PUP_PRI_UPDATES_PER_TSr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, PUP_PRI_UPDATES_PER_TSr, &uRegValue, UPD_TSf, 0x28);
    SOC_IF_ERROR_RETURN(WRITE_PUP_PRI_UPDATES_PER_TSr(SIRIUS_UNIT, uRegValue));

    if (!soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
        SOC_IF_ERROR_RETURN(READ_PUP_CTXT_HIT_ALLOWr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, PUP_CTXT_HIT_ALLOWr, &uRegValue, BACKGROUND_SYSPORT_REFRESH_RANGEf, 2815);
	if (SOC_SBX_CFG(SIRIUS_UNIT)->num_ds_ids > 0 &&  SOC_SBX_CFG(SIRIUS_UNIT)->num_ds_ids <= 1024) {
	  soc_reg_field_set(SIRIUS_UNIT, PUP_CTXT_HIT_ALLOWr, &uRegValue, BACKGROUND_ESET_REFRESH_RANGEf, 
			    SOC_SBX_CFG(SIRIUS_UNIT)->num_ds_ids);
	}
	SOC_IF_ERROR_RETURN(WRITE_PUP_CTXT_HIT_ALLOWr(SIRIUS_UNIT, uRegValue));
    }

    /* Local queue burst size - set to 370 in TME mode, scale up based on hybrid timeslot size
     */
    SOC_IF_ERROR_RETURN(READ_GG_LOCAL_BSr(SIRIUS_UNIT, &uRegValue));

    if (SOC_SBX_CFG(SIRIUS_UNIT)->uClockSpeedInMHz == 405) {
	
        if  (soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
	    switch (pInitParams->uDdr3NumMemories) {
		case 8:
		    local_burst_size = 376;
		    break;
		case 7:
		    local_burst_size = 321;
		    break;
		case 6:
		    local_burst_size = 276;
		    break;
		case 5:
		    local_burst_size = 215;
		    break;
		case 4:
		    local_burst_size = 165;
		    break;
		case 3:
		    local_burst_size = 121;
		    break;
		case 2:
		    local_burst_size = 77;
		    break;
		case 1:
		    local_burst_size = 38;
		    break;
		case 10:
		case 9:
		default:
		    local_burst_size = 409;
		    break;
	    }	
	    soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, local_burst_size);
	} else if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {
	    
	    soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 340);
	} else { /* FIC */
            soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 0);
	}
        if (SAL_BOOT_BCMSIM) {
            /* set it to MAX in BCMSIM environment */
            soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 0x3ff);
        }
        SOC_IF_ERROR_RETURN(WRITE_GG_LOCAL_BSr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_QM_BP_BSBr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_QM_BP_BSBr, &uRegValue, QM_BP_BURST_SIZEf, 302);
        SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSBr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_QM_BP_BSAr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_QM_BP_BSAr, &uRegValue, QM_BP_BURST_SIZEf, 302);
        SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSAr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_CI_BP_BSAr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_CI_BP_BSAr, &uRegValue, CI_BP_BURST_SIZEf, 302);
        SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSAr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_CI_BP_BSBr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_CI_BP_BSBr, &uRegValue, CI_BP_BURST_SIZEf, 302);
        SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSBr(SIRIUS_UNIT, uRegValue));
    } else {
        if  (soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
	    soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 380);
	} else if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {
	    
	    soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 340);
	} else { /* FIC */
            soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 0);
	}
        if (SAL_BOOT_BCMSIM) {
            /* set it to MAX in BCMSIM environment */
            soc_reg_field_set(SIRIUS_UNIT, GG_LOCAL_BSr, &uRegValue, LOCAL_BURST_SIZEf, 0x3ff);
        }
        SOC_IF_ERROR_RETURN(WRITE_GG_LOCAL_BSr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_QM_BP_BSBr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_QM_BP_BSBr, &uRegValue, QM_BP_BURST_SIZEf, 237);
        SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSBr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_QM_BP_BSAr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_QM_BP_BSAr, &uRegValue, QM_BP_BURST_SIZEf, 237);
        SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSAr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_CI_BP_BSAr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_CI_BP_BSAr, &uRegValue, CI_BP_BURST_SIZEf, 237);
        SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSAr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_GG_CI_BP_BSBr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, GG_CI_BP_BSBr, &uRegValue, CI_BP_BURST_SIZEf, 237);
        SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSBr(SIRIUS_UNIT, uRegValue));
    }


    
    /* for now, set to 1000us timeslot size and guess at epoch length worst case  */
    uClocksPerEpoch =  1000 * SB_FAB_DMODE_EPOCH_IN_TIMESLOTS * (1/pInitParams->uClockSpeedInMHz);
    SOC_IF_ERROR_RETURN(READ_RU_CONFIG1r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, RU_CONFIG1r, &uRegValue, CLOCKS_PER_EPOCHf, uClocksPerEpoch);
    SOC_IF_ERROR_RETURN(WRITE_RU_CONFIG1r(SIRIUS_UNIT, uRegValue));

    /* Enable appropriate blocks in QS */
    SOC_IF_ERROR_RETURN(READ_QS_CONFIG0r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG0r, &uRegValue, QSA_QPP_ENABLEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG0r, &uRegValue, GGP_ENABLEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG0r, &uRegValue, QGI_ENABLEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG0r, &uRegValue, AGER_ENABLEf, 1);
#if 000
    
    soc_reg_field_set(SIRIUS_UNIT, QS_CONFIG0r, &uRegValue, CALENDAR_ENABLEf, 1);
#endif
    SOC_IF_ERROR_RETURN(WRITE_QS_CONFIG0r(SIRIUS_UNIT, uRegValue));

    /* force rx plane, need to force to plane A for qe_type 1 (qe2000) */
    SOC_IF_ERROR_RETURN(READ_NODETYPEFORCERXPLANEr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, NODETYPEFORCERXPLANEr, &uRegValue, 
                      FORCE_RX_PLANEf, 0x2);
    soc_reg_field_set(SIRIUS_UNIT, NODETYPEFORCERXPLANEr, &uRegValue, 
                      FORCE_RX_PLANE_VALUEf, 0x0);
    SOC_IF_ERROR_RETURN(WRITE_NODETYPEFORCERXPLANEr(SIRIUS_UNIT, uRegValue));

    /* force link enable mask, local planes need to be forced enable */
    if  (soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
	SOC_IF_ERROR_RETURN(READ_FORCE_LINK_ENABLE_Ar(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, FORCE_LINK_ENABLE_Ar, &uRegValue, FORCE_LINK_EN_Af, 0xFFFFFF);
	SOC_IF_ERROR_RETURN(WRITE_FORCE_LINK_ENABLE_Ar(SIRIUS_UNIT, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FORCE_LINK_ENABLE_Br(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, FORCE_LINK_ENABLE_Br, &uRegValue, FORCE_LINK_EN_Bf, 0xFFFFFF);
	SOC_IF_ERROR_RETURN(WRITE_FORCE_LINK_ENABLE_Br(SIRIUS_UNIT, uRegValue));
    } else { /* FIC */
	SOC_IF_ERROR_RETURN(READ_FORCE_LINK_ENABLE_Ar(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, FORCE_LINK_ENABLE_Ar, &uRegValue, FORCE_LINK_EN_Af, 0);
	SOC_IF_ERROR_RETURN(WRITE_FORCE_LINK_ENABLE_Ar(SIRIUS_UNIT, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FORCE_LINK_ENABLE_Br(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, FORCE_LINK_ENABLE_Br, &uRegValue, FORCE_LINK_EN_Bf, 0);
	SOC_IF_ERROR_RETURN(WRITE_FORCE_LINK_ENABLE_Br(SIRIUS_UNIT, uRegValue));
    }

    /* define qe_type channel masks 
     *   qe_type 0: sirius fic mode, 44 channels, even on A, odd on B, 44,45 unused until SFI_SCI supported
     *              plane A: 0x055555555555  plane B: 0x0AAAAAAAAAAA
     *   qe_type 1: qe2k, 36 channels, even on A, odd on B
     *              plane A: 0x555555555  plane B: 0xAAAAAAAAA
     *   qe_type 2: sirius hybrid mode, 22 channels, both even/odd on A.
     *              plane B is not used, doesn't hurt to set it up though
     * standalone defaults:
     *   qe_type 0 :plane A: 0x155555555555  plane B: 0x2AAAAAAAAAAA
     *   NOTE:
     *   due to the mux/demux effect of polaris between FIC and Hybrid node
     *   for FIC mode nodes, even if source node is qe_type2, the mask should
     *              be same as qe_type0 masks. In both QS and FR
     *   for Hybrid mode nodes, even if source node is qe_type0, the mask
     *              should be same as qe_type2 masks. in both QS and FR
     */

    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {
    /* type 0, SS FIC */
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A0_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A0_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A0f, 0x1555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A0_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A0_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A0_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A0f, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A0_LOr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B0_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B0_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B0f, 0x2AAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B0_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B0_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B0_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B0f, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B0_LOr(SIRIUS_UNIT, uRegValue));

	/* define channel masks - don't mask channels 44/45 at this time */
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_A_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_A_HIr, &uRegValue, 
			  CHANNEL_MASK_A1f, 0x1555);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_A_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_A_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_A_LOr, &uRegValue, 
			  CHANNEL_MASK_A0f, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_A_LOr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_B_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_B_HIr, &uRegValue, 
			  CHANNEL_MASK_B1f, 0x2AAA);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_B_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_B_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_B_LOr, &uRegValue, 
			  CHANNEL_MASK_B0f, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_B_LOr(SIRIUS_UNIT, uRegValue));
    } else {

	/* type 0, SS FIC */
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A0_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A0_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A0f, 0x1555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A0_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A0_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A0_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A0f, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A0_LOr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B0_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B0_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B0f, 0x2AAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B0_HIr(SIRIUS_UNIT, uRegValue));

	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B0_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B0_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B0f, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B0_LOr(SIRIUS_UNIT, uRegValue));
	
	/* type 1, QE2K */
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A1_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A1_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A1f, 0x5);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A1_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A1_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A1_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A1f, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A1_LOr(SIRIUS_UNIT, uRegValue));
	
    if ( soc_feature(SIRIUS_UNIT, soc_feature_hybrid) ) {

        SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B1_HIr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B1_HIr, &uRegValue, 
                          QE_TYPE_CHANNEL_MASK_B1f, 0x0);
        SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B1_HIr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B1_LOr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B1_LOr, &uRegValue, 
                          QE_TYPE_CHANNEL_MASK_B1f, 0x0);
        SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B1_LOr(SIRIUS_UNIT, uRegValue));
    } else {
        SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B1_HIr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B1_HIr, &uRegValue, 
                          QE_TYPE_CHANNEL_MASK_B1f, 0xA);
        SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B1_HIr(SIRIUS_UNIT, uRegValue));
        
        SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B1_LOr(SIRIUS_UNIT, &uRegValue));
        soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B1_LOr, &uRegValue, 
                          QE_TYPE_CHANNEL_MASK_B1f, 0xAAAAAAAA);
        SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B1_LOr(SIRIUS_UNIT, uRegValue));
    }
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A2_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A2_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A2f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A2_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A2_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A2_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A2f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A2_LOr(SIRIUS_UNIT, uRegValue));
    
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B2_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B2_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B2f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B2_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B2_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B2_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B2f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B2_LOr(SIRIUS_UNIT, uRegValue));
	
	/* type 3, not used */
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A3_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A3_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A3f, 0x0555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A3_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_A3_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_A3_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_A3f, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_A3_LOr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B3_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B3_HIr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B3f, 0x0AAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B3_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_QE_TYPE_CHANNEL_MASK_B3_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, QE_TYPE_CHANNEL_MASK_B3_LOr, &uRegValue, 
			  QE_TYPE_CHANNEL_MASK_B3f, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_QE_TYPE_CHANNEL_MASK_B3_LOr(SIRIUS_UNIT, uRegValue));    
    /* Now done during bcm_port_enable_set() */
	/* define channel masks - don't mask channels 44/45 at this time */
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_A_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_A_HIr, &uRegValue, 
		      CHANNEL_MASK_A1f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_A_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_A_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_A_LOr, &uRegValue, 
			  CHANNEL_MASK_A0f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_A_LOr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_B_HIr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_B_HIr, &uRegValue, 
			  CHANNEL_MASK_B1f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_B_HIr(SIRIUS_UNIT, uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_CHANNEL_MASK_B_LOr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, CHANNEL_MASK_B_LOr, &uRegValue, 
			  CHANNEL_MASK_B0f, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MASK_B_LOr(SIRIUS_UNIT, uRegValue));

	/* Disable plane crossover on SFI channels which are possible SFI_SCI */
	SOC_IF_ERROR_RETURN(READ_PLANE_CROSSOVERr(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, PLANE_CROSSOVERr, &uRegValue, 
			  PLANE_CROSSOVER_LINKSf, 0x3fffff);
	SOC_IF_ERROR_RETURN(WRITE_PLANE_CROSSOVERr(SIRIUS_UNIT, uRegValue));

    }

    if (!soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {
        /* Configure number of Bytes per timeslot, 
         * table indexed by number of channels
         */
        els = 0; /* no Enhanced Load Sharing */
        for (channel=0; (channel < (SIRIUS_NUM_SFI_CHANNELS + 2)); channel++) {
            for (node_type=0; node_type<SIRIUS_MAX_NODE_TYPES; node_type++) {
                index = (channel * SIRIUS_MAX_NODE_TYPES) + node_type;
                BCM_IF_ERROR_RETURN(soc_sirius_ts_burst_size_bytes_get(
                           SIRIUS_UNIT, els, node_type, channel, &burst_size));
                SOC_IF_ERROR_RETURN(WRITE_TIMESLOT_BURST_SIZE_BYTESm(
                              SIRIUS_UNIT, MEM_BLOCK_ANY, index, &burst_size));
            }
        }
        /* set the Back pressure case burst sizes */
        SOC_IF_ERROR_RETURN(soc_sirius_bp_burst_size_bytes_set(SIRIUS_UNIT));
    }

    /*
     * Configure burst size per node.
     */
    channels = 44;
    for (index=0; index<256; index++) {
      SOC_IF_ERROR_RETURN(WRITE_BURST_SIZE_PER_NODEm(SIRIUS_UNIT,
						     MEM_BLOCK_ANY, index, &channels));
    }

    /* Enable appropriate blocks in QSB */
    SOC_IF_ERROR_RETURN(READ_QSB_ENABLEr(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_QPPf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_SPPf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_PUPf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_GGPf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_BAAf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QSB_SHAPERf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, QM_RI_ENABLEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, SCI_RI_ENABLEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, BAA_NEXT_HUNGRY_MODEf, 1);
    soc_reg_field_set(SIRIUS_UNIT, QSB_ENABLEr, &uRegValue, BAA_CHANGE_SOON_UPDATE_FROM_QPPf, 1);

    SOC_IF_ERROR_RETURN(WRITE_QSB_ENABLEr(SIRIUS_UNIT, uRegValue));



    if ( soc_feature(SIRIUS_UNIT, soc_feature_hybrid) ) {
      /* Node 255 in N2NT registers should point to the hybrid channel masks for local */
	/* this is reserved. This is because in the local path, the QS doesn't use the   */
	/* Sysport to node table to determine the node number.  It always takes node 255 */
	/* from the N2NT registers and the node type value set there.                    */
	SOC_IF_ERROR_RETURN(READ_N2NT_15r(SIRIUS_UNIT, &uRegValue));
	soc_reg_field_set(SIRIUS_UNIT, N2NT_15r, &uRegValue, SUB_N2NT15f, SIRIUS_NODE_TYPE_HYBRID);
	SOC_IF_ERROR_RETURN(WRITE_N2NT_15r(SIRIUS_UNIT, uRegValue));
    }

    /* make node 255 dummy, and point to QE2k type, sysport_to_node by default S2N=255 */
    if (!soc_feature(SIRIUS_UNIT, soc_feature_standalone) && !soc_feature(SIRIUS_UNIT, soc_feature_hybrid))  {
      for (i=0; i<4096; i++){
	  rv = soc_sirius_qs_sysport_to_node_set(SIRIUS_UNIT, i, 255);
	  if (rv) {
              LOG_ERROR(BSL_LS_SOC_COMMON,
                        (BSL_META_U(SIRIUS_UNIT,
                                    "ERROR: write to S2N table failed for queue(%d)\n"), i));
	      return rv;
	  }
      }
      SOC_IF_ERROR_RETURN(READ_N2NT_15r(SIRIUS_UNIT, &uRegValue));
      soc_reg_field_set(SIRIUS_UNIT, N2NT_15r, &uRegValue, SUB_N2NT15f, SIRIUS_NODE_TYPE_QE2K);
      SOC_IF_ERROR_RETURN(WRITE_N2NT_15r(SIRIUS_UNIT, uRegValue));
    }
    return rv;
}

static int
_soc_sirius_hw_init_tx( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32  unit = (int32) pInitParams->unit;
    cblock_mod_lookup_entry_t cblock_mod_lookup;
    tx_pfc_src_port_lkup_entry_t TxPFCSrcPortLutEntry;
    uint32 nIndex;
    soc_timeout_t timeout;
    uint32 nInitDone = 0;
    uint32 regval = 0;
    int i = 0;
    uint32 firstread_mask0, firstread_mask1, firstread_mask2, firstread_mask3, firstread_mask4;
    uint32 firstread_mask5, firstread_mask6, firstread_mask7, firstread_mask8, firstread_mask9;
    uint32 seqread_mask0, seqread_mask1, seqread_mask2, seqread_mask3;
    uint32 div = 0, max_seq = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "Sirius hardware init tx called.\n")));

    /*
     * Take out of soft reset
     */

    soc_reg_field_set(unit, TX_SW_RESETr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_TX_SW_RESETr(unit, regval));

    regval = 0;

    soc_reg_field_set(unit, TX_CONFIG0r, &regval, GRANT_SFI_DELAYf, 308); /* 308 proven on customer system */
    soc_reg_field_set(unit, TX_CONFIG0r, &regval, CRC_MODEf, 1);
    soc_reg_field_set(unit, TX_CONFIG0r, &regval, DYNAMIC_MODEf, 1);
    soc_reg_field_set(unit, TX_CONFIG0r, &regval, LENGTH_MODEf, 1);
    soc_reg_field_set(unit, TX_CONFIG0r, &regval, START_SFI_SEQf, 0x17);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG0r(unit, regval));

    /* reduced memory configuration */
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, MAX_CIf, pInitParams->uDdr3NumMemories - 1);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, DRAM_PAGE_SIZEf, 0);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, NUM_COL_BITSf, pInitParams->uNumColBits);
    soc_reg_field_set(unit, RB_CI_CONFIGr, &regval, BUFFER_SIZEf, pInitParams->uBufferSize);
    SOC_IF_ERROR_RETURN(WRITE_RB_CI_CONFIGr(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_CI_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, TX_CI_CONFIGr, &regval, MAX_CIf, pInitParams->uDdr3NumMemories - 1);
    soc_reg_field_set(unit, TX_CI_CONFIGr, &regval, DRAM_PAGE_SIZEf, 0);			
    soc_reg_field_set(unit, TX_CI_CONFIGr, &regval, NUM_COL_BITSf, pInitParams->uNumColBits);	
    soc_reg_field_set(unit, TX_CI_CONFIGr, &regval, BUFFER_SIZEf, pInitParams->uBufferSize);
    SOC_IF_ERROR_RETURN(WRITE_TX_CI_CONFIGr(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP0r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_0f,
		      (0 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_1f,
		      (1 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_2f,
		      (2 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_3f,
		      (3 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_4f,
		      (4 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_5f,
		      (5 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_6f,
		      (6 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP0r, &regval, CI_LOOKUP_7f,
		      (7 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP0r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP1r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_8f,
		      (8 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_9f,
		      (9 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_10f,
		      (10 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_11f,
		      (11 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_12f,
		      (12 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_13f,
		      (13 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_14f,
		      (14 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP1r, &regval, CI_LOOKUP_15f,
		      (15 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP1r(unit, regval));
    
    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP2r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_16f,
		      (16 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_17f,
		      (17 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_18f,
		      (18 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_19f,
		      (19 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_20f,
		      (20 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_21f,
		      (21 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_22f,
		      (22 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP2r, &regval, CI_LOOKUP_23f,
		      (23 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP2r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP3r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_24f,
		      (24 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_25f,
		      (25 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_26f,
		      (26 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_27f,
		      (27 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_28f,
		      (28 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_29f,
		      (29 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_30f,
		      (30 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP3r, &regval, CI_LOOKUP_31f,
		      (31 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP3r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP4r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_32f,
		      (32 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_33f,
		      (33 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_34f,
		      (34 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_35f,
		      (35 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_36f,
		      (36 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_37f,
		      (37 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_38f,
		      (38 % pInitParams->uDdr3NumMemories));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP4r, &regval, CI_LOOKUP_39f,
		      (39 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP4r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_FIRST_CI_LOOKUP5r(unit, &regval));
    soc_reg_field_set(unit, TX_FIRST_CI_LOOKUP5r, &regval, CI_LOOKUP_40f,
		      (40 % pInitParams->uDdr3NumMemories));
    SOC_IF_ERROR_RETURN(WRITE_TX_FIRST_CI_LOOKUP5r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_CONFIG3r(unit, &regval));
    firstread_mask0 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK0f);
    firstread_mask1 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK1f);
    firstread_mask2 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK2f);
    firstread_mask3 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK3f);
    firstread_mask4 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK4f);
    firstread_mask5 = soc_reg_field_get(unit, TX_CONFIG3r, regval, FIRSTCI_SEQREADMASK5f);
    if ( pInitParams->uDdr3NumMemories < 2) {
	firstread_mask0 &= 0x19;
	firstread_mask1 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 3) {
	firstread_mask0 &= 0x1E;
	firstread_mask1 &= 0x1E;
	firstread_mask2 &= 0x1E;
    }
    if ( pInitParams->uDdr3NumMemories < 4) {
	firstread_mask3 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 5) {
	firstread_mask3 &= 0x1C;
	firstread_mask4 &= 0x1C;
    }
    if ( pInitParams->uDdr3NumMemories < 6) {
	firstread_mask5 &= 0x07;
    }
    if ( pInitParams->uDdr3NumMemories < 7) {
	firstread_mask5 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 8) {
	firstread_mask5 &= 0x1E;
    }
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK0f, firstread_mask0);
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK1f, firstread_mask1);
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK2f, firstread_mask2);
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK3f, firstread_mask3);
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK4f, firstread_mask4);
    soc_reg_field_set(unit, TX_CONFIG3r, &regval,  FIRSTCI_SEQREADMASK5f, firstread_mask5);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG3r(unit, regval));

    SOC_IF_ERROR_RETURN(READ_TX_CONFIG4r(unit, &regval));
    firstread_mask6 = soc_reg_field_get(unit, TX_CONFIG4r, regval, FIRSTCI_SEQREADMASK6f);
    firstread_mask7 = soc_reg_field_get(unit, TX_CONFIG4r, regval, FIRSTCI_SEQREADMASK7f);
    firstread_mask8 = soc_reg_field_get(unit, TX_CONFIG4r, regval, FIRSTCI_SEQREADMASK8f);
    firstread_mask9 = soc_reg_field_get(unit, TX_CONFIG4r, regval, FIRSTCI_SEQREADMASK9f);
    if ( pInitParams->uDdr3NumMemories < 7) {
	firstread_mask6 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 8) {
	firstread_mask6 &= 0x1E;
	firstread_mask7 &= 0x1E;
    }
    if ( pInitParams->uDdr3NumMemories < 9) {
	firstread_mask8 &= 0x13;
    }
    if ( pInitParams->uDdr3NumMemories < 10) {
	firstread_mask8 &= 0x1C;
	firstread_mask9 &= 0x1C;
    }
    soc_reg_field_set(unit, TX_CONFIG4r, &regval,  FIRSTCI_SEQREADMASK6f, firstread_mask6);
    soc_reg_field_set(unit, TX_CONFIG4r, &regval,  FIRSTCI_SEQREADMASK7f, firstread_mask7);
    soc_reg_field_set(unit, TX_CONFIG4r, &regval,  FIRSTCI_SEQREADMASK8f, firstread_mask8);
    soc_reg_field_set(unit, TX_CONFIG4r, &regval,  FIRSTCI_SEQREADMASK9f, firstread_mask9);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG4r(unit, regval));
    
    SOC_IF_ERROR_RETURN(READ_TX_CONFIG5r(unit, &regval));
    seqread_mask0 = soc_reg_field_get(unit, TX_CONFIG5r, regval, SEQ_READMASK0f);
    seqread_mask1 = soc_reg_field_get(unit, TX_CONFIG5r, regval, SEQ_READMASK1f);
    seqread_mask2 = soc_reg_field_get(unit, TX_CONFIG5r, regval, SEQ_READMASK2f);
    seqread_mask3 = soc_reg_field_get(unit, TX_CONFIG5r, regval, SEQ_READMASK3f);
    if ( pInitParams->uDdr3NumMemories < 2) {
	seqread_mask0 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 3) {
	seqread_mask0 &= 0x1E;
	seqread_mask1 &= 0x0F;
    }
    if ( pInitParams->uDdr3NumMemories < 4) {
	seqread_mask1 &= 0x13;
    }
    if ( pInitParams->uDdr3NumMemories < 5) {
	seqread_mask1 &= 0x1C;
    }
    if ( pInitParams->uDdr3NumMemories < 6) {
	seqread_mask2 &= 0x07;
    }
    if ( pInitParams->uDdr3NumMemories < 7) {
	seqread_mask2 &= 0x19;
    }
    if ( pInitParams->uDdr3NumMemories < 8) {
	seqread_mask2 &= 0x1E;
	seqread_mask3 &= 0x0F;
    }
    if ( pInitParams->uDdr3NumMemories < 9) {
	seqread_mask3 &= 0x13;
    }
    if ( pInitParams->uDdr3NumMemories < 10) {
	seqread_mask3 &= 0x1C;
    }

    if (seqread_mask1 == 0) {
	max_seq = 0;
    } else if (seqread_mask2 == 0) {
	max_seq = 1;
    } else if (seqread_mask3 == 0) {
	max_seq = 2;
    } else {
	max_seq = 3;
    }

    soc_reg_field_set(unit, TX_CONFIG5r, &regval,  SEQ_READMASK0f, seqread_mask0);
    soc_reg_field_set(unit, TX_CONFIG5r, &regval,  SEQ_READMASK1f, seqread_mask1);
    soc_reg_field_set(unit, TX_CONFIG5r, &regval,  SEQ_READMASK2f, seqread_mask2);
    soc_reg_field_set(unit, TX_CONFIG5r, &regval,  SEQ_READMASK3f, seqread_mask3);
    soc_reg_field_set(unit, TX_CONFIG5r, &regval,  MAX_SEQVALUEf,  max_seq);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG5r(unit, regval));
    

    /*
     * Initialize TX Memory
     */

    SOC_IF_ERROR_RETURN(READ_TX_CONFIG0r(unit, &regval));
    soc_reg_field_set(unit, TX_CONFIG0r, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG0r(unit, regval));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_timeout_init(&timeout, _sirius_init_timeout,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_TX_CONFIG0r(unit, &regval));
            
            nInitDone = soc_reg_field_get(unit,TX_CONFIG0r,regval,INIT_DONEf);
            if (nInitDone)
                break;
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("TX Config0 init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    soc_reg_field_set(unit, TX_CONFIG0r, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG0r(unit, regval));

    /*
     * For default config, the CBLOCK_MOD_LOOKUP table is
     * configured during init. 
     */
    div = 0;
    for (i=0; i <= SOC_MEM_INFO(unit, CBLOCK_MOD_LOOKUPm).index_max; i++) {
	soc_mem_field32_set(unit, CBLOCK_MOD_LOOKUPm, &cblock_mod_lookup, MODf,
			    (i%pInitParams->uDdr3NumMemories));
	/* INFO: mod 64 of div is not in original doc, wait for hardware feedback */
	soc_mem_field32_set(unit, CBLOCK_MOD_LOOKUPm, &cblock_mod_lookup, DIVf, div%64 );
	if ((i > 0) && (((i+1) % pInitParams->uDdr3NumMemories)== 0)) {
	    div++;
	}
	SOC_IF_ERROR_RETURN(WRITE_CBLOCK_MOD_LOOKUPm(unit, MEM_BLOCK_ANY, i, &cblock_mod_lookup));
    }

    /* Need to set to 0 for TME Mode */
    SOC_IF_ERROR_RETURN(READ_TX_CONFIG0r(unit, &regval));
    if  (soc_feature(SIRIUS_UNIT, soc_feature_standalone) || 
	 soc_feature(SIRIUS_UNIT, soc_feature_hybrid) || 
         ((SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_FIC) && 
          SAL_BOOT_BCMSIM)) {
	
	soc_reg_field_set(unit, TX_CONFIG0r, &regval, DYNAMIC_MODEf, 0);
    }
    SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG0r(unit, regval));

    /* workround for multicast jumbo frame drops on qe2k+sirius */
    if (SOC_SBX_CFG(unit)->uFabricConfig == SOC_SBX_SYSTEM_CFG_VPORT_MIX) {
	SOC_IF_ERROR_RETURN(READ_TX_CONFIG6r(unit, &regval));
	if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid)) {
	    /* Hybrid mode, plane A tag override */
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_MASK_Af, 0x7);
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_Af, 0);
	} else if (!soc_feature(SIRIUS_UNIT, soc_feature_standalone)) {
	    /* FIC mode, plane A/B tag override */
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_MASK_Af, 0x7);
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_Af, 0);
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_MASK_Bf, 0x7);
	    soc_reg_field_set(unit, TX_CONFIG6r, &regval, TS_TAG_Bf, 0);
	}	
	SOC_IF_ERROR_RETURN(WRITE_TX_CONFIG6r(unit, regval));
    }

    /* PFC config */
    if (soc_feature(unit, soc_feature_source_port_priority_flow_control)) {
        /* source port ID generation, only care about lower 4 bits */
        SOC_IF_ERROR_RETURN(READ_TX_PFC_SRC_PORT_LKUP_CFGr(SIRIUS_UNIT, &regval));    
        soc_reg_field_set(SIRIUS_UNIT, TX_PFC_SRC_PORT_LKUP_CFGr, &regval,
                          SOURCE_ID_MASKf, 0xFFF0);	
        SOC_IF_ERROR_RETURN(WRITE_TX_PFC_SRC_PORT_LKUP_CFGr(SIRIUS_UNIT, regval));
        
        /* user lower 4 bits of SID as source port ID */
        for (nIndex = 0; nIndex <= SOC_MEM_INFO(unit, TX_PFC_SRC_PORT_LKUPm).index_max; nIndex++) {
            soc_mem_field32_set(unit, TX_PFC_SRC_PORT_LKUPm, &TxPFCSrcPortLutEntry, ENABLEf, 1);
            soc_mem_field32_set(unit, TX_PFC_SRC_PORT_LKUPm, &TxPFCSrcPortLutEntry, KEYf, nIndex);
            SOC_IF_ERROR_RETURN(WRITE_TX_PFC_SRC_PORT_LKUPm(unit, MEM_BLOCK_ANY, nIndex, &TxPFCSrcPortLutEntry));
        }
        
        /* pfc enable, SID extraction and clear ECN */
        SOC_IF_ERROR_RETURN(READ_TX_PFC_CONFIGr(SIRIUS_UNIT, &regval));    
        soc_reg_field_set(SIRIUS_UNIT, TX_PFC_CONFIGr, &regval, PFC_ENf, 0x1);
        soc_reg_field_set(SIRIUS_UNIT, TX_PFC_CONFIGr, &regval, PFC_SRC_EXTRACT_BIT_OFFSETf, 0);
        soc_reg_field_set(SIRIUS_UNIT, TX_PFC_CONFIGr, &regval, PFC_SRC_EXTRACT_BYTE_OFFSETf, 0x8);
        soc_reg_field_set(SIRIUS_UNIT, TX_PFC_CONFIGr, &regval, PFC_CLR_ECNf, 0);
        SOC_IF_ERROR_RETURN(WRITE_TX_PFC_CONFIGr(SIRIUS_UNIT, regval));
    }

    /* Don't allow errors to cause fatal error state.  This causes TX block to stop processing */
    SOC_IF_ERROR_RETURN(READ_TX_DEBUG_INFO_0r(SIRIUS_UNIT, &regval));    
    soc_reg_field_set(SIRIUS_UNIT, TX_DEBUG_INFO_0r, &regval, TX_FATAL_ERROR_STATE_ENf, 0);
    SOC_IF_ERROR_RETURN(WRITE_TX_DEBUG_INFO_0r(SIRIUS_UNIT, regval));

    return rv;
}

static int
_soc_sirius_hw_init_ci( uint32 ci,
                        siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue = 0;
    uint32 uRegValue2 = 0;
    int pll_lock_usec;
    int calib_lock_usec;
    int locked = 0;
    int calib_locked = 0;
    soc_timeout_t to;
    int pll_ndiv_int = 0;
    int pll_m1div = 0;
    int read_en_vdl = 0;
    int read_vdl = 0;
    int tread_enb = 0;
    uint32 one_cycle;
    uint32 two_cycle;
    uint32 step_delay;
    uint32 clock_period;
    siriusInitParamsCi_t *pCI = &(pInitParams->ci[ci]);
    uint32 dq_adjust = 0;
    uint32 ctl_adjust = 0;
    uint32 rd_en_adjust = 1056;
    uint32 cke_usec;
    uint32 refresh_interval;
    uint16 dev_id;
    uint8  rev_id;
    int32  loop_cnt, calib_cnt, zq_results[3];

#define SIRIUS_DDR_REFRESH_INTERVAL_NS 7800

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ci%d called.\n"), ci));

    if (!pCI->bBringUp) {
      LOG_VERBOSE(BSL_LS_SOC_COMMON,
                  (BSL_META("skipping ci%d bringup\n"),
                   ci));
      return SOC_E_NONE;
    }

    rd_en_adjust = soc_property_get(SIRIUS_UNIT, spn_SIRIUS_DDR3_RD_EN_ADJUST, rd_en_adjust);

    /* bring CI block out of reset */
    SOC_IF_ERROR_RETURN(READ_CI_RESETr(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,DDR_RESET_Nf,0);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,PHY_SW_RESETf,1);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,SW_RESETf,0);
    SOC_IF_ERROR_RETURN(WRITE_CI_RESETr(SIRIUS_UNIT,ci,uRegValue));

    /* bring CI PHY out of reset */
    SOC_IF_ERROR_RETURN(READ_CI_RESETr(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,DDR_RESET_Nf,0);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,PHY_SW_RESETf,0);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,SW_RESETf,0);
    SOC_IF_ERROR_RETURN(WRITE_CI_RESETr(SIRIUS_UNIT,ci,uRegValue));

    if (SAL_BOOT_QUICKTURN) {
        /* return if running on emulator, no DDR PHYs on emulator */
        return SOC_E_NONE;
    }

    /* intialize CI internal memories
     * !NOT DONE IN DV code 
     */
    SOC_IF_ERROR_RETURN(READ_CI_DEBUGr(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_DEBUGr,&uRegValue,INITf,1);
    SOC_IF_ERROR_RETURN(WRITE_CI_DEBUGr(SIRIUS_UNIT,ci,uRegValue));
    

    if (!SAL_BOOT_PLISIM && !SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
      sal_usleep(100);
      SOC_IF_ERROR_RETURN(READ_CI_DEBUGr(SIRIUS_UNIT,ci,&uRegValue));
      if (soc_reg_field_get(SIRIUS_UNIT,CI_DEBUGr,uRegValue,INIT_DONE_CTLf) != 1) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("ctl mem did not finish init\n")));
      }
      if (soc_reg_field_get(SIRIUS_UNIT,CI_DEBUGr,uRegValue,INIT_DONE_DATA0_LSBf) != 1) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("DATA0_LSB did not finish init\n")));
      }
      if (soc_reg_field_get(SIRIUS_UNIT,CI_DEBUGr,uRegValue,INIT_DONE_DATA0_MSBf) != 1) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("DATA0_MSB did not finish init\n")));
      }
      if (soc_reg_field_get(SIRIUS_UNIT,CI_DEBUGr,uRegValue,INIT_DONE_DATA1_LSBf) != 1) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("DATA1_LSB did not finish init\n")));
      }
      if (soc_reg_field_get(SIRIUS_UNIT,CI_DEBUGr,uRegValue,INIT_DONE_DATA1_MSBf) != 1) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("DATA1_MSB did not finish init\n")));
      }
    }

    /* program configurable CI parameters(CI_CONFIGx) if non-default values required */

    /* based on memory topology setup CI configuration */
    /* RB needs to be in sync with CI on num_col_bits in its config register */

    /* make the refresh interval to be 7800ns since we are tight on DDR bandwidth 
     *  round down the interval a bit to be save
     */
    refresh_interval = (SIRIUS_DDR_REFRESH_INTERVAL_NS * SOC_SBX_CFG(SIRIUS_UNIT)->uClockSpeedInMHz) / 1000;
    refresh_interval -= 9;

    SOC_IF_ERROR_RETURN(READ_CI_CONFIG4r(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG4r,&uRegValue,NUM_COL_BITSf,pInitParams->uNumColBits);
    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG4r,&uRegValue,REFRESH_INTERVALf,refresh_interval);
    SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG4r(SIRIUS_UNIT,ci,uRegValue));


    /* set CI mrs */
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ci%d to speed %s mem-grade %s\n"),ci,
                 (pInitParams->uDdr3ClockMhz == 667)?"667Mhz":
                 (pInitParams->uDdr3ClockMhz == 533)?"533Mhz":
                 (pInitParams->uDdr3ClockMhz == 400)?"400Mhz":"333Mhz",
                 (pCI->mem_grade == 2)?"10-10-10":
                 (pCI->mem_grade == 1)?"7-7-7":"9-9-9"));

    /* enable ODT */
    SOC_IF_ERROR_RETURN(READ_CI_CONFIG2r(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,ODT_ENABLEf,0x1);
    SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG2r(SIRIUS_UNIT,ci,uRegValue));

    if (pInitParams->uNumColBits == 2) {
        SOC_IF_ERROR_RETURN(READ_CI_CONFIG6r(SIRIUS_UNIT,ci,&uRegValue));
	soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG6r,&uRegValue,TRFCf,0x6B);
	SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG6r(SIRIUS_UNIT,ci,uRegValue));

	SOC_IF_ERROR_RETURN(READ_CI_CONFIG2r(SIRIUS_UNIT,ci,&uRegValue));
	tread_enb = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_TREAD_ENB,-1);
	if (tread_enb >= 0) {
	  LOG_VERBOSE(BSL_LS_SOC_COMMON,
	              (BSL_META("ci%d using tread_enb=%d.\n"),
	               ci, tread_enb));
	  soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,tread_enb);
	} else {
	  soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,pInitParams->ci[ci].read_enb);
	}
	SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG2r(SIRIUS_UNIT,ci,uRegValue));
    }

    SOC_IF_ERROR_RETURN(READ_CI_DDR_MR1r(SIRIUS_UNIT,ci,&uRegValue));
    uRegValue |= (0x1 << 2);             /* RTT bit9/6/2 = 0b001*/
    uRegValue &= ~(0x1 << 6);            /* RTT bit9/6/2 = 0b001*/
    uRegValue &= ~(0x1 << 9);            /* RTT bit9/6/2 = 0b001*/
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_MR1r(SIRIUS_UNIT,ci,uRegValue));	    
    
    SOC_IF_ERROR_RETURN(READ_CI_DDR_MR2r(SIRIUS_UNIT,ci,&uRegValue));
    uRegValue &= ~(0x3 << 9);            /* RTT-WR bit10:9 = 0b01 */
    uRegValue |= (0x1 << 9);             /* RTT-WR bit10:9 = 0b01 */
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_MR2r(SIRIUS_UNIT,ci,uRegValue));	    
    
    if (pInitParams->uDdr3ClockMhz == 533) {
	/* speed 533 */
	SOC_IF_ERROR_RETURN(READ_CI_DDR_MR0r(SIRIUS_UNIT,ci,&uRegValue));
	uRegValue &= ~(0x7 << 4);        /* CAS */
	uRegValue |= (0x3 << 4);
	uRegValue &= ~(0x7 << 9);        /* WR */
	uRegValue |= (0x4 << 9);
	SOC_IF_ERROR_RETURN(WRITE_CI_DDR_MR0r(SIRIUS_UNIT,ci,uRegValue));	    
	
	sal_usleep(20);
	
	SOC_IF_ERROR_RETURN(READ_CI_DDR_MR2r(SIRIUS_UNIT,ci,&uRegValue));
	uRegValue &= ~(0x7 << 3);        /* CWL */
	uRegValue |= (0x1 << 3);
	SOC_IF_ERROR_RETURN(WRITE_CI_DDR_MR2r(SIRIUS_UNIT,ci,uRegValue));	    
	
	sal_usleep(20);
	
	SOC_IF_ERROR_RETURN(READ_CI_CONFIG2r(SIRIUS_UNIT,ci,&uRegValue));
	soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TALf,0x3);
	
	tread_enb = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_TREAD_ENB,-1);
	if (tread_enb >= 0) {
	    LOG_VERBOSE(BSL_LS_SOC_COMMON,
	                (BSL_META("ci%d using tread_enb=%d.\n"),
	                 ci, tread_enb));
	    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,tread_enb);
	} else {
	    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,pInitParams->ci[ci].read_enb);
	}
	
	SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG2r(SIRIUS_UNIT,ci,uRegValue));
    } else if (pInitParams->uDdr3ClockMhz == 667) {
	/* speed 667 */
	if (pCI->mem_grade == 2) {
	    /* mem_grade 10-10-10 */
	    SOC_IF_ERROR_RETURN(READ_CI_DDR_MR0r(SIRIUS_UNIT,ci,&uRegValue));
	    uRegValue &= ~(0x7 << 4);        /* CAS */
	    uRegValue |= (0x6 << 4);
	    uRegValue &= ~(0x7 << 9);        /* WR */
	    uRegValue |= (0x5 << 9);
	    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_MR0r(SIRIUS_UNIT,ci,uRegValue));
	    
	    sal_usleep(20);
	    
	    SOC_IF_ERROR_RETURN(READ_CI_CONFIG2r(SIRIUS_UNIT,ci,&uRegValue));
	    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TALf,0x7);
	    
	    tread_enb = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_TREAD_ENB,-1);
	    if (tread_enb >= 0) {
		LOG_VERBOSE(BSL_LS_SOC_COMMON,
		            (BSL_META("ci%d using tread_enb=%d.\n"),
		             ci, tread_enb));
		soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,tread_enb);
	    } else {
		soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,pInitParams->ci[ci].read_enb);
	    }
	    
	    soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TRTWf,0x9);
	    SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG2r(SIRIUS_UNIT,ci,uRegValue));		
	} else if (pCI->mem_grade == 0) {
	    /* mem_grade 9-9-9, set tread_enb to 0xD, which seems apply to most customer board */
	    SOC_IF_ERROR_RETURN(READ_CI_CONFIG2r(SIRIUS_UNIT,ci,&uRegValue));
	    tread_enb = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_TREAD_ENB,-1);
	    if (tread_enb >= 0) {
		LOG_VERBOSE(BSL_LS_SOC_COMMON,
		            (BSL_META("ci%d using tread_enb=%d.\n"),
		             ci, tread_enb));
		soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,tread_enb);
	    } else {
		soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG2r,&uRegValue,TREAD_ENBf,pInitParams->ci[ci].read_enb);
	    }
	    SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG2r(SIRIUS_UNIT,ci,uRegValue));		
	} else {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("Bad DDR3 Interface speed_mhz/mem_grade specified (%d)/(%d)\n"),
                       pInitParams->uDdr3ClockMhz, pCI->mem_grade));
	    return SOC_E_UNAVAIL;
	}	    
    } else {
	LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("Bad DDR3 Interface speed_mhz/mem_grade specified (%d)/(%d)\n"),
                   pInitParams->uDdr3ClockMhz, pCI->mem_grade));
	return SOC_E_UNAVAIL;
    }

    /* set byte lane preamble mode to 1 cycle */
    uRegValue = 0;
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,WR_PREAMBLE_MODE, MODE, 1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_WR_PREAMBLE_MODEr(SIRIUS_UNIT,ci,uRegValue));

    uRegValue = 0;
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,WR_PREAMBLE_MODE, MODE, 1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_WR_PREAMBLE_MODEr(SIRIUS_UNIT,ci,uRegValue));

    /*
     * Reset clock generation logic, and PLL ARESET, DRESET
     */
    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,&uRegValue));
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN,          0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED0,      0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ARESET,         1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DRESET,         1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ENB_CLKOUT,     0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, BYPEN,          0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN_CH1,      0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED1,      0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, VCO_RNG,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DIV2_CLK_RESET, 1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,uRegValue));

    /*
     *  setup PLL dividers based on DDR3 speed grade, based on 25Mhz reference clock.
     *  2*DDR3_SPEED_MHZ (Data Rate)  = 25MHZ * NDIV_INT/M1DIV
     *
     */
    switch(pInitParams->uDdr3ClockMhz) {
    case 333: pll_ndiv_int = 53; pll_m1div = 2; clock_period = 3000; break;
    case 400: pll_ndiv_int = 64; pll_m1div = 2; clock_period = 2500; break;
    case 533: pll_ndiv_int = 42; pll_m1div = 1; clock_period = 1876; break;
    case 667: pll_ndiv_int = 53; pll_m1div = 1; clock_period = 1500; break;
    default:
      LOG_ERROR(BSL_LS_SOC_COMMON,
                (BSL_META("Bad DDR3 Interface speed_mhz specified (%d)\n"),pInitParams->uDdr3ClockMhz));
      return SOC_E_INTERNAL;
    }

    pll_ndiv_int = soc_property_get(SIRIUS_UNIT, "diag_sirius_pll_ndiv", pll_ndiv_int);
    pll_m1div = soc_property_get(SIRIUS_UNIT, "diag_sirius_pll_m1div", pll_m1div);

    uRegValue = 0;
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_PRE_DIVIDER,P1DIV,1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_PRE_DIVIDER,P2DIV,1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_PRE_DIVIDER,NDIV_INT,pll_ndiv_int);
    uRegValue |= (1<<24); /* BYPASS_SDMOD */
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_PRE_DIVIDERr(SIRIUS_UNIT,ci,uRegValue));

    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_DIVIDERr(SIRIUS_UNIT,ci,&uRegValue));
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_DIVIDER,M1DIV,pll_m1div);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_DIVIDERr(SIRIUS_UNIT,ci,uRegValue));

    /* clear ARESET */
    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,&uRegValue));
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED0,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ARESET,           0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DRESET,           1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ENB_CLKOUT,       0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, BYPEN,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN_CH1,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED1,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, VCO_RNG,          0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DIV2_CLK_RESET,   1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,uRegValue));

    if (!SAL_BOOT_BCMSIM && !SAL_BOOT_PLISIM && !SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
    /* wait for lock */
    pll_lock_usec = 500000;
    locked = 0;
    soc_timeout_init(&to,pll_lock_usec,0);
    while (!soc_timeout_check(&to) && !locked) {
        SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_STATUSr(SIRIUS_UNIT,ci,&uRegValue));
        locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, PLL_STATUS, LOCK);
    }

    if (!locked) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("CI%d PHY PLL lock timedout\n"),ci));
        return SOC_E_TIMEOUT;
    }
    } /* !SIM */

    /* de-assert digital reset */
    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,&uRegValue));
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN,             0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED0,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ARESET,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DRESET,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ENB_CLKOUT,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, BYPEN,             0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN_CH1,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED1,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, VCO_RNG,           0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DIV2_CLK_RESET,    1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,uRegValue));

    /* de-assert reset of clock logic */
    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,&uRegValue));
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN,             0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED0,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ARESET,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DRESET,            0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, ENB_CLKOUT,        0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, BYPEN,             0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, PWRDN_CH1,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, RESERVED1,         0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, VCO_RNG,           0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,PLL_CONFIG, DIV2_CLK_RESET,    0);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_PLL_CONFIGr(SIRIUS_UNIT,ci,uRegValue));

    sal_usleep(1000);

    if (!SAL_BOOT_QUICKTURN && !SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        /* SSTL voltage level */
        /* set reciever current to full power, and sel_sstl18 for 1.5V
	 * Would this work for sirius?
	 */
        SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,&uRegValue));
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, DRIVE_PAD_CTL, SEL_SSTL18,  0);
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, DRIVE_PAD_CTL, SLEW,  0);
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, DRIVE_PAD_CTL, RT60B,  0);
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, DRIVE_PAD_CTL, SELRXDRV,  0);
	SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,uRegValue));

        SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE0_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,&uRegValue));
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, DRIVE_PAD_CTL, SEL_SSTL18,  0);
	SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,uRegValue));

        SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,&uRegValue));
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, DRIVE_PAD_CTL, SEL_SSTL18,  0);
	SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,uRegValue));

        /*
         * PHY VDL(Variable delay lines) Byte lane Calibration for both byte lanes
         */
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_CALIBRATE, CALIB_FAST, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_CALIBRATE, CALIB_ONCE, 1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_FAST, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_ONCE, 1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));

        /* poll for calib lock set */
        calib_lock_usec = 500000;
        locked = 0;
        soc_timeout_init(&to,calib_lock_usec,0);
        while(!soc_timeout_check(&to) && !locked) {
            SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE0_VDL_STATUSr(SIRIUS_UNIT,ci,&uRegValue));
            locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_STATUS, CALIB_LOCK);
        }
        if (!locked) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("CI%d Byte Lane 0 calibration timedout\n"),ci));
            return SOC_E_TIMEOUT;
        }

        locked = 0;
        soc_timeout_init(&to,calib_lock_usec,0);
        while(!soc_timeout_check(&to) && !locked) {
            SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_VDL_STATUSr(SIRIUS_UNIT,ci,&uRegValue2));
            locked = DDR23_GET_FIELD(uRegValue2, DDR23_PHY_BYTE_LANE1, VDL_STATUS, CALIB_LOCK);
        }
        if (!locked) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("CI%d Byte Lane 1 calibration timedout\n"),ci));
            return SOC_E_TIMEOUT;
        }

        /* The VDL calibration should now be idle */
        if ( (DDR23_GET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_STATUS, CALIB_IDLE) != 1) ||
             (DDR23_GET_FIELD(uRegValue2, DDR23_PHY_BYTE_LANE1, VDL_STATUS, CALIB_IDLE) != 1) ) {
            LOG_WARN(BSL_LS_SOC_COMMON,
                     (BSL_META("CI%d Byte Lane calibration finished, but VDL is not idle\n"), ci));
            return SOC_E_INTERNAL;
        }

        /* Clear PHY calibration */
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));

	/* Use 2-cycle calibration */
        /* Use the results from byte lane0 for address/ctrl calibration */
        SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE0_VDL_STATUSr(SIRIUS_UNIT,ci,&uRegValue));
        one_cycle = DDR23_GET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_STATUS,CALIB_TOTAL);
	
	LOG_VERBOSE(BSL_LS_SOC_COMMON,
	            (BSL_META("ci%d one_cycle %d.\n"),
	             ci, one_cycle>>4));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_FAST, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_ONCE, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_TEST, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_CLOCKS, 1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));

        calib_lock_usec = 500000;
        calib_locked = 0;
        soc_timeout_init(&to,calib_lock_usec,0);
        while(!soc_timeout_check(&to) && !calib_locked) {
            SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_VDL_STATUSr(SIRIUS_UNIT,ci,&uRegValue));
            calib_locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_STATUS, CALIB_LOCK);
        }
        two_cycle = DDR23_GET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_STATUS,CALIB_TOTAL);
	
	LOG_VERBOSE(BSL_LS_SOC_COMMON,
	            (BSL_META("ci%d two_cycle %d.\n"),
	             ci, two_cycle>>4));

	/* restore byte lane 0 to single cycle timing */
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_FAST, 1);
        DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_ONCE, 1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));
	
        calib_lock_usec = 500000;
        locked = 0;
        soc_timeout_init(&to,calib_lock_usec,0);
        while(!soc_timeout_check(&to) && !locked) {
            SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_VDL_STATUSr(SIRIUS_UNIT,ci,&uRegValue));
            locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_STATUS, CALIB_LOCK);
        }

        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,0));

	if (!calib_locked || (two_cycle <= one_cycle)) {
	    step_delay = 20;
	} else {
	    step_delay = (clock_period * 4 / (two_cycle - one_cycle));
	}
	LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius hardware init ci%d computed VDL step size %d ps..\n"), ci, step_delay));
        /* Override PHY calibration for ADDR/CTRL */
	uRegValue2 = (one_cycle >> 4) + (ctl_adjust / step_delay);
	if (uRegValue2 > 63) {
	    uRegValue2 = 63;
	}

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,STATIC_VDL_OVERRIDE,OVR_STEP,      uRegValue2);
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,STATIC_VDL_OVERRIDE,OVR_FINE_RISE, 0);
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,STATIC_VDL_OVERRIDE,OVR_FINE_FALL, 0);
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,STATIC_VDL_OVERRIDE,OVR_EN,        1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_STATIC_VDL_OVERRIDEr(SIRIUS_UNIT,ci,uRegValue));

        /* Override write DQ VDL's PHY calibration for both Bytelanes */
	uRegValue2 = (one_cycle >> 4) + (dq_adjust / step_delay);
	if (uRegValue2 > 63) {
	    uRegValue2 = 63;
	}

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_3,OVR_STEP,      uRegValue2);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_3,OVR_FINE_RISE, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_3,OVR_FINE_FALL, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_3,OVR_EN,        1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_OVERRIDE_3r(SIRIUS_UNIT,ci,uRegValue));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_3,OVR_STEP,      uRegValue2);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_3,OVR_FINE_RISE, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_3,OVR_FINE_FALL, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_3,OVR_EN,        1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_OVERRIDE_3r(SIRIUS_UNIT,ci,uRegValue));

        /* Override read_en VDL's PHY calibration for both Bytelanes */
	uRegValue2 = (one_cycle >> 4) + (rd_en_adjust / step_delay);
	if (uRegValue2 > 63) {
	    uRegValue2 = 63;
	}

	uRegValue = 0;
	read_en_vdl = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_READ_EN_VDL,-1);
	if (read_en_vdl >= 0) {
	  LOG_VERBOSE(BSL_LS_SOC_COMMON,
	              (BSL_META("ci%d using read_en_vdl=%d.\n"),
	               ci, read_en_vdl));
	  uRegValue2 = read_en_vdl;
	}

        DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_2,OVR_STEP,      uRegValue2);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_2,OVR_FINE_RISE, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_2,OVR_FINE_FALL, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_2,OVR_EN,        1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_OVERRIDE_2r(SIRIUS_UNIT,ci,uRegValue));

	uRegValue = 0;
        DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_2,OVR_STEP,      uRegValue2);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_2,OVR_FINE_RISE, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_2,OVR_FINE_FALL, 0);
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_2,OVR_EN,        1);
        SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_OVERRIDE_2r(SIRIUS_UNIT,ci,uRegValue));


	/* use soc properties if present for read DQSP/DQSN delay values */
	uRegValue = 0;
	read_vdl = soc_property_port_get(SIRIUS_UNIT,ci,spn_SIRIUS_DDR3_READ_VDL,-1);
	if (read_vdl >= 0) {
	  LOG_VERBOSE(BSL_LS_SOC_COMMON,
	              (BSL_META("ci%d using read_vdl=%d.\n"),
	               ci, read_vdl));
	  /* bytelane 0 readDQSP and readDQSN */
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_0,OVR_EN,0x1);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_0,OVR_FINE_FALL,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_0,OVR_FINE_RISE,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_0,OVR_STEP,read_vdl);
	  SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_OVERRIDE_0r(SIRIUS_UNIT,ci,uRegValue));
	  uRegValue = 0;
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_1,OVR_EN,0x1);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_1,OVR_FINE_FALL,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_1,OVR_FINE_RISE,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,VDL_OVERRIDE_1,OVR_STEP,read_vdl);
	  SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_OVERRIDE_1r(SIRIUS_UNIT,ci,uRegValue));
	  /* bytelane 1 readDQSP and readDQSN */
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_0,OVR_EN,0x1);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_0,OVR_FINE_FALL,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_0,OVR_FINE_RISE,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_0,OVR_STEP,read_vdl);
	  SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_OVERRIDE_0r(SIRIUS_UNIT,ci,uRegValue));
	  uRegValue = 0;
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_1,OVR_EN,0x1);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_1,OVR_FINE_FALL,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_1,OVR_FINE_RISE,0);
	  DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,VDL_OVERRIDE_1,OVR_STEP,read_vdl);
	  SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_OVERRIDE_1r(SIRIUS_UNIT,ci,uRegValue));

	}

        if (!SAL_BOOT_PLISIM) {
	/* ZQ calibration */
	/* ZQ calibration workaround for bcm88230 A0/B0/C0 */
	soc_cm_get_id(SIRIUS_UNIT, &dev_id, &rev_id);
	if ( (rev_id == BCM88230_A0_REV_ID) ||
	     (rev_id == BCM88230_B0_REV_ID) ||
	     (rev_id == BCM88230_C0_REV_ID) ) {
	    /* A0/B0/C0 parts */
	    for (loop_cnt = 0; loop_cnt < 100; loop_cnt++) {
		for (calib_cnt = 0; calib_cnt < 3; calib_cnt++) {
		    uRegValue = 0;
		    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_ZQ_PVT_COMP_CTLr(SIRIUS_UNIT,ci,uRegValue));

		    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,ZQ_PVT_COMP_CTL,SAMPLE_EN,    1);
		    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_ZQ_PVT_COMP_CTLr(SIRIUS_UNIT,ci,uRegValue));

		    calib_lock_usec = 500000;
		    locked = 0;
		    soc_timeout_init(&to,calib_lock_usec,0);
		    while(!soc_timeout_check(&to) && !locked) {
			SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_ZQ_PVT_COMP_CTLr(SIRIUS_UNIT,ci,&uRegValue));
			locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, ZQ_PVT_COMP_CTL, SAMPLE_DONE);
		    }
		    
		    if (!locked) {
			LOG_ERROR(BSL_LS_SOC_COMMON,
                                  (BSL_META("CI%d ZQ calibration loop %d calib %d timedout\n"),ci, loop_cnt, calib_cnt));
			return SOC_E_TIMEOUT;
		    } else {
			zq_results[calib_cnt] = uRegValue;
		    }
		}
		if ((zq_results[0] == zq_results[1]) && 
		    (zq_results[0] == zq_results[2])) {
		    break;
		}
	    }
	    if (loop_cnt >= 100) {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("CI%d ZQ calibration timedout\n"),ci));
		return SOC_E_TIMEOUT;
	    }
	} else {
	    uRegValue = 0;
	    DDR23_SET_FIELD(uRegValue,DDR23_PHY_ADDR_CTL,ZQ_PVT_COMP_CTL,SAMPLE_EN,    1);
	    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_ADDR_CTL_ZQ_PVT_COMP_CTLr(SIRIUS_UNIT,ci,uRegValue));
	    
	    calib_lock_usec = 500000;
	    locked = 0;
	    soc_timeout_init(&to,calib_lock_usec,0);
	    while(!soc_timeout_check(&to) && !locked) {
		SOC_IF_ERROR_RETURN(READ_DDR23_PHY_ADDR_CTL_ZQ_PVT_COMP_CTLr(SIRIUS_UNIT,ci,&uRegValue));
		locked = DDR23_GET_FIELD(uRegValue, DDR23_PHY_ADDR_CTL, ZQ_PVT_COMP_CTL, SAMPLE_DONE);
	    }
	    
	    if (!locked) {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("CI%d ZQ calibration timedout\n"),ci));
		return SOC_E_TIMEOUT;
	    }
	}
        } /* !PLISIM */

        /* turn on the update vdl */
	SOC_IF_ERROR_RETURN(READ_CI_CONFIG3r(SIRIUS_UNIT,ci,&uRegValue));
	soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG3r,&uRegValue,PHY_UPD_VDL_BL0f,0x1);
	soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG3r,&uRegValue,PHY_UPD_VDL_BL1f,0x1);
	soc_reg_field_set(SIRIUS_UNIT,CI_CONFIG3r,&uRegValue,PHY_UPD_VDL_ADDRf,0x1);
	SOC_IF_ERROR_RETURN(WRITE_CI_CONFIG3r(SIRIUS_UNIT,ci,uRegValue));		

	/* turn on refresh */
        SOC_IF_ERROR_RETURN(READ_CI_DEBUGr(SIRIUS_UNIT,ci,&uRegValue));
	soc_reg_field_set(SIRIUS_UNIT,CI_DEBUGr,&uRegValue,REFRESH_OVERRIDEf,1);
	SOC_IF_ERROR_RETURN(WRITE_CI_DEBUGr(SIRIUS_UNIT,ci,uRegValue));

	/* wait 3000 us */
	sal_usleep(3000);
	
	/* turn off refresh */
        SOC_IF_ERROR_RETURN(READ_CI_DEBUGr(SIRIUS_UNIT,ci,&uRegValue));
	soc_reg_field_set(SIRIUS_UNIT,CI_DEBUGr,&uRegValue,REFRESH_OVERRIDEf,0);
	SOC_IF_ERROR_RETURN(WRITE_CI_DEBUGr(SIRIUS_UNIT,ci,uRegValue));

	
	sal_usleep(20); /* do as what A said */
    }

    /*
     * DDR3 PHY setting
     */
    /* override some default PHY parameters to support DDR3 (sirius currently only supports DDR3) */
    uRegValue = 0;
    {
	DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0, READ_CONTROL, RD_DATA_DLY, (pInitParams->uDdr3ClockMhz==667)?2:3);
    }      

    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0, READ_CONTROL, DQ_ODT_ENABLE, 1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0, READ_CONTROL, DQ_ODT_ADJ, 0);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0, READ_CONTROL, RD_ENB_ODT_ENABLE, 1);
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0, READ_CONTROL, RD_ENB_ODT_ADJ, 0);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_READ_CONTROLr(SIRIUS_UNIT,ci,uRegValue));
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_READ_CONTROLr(SIRIUS_UNIT,ci,uRegValue));
    

    /* set byte lane preamble mode to 1 cycle */
    uRegValue = 0;
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE0,WR_PREAMBLE_MODE, MODE, 1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_WR_PREAMBLE_MODEr(SIRIUS_UNIT,ci,uRegValue));

    uRegValue = 0;
    DDR23_SET_FIELD(uRegValue,DDR23_PHY_BYTE_LANE1,WR_PREAMBLE_MODE, MODE, 1);
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_WR_PREAMBLE_MODEr(SIRIUS_UNIT,ci,uRegValue));

    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE0_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,&uRegValue));
    uRegValue &= 0xFC;
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,uRegValue));
    
    SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,&uRegValue));
    uRegValue &= 0xFC;
    SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_DRIVE_PAD_CTLr(SIRIUS_UNIT,ci,uRegValue));

    /* Wait for 400usecs to allow DRAM clock to stabilize */
    sal_usleep(400);

    /* clear PHY reset */
    SOC_IF_ERROR_RETURN(READ_CI_RESETr(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,DDR_RESET_Nf,1);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,PHY_SW_RESETf,0);
    soc_reg_field_set(SIRIUS_UNIT,CI_RESETr,&uRegValue,SW_RESETf,0);
    SOC_IF_ERROR_RETURN(WRITE_CI_RESETr(SIRIUS_UNIT,ci,uRegValue));

    if(!SAL_BOOT_BCMSIM && !SAL_BOOT_PLISIM && !SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
    /* check for cke status */
    cke_usec = 1000000;
    locked = 0;
    soc_timeout_init(&to,cke_usec,0);
    while(!soc_timeout_check(&to) && !locked) {
        SOC_IF_ERROR_RETURN(READ_CI_DDR_AUTOINITr(SIRIUS_UNIT,ci,&uRegValue));
	locked = soc_reg_field_get(SIRIUS_UNIT,CI_DDR_AUTOINITr,uRegValue,CI_PHY_CKEf);
    }
	
    if (!locked) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("CI%d CKE timedout\n"),ci));
	return SOC_E_TIMEOUT;
    }
    }

    /* Program DDR mode configuration registers MR0-MR3 automatically */
    SOC_IF_ERROR_RETURN(READ_CI_DDR_AUTOINITr(SIRIUS_UNIT,ci,&uRegValue));
    soc_reg_field_set(SIRIUS_UNIT,CI_DDR_AUTOINITr,&uRegValue,STARTf,1);
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_AUTOINITr(SIRIUS_UNIT,ci,uRegValue));

    if (!SAL_BOOT_BCMSIM && !SOC_WARM_BOOT(SIRIUS_UNIT) && !SOC_IS_DETACHING(SIRIUS_UNIT)) {
        /* wait for done */
        if (sirius_reg_done_timeout(SIRIUS_UNIT,
                                    CI_DDR_AUTOINITr,
                                    ci,
                                    0,
                                    DONEf,
                                    _sirius_init_timeout) ) {
            LOG_WARN(BSL_LS_SOC_COMMON,
                     (BSL_META("Waiting for config done for CI%d timedout\n"),ci));
            return SOC_E_TIMEOUT;
        }
    }

#ifdef NOTDEF_NO_HW_CALIB
    /* Run time calibration (training) options
     * 1 HW Controlled (every 16th refresh cycle HW will auto calibrate).
     * 2 SW Controlled
     */

    if (!SAL_BOOT_QUICKTURN && (pCI->bHwRunTimeDDRCalibration == TRUE)) {
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius hardware init ci%d setup runtime DDR calibration.\n"),ci));
	
	SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE0_VDL_CALIBRATEr(SIRIUS_UNIT,ci,&uRegValue));
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_CALIBRATE, CALIB_ALWAYS, 1);
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE0, VDL_CALIBRATE, RESERVED0, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE0_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));
	
	SOC_IF_ERROR_RETURN(READ_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,&uRegValue));
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, CALIB_ALWAYS, 1);
	DDR23_SET_FIELD(uRegValue, DDR23_PHY_BYTE_LANE1, VDL_CALIBRATE, RESERVED0, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_DDR23_PHY_BYTE_LANE1_VDL_CALIBRATEr(SIRIUS_UNIT,ci,uRegValue));	
    }
#endif

    /* Do a dummy modify to make compiler happy, make mask = 0 so that no write will happen */
    MODIFY_DDR23_PHY_ADDR_CTL_REVISIONr(SIRIUS_UNIT, ci, uRegValue, 0);

    return rv;
}

static int
_soc_sirius_hw_init_sc_sf( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32  unit = (int32) pInitParams->unit;
    uint32 regval = 0, regAddr;
    uint32 uCurrentRemapLink=0;
    uint32 uTempLinkEnableRemapRegValue=0;
    uint32 uTempLinkStatusRemapRegValue=0;
    int sfi_port, index;
    uint si;
    int enable_auto_switchover, one_plus_one;
    uint32 nInitDone = 0;
    soc_timeout_t timeout;

    if ( !((pInitParams->sc.bBringUp) || (pInitParams->sf.bBringUp)) ) {
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META("Sirius hardware init sc_sf skipped.\n")));
        return rv;
    }

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init sc_sf called.\n")));

    regval = 0;
    soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, INITf, 0);
    soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, SOFT_RESETf, 0);
    soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, TME_ONLYf, 0);
    SOC_IF_ERROR_RETURN(WRITE_SFI_TOP_CONFIG0r(unit, regval));

    /*
     * Take SC out of soft reset
     */
    regval = 0;
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, INITf, 1);
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, LOOPBACK_FIFO_THRESHOLDf, 4);
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_SC_SW_RESETr(unit, regval));

    regval = 0;
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, INIT_DONEf, 1);
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, LOOPBACK_FIFO_THRESHOLDf, 4);
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_SC_SW_RESETr(unit, regval));

    if (pInitParams->sf.bBringUp) {
        /*
         * Take SF out of soft reset
         */
        regval = 0;
        soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, INITf, 1);
        soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, SOFT_RESETf, 0);
        soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, LOOPBACK_FIFO_THRESHOLDf, 4);
        soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, TME_ONLYf, pInitParams->sf.bTmeOnly);
        SOC_IF_ERROR_RETURN(WRITE_SFI_TOP_CONFIG0r(unit, regval));
    }

    /*
     * Initialize SC Memory, even though SC seems has no memories
     */
    SOC_IF_ERROR_RETURN(READ_SC_SW_RESETr(unit, &regval));
    soc_reg_field_set(unit, SC_SW_RESETr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_SC_SW_RESETr(unit, regval));

    if(!SAL_BOOT_BCMSIM && !SAL_BOOT_PLISIM && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
    soc_timeout_init(&timeout, _sirius_init_timeout, 0);
    while(!soc_timeout_check(&timeout)) {
        SOC_IF_ERROR_RETURN(READ_SC_SW_RESETr(unit, &regval));
        nInitDone = soc_reg_field_get(unit, SC_SW_RESETr, regval, INIT_DONEf);
        if (nInitDone)
            break;
    }

    if (!nInitDone) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("SC mem init done timeout\n")));
	if (!SAL_BOOT_QUICKTURN) {
	    return SOC_E_TIMEOUT;
	}
    }

    /*
     * Initialize SF Memory, even though SF seems has no memories
     */
    /*
     * Initialize SC Memory, even though SC seems has no memories
     */
    SOC_IF_ERROR_RETURN(READ_SFI_TOP_CONFIG0r(unit, &regval));
    soc_reg_field_set(unit, SFI_TOP_CONFIG0r, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_SFI_TOP_CONFIG0r(unit, regval));

    soc_timeout_init(&timeout, _sirius_init_timeout, 0);
    while(!soc_timeout_check(&timeout)) {
        SOC_IF_ERROR_RETURN(READ_SFI_TOP_CONFIG0r(unit, &regval));
        nInitDone = soc_reg_field_get(unit, SFI_TOP_CONFIG0r, regval, INIT_DONEf);
        if (nInitDone)
            break;
    }

    if (!nInitDone) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("SF mem init done timeout\n")));
	if (!SAL_BOOT_QUICKTURN) {
            return SOC_E_TIMEOUT;
	}
    }
    }

    if ( pInitParams->sc.bBringUp ) {
        /* default SCI link sirius listens to in FIC/Hybrid mode */
        SOC_IF_ERROR_RETURN(READ_SC_CONFIG0r(unit, &regval));
        soc_reg_field_set(unit, SC_CONFIG0r, &regval, DEFAULT_BMf, pInitParams->sc.uDefaultBmId);
        SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG0r(unit, regval));

        /* configure the redundancy */
        enable_auto_switchover = 0;
        one_plus_one = 0;
        switch (SOC_SBX_CFG(unit)->uRedMode) {
        case bcmFabricRed1Plus1Both:
            enable_auto_switchover = 1;
            one_plus_one = 1;
            break;
        case bcmFabricRed1Plus1ELS: /* intentional fall through */
        case bcmFabricRed1Plus1LS:
            enable_auto_switchover = 1;
            break;
        case bcmFabricRedELS: /* intentional fall through */
        case bcmFabricRedLS:
        case bcmFabricRedManual:
            break;
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("unsupported bcmFabricRedundancyMode"
                                ":%d\n"), SOC_SBX_CFG(unit)->uRedMode));
            return SOC_E_CONFIG;
        }
        BCM_IF_ERROR_RETURN(READ_SC_CONFIG0r(unit, &regval));
        soc_reg_field_set(unit, SC_CONFIG0r, &regval, ENABLE_AUTO_SWITCHOVERf,
                          enable_auto_switchover);
        soc_reg_field_set(unit, SC_CONFIG0r, &regval, MODEf, one_plus_one);
        BCM_IF_ERROR_RETURN(WRITE_SC_CONFIG0r(unit, regval));

        BCM_IF_ERROR_RETURN(READ_FR_CONFIG0r(unit, &regval));
        if ( (SOC_SBX_CFG(unit)->uRedMode == bcmFabricRed1Plus1ELS) || (SOC_SBX_CFG(unit)->uRedMode == bcmFabricRedELS) ) {
            soc_reg_field_set(unit, FR_CONFIG0r, &regval, MODEf, 1);
        }
        else {
            soc_reg_field_set(unit, FR_CONFIG0r, &regval, MODEf, 0);
        }
        BCM_IF_ERROR_RETURN(WRITE_FR_CONFIG0r(unit, regval));

        /* load link enable/status remapping */
        for (uCurrentRemapLink=0; uCurrentRemapLink<SB_FAB_DEVICE_SIRIUS_LINKS; uCurrentRemapLink++) {
            if ( (uCurrentRemapLink % 6) == 0 ) {
                uTempLinkEnableRemapRegValue=0;
            }

            uTempLinkEnableRemapRegValue=uTempLinkEnableRemapRegValue |
            (pInitParams->sc.uLinkEnRemap[uCurrentRemapLink]<<((uCurrentRemapLink%6)*5));

            if (uCurrentRemapLink==5) { /* Write remap values for links 0:5 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_ENABLE_REMAP0r(unit, uTempLinkEnableRemapRegValue));
            } else if (uCurrentRemapLink==11) { /* Write remap values for links 6:11 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_ENABLE_REMAP1r(unit, uTempLinkEnableRemapRegValue));
            } else if (uCurrentRemapLink==17) { /* Write remap values for links 12:17 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_ENABLE_REMAP2r(unit, uTempLinkEnableRemapRegValue));
            } else if (uCurrentRemapLink==23) { /* Write remap values for links 18:23 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_ENABLE_REMAP3r(unit, uTempLinkEnableRemapRegValue));
            }
        }

        for (uCurrentRemapLink=0; uCurrentRemapLink<SB_FAB_DEVICE_SIRIUS_INTERNAL_LINKS; uCurrentRemapLink++) {
            if ( (uCurrentRemapLink % 6) == 0 ) {
                uTempLinkStatusRemapRegValue=0;
            }

            uTempLinkStatusRemapRegValue=uTempLinkStatusRemapRegValue |
                (pInitParams->sc.uLinkStatusRemap[uCurrentRemapLink]<<((uCurrentRemapLink%6)*5));

            if (uCurrentRemapLink==5) { /* Write remap values for links 0:5 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP0r(unit, uTempLinkStatusRemapRegValue));
            } else if (uCurrentRemapLink==11) { /* Write remap values for links 6:11 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP1r(unit, uTempLinkStatusRemapRegValue));
            } else if (uCurrentRemapLink==17) { /* Write remap values for links 12:17 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP2r(unit, uTempLinkStatusRemapRegValue));
            } else if (uCurrentRemapLink==23) { /* Write remap values for links 18:23 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP3r(unit, uTempLinkStatusRemapRegValue));
            } else if (uCurrentRemapLink==29) { /* Write remap values for links 24:29 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP4r(unit, uTempLinkStatusRemapRegValue));
            } else if (uCurrentRemapLink==31) { /* Write remap values for links 30:31 */
                SOC_IF_ERROR_RETURN(WRITE_SC_LINK_STATUS_REMAP5r(unit, uTempLinkStatusRemapRegValue));
            }
        }
    }

    if ( pInitParams->sf.bBringUp ) {
        /* SFI port remap/enable/loopback/backpresure */
        for (sfi_port = 0; sfi_port < SB_FAB_DEVICE_SIRIUS_SFI_PORTS; sfi_port++) {
            /* mapping:
             *  sfi_port 0-19 mapped to SC_TOP_SFI_PORT_CONFIG0 0-19
             *  sfi_port 20-43 mapped to SFI_PORT_CONFIG0 0-23
             *  sfi_port 44-45 mapped to SC_TOP_SFI_PORT_CONFIG0 20-21
             */
            if (sfi_port < 20) {
                index = sfi_port;
                regAddr = SC_TOP_SFI_PORT_CONFIG0r;
            } else if (sfi_port < 44) {
                index = sfi_port - 20;
                regAddr = SFI_PORT_CONFIG0r;
            } else {
                index = sfi_port - 24;
                regAddr = SC_TOP_SFI_PORT_CONFIG0r;
            }

            SOC_IF_ERROR_RETURN(soc_reg32_read(unit, soc_reg_addr(unit, regAddr, REG_PORT_ANY, index),
                                               &regval));

            soc_reg_field_set(unit, regAddr, &regval, LOOPBACK_ENf,
                              pInitParams->sf.uSfiPortLoopback[sfi_port]);
            soc_reg_field_set(unit, regAddr, &regval, BACKPRESSURE_ENf,
                              pInitParams->sf.uSfiPortBackpressure[sfi_port]);
            soc_reg_field_set(unit, regAddr, &regval, IDLE_FREQf,
                              pInitParams->sf.uSfiPortIdleFreq[sfi_port]);
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit, soc_reg_addr(unit, regAddr, REG_PORT_ANY, index),
                                               regval));

            soc_reg_field_set(unit, regAddr, &regval, ENABLEf,
                              pInitParams->sf.uSfiPortEnable[sfi_port]);
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit, soc_reg_addr(unit, regAddr, REG_PORT_ANY, index),
                                               regval));

            /* mapping:
             *  sfi_port 0-19 mapped to SC_TOP_SFI_NUM_REMAP0 0-19
             *  sfi_port 20-43 mapped to SFI_NUM_REMAP0 0-23
             *  sfi_port 44-45 mapped to SC_TOP_SFI_NUM_REMAP0 20-21
             */
            if (sfi_port < 20) {
                index = sfi_port;
                regAddr = SC_TOP_SFI_NUM_REMAP0r;
            } else if (sfi_port < 44) {
                index = sfi_port - 20;
                regAddr = SFI_NUM_REMAP0r;
            } else {
                index = sfi_port - 24;
                regAddr = SC_TOP_SFI_NUM_REMAP0r;
            }

            SOC_IF_ERROR_RETURN(soc_reg32_read(unit, soc_reg_addr(unit, regAddr, REG_PORT_ANY, index),
                                               &regval));

            soc_reg_field_set(unit, regAddr, &regval, REMAPPED_SFI_NUM_0f,
                              pInitParams->sf.uSfiPortRemap[sfi_port]);

            SOC_IF_ERROR_RETURN(soc_reg32_write(unit, soc_reg_addr(unit, regAddr, REG_PORT_ANY, index),
                                               regval));
        }
    }

    if (!pInitParams->sf.bTmeOnly) {
        /* Bringup all SIs, but force low, following the proven bringup sequence of bm9600 for now */
        for (si = 0; si < SB_FAB_DEVICE_SIRIUS_LINKS; si++) {
	    soc_sirius_init_si_step0(unit, si, 0x10, SS_HC_LANE_MODE_HALF_SPEED, pInitParams);
	}

	for (si = 0; si < SB_FAB_DEVICE_SIRIUS_LINKS; si++) {
	    soc_sirius_init_si_step1(unit, si, pInitParams);
	}

	for (si = 0; si < SB_FAB_DEVICE_SIRIUS_LINKS; si++) {	
	    /* Disable los error transmit on receive errors */
	    if (si < 12) {
	        SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_CONFIG2r(unit, si, &regval));
		soc_reg_field_set(unit, SC_TOP_SI_CONFIG2r, &regval, LS_ERR_WINDOWf, pInitParams->uSiLsWindow);
		soc_reg_field_set(unit, SC_TOP_SI_CONFIG2r, &regval, LS_ERR_THRESHf, pInitParams->uSiLsThreshold);
		SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_CONFIG2r(unit, si, regval));
	    } else {
	        SOC_IF_ERROR_RETURN(READ_SI_CONFIG2r(unit, (si - 12), &regval));
		soc_reg_field_set(unit, SI_CONFIG2r, &regval, LS_ERR_WINDOWf, pInitParams->uSiLsWindow);
		soc_reg_field_set(unit, SI_CONFIG2r, &regval, LS_ERR_THRESHf, pInitParams->uSiLsThreshold);
		SOC_IF_ERROR_RETURN(WRITE_SI_CONFIG2r(unit, (si - 12), regval));
	    }
	}

	/* Hypercore bringup and additional SI bringup are moved to bcm port init */
    }

    if ( pInitParams->sc.bBringUp ) {
        /* Enable SC block */
        SOC_IF_ERROR_RETURN(READ_SC_CONFIG0r(unit, &regval));
        soc_reg_field_set(unit, SC_CONFIG0r, &regval, ENABLEf, 1);
        SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG0r(unit, regval));

    }

    /*
     * SC_CONFIG3.sc_default_grant_period:
     */
    if (pInitParams->sc.bBringUp) {
        if ( pInitParams->sf.bTmeOnly ) {
	    SOC_IF_ERROR_RETURN(READ_SC_CONFIG0r(unit, &regval));
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, ENABLEf, 1);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, FULL_CNTf, 1);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, SC_GRANTS_TO_OK_GRANT_LOSSf, 0x3);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, SOT_WATCHDOG_THRESHf, 0xc);
	    SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG0r(unit, regval));
	    
	    /* this should really driven by a table indexed by the max rate
	     * 80/40/20G and the SC clocks, for now, use the value tuned by SV
	     * team during their tests. 250 when running at 405Mhz/289
	     * and 190 when running at 400/285
	     */ 
	    SOC_IF_ERROR_RETURN(READ_SC_CONFIG3r(unit, &regval));
	    soc_reg_field_set(unit, SC_CONFIG3r, &regval, SC_DEFAULT_EPOCH_PERIODf, 0);
	    if (SOC_SBX_CFG(unit)->uClockSpeedInMHz == 405) {
		/* when Core clock = 405Mhz, timeslot is
		 *  257 * (1000/289.3) = 888.35 ns  (SC use clock of 285Mhz)
		 */
	        soc_reg_field_set(unit, SC_CONFIG3r, &regval, SC_DEFAULT_GRANT_PERIODf, 257);
	    } else {
	        soc_reg_field_set(unit, SC_CONFIG3r, &regval, SC_DEFAULT_GRANT_PERIODf, 190);
	    }
	    SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG3r(unit, regval));
	    
	    SOC_IF_ERROR_RETURN(READ_SC_CONFIG2r(unit, &regval));
	    soc_reg_field_set(unit, SC_CONFIG2r, &regval, SC_MIN_TIMESLOTf, 0x60);
	    soc_reg_field_set(unit, SC_CONFIG2r, &regval, SC_GRANT_TOLERANCEf, 0x64);
	    SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG2r(unit, regval));
	}
	else {
	    SOC_IF_ERROR_RETURN(READ_SC_CONFIG0r(unit, &regval));
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, ENABLEf, 1);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, FULL_CNTf, 0x23);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, SC_GRANTS_TO_OK_GRANT_LOSSf, 0x3);
	    soc_reg_field_set(unit, SC_CONFIG0r, &regval, SOT_WATCHDOG_THRESHf, 0xc);
	    SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG0r(unit, regval));

	    if ( soc_feature(unit, soc_feature_hybrid) ) {
		/* min_timeslot should be set based on the minimum possible timeslot size,
		 * default_grant_period be set based on the maximum possible timeslot size
		 * below settings 0xB9 for minimum timeslot and 0x786 for maximum timeslot
		 * is based on customer setting
		 */
		/* set the min timeslot to be 0xB9*5us/cycle*0.9/(1000/285) */
		SOC_IF_ERROR_RETURN(READ_SC_CONFIG2r(unit, &regval));
		soc_reg_field_set(unit, SC_CONFIG2r, &regval, SC_MIN_TIMESLOTf, 0x100);
		soc_reg_field_set(unit, SC_CONFIG2r, &regval, SC_GRANT_TOLERANCEf, 0x20);
		SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG2r(unit, regval));
		
		/* Set the grant period to be as large as possible in fic mode to minimize
		 * effect of idle grant generation on crossbar when SCI link goes down on one node.
         * The automatic grant generation is not synchronous with the SCI grant generation.
		 */
		SOC_IF_ERROR_RETURN(READ_SC_CONFIG3r(unit, &regval));
		soc_reg_field_set(unit, SC_CONFIG3r, &regval, SC_DEFAULT_GRANT_PERIODf, 0xffff);
		SOC_IF_ERROR_RETURN(WRITE_SC_CONFIG3r(unit, regval));
	    }
	}
    }
 
    return rv;
}


#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_64   (1 <<  6)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_128  (1 <<  7)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_256  (1 <<  8)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_512  (1 <<  9)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_1K   (1 << 10)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_2K   (1 << 11)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_4K   (1 << 12)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_8K   (1 << 13)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_16K  (1 << 14)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_32K  (1 << 15)
#define CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_64K  (1 << 16)

static int
_soc_sirius_hw_init_cs( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32             unit = (int32) pInitParams->unit;
    soc_sbx_config_t *sbx = SOC_SBX_CFG(unit);
    soc_sbx_sirius_config_t *sir = SOC_SBX_CFG_SIRIUS(unit);
    uint32            entries = CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_1K;
    uint32            host_ent_sel = 0, beat_bytes = 0, regval = 0;
    uint32            bufsize = 0;
    uint8             idx = 0;
    statscfg_entry_t  statsCfg;
    cs_brick_config_table_entry_t  brickCfg;
    ep_stats_ctrl_entry_t ep_stats_ctrl;

    if (SOC_IS_DETACHING(unit)) {
        /* don't blow away old alloc and then realloc if detaching */
        return BCM_E_NONE;
    }
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init cs called.\n")));

    /*
     * Initialize the CS structures to 0
     */

    sal_memset(&sir->cs, 0, sizeof(soc_sbx_sirius_cs_t));

    /*
     * Create a buffer to store global statistics
     */

    sir->cs.gbl_stats = sal_alloc(sizeof(uint64) *
                                  (SOC_MEM_INFO(unit, GLOBAL_STATSm).index_max + 1) *
                                  SOC_MEM_INFO(unit, GLOBAL_STATSm).nFields, "GLOBAL STATS Counters");

    /*
     * Create a buffer to store selected queue statistics
     */

    sir->cs.slq_stats = sal_alloc(sizeof(uint64) * 512, "SLQ STAT Counters");

    /*
     * Create a buffer to store Admission Control Counters
     */

    sir->cs.fd_drop[FD_ALL] = sal_alloc(sizeof(uint64) *
					(SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).index_max + 1) *
					SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).nFields, "FD DROP ALL");
    
    sir->cs.fd_drop[FD_GREEN] = sal_alloc(sizeof(uint64) *
					  (SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).index_max + 1) *
					  SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).nFields, "FD DROP GREEN");
    
    sir->cs.fd_drop[FD_YELLOW] = sal_alloc(sizeof(uint64) *
					   (SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).index_max + 1) *
					   SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).nFields, "FD DROP YELLOW");
    
    sir->cs.fd_drop[FD_RED] = sal_alloc(sizeof(uint64) *
					(SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).index_max + 1) *
					SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).nFields, "FD DROP RED");
    
    sir->cs.fd_drop[FD_MC] = sal_alloc(sizeof(uint64) *
				       (SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).index_max + 1) *
				       SOC_MEM_INFO(unit, EG_FD_PER_PORT_DROP_COUNT1m).nFields, "FD DROP MC");
    /*
     * Create a buffer to store custom statistics 
     */

    sbx->custom_stats = sal_alloc(sizeof(uint32) * SBX_FAB_ERRORS * 
				  (SB_FAB_DEVICE_SIRIUS_SFI_LINKS+SB_FAB_DEVICE_SIRIUS_SCI_LINKS), 
				  "custom stats");

    /*
     * Write CS_CONFIG0 to soft reset the CS registers.
     */

    regval = 0;
    soc_reg_field_set(unit, CS_CONFIG0r, &regval, SOFT_RESETf, 0);
    if ((rv = WRITE_CS_CONFIG0r(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: unable to reset CS Block for unit %d\n"),unit));
      return rv;
    }

    /*
     * Initialize all 32 segments for background statistics gathering
     * to disabled. For each segment enabled, individually enable the
     * bit in this register;
     */

    regval = 0;
    if ((rv = WRITE_CS_CONFIG_BACKGROUND_ENABLEr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to enable CS Background trolling for"
                         " unit %d\n"), unit));
      return rv;
    }


    regval = 0;

   /*
     * Set EJECT_MODE_LINK to transmit pkt/byte pairs with each method.
     * Currently defaults to sending only pkt or byte count that reaches
     * ACE threshold.
     */

    soc_reg_field_set(unit, CS_ACE_CTRLr, &regval, EJECT_MODE_LINKf, 1);
    if ((rv = WRITE_CS_ACE_CTRLr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to enable CS pkt/byte pair ejection"
                         " for unit %d\n"), unit));
      return rv;
    }

    /*
     * Set ACE Random seed to title of the 11th studio album released by Genesis.
     * Setting this seed value to a generic random number makes deterministic
     * debugging impossible. This value can be changed to the record album of
     * your choice in the future.
     */

    regval = 0xabacab;
    if ((rv = WRITE_CS_ACE_RANDOM_SEEDr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to set CS ACE Random seed for unit %d"
                         " to %x\n"), unit, regval));
      return rv;
    }

    /*
     * Set Background Eject Rate.
     */

    regval = 0xffffff;
    if ((rv = WRITE_CS_CONFIG_BACKGROUND_RATEr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to set CS CONFIG BACKGROUND RATE for"
                         " unit %d to %x\n"), unit, regval));
      return rv;
    }

    /*
     * beat_bytes is # of beats * 4 bytes
     * This is the number of bits that the CS will transmit over
     * a serial line per statistics update.
     *
     * Currently, configurable via config.bcm for optimization
     */

    beat_bytes = soc_property_get(unit,
                                  "sirius_dma_beat_count",
                                  SOC_MEM_INFO(unit,CS_EJECTION_MESSAGE_TABLEm).bytes);

    entries = soc_property_get(unit,
                               "sirius_dma_hostnum_entries",
                               entries);

    /*
     * set ring buffer size based on entries x beat_bytes
     */

    bufsize = entries * beat_bytes;

    

    switch (entries) {
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_64:
          host_ent_sel = 0;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_128:
          host_ent_sel = 1;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_256:
          host_ent_sel = 2;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_512:
          host_ent_sel = 3;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_1K:
          host_ent_sel = 4;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_2K:
          host_ent_sel = 5;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_4K:
          host_ent_sel = 6;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_8K:
          host_ent_sel = 7;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_16K:
          host_ent_sel = 8;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_32K:
          host_ent_sel = 9;
          break;
        case CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_64K:
          host_ent_sel = 10;
          break;
        default:
          LOG_WARN(BSL_LS_SOC_COMMON,
                   (BSL_META("CS: Incorrect value %d for Hostnum Entries."
                             " Defaulting to %d\n"),
                    entries, CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_1K));
          host_ent_sel = 4;
          entries = CS_FIFO_RD_DMA_HOST_ENTRIES_SEL_1K;
    }

    /*
     * Write CS_DMA_FIFO_CONFIG to proper defaults.
     */

    regval = 0;
    soc_reg_field_set(unit, CS_DMA_FIFO_CONFIGr, &regval, DMA_NUM_PADSf, 4);
    soc_reg_field_set(unit, CS_DMA_FIFO_CONFIGr, &regval, DMA_FIFO_STALE_TIMERf, 100);
    soc_reg_field_set(unit, CS_DMA_FIFO_CONFIGr, &regval, DMA_FIFO_BACKPRESSURE_ENf, 1);
    soc_reg_field_set(unit, CS_DMA_FIFO_CONFIGr, &regval, DMA_FIFO_THRESHOLDf, 768);
    if ((rv = WRITE_CS_DMA_FIFO_CONFIGr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: unable to write CS_DMA_FIFO_CONFIGr register for"
                         " unit %d with %x\n"), unit, regval));
      return rv;
    }

    /*
     * Write CS_MANUAL_EJECT_CONFIG3 to proper eject rate.
     * This value should not change.
     */

    regval = 0;
    soc_reg_field_set(unit, CS_MANUAL_EJECT_CONFIG3r, &regval, EJECT_RATEf, 0x64);
    if ((rv = WRITE_CS_MANUAL_EJECT_CONFIG3r(unit,regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: unable to write CS_MANUAL_EJECT_CONFIG3r register"
                         " for unit %d with %d\n"), unit, regval));
      return rv;
    }

    /*
     * Write CS_DMA_MESSAGE_SIZE to proper beat. This value must
     * be consistent with the beat cnt written to the CMIC.
     */

    regval = 0;
    soc_reg_field_set(unit, CS_DMA_MESSAGE_SIZEr, &regval, DW_CNTf, (beat_bytes/4));
    if ((rv = WRITE_CS_DMA_MESSAGE_SIZEr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: unable to write CS_DMA_MESSAGE_SIZEr register for"
                         " unit %d with %x\n"), unit, regval));
      return rv;
    }

    /*
     * Set the DMA Ring Buffer interrupt threshold value to the CMIC register.
     */

    regval = beat_bytes * (entries / 4);
    if((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_HOSTMEM_THRESHOLDr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to write DMA_HOSTMEM_THRESHOLDr %x\n"),
                regval));
      return rv;
    }

    /*
     * Initialize SBUS_START_ADDRESS to CS_EJECTION_MESSAGE_TABLE.
     */

    regval = soc_mem_addr(unit,
                          CS_EJECTION_MESSAGE_TABLEm,
                          0,
                          SOC_MEM_BLOCK_ANY(unit, CS_EJECTION_MESSAGE_TABLEm),
                          0);

    /* coverity[result_independent_of_operands] */
    if ((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_SBUS_START_ADDRESSr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to initialize DMA_SBUS_START_ADDRESSr"
                         " to 0\n")));
      return rv;
    }

    /*
     * Initialize the DMA RING BUFFER
     */
    

    sir->cs.fifo_dma_rbuf_begin = soc_cm_salloc(unit, bufsize, "dma_ring_buf");

    if (sir->cs.fifo_dma_rbuf_begin == NULL) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to allocate dma_ring_buf\n")));
      return SOC_E_MEMORY;
    }

    sal_memset(sir->cs.fifo_dma_rbuf_begin, 0, bufsize);
    sir->cs.fifo_dma_rbuf_read_ptr = sir->cs.fifo_dma_rbuf_begin;
    sir->cs.fifo_dma_rbuf_end = sir->cs.fifo_dma_rbuf_begin + (bufsize/4);

    regval = soc_cm_l2p(unit, sir->cs.fifo_dma_rbuf_begin);

    if((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_HOSTMEM_START_ADDRESSr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to write DMA_HOSTMEM_START_ADDRESSr %x\n"),
                regval));

      sal_free(sir->cs.fifo_dma_rbuf_begin);
      return rv;
    }

    /*
     * Set the read ptr to the head of the DMA Ring Buffer and
     * write that value to the CMIC register.
     */

    if((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_HOSTMEM_READ_PTRr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to write DMA_HOSTMEM_READ_PTRr %x\n"),
                regval));

      sal_free(sir->cs.fifo_dma_rbuf_begin);
      return rv;
    }

   /*
     * Write and enable the CMIC DMA CFGr with the initial settings
     * and ring buffer address for Central Statistics
     */

    regval = 0;
    soc_reg_field_set(unit, CMIC_FIFO_CH0_RD_DMA_CFGr, &regval, BEAT_COUNTf, (beat_bytes/4));
    soc_reg_field_set(unit, CMIC_FIFO_CH0_RD_DMA_CFGr, &regval, HOST_NUM_ENTRIES_SELf, host_ent_sel);
    soc_reg_field_set(unit, CMIC_FIFO_CH0_RD_DMA_CFGr, &regval, TIMEOUT_COUNTf, 0x3fff);

    if((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_CFGr(unit, regval)) < 0) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to Write DMA CFGr unit %d beat_count %d"
                         " entries %d\n"), unit, (beat_bytes/4), host_ent_sel));

      sal_free(sir->cs.fifo_dma_rbuf_begin);
      return rv;
    }

    regval = 0;
    soc_reg_field_set(unit, CMIC_FIFO_CH0_RD_DMA_CFGr, &regval, ENABLEf, 1);
    soc_reg_field_set(unit, CMIC_FIFO_CH0_RD_DMA_CFGr, &regval, ENABLE_VALf, 1);

    if((rv = WRITE_CMIC_FIFO_CH0_RD_DMA_CFGr(unit, regval)) < 0) {
      /* coverity[dead_error_begin] */
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: failed to Enable DMA CFGr unit %d\n"),
                unit));

      sal_free(sir->cs.fifo_dma_rbuf_begin);
      return rv;
    }

    /*
     * create semaphore for cs manual eject
     */

    sir->cs.CsFifoSem = NULL;
    sir->cs.CsFifoSem = sal_sem_create("CsFifo", sal_sem_BINARY, 0);
    if (sir->cs.CsFifoSem == NULL) {
      LOG_WARN(BSL_LS_SOC_COMMON,
               (BSL_META("CS: unit %d failed to allocate semaphore\n"), unit));
      sal_free(sir->cs.fifo_dma_rbuf_begin);
      return SOC_E_RESOURCE;
    }

    /*
     * Initialize the QM/CS tables
     */

    /*
     * Dequeue fields
     */

    regval = 0;
    soc_reg_field_set(unit, QM_CS_CONFIG1r, &regval, CS_DEQUEUE_HIGH_QUEUE_IDf, 0xffff);
    soc_reg_field_set(unit, QM_CS_CONFIG1r, &regval, CS_DEQUEUE_LOW_QUEUE_IDf,  0x0);
    SOC_IF_ERROR_RETURN(WRITE_QM_CS_CONFIG1r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_CS_UNMAPPED_ERROR_MASKr(unit, 0));

    /*
     * Enable QM/CS Stats
     */
    soc_reg_field_set(unit, QM_CS_CONFIG0r, &regval, DEQ_CS_STATS_ENf, 0);
    soc_reg_field_set(unit, QM_CS_CONFIG0r, &regval, QM_CS_ENf, 1);
    SOC_IF_ERROR_RETURN(WRITE_QM_CS_CONFIG0r(unit, regval));

    /*
     * Initialize the QM STATSCFG table
     */

    sal_memset(&statsCfg, 0, sizeof(statscfg_entry_t));
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, PARITYf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, ECCf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD0_ADDR_SELf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD0_EVENT_SELf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD0_SEGMENT_SELf,0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD1_ADDR_SELf,0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD1_EVENT_SELf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD1_SEGMENT_SELf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD2_ADDR_SELf, 0);
    soc_mem_field32_set(unit, STATSCFGm, &statsCfg, RECORD2_EVENT_SELf, 0);
    for (idx = 0; idx <= SOC_MEM_INFO(unit,STATSCFGm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_STATSCFGm(unit, MEM_BLOCK_ANY, idx, &statsCfg));
    }

    /*
     * Initialize BrickCFG
     */

    sal_memset(&brickCfg, 0, sizeof(cs_brick_config_table_entry_t));
    soc_mem_field32_set(unit, CS_BRICK_CONFIG_TABLEm, &brickCfg, ENABLEf, 0);
    soc_mem_field32_set(unit, CS_BRICK_CONFIG_TABLEm, &brickCfg, SEGMENTf, 0);
    soc_mem_field32_set(unit, CS_BRICK_CONFIG_TABLEm, &brickCfg, BASE_CNTRIDf, 0);
    soc_mem_field32_set(unit, CS_BRICK_CONFIG_TABLEm, &brickCfg, PHYSICALf, 0);
    for (idx = 0; idx <= SOC_MEM_INFO(unit,CS_BRICK_CONFIG_TABLEm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_CS_BRICK_CONFIG_TABLEm(unit, MEM_BLOCK_ANY, idx, &brickCfg));
    }

    /*
     * Initialize Egress Processor CS table
     */

    sal_memset(&ep_stats_ctrl, 0, sizeof(ep_stats_ctrl_entry_t));
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, PARITYf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, ECCf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, RSVDf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, COMBINEf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_PER_FRAME_ADJf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_ADJUSTf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_LENGTH1f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_OFFSET1f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_META1_SELf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_LENGTH0f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_OFFSET0f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_META0_SELf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT1_SEGMENTf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_PER_FRAME_ADJf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_ADJUSTf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_LENGTH1f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_OFFSET1f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_META1_SELf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_LENGTH0f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_OFFSET0f, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_META0_SELf, 0);
    soc_mem_field32_set(unit, EP_STATS_CTRLm, &ep_stats_ctrl, STAT0_SEGMENTf, 0);
    for (idx = 0; idx <= SOC_MEM_INFO(unit,EP_STATS_CTRLm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_EP_STATS_CTRLm(unit, MEM_BLOCK_ANY, idx, &ep_stats_ctrl));
    }

    /*
     * enable interrupts to handle reading the FIFO DMA Ring Buffer
     */
    soc_intr_enable(unit, IRQ_FIFO_CH0_DMA);

    return rv;
}

static int
_soc_sirius_hw_init_ts( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 uRegValue = 0;
    uint32 nTimeoutInUsec;
    uint32 nInitDone;
    int32  root_delay1, root_delay2;
    uint32 mtu_size;
    soc_timeout_t timeout;
    rt_if_entry_t rt_if_cfg;
    int    intf;
    int32  unit = (int32) pInitParams->unit;

    /* Note: SIRIUS_TS_GRANT_TO_ROOTDELAY_OFFSET
     *     the minimum offset between rootdelay and sot_to_grant depends on the levels used
     * in the TS block, value of 59 assumes all 7 levels are used, hardcode it for now since
     * we probablly need all levels of scheduler for most customer configuration anyhow
     * can tune this if any special configuration need to have a smaller timeslot size and
     * can afford to bypass some levels of scheduler
     */
#define SIRIUS_TS_GRANT_TO_ROOTDELAY_OFFSET   (64)

    if ( !(pInitParams->ts.bBringUp) ) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("TS bring up skipped on unit %d\n"), unit));
        return rv;
    }

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ts called.\n")));

    /*======================================================
     * Config register init
     *=====================================================*/

    /* first toggle soft reset */
    if (pInitParams->reset) {
        SOC_IF_ERROR_RETURN(READ_TS_CONFIG0r(unit, &uRegValue));
        soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, SOFT_RESETf, 1);
    }

    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG0r(unit, uRegValue));
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, SOFT_RESETf,0);
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG0r(unit, uRegValue));

    /* then initialize the memories */
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG0r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, INITf, 1);
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, INIT_DONEf, 0);
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, ENABLEf, 0); 
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG0r(unit, uRegValue));

    nTimeoutInUsec = _sirius_init_timeout;
    nInitDone = 0;
    soc_timeout_init(&timeout, nTimeoutInUsec,0);
    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_TS_CONFIG0r(unit, &uRegValue));
            
            nInitDone = soc_reg_field_get(unit, TS_CONFIG0r, uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("TS init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* Grants config */
    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {
        /* dual local grants */
	/* set root delay */
	root_delay1 = 1;
	root_delay2 = 0x5E; /* from SV */

	uRegValue = 0;
	SOC_IF_ERROR_RETURN(READ_TS_CONFIG1r(unit, &uRegValue));
	soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, ROOT_DELAY1f, root_delay1);
        soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, ROOT_DELAY2f, root_delay2);
        /* On HW, force dual local grants in TME mode */
        soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, GRANT2_ENABLEf,
                          SOC_SBX_CFG_SIRIUS(unit)->bDualLocalGrants);
        SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG1r(unit, uRegValue));
	
        /* config sot_to_grant */
        SOC_IF_ERROR_RETURN(READ_TS_CONFIG2r(unit, &uRegValue));
	soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, SOT_TO_GRANT1f, (root_delay1 + SIRIUS_TS_GRANT_TO_ROOTDELAY_OFFSET));
        soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, SOT_TO_GRANT2f, (root_delay2 + SIRIUS_TS_GRANT_TO_ROOTDELAY_OFFSET));
        SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG2r(unit, uRegValue));
    } else if ( soc_feature(unit, soc_feature_hybrid) ) {
	/* one fabric grant and one local grant */
	root_delay1 = 72;
	root_delay2 = 0;

	uRegValue = 0;
        SOC_IF_ERROR_RETURN(READ_TS_CONFIG1r(unit, &uRegValue));
	soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, ROOT_DELAY1f, root_delay1);
        soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, ROOT_DELAY2f, root_delay2);
	soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, GRANT2_ENABLEf, 0);
	soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, HYBRID_GRANT2_ENABLEf, 0);
	SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG1r(unit, uRegValue));

        /* config sot_to_grant */
        SOC_IF_ERROR_RETURN(READ_TS_CONFIG2r(unit, &uRegValue));
	soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, SOT_TO_GRANT1f, (root_delay1 + 72));
        soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, SOT_TO_GRANT2f, 0);
        SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG2r(unit, uRegValue));
    }

    /* creditor state map
     *  use the default value of 4, which maps pri0(starved) and pri1(hungry) to 0(hungry),
     *  maps pri1(satisfied) to 1(satisfied). When state is 1, the child will participate
     *  in fair shaing of the excessive bandwidth
     */
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG2r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, LEAF_CREDITOR_STATE_MAPf, 4);
    soc_reg_field_set(unit, TS_CONFIG2r, &uRegValue, LEAF_BG_PERIODf, pInitParams->ts.uLeafBgPeriod);
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG2r(unit, uRegValue));

    /* Global min threshold config */
    if (1) {
        /* disable the global min thresh1/2 */
        mtu_size = 0;
    } else {
        /* min thresh1/2
         *  global setting to patch things up when have very low rate queues.
         *  value used by Arch team on model:
         *  set min_threshold_1 to be 4 * jumbo frame size (9000 bytes)
         *  set min_threshold_2 to be 6 * jumbo frame size
         */
        mtu_size = 9000;
    }
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG5r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG5r, &uRegValue, MIN_THRESH1f, 4 * mtu_size * 64);
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG5r(unit, uRegValue));

    SOC_IF_ERROR_RETURN(READ_TS_CONFIG6r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG6r, &uRegValue, MIN_THRESH2f, 6 * mtu_size * 64);
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG6r(unit, uRegValue));

    /* set sysport base, full mode and priority threshold */
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG4r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, SYS_PORT_BASEf, pInitParams->ts.nSysportBase);
    /* priority threshold
     *  config based on the recommended value and the full mode
     *  full_mode = 0 (1 bit full state)
     *       priority_threshold_0 = 0         (Allow all traffic)
     *       priority_threshold_1 = 15        (Block all traffic)
     *       priority_threshold_2 = NA        (don't apply)
     *       priority_threshold_3 = NA        (don't apply)
     *  full_mode = 0 (1 bit full state) and Extende port mode
     *       priority_threshold_0 = 0         (Allow all traffic)
     *       priority_threshold_1 = 13        (Block !EF traffic only, no backpressure for EF to reduce latency)
     *       priority_threshold_2 = NA        (don't apply)
     *       priority_threshold_3 = NA        (don't apply)
     *  full_mode = 1 (2 bits full state)
     *       priority_threshold_0 = 0         (Allow all traffic)
     *       priority_threshold_1 = 0         (Allow all traffic)
     *       priority_threshold_2 = 13        (Allow EF traffic, assuming EF use priority 14)
     *       priority_threshold_3 = 15        (Block all traffic)
     */
    if (soc_feature(unit, soc_feature_egr_independent_fc)) {
        /* full mode = 0 */
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, FULL_MODEf, 0);
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH0f, 0);
	if (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode) {
	    soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH1f, 13);
	} else {
	    soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH1f, 15);
	}
    } else {
        /* full mode = 1 */
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, FULL_MODEf, 1);
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH0f, 0);
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH1f, 0);
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH2f, 13);
        soc_reg_field_set(unit, TS_CONFIG4r, &uRegValue, PRIORITY_THRESH3f, 15);
    }
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG4r(unit, uRegValue));

    /* 4 or 8 Children per level node */
    SOC_IF_ERROR_RETURN(READ_TS_LEVEL1_CONFIG0r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_LEVEL1_CONFIG0r, &uRegValue, EIGHTK_NODESf, ((pInitParams->ts.b8kNodes) ? 1 : 0));
    SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL1_CONFIG0r(unit, uRegValue));

    /* root full period
     *   the root full period controls how often the full state messages will be distributed to nodes mapped
     *   to a fifo, given the period and the supported 264 fifos, it will take (root full period) * 264 to
     *   update the entire full state map. We want to set it to a low value so that the full state map
     *   is accurate enough, but don't want to set it too low to cause TS memory congestion
     *   we also need to make sure the full state message delay introduced here and in other blocks will
     *   not lead to egress fifo overflow,  the fifo thresholds in the FDM block need to be tuned to
     *   ensure this.
     *   Use fastest configuration (2 cycles) for now, which means 1 full state update message will be send out for every
     *   2 cycles, so it takes 264*2 = 528 cycles to update the full state for a perticular fifo, which
     *   translate to 1.65KBytes for a 10G port
     *
     */
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG1r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG1r, &uRegValue, ROOT_FULL_PERIODf, 0x2); /* use 2 cycles period for now */
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG1r(unit, uRegValue));

    /* periodical (leak cycle), aperiodical interval for each level */
    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 1, pInitParams->ts.bBypassLevel[1], pInitParams->ts.uNumTsNode[1],
                                                   pInitParams->ts.uLeakCycle[1], pInitParams->ts.uAperiodicInterval[1]));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 2, pInitParams->ts.bBypassLevel[2], pInitParams->ts.uNumTsNode[2],
                                                   pInitParams->ts.uLeakCycle[2], pInitParams->ts.uAperiodicInterval[2]));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 3, pInitParams->ts.bBypassLevel[3], pInitParams->ts.uNumTsNode[3],
                                                   pInitParams->ts.uLeakCycle[3], pInitParams->ts.uAperiodicInterval[3]));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 4, pInitParams->ts.bBypassLevel[4], pInitParams->ts.uNumTsNode[4],
                                                   pInitParams->ts.uLeakCycle[4], pInitParams->ts.uAperiodicInterval[4]));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 5, pInitParams->ts.bBypassLevel[5], pInitParams->ts.uNumTsNode[5],
                                                   pInitParams->ts.uLeakCycle[5], SOC_SIRIUS_API_PARAM_NO_CHANGE));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 6, pInitParams->ts.bBypassLevel[6], pInitParams->ts.uNumTsNode[6],
                                                   pInitParams->ts.uLeakCycle[6], SOC_SIRIUS_API_PARAM_NO_CHANGE));

    SOC_IF_ERROR_RETURN(soc_sirius_ts_level_config(unit, 7, pInitParams->ts.bBypassLevel[7], pInitParams->ts.uNumTsNode[7],
                                                   pInitParams->ts.uLeakCycle[7], SOC_SIRIUS_API_PARAM_NO_CHANGE));

    /*======================================================
     * Config memory init
     *====Egress queue destination
     *    requries bcm_cosq_gport_add to map (queue, fifo)
     *    leave alone at bringup time
     *====Node mapping 1-6
     *    node type,          (default, leaf relay, inner relay, root relay)
     *    bucket type,        (bucket, multipath, multipath master, subtree)
     *    node profile select,
     *    bucket table ptr    (for bucket and multipath master, point to node itself,
     *                         for multipath, point to multipath master,
     *                         for subtree, point to )
     *====Node group 1-6
     *    configuration for multipath shaper (link list), state for subtree
     *    leave alone at bringup time
     *====Bucket params 1-7
     *    shaper rate/burst, creditor rate table
     *    leave alone at bringup time
     *====Node profile 1-7
     *    32 node profile for each level
     *    Alloc and Init profiles or setup some typical value???
     *====Node info_1 1-7
     *    child weights
     *    leave alone at bringup time
     *====Node info_2 1-7
     *    parent, first child, child offset
     *====Full map table
     *    build based on the full mode and higig subports on each interfaces
     *====Interface meter table
     *    all interface meters are disabled by default
     *====Root Node config
     *    root node weights, plane and enable
     *====Leaf Node to Queue mapping (QS block)
     *      high 12 bits translated, lower 4 bits pass through. This means lower 4 bits
     *      of queue number and leaf node number has to match.
     *====Queue to Leaf Node mapping (QS block)
     *      Queue_to_sc_0~3 table (16 bits to 16 bits mapping)
     *=====================================================*/

    /* root interface plane and weight */
    for (intf = 0; intf <SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES; intf++) {
        SOC_IF_ERROR_RETURN(READ_RT_IFm(unit, MEM_BLOCK_ANY, intf, &rt_if_cfg));
        soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, PLANEf,
                            pInitParams->ts.uInterfacePlane[intf]);
        soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, WEIGHT_RECIPf,
                            pInitParams->ts.uInterfaceWeight[intf]);
        /* interface meter, setup for 24G cases */
	if (intf == SB_FAB_DEVICE_SIRIUS_CPU_INTF) {
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, ENABLEf, 0);
	} else {
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, ENABLEf,           1);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, RATEf,             0xED0);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, WEIGHT_RECIPf,     0xF);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, MAX_DEPTH_EXPf,    0xF);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, MAX_DEPTH_MANTf,   0xFFF);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH1_EXPf,      0xA);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH1_MANTf,     0xED8);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH2_EXPf,      0xB);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH2_MANTf,     0xED8);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH3_EXPf,      0xC);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH3_MANTf,     0xED8);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH4_EXPf,      0xD);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH4_MANTf,     0xED8);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH5_EXPf,      0xE);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH5_MANTf,     0xED8);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH6_EXPf,      0xF);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH6_MANTf,     0x7D0);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH7_EXPf,      0xF);
	    soc_mem_field32_set(unit, RT_IFm, &rt_if_cfg, THRESH7_MANTf,     0xED8);
	}
	SOC_IF_ERROR_RETURN(WRITE_RT_IFm(unit, MEM_BLOCK_ANY, intf, &rt_if_cfg));

    }

    /* enable the block */
    SOC_IF_ERROR_RETURN(READ_TS_CONFIG0r(unit, &uRegValue));
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, INITf, 0);
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, INIT_DONEf, 0);
    soc_reg_field_set(unit, TS_CONFIG0r, &uRegValue, ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_TS_CONFIG0r(unit, uRegValue));

    return rv;
}

static int
_soc_sirius_hw_init_fr( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32 unit = (int32) pInitParams->unit;
    int i;
    uint32 uRegValue;
    soc_timeout_t timeout;
    uint32 nInitDone = 0;
    uint32 nTimeoutInUsec;
    int uDomain0, uDomain1;
    uint16 dev_id;
    uint8  rev_id;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init fr called.\n")));
    uRegValue = 0;
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG0r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG0r(unit, uRegValue));

    /* then initialize the memories */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG0r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, INITf, 1);
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, INIT_DONEf, 0);
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, ENABLEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG0r(unit, uRegValue));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        nTimeoutInUsec = _sirius_init_timeout;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_FR_CONFIG0r(unit, &uRegValue));
            
            nInitDone = soc_reg_field_get(unit, FR_CONFIG0r, uRegValue, INIT_DONEf);
            
            if (nInitDone) {
                break;
            }
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("FR init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    /* threshold */
    for (i = 0; i <= SB_FAB_DEVICE_SIRIUS_MAX_FABRIC_PORTS; i+= 2) {
	if (SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) {
            soc_sirius_dt_mem_set(unit, i, 0, 0xc300, 0x3fff80);
	} else {
            soc_sirius_dt_mem_set(unit, i, SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x6180, 0xc300);
            soc_sirius_dt_mem_set(unit, i, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x12480, 0x3fff80);
        }
    }
    
    /* multicast flow control */
    if (SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) {
        soc_sirius_dt_mem_set(unit, SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS, 0, 0x5dc00, 0x3fff80);
	} else {
            soc_sirius_dt_mem_set(unit, SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS, 
                                  SB_FAB_XCORE_COS_FIFO_MULTICAST_EF, 0x1f400, 0x3e800);
            soc_sirius_dt_mem_set(unit, SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS, 
                                  SB_FAB_XCORE_COS_FIFO_MULTICAST_NEF, 0x5dc00, 0x3fff80);
    }

    SOC_IF_ERROR_RETURN(READ_FR_CONFIG7r(unit, &uRegValue));
    if (SOC_SBX_CFG(unit)->bEgressMulticastFifoIndependentFlowControl) {
	soc_reg_field_set(unit, FR_CONFIG7r, &uRegValue, MC_FLOW_CTL_METHODf, 0);
    } else {
	soc_reg_field_set(unit, FR_CONFIG7r, &uRegValue, MC_FLOW_CTL_METHODf, 1);
    }
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG7r(unit, uRegValue));

    /* domain mapping */
    for (i = 0; i <= SOC_MEM_INFO(unit, DMT_MEMm).index_max; i++) {

	if (SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) {
	    /* initialized to last unicast flow control domain */
	    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN_NON_EF - 2;
	    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN_EF - 2;
	} else {
	    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN - 2;
	    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN - 2;
	}

	if ( (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME) ||
	     (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) ||
	     (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_HYBRID) ) {
	    /* Fix mapping in DMT for unicast packets from local sysports
	     * sysport = SIRIUS_TS_LOCAL_SYSPORT_BASE + fabric port
	     * domain  = fabric port * 2
	     */
	    if (i >= SIRIUS_TS_LOCAL_SYSPORT_BASE) {
		if (SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) {
		    uDomain0 = (i - SIRIUS_TS_LOCAL_SYSPORT_BASE) * 2 + 1;
		    uDomain1 = (i - SIRIUS_TS_LOCAL_SYSPORT_BASE) * 2;

                    if (SOC_SBX_CFG(unit)->bEgressMulticastFifoIndependentFlowControl) {
		        if (uDomain0 > SIRIUS_FR_FC_MC_DOMAIN_NON_EF) {
			    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN_NON_EF;
		        }

		        if (uDomain1 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN_EF;
		        }
                    }
                    else {
		        if (uDomain0 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN_EF;
		        }

		        if (uDomain1 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN_EF;
                        }
                    }
		} else {
		    uDomain0 = (i - SIRIUS_TS_LOCAL_SYSPORT_BASE) * 2;
		    uDomain1 = (i - SIRIUS_TS_LOCAL_SYSPORT_BASE) * 2;
		    
                    if (SOC_SBX_CFG(unit)->bEgressMulticastFifoIndependentFlowControl) {
		        if (uDomain0 > SIRIUS_FR_FC_MC_DOMAIN_NON_EF) {
			    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN_NON_EF;
		        }

		        if (uDomain1 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN_EF;
		        }
                    }
                    else {
		        if (uDomain0 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain0 = SIRIUS_FR_FC_MC_DOMAIN_EF;
		        }

		        if (uDomain1 > SIRIUS_FR_FC_MC_DOMAIN_EF) {
			    uDomain1 = SIRIUS_FR_FC_MC_DOMAIN_EF;
		        }
                    }
		}
	    }
	}

        SOC_IF_ERROR_RETURN(soc_sirius_dmt_mem_set(unit, i, uDomain0, uDomain1));
    }

    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG1r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, IDLE_TIMESLOT_THRESHf, 55);
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, FORCE_LINK_ENABLE_Af, 0xFFFFFF);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG1r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG2r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG2r, &uRegValue, FORCE_LINK_ENABLE_Bf, 0xFFFFFF);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG2r(unit, uRegValue));	
    } else if (soc_feature(SIRIUS_UNIT, soc_feature_hybrid) )  {
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG1r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, IDLE_TIMESLOT_THRESHf, 55);
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, FORCE_LINK_ENABLE_Af, 0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG1r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG2r(unit, &uRegValue));
#if 000
	soc_reg_field_set(unit, FR_CONFIG2r, &uRegValue, FORCE_LINK_ENABLE_Bf, 0xFFFFFF);
#else
	soc_reg_field_set(unit, FR_CONFIG2r, &uRegValue, FORCE_LINK_ENABLE_Bf, 0x0);
#endif
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG2r(unit, uRegValue));

	/* 8b10b setting, QE type 1 reserved for qe2k, 0,2,3 reserved for qe4k
	 * Hybrid mode only use plane A for FIC traffic
	 */
	SOC_IF_ERROR_RETURN(READ_NODETYPE8B10Br(unit, &uRegValue));
	soc_reg_field_set(unit, NODETYPE8B10Br, &uRegValue, PLANE_A_NODETYPE_8B10Bf, 2);
	soc_reg_field_set(unit, NODETYPE8B10Br, &uRegValue, PLANE_B_NODETYPE_8B10Bf, 0);
	SOC_IF_ERROR_RETURN(WRITE_NODETYPE8B10Br(unit, uRegValue));	
    } else if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_FIC) {
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG1r(unit, &uRegValue));
	/* NOTE: idle_timeslot_thresh need to be larger than sfi_skew_tol */
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, IDLE_TIMESLOT_THRESHf, 55); 
	soc_reg_field_set(unit, FR_CONFIG1r, &uRegValue, FORCE_LINK_ENABLE_Af, 0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG1r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG2r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG2r, &uRegValue, FORCE_LINK_ENABLE_Bf, 0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG2r(unit, uRegValue));

	/* 8b10b setting, QE type 1 reserved for qe2k, 0,2,3 reserved for qe4k
	 * FIC mode both planes
	 */
	SOC_IF_ERROR_RETURN(READ_NODETYPE8B10Br(unit, &uRegValue));
	soc_reg_field_set(unit, NODETYPE8B10Br, &uRegValue, PLANE_A_NODETYPE_8B10Bf, 2);
	soc_reg_field_set(unit, NODETYPE8B10Br, &uRegValue, PLANE_B_NODETYPE_8B10Bf, 2);
	SOC_IF_ERROR_RETURN(WRITE_NODETYPE8B10Br(unit, uRegValue));	
    }
	
    if (soc_feature(SIRIUS_UNIT, soc_feature_standalone) )  {

	SOC_IF_ERROR_RETURN(READ_FR_CONFIG3r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG3r, &uRegValue, CHANNEL_MASK_Af, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG3r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG4r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG4r, &uRegValue, CHANNEL_MASK_Af, 0x1555);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG4r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG5r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG5r, &uRegValue, CHANNEL_MASK_Bf, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG5r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG6r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG6r, &uRegValue, CHANNEL_MASK_Bf, 0x2AAA);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG6r(unit, uRegValue));    
    } else  {
#if 000
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG3r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG3r, &uRegValue, CHANNEL_MASK_Af, 0x55555555);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG3r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG4r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG4r, &uRegValue, CHANNEL_MASK_Af, 0x1555);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG4r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG5r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG5r, &uRegValue, CHANNEL_MASK_Bf, 0xAAAAAAAA);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG5r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG6r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG6r, &uRegValue, CHANNEL_MASK_Bf, 0x2AAA);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG6r(unit, uRegValue));    
#else
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG3r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG3r, &uRegValue, CHANNEL_MASK_Af, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG3r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG4r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG4r, &uRegValue, CHANNEL_MASK_Af, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG4r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG5r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG5r, &uRegValue, CHANNEL_MASK_Bf, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG5r(unit, uRegValue));
	SOC_IF_ERROR_RETURN(READ_FR_CONFIG6r(unit, &uRegValue));
	soc_reg_field_set(unit, FR_CONFIG6r, &uRegValue, CHANNEL_MASK_Bf, 0x0);
	SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG6r(unit, uRegValue));    
#endif
    }

    /* Do not force planes for QE2000 */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG7r(SIRIUS_UNIT, &uRegValue));
    soc_reg_field_set(SIRIUS_UNIT, FR_CONFIG7r, &uRegValue, FORCE_TX_PLANEf, 0x0);
    soc_reg_field_set(SIRIUS_UNIT, FR_CONFIG7r, &uRegValue, FORCE_TX_PLANE_VALUEf, 0x0);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG7r(SIRIUS_UNIT, uRegValue));

    /* see mask settings comment in init_qs */
    /* type 0 */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG8r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG8r, &uRegValue, CHANNEL_ENABLE_TYPE0f, 0xFFFFFFFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG8r(unit, uRegValue));
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG9r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG9r, &uRegValue, CHANNEL_ENABLE_TYPE0f, 0x3FFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG9r(unit, uRegValue));

    /* type 1 */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG10r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG10r, &uRegValue, CHANNEL_ENABLE_TYPE1f, 0xFFFFFFFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG10r(unit, uRegValue));
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG11r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG11r, &uRegValue, CHANNEL_ENABLE_TYPE1f, 0xF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG11r(unit, uRegValue));
    /* type 2 */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG12r(unit, &uRegValue));

    soc_reg_field_set(unit, FR_CONFIG12r, &uRegValue, CHANNEL_ENABLE_TYPE2f, 0xFFFFFFFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG12r(unit, uRegValue));
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG13r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG13r, &uRegValue, CHANNEL_ENABLE_TYPE2f, 0x0FFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG13r(unit, uRegValue));

    /* type 3 */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG14r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG14r, &uRegValue, CHANNEL_ENABLE_TYPE3f, 0xFFFFFFFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG14r(unit, uRegValue));
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG15r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG15r, &uRegValue, CHANNEL_ENABLE_TYPE3f, 0x0FFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG15r(unit, uRegValue));

    /* SFI_SCI links disable crossover */
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG16r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG16r, &uRegValue, PLANE_CROSSOVER_LINKS_ENABLEf, 0xFFFFFFFF);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG16r(unit, uRegValue));
    SOC_IF_ERROR_RETURN(READ_FR_CONFIG17r(unit, &uRegValue));
    soc_reg_field_set(unit, FR_CONFIG17r, &uRegValue, PLANE_CROSSOVER_LINKS_ENABLEf, 0x0FFF);

    soc_cm_get_id(SIRIUS_UNIT, &dev_id, &rev_id);

    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG17r(unit, uRegValue));


    SOC_IF_ERROR_RETURN(READ_FR_CONFIG0r(unit, &uRegValue));
    if ((SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) &&
        (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_TME) && 
        (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_TME_BYPASS))  {
        soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, SYNC_AB_PLANESf, 1);
    } else {
        soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, SYNC_AB_PLANESf, 0);
    }
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, ENABLEf, 1);
    /* QE type 1 reserved for qe2k, 0,2,3 reserved for qe4k */
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, QE_TYPEf, 0xD);
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, MODEf, 0x0);
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, TS_TAG_PARITY_ENf, 0);
    soc_reg_field_set(unit, FR_CONFIG0r, &uRegValue, SFI_SKEW_TOLf, 0x20);
    SOC_IF_ERROR_RETURN(WRITE_FR_CONFIG0r(unit, uRegValue));

    /* enable global flow control threshold to prevent egress drops */
    SOC_IF_ERROR_RETURN(READ_FR_FLOW_CTL_GLOBALr(unit, &uRegValue));
    soc_reg_field_set(unit, FR_FLOW_CTL_GLOBALr, &uRegValue, GLOBAL_THRESH_HIf, 0x6FFF);
    soc_reg_field_set(unit, FR_FLOW_CTL_GLOBALr, &uRegValue, GLOBAL_THRESH_LOf, 0x67FF);
    SOC_IF_ERROR_RETURN(WRITE_FR_FLOW_CTL_GLOBALr(unit, uRegValue));

    SOC_IF_ERROR_RETURN(READ_FR_FLOW_CTL_UNICASTr(unit, &uRegValue));
    soc_reg_field_set(unit, FR_FLOW_CTL_UNICASTr, &uRegValue, UC_THRESH_HIf, 0x6F00);
    soc_reg_field_set(unit, FR_FLOW_CTL_UNICASTr, &uRegValue, UC_THRESH_LOf, 0x6700);
    SOC_IF_ERROR_RETURN(WRITE_FR_FLOW_CTL_UNICASTr(unit, uRegValue));

    return(rv);
}

static int
_soc_sirius_hw_init_eb( siriusInitParams_t *pInitParams)
{
    int32  unit = (int32) pInitParams->unit;
    int rv = SOC_E_NONE;
    soc_timeout_t timeout;
    uint32 nInitDone = 0;
    uint32 regval = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init eb called.\n")));


    /*
     * Take out of soft reset
     */

    SOC_IF_ERROR_RETURN(READ_EB_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, EB_CONFIGr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_EB_CONFIGr(unit, regval));

    /*
     * Initialize FD Memory
     */

    SOC_IF_ERROR_RETURN(READ_EB_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, EB_CONFIGr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_EB_CONFIGr(unit, regval));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_timeout_init(&timeout, _sirius_init_timeout,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_EB_CONFIGr(unit, &regval));
            
            nInitDone = soc_reg_field_get(unit,EB_CONFIGr,regval,INIT_DONEf);
            if (nInitDone)
                break;
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("EB Config init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    soc_reg_field_set(unit, EB_CONFIGr, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_EB_CONFIGr(unit, regval));

    /*
     *  Set up buffer age tic so it happens once per second
     */
    
    SOC_IF_ERROR_RETURN(READ_PKTAGINGTIMERr(unit, &regval));
    soc_reg_field_set(unit, PKTAGINGTIMERr, &regval, DURATIONSELECTf, 0);
    soc_reg_field_set(unit, PKTAGINGTIMERr, &regval, AGINGTICKSELf, 0x1);
    SOC_IF_ERROR_RETURN(WRITE_PKTAGINGTIMERr(unit, regval));

    /*
     *  Set buffer age threshold so it happens on 8th tic (15 - 7)...
     *
     *  Since some parts of the egress configuration are accessed at different
     *  stages of the forwarding by frames, we can only release resources once
     *  we are certain no more frames will be needing those resources.  From
     *  this, it is clear that the buffer age feature must be enabled.
     */
    
    SOC_IF_ERROR_RETURN(READ_PKTAGINGLIMITr(unit, &regval));
    soc_reg_field_set(unit, PKTAGINGLIMITr, &regval, CLASS0_LIMITf, 0x7);
    soc_reg_field_set(unit, PKTAGINGLIMITr, &regval, CLASS1_LIMITf, 0x7);
    soc_reg_field_set(unit, PKTAGINGLIMITr, &regval, CLASS2_LIMITf, 0x7);
    soc_reg_field_set(unit, PKTAGINGLIMITr, &regval, CLASS3_LIMITf, 0x7);
    SOC_IF_ERROR_RETURN(WRITE_PKTAGINGLIMITr(unit, regval));

    /*
     *  Enable the block
     */
    SOC_IF_ERROR_RETURN(READ_EB_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, EB_CONFIGr, &regval, EB_ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_EB_CONFIGr(unit, regval));
    return rv;
}

/*
 *  Calling this will tear down any existing configuration and replace it
 *  according to the current settings.  Probably very disruptive to traffic,
 *  and so should only be invoked as part of initial configuration.
 *
 *  WARNING: This sets up the SDK flags and SDK honours them everywhere *but*
 *  here.  Here, it explicitly destroys all ingress resources associated with
 *  the ingress processing -- predicate_action rules, actions, predicates,
 *  queue_map blocks -- even if they were owned by the application.  The
 *  application must (re)establish its ingress processing after making any call
 *  that would result in this function being invoked (such as changing the
 *  encapsulation / header format).
 *
 *  NOTE: IDs are not kept here; they have specific values that are published
 *  in other header files and referenced here WITH_ID during setup so other
 *  features know what belongs to base SDK functionality.
 *
 *  Predicates in XGS mode:
 *    0 = interface number bit 0 (common code)
 *    1 = interface number bit 1 (common code)
 *    2 = interface number bit 2 (common code)
 *    3 = multicast (!unicast) (common code)
 *    4 = remote replication (front-panel device does final replication)
 *    5 = HiGig opcode is 010 or 011
 *    6 = HiGig opcode is 100
 *    7 = HiGig overlay type is 2
 *    8 =
 *    9 =
 *
 *  Predicates in SBX mode:
 *    0 = interface number bit 0 (common code)
 *    1 = interface number bit 1 (common code)
 *    2 = interface number bit 2 (common code)
 *    3 = multicast (!unicast) (common code)
 *    4 = IPMC (MC group ID is 0x1000..0x1FFF)
 *    5 = LB (MC group ID is 0x2000..0xFFFF)
 *    6 =
 *    7 =
 *    8 =
 *    9 =
 *
 *  Frame parsers in XGS mode:
 *     0 = unicast frames
 *     1 = multicast raw (used for remote replication)
 *     2 = multicast L2
 *     3 = multicast L2 directed requeue
 *     4 = multicast L3 (and multicast L3 directed requeue)
 *     5 = multicast DVP (and multicast DVP simple requeue)
 *     6 =
 *     7 =
 *     8 =
 *     9 =
 *    10 =
 *    11 =
 *    12 =
 *    13 =
 *    14 = diagnostic mode
 *    15 = invalid
 *
 *  Frame parsers in SBX mode:
 *     0 = passthrough
 *     1 = traditional bridging unicast and L2 multicast
 *     2 = traditional bridging L3 multicast
 *     3 = logical bridging unicast
 *     4 = logical bridging multicast
 *     5 =
 *     6 =
 *     7 =
 *     8 =
 *     9 =
 *    10 =
 *    11 =
 *    12 =
 *    13 =
 *    14 = diagnostic mode
 *    15 = invalid
 */
int
soc_sirius_hw_update_crt(uint32 unit)
{
    int rv = SOC_E_NONE;
    soc_sirius_parser_info_t parser;
    uint32 regval = 0, oi_rd_len=16, hdr_fmt = 0;
    uint16 i = 0;
    int intf, hg, cpu_subport;
    unsigned int predId;
    unsigned int parserId;
    unsigned int predParserId;
#ifdef SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS
    unsigned int qselId;
#endif /* def SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS */
    unsigned int next;
    soc_sirius_predicate_parser_rule_t predParserMap0;

    /* Get rid of existing egress processing configuration */
    predParserId = SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS - 1;
    do {
        rv = soc_sirius_predicate_parser_map_get_next(unit,
                                                      predParserId,
                                                      &next,
                                                      &predParserMap0);
        if (SOC_E_NONE == rv) {
            /* got next predicate_parser rule */
            predParserId = next;
            if (predParserMap0.flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS) {
                /* predicate_parser rule is ingress, destroy it */
                rv = soc_sirius_predicate_parser_map_delete(unit, predParserId);
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
    parserId = SIRIUS_PARSER_OFFSET_EGRESS - 1;
    do {
        rv = soc_sirius_parser_next(unit, parserId, &next);
        if (SOC_E_NONE == rv) {
            parserId = next;
            rv = soc_sirius_parser_get(unit, parserId, &parser);
            if (SOC_E_NONE == rv) {
                /* got next parser */
                if (parser.ingress.flags & SIRIUS_PARSER_FLAGS_EGRESS) {
                    /* parser is ingress, destroy it */
                    rv = soc_sirius_parser_free(unit, parserId);
                }
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
#ifdef SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS

    qselId = SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS - 1;
    do {
        rv = soc_sirius_queue_map_block_next(unit, qselId, &next);
        if (SOC_E_NONE == rv) {
            /* got next queue_map block */
            qselId = next;
            if (SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS <= qselId) {
                /* queue_map block is ingress, destroy it */
                rv = soc_sirius_queue_map_block_free(unit, qselId);
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
#endif /* def SIRIUS_QUEUE_MAP_BLOCK_OFFSET_EGRESS */
    predId = SIRIUS_PREDICATE_OFFSET_EGRESS - 1;
    do {
        rv = soc_sirius_predicate_next(unit, predId, &next);
        if (SOC_E_NONE == rv) {
            /* got next predicate_parser rule */
            predId = next;
            if (SIRIUS_PREDICATE_OFFSET_EGRESS <= predId) {
                /* parser is ingress, destroy it */
                rv = soc_sirius_predicate_free(unit, predId);
            }
        } else if (SOC_E_NOT_FOUND != rv) {
            /* something unexpected went wrong */
            return rv;
        }
    } while (SOC_E_NONE == rv);
    /* at this point, all is well */
    rv = SOC_E_NONE;

    /*
     *  Set egress processor predicates 0..2 so they are the interface number,
     *  so we can make some header processing decisions based upon interface.
     */
    for (i = 0; i < 3; i++) {
        predId = i + _SIRIUS_E_PRED_ALL_IF0 + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         ep_intf_num,
                                                         TRUE,
                                                         FALSE,
                                                         0x0001 << i,
                                                         0x0001 << i));
    }
    /*
     *  Want to be able to determine multicast from unicast, so there's another
     *  predicate to add to our set.
     */
    predId = _SIRIUS_E_PRED_ALL_MC + SIRIUS_PREDICATE_OFFSET_EGRESS;
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                      SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                      SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                      SIRIUS_PREDICATE_FLAGS_SDK,
                                                      &predId));
    SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                     predId,
                                                     2,
                                                     FALSE,
                                                     FALSE,
                                                     0x0800,
                                                     0x0800));

    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
        /*
         *  Want to be able to select between local replication and remote
         *  replication.  Will do this using the remote replication FIFO IDs
         *  to indicate remote replication (unicast will ignore this bit).
         *
         *  When the remote replication targets are set up by MC/Aggr, a
         *  function in this module will be called to configure the range.
         */
        
        predId = _SIRIUS_E_PRED_XGS_RREP + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         ep_fifo_num,
                                                         TRUE,
                                                         TRUE,
                                                         0xFFFF,
                                                         0xFFFF));
        /*
         *  Need a way to tell if HGX opcode is 01x
         */
        predId = _SIRIUS_E_PRED_XGS_OP23 + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         15,
                                                         FALSE,
                                                         FALSE,
                                                         0x0006,
                                                         0x0002));
        /*
         *  Need a way to tell if HGX opcode is 100
         */
        predId = _SIRIUS_E_PRED_XGS_OP4 + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         15,
                                                         FALSE,
                                                         FALSE,
                                                         0x0007,
                                                         0x0004));
        /*
         *  Need a way to tell if HGX is MP, use PPD type 2
         */
        predId = _SIRIUS_E_PRED_XGS_PPD2 + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         8,
                                                         FALSE,
                                                         FALSE,
                                                         0x0007,
                                                         0x0002));
    } else if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {
        /*
         *  Want to be able to determine OI[15:12] == 1 to differentiate TB
         *  IPMC with TB UC and TB MC
         */
        predId = _SIRIUS_E_PRED_SBX_IPMC + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         3,
                                                         FALSE,
                                                         FALSE,
                                                         0xF000,
                                                         0x1000));
        /*
         *  Want to be able to determine OI[15:13] == 0 for LB
         */
        predId = _SIRIUS_E_PRED_SBX_LB + SIRIUS_PREDICATE_OFFSET_EGRESS;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_allocate(unit,
                                                          SIRIUS_PREDICATE_FLAGS_EGRESS |
                                                          SIRIUS_PREDICATE_FLAGS_WITH_ID |
                                                          SIRIUS_PREDICATE_FLAGS_SDK,
                                                          &predId));
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                         predId,
                                                         3,
                                                         FALSE,
                                                         TRUE,
                                                         0x2000,
                                                         0xFFFF));
    }
    /* clear any egress predicates we are not using yet */
    SOC_IF_ERROR_RETURN(soc_sirius_egress_predicates_clear_unused(unit));

    /*
     *  The predicate vector is now:
     *
     *   XGS:    0    0 PPD2  OP4 OP23 RREP   MC   P2   P1   P0
     *   SBX:    0    0    0    0   LB IPMC   MC   P2   P1   P0
     *
     *  Common predicates are:
     *    P0..P2 = destination port ID
     *             000      = CMIC
     *             001..100 = higig to front-panel
     *             101..110 = requeue (recirculate locally)
     *    MC     = Multicast bit is set
     *
     *  In XGS mode, these are the addiitonal predicates:
     *    RREP   = Remote replication (actually, XGS MC higig targets)
     *    OP23   = HGX opcode is either 010 or 011
     *    OP4    = HGX opcode is 100
     *    PPD2   = HGX PPD overlay is type 2
     *
     *  In SBX mode, these are the additional predicates:
     *    IPMC   = Multicast group ID is 0x1000..0x1FFF (IPMC)
     *    LB     = Multicast group ID is 0x2000..0xFFFF (LB)
     *
     *  Note: The XGS predicates for OP23 and OP4 are contradictory conditions.
     *  Similarly, on XGS, !MC contradicts !(OP23 || OP4).
     */

    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {

        /*
         *  XGS_UC -- allow to pass unmolested
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_UC +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  XGS_RAW -- no header modifications (raw multicast)
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_RAW +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  XGS_MC_L2 -- multicast L2 (also 'simple' L2 requeue)
         *
         *  This needs to occur for MC, !RREP, OP23, !OP4, !PPD2, P[2..0] =
         *  001..100
         *
         *  This clears MC, replaces mcGroup with target {modId,port}, and sets
         *  the opcode to 001.
         *
         *  It requires that the multicast reserve ep_oi2qb_map[0] for opcode
         *  replacement, and place the value 1 in it.  Since only the lower
         *  three bits of ep_oi2qb_map[0] are used for opcode replacement,
         *  the other bits can be used for other purposes (currently we use
         *  them to mark invalid frames).
         *
         *  This does not use the OI for the replicant.
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.queue_write_byte = 14;
        parser.egress.queue_write_length = 3;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_MC_L2 +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  XGS_MC_L2 -- multicast L2 directed requeue
         *
         *  This needs to occur for MC, !RREP, OP23, !OP4, !PPD2, P[2..0] =
         *  001..100
         *
         *  This clears MC, replaces mcGroup with new queue ID, and sets the
         *  opcode to 001.
         *
         *  It requires that the multicast reserve ep_oi2qb_map[0] for opcode
         *  replacement, and place the value 1 in it.  Since only the lower
         *  three bits of ep_oi2qb_map[0] are used for opcode replacement,
         *  the other bits can be used for other purposes (currently we use
         *  them to mark invalid frames).
         *
         *  This gets the new queue ID from the ep_oi2qb_map entry for the
         *  replicant's OI.
         */
        /*
         *  Note that in the default configuration, this parser is always
         *  'orphaned' -- it is not used by any combination of predicates.
         *  This is because there must be specialised ingress changes for
         *  this model to be useful, and those ingress changes are not
         *  implemented.  Instead, this serves more as an example for the
         *  moment, and may be reclaimed in a later version of the code.
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.queue_write_byte = 14;
        parser.egress.queue_write_length = 3;
        parser.egress.oi_write_byte = 3;
        parser.egress.oi_write_length = 16;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_MC_L2R +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  XGS_MC_L3 -- multicast L3 (also L3 requeue)
         *
         *  This needs to occur for MC, !RREP, OP4, !OP23, !PPD2, P[2..0] =
         *  001..100
         *
         *  This substitutes the OI for the mcGroup, but otherwise leaves the
         *  frame unchanged.  This allows the XGS to handle egress modification
         *  based upon the OI.
         *
         *  For requeue, the OI must be the mcGroup for requeue pass, which
         *  maps to the ingress queue using the RB lookup.  The second time
         *  through, the replicants will be generated from their respecitve
         *  remapped mcGroups (which also must be configured by the
         *  application) and those OIs will be substituted and passed to XGS.
         *
         *  This uses ep_oi2qb_map for the replacement OI (or mcGroup).
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.oi_write_byte = 3;
        parser.egress.oi_write_length = 16;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_MC_L3 +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  XGS_MC_DVP -- multicast DVP (also 'simple' DVP requeue)
         *
         *  This needs to occur for MC, PPD2, !OP23, OP4, !RREP, P[2..0] =
         *  001..100
         *
         *  This clears MC and MP, places the OI into the dest VP field, sets
         *  the destination {modId,port} to the destination field, and changes
         *  the opcode to 001.
         *
         *  It requires that the multicast reserve ep_oi2qb_map[0] for opcode
         *  replacement, and place the value 1 in it.  Since only the lower
         *  three bits of ep_oi2qb_map[0] are used for opcode replacement,
         *  the other bits can be used for other purposes (currently we use
         *  them to mark invalid frames).
         *
         *  This uses ep_oi2qb_map for the OI.
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = 71;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.queue_write_byte = 14;
        parser.egress.queue_write_length = 3;
        parser.egress.oi_write_byte = 11;
        parser.egress.oi_write_length = 16;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_XGS_MC_DVP +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  Class INVALID
         */
        
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.queue_write_byte = 3;
        parser.egress.queue_write_length = 16;
        parser.egress.lengthAdj_length = 0;
        parserId = (_SIRIUS_E_PARSER_ALL_INVALID +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));
    } else  if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {

	/*
	 * If control_fabric_header_custom, disable default dp
	 */
	if (SOC_SBX_CONTROL(unit)->state == NULL) {
	    hdr_fmt = BCM_PORT_CONTROL_FABRIC_HEADER_88230;
	} else {
	    hdr_fmt = SOC_SBX_STATE(unit)->port_state->fabric_header_format;
	}

	if (hdr_fmt == BCM_PORT_CONTROL_FABRIC_HEADER_CUSTOM) {
	    oi_rd_len = 18;
	} else if (hdr_fmt == BCM_PORT_CONTROL_FABRIC_HEADER_88230) {
	    oi_rd_len = 16;
	} else {
	    return SOC_E_INTERNAL;
	}

	/*
	 *  Class 0 for SBX (Pass Thru)
	 */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_SBX_PASSTHRU +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

	/*
	 *  Class 1 for SBX (Traditional Bridging for Unicast and Multicast)
	 */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.oi_read_byte = 4;
        parser.egress.oi_read_length = oi_rd_len;
        parser.egress.oi_index_offset = SOC_SBX_CFG_SIRIUS(unit)->requeueMinPage;
        parser.egress.fcos_bit = 67;
        parser.egress.fcos_length = 3;
        parser.egress.queue_write_byte = 3;
        parser.egress.queue_write_length = 8;
        parser.egress.insertSel = 4;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_SBX_TB +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

	/*
	 *  Class 2 for SBX (Traditional Bridging for IP Multicast)
	 */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.oi_read_byte = 4;
        parser.egress.oi_read_length = oi_rd_len;
        parser.egress.oi_index_offset = SOC_SBX_CFG_SIRIUS(unit)->requeueMinPage;
        parser.egress.fcos_bit = 67;
        parser.egress.fcos_length = 3;
        parser.egress.queue_write_byte = 3;
        parser.egress.queue_write_length = 8;
        parser.egress.insertSel = 2;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_SBX_TB_IPMC +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

	/*
	 *  Class 3 for SBX (Logical Bridging Unicast)
	 */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.oi_read_byte = 4;
        parser.egress.oi_read_length = oi_rd_len;
        parser.egress.insertSel = 4;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_SBX_LB_UC +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  Class 4 for SBX (Logical Bridging Multicast)
         */
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_XGS_MODE |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.insertSel = 2;
        parser.egress.requeueSel = 2;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_SBX_LB_MC +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));

        /*
         *  Class INVALID
         */
        
        sal_memset(&parser, 0x00, sizeof(parser));
        parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                               SIRIUS_PARSER_FLAGS_WITH_ID |
                               SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                               SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                               SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                               SIRIUS_PARSER_FLAGS_SDK);
        parser.egress.eh_bit = -1;
        parser.egress.mp_bit = -1;
        parser.egress.fourByteRemove_quadbyte = -1;
        parser.egress.queue_write_byte = 3;
        parser.egress.queue_write_length = 16;
        parser.egress.lengthAdj_nybble = 2;
        parser.egress.lengthAdj_length = 4;
        parserId = (_SIRIUS_E_PARSER_ALL_INVALID +
                    SIRIUS_PARSER_OFFSET_EGRESS);
        SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                       parser.egress.flags,
                                                       &parserId));
        SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                      parserId,
                                                      &parser));
    }

    /*
     *  Class DIAG (same configuration in XGS and SBX modes)
     *
     *  Diagnostic mode -- assumes frames came in diagnostic mode and so need
     *  to leave raw (without first octbyte, which was inserted from register
     *  configuration on ingress to a port in diagnostic mode).
     */
    sal_memset(&parser, 0x00, sizeof(parser));
    parser.egress.flags = (SIRIUS_PARSER_FLAGS_EGRESS |
                           SIRIUS_PARSER_FLAGS_SDK |
                           SIRIUS_PARSER_FLAGS_WITH_ID);
    parser.egress.eh_bit = -1;
    parser.egress.mp_bit = -1;
    parser.egress.fourByteRemove_quadbyte = -1;
    parser.egress.hdrRemove_bytes = 8;
    parserId = (_SIRIUS_E_PARSER_ALL_DIAG +
                SIRIUS_PARSER_OFFSET_EGRESS);
    SOC_IF_ERROR_RETURN(soc_sirius_parser_allocate(unit,
                                                   parser.egress.flags,
                                                   &parserId));
    SOC_IF_ERROR_RETURN(soc_sirius_parser_set_sdk(unit,
                                                  parserId,
                                                  &parser));


    /* Configure rules for mapping predicates to parsers */
    if (SOC_SBX_IF_PROTOCOL_XGS == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        /*
         *  Note that we have any frames destined for the CPU port to have the
         *  same parsing treatment as those destined for the XGS.  This should
         *  help some with live debugging, but it also seems to make sense that
         *  the CPU would want the frame processed properly.
         *
         *  XGS:    0    0 PPD2  OP4 OP23 RREP   MC   P2   P1   P0
         *
         *  XGS mapping rules are chosen to avoid overlap, so they can all use
         *  the same priority.
         */
        /*
         *  Unicast, applies to ports 0..4 (requeue not allowed)
         *  PPD2 is don't care; other predicates false
         *
         *  Need two rules -- one covers 0..3 and one covers 4
         *
         *  Note we specifically avoid allowing unicast requeue.
         */
        sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
        predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        predParserMap0.parser = _SIRIUS_E_PARSER_XGS_UC + SIRIUS_PARSER_OFFSET_EGRESS;
        predParserMap0.priority = 8;
        /* x x x 0 0 0 0 0 x x - ports 0..3 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = 0;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 0 0 0 0 1 0 0 - port 4 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF_BITS |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = _SIRIUS_E_PRED_ALL_IF2_BIT;
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /*
         *  Raw multicast, applies to ports 0..4 (requeue not allowed)
         *  Other preciates: MC = true
         *                   RREP = true
         *                   exactly one of OP23, OP4 = true
         *                   PPD2 = don't care
         *
         *  Need four rules for this
         */
        
        sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
        predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        predParserMap0.parser = _SIRIUS_E_PARSER_XGS_RAW + SIRIUS_PARSER_OFFSET_EGRESS;
        predParserMap0.priority = 8;
        /* x x x 0 1 1 1 0 x x - OP23, ports 0..3 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_RREP_BIT |
                                    _SIRIUS_E_PRED_XGS_OP23_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 1 0 1 1 0 x x - OP4, port 0..3 */
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_RREP_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 0 1 1 1 1 0 0 - OP23, port 4 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF_BITS |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_RREP_BIT |
                                    _SIRIUS_E_PRED_XGS_OP23_BIT |
                                    _SIRIUS_E_PRED_ALL_IF2_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 1 0 1 1 1 0 0 - OP4, port 4 */
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_RREP_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT |
                                    _SIRIUS_E_PRED_ALL_IF2_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /*
         *  L2 multicast, applies to ports 0..6 (5,6 are requeue)
         *  Other preciates: MC = true
         *                   RREP = false
         *                   OP23 = true
         *                   OP4 = false
         *                   PPD2 = don't care
         *
         *  Need three rules for this
         */
        sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
        predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        predParserMap0.parser = _SIRIUS_E_PARSER_XGS_MC_L2 + SIRIUS_PARSER_OFFSET_EGRESS;
        predParserMap0.priority = 8;
        /* x x x 0 1 0 1 0 x x - ports 0..3 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP23_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 0 1 0 1 1 0 x - ports 4,5 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                   _SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP23_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x x 0 1 0 1 1 1 0 - port 6 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                   _SIRIUS_E_PRED_XGS_RREP_BIT |
                                   _SIRIUS_E_PRED_XGS_OP23_BIT |
                                   _SIRIUS_E_PRED_XGS_OP4_BIT);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                    _SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP23_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /*
         *  L3 multicast, applies to ports 0..6 (5,6 are requeue)
         *  Other preciates: MC = true
         *                   RREP = false
         *                   OP23 = false
         *                   OP4 = true
         *                   PPD2 = false
         *
         *  Need three rules for this
         */
        sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
        predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        predParserMap0.parser = _SIRIUS_E_PARSER_XGS_MC_L3 + SIRIUS_PARSER_OFFSET_EGRESS;
        predParserMap0.priority = 8;
        /* x x 0 1 0 0 1 0 x x - ports 0..3 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x 0 1 0 0 1 1 0 x - ports 4,5 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                   _SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x 0 1 0 0 1 1 1 0 - port 6 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                    _SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /*
         *  VP multicast, applies to ports 0..6 (5,6 are requeue)
         *  Other preciates: MC = true
         *                   RREP = false
         *                   OP23 = false
         *                   OP4 = true
         *                   PPD2 = true
         *
         *  Need three rules for this
         */
        sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
        predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        predParserMap0.parser = _SIRIUS_E_PARSER_XGS_MC_DVP + SIRIUS_PARSER_OFFSET_EGRESS;
        predParserMap0.priority = 8;
        /* x x 1 1 0 0 1 0 x x - ports 0..3 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT |
                                    _SIRIUS_E_PRED_XGS_PPD2_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x 1 1 0 0 1 1 0 x - ports 4,5 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                   _SIRIUS_E_PRED_ALL_IF2_BIT |
                                   _SIRIUS_E_PRED_ALL_MC_BIT |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT |
                                    _SIRIUS_E_PRED_XGS_PPD2_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
        /* x x 1 1 0 0 1 1 1 0 - port 6 */
        predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                   _SIRIUS_E_PRED_XGS_BITS);
        predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                    _SIRIUS_E_PRED_ALL_IF2_BIT |
                                    _SIRIUS_E_PRED_ALL_MC_BIT |
                                    _SIRIUS_E_PRED_XGS_OP4_BIT |
                                    _SIRIUS_E_PRED_XGS_PPD2_BIT);
        SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                &predParserMap0,
                                                                &predParserId));
    } else if (SOC_SBX_IF_PROTOCOL_SBX == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        /*
         *  The predicate vector is now:
         *
         *   SBX:    0    0    0    0   LB IPMC   MC   P2   P1   P0
         *
         */
        if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) {
            /*
             *  For this mode, none of the rules overlap, so all can be the
             *  same priority without problems.
             */
            /*
             *  Traditional bridging (both unicast and multicast)
             *  Applies to ports 0..4, IPMC = false, LB = false
             *
             *  Need two rules for this
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_TB + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 0 0 x 0 x x - ports 0..3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = 0;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 0 0 x 1 0 0 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF_BITS |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = _SIRIUS_E_PRED_ALL_IF2_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  IPv4 traditional bridging multicast (no associated unicast)
             *  Applies to ports 0..4, IPMC = true, LB = false
             *
             *  Need two rules for this
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_TB_IPMC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 0 1 1 0 x x - ports 0..3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_SBX_IPMC_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 0 1 1 1 0 0 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_SBX_IPMC_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Logical bridging unicast
             *  Applies to ports 0..4, IPMC = don't care, LB = true
             *
             *  Need two rules for this
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_LB_UC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 1 x 0 0 x x - ports 0..3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = _SIRIUS_E_PRED_SBX_LB_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 1 x 0 1 0 0 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Logical bridging multicast
             *  Applies to ports 0..4, IPMC = don't care, LB = true
             *
             *  Need two rules for this
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_LB_MC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 1 x 1 0 x x - ports 0..3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF2_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_MC_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 1 x 1 1 0 0 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
        } else { /* if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) */
            /*
             *  For this mode, in order to simplify this part of the setup,
             *  there is a lot of rule overlap.  This means that the overlap
             *  rules must be given a higher priority than the ones being
             *  overlapped.  We'll add the rules in decreasing order of
             *  priority, since we don't want glitching.
             *
             *  There are several ways to accomplish the desired map using
             *  priorities rather than precise mapping.  This method was chosen
             *  because it seemed to make sense, by keeping the groups we had
             *  above (non-hybrid mode) and masking them with higher priority
             *  rules based upon the special cases for hybrid mode.  Also note
             *  that the requeue path is now valid, which does slightly change
             *  the rules, so it's not a strict cut-and-paste + overlap.
             */
            /*
             *  Later will add SBX PASSTHROUGH parser for all references to
             *  ports 1..4, but unicast + IPMC is bogus and should remain as
             *  INVALID.
             *
             *  This requires a single rule.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_ALL_INVALID + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 16;
            /* x x x x 0 1 0 x x x - ports 0..3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = _SIRIUS_E_PRED_SBX_IPMC_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Now add the passtrhough parser for all of the other cases where
             *  port is 1..4.
             *
             *  This requires three rules(!) - if = {001, 01x, 100}.  Note the
             *  unicast IP multicast contradiction is masked by the special
             *  rule immediately above, which renders those back to INVALID.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_PASSTHRU + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 12;
            /* x x x x x x x 0 0 1 - port 1 */
            predParserMap0.predMask = _SIRIUS_E_PRED_ALL_IF_BITS;
            predParserMap0.predState = _SIRIUS_E_PRED_ALL_IF0_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x x x x 0 1 x - ports 2,3 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF1_BIT |
                                       _SIRIUS_E_PRED_ALL_IF2_BIT);
            predParserMap0.predState = _SIRIUS_E_PRED_ALL_IF1_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x x x x 1 0 0 - port 4 */
            predParserMap0.predMask = _SIRIUS_E_PRED_ALL_IF_BITS;
            predParserMap0.predState = _SIRIUS_E_PRED_ALL_IF2_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Traditional bridging (both unicast and multicast)
             *  Applies to ports 0,5,6, IPMC = false, LB = false
             *
             *  Need two rules for this; note ports 2,4 are masked by the
             *  higher priority rule for passthrough, above.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_TB + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 0 0 x x x 0 - ports 0, 2, 4, 6 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF0_BIT |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = 0;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 0 0 x 1 0 0 - port 5 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF_BITS |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = (_SIRIUS_E_PRED_ALL_IF0_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  IPv4 traditional bridging multicast (no associated unicast)
             *  Applies to ports 0,5,6, IPMC = true, LB = false
             *
             *  Need two rules for this; note ports 2,4 are masked by the
             *  higher priority rule for passthrough, above.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_TB_IPMC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 0 1 1 x x 0 - ports 0,2,4,6 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF0_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_SBX_IPMC_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 0 1 1 1 0 1 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_BITS);
            predParserMap0.predState = (_SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_SBX_IPMC_BIT |
                                        _SIRIUS_E_PRED_ALL_IF0_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Logical bridging unicast
             *  Applies to ports 0,5,6, IPMC = don't care, LB = true
             *
             *  Need two rules for this; note ports 2,4 are masked by the
             *  higher priority rule for passthrough, above.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_LB_UC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 1 x 0 x x 0 - ports 0,2,4,6 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF0_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = _SIRIUS_E_PRED_SBX_LB_BIT;
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 1 x 0 1 0 1 - port 4 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_IF0_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /*
             *  Logical bridging multicast
             *  Applies to ports 0,5,6, IPMC = don't care, LB = true
             *
             *  Need two rules for this; note ports 2,4 are masked by the
             *  higher priority rule for passthrough, above.
             */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_SBX_LB_MC + SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 8;
            /* x x x x 1 x 1 x x 0 - ports 0,2,4,6 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_IF0_BIT |
                                       _SIRIUS_E_PRED_ALL_MC_BIT |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_MC_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
            /* x x x x 1 x 1 1 0 1 - port 5 */
            predParserMap0.predMask = (_SIRIUS_E_PRED_ALL_BITS |
                                       _SIRIUS_E_PRED_SBX_LB_BIT);
            predParserMap0.predState = (_SIRIUS_E_PRED_SBX_LB_BIT |
                                        _SIRIUS_E_PRED_ALL_MC_BIT |
                                        _SIRIUS_E_PRED_ALL_IF0_BIT |
                                        _SIRIUS_E_PRED_ALL_IF2_BIT);
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
        } /* if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) */
    }

    /*
     *  For each interface in diagnostic mode:
     *
     *    Add predicate->action rule mapping interface to diag parser
     */
    for (intf = 0;
         intf < SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES;
         intf++) {
        if ((SOC_SBX_CFG_SIRIUS(unit)->if_diag_mode[intf]) & 0x01) {
            /* interface is configured in diagnostic mode */
            sal_memset(&predParserMap0, 0x00, sizeof(predParserMap0));
            predParserMap0.flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
            predParserMap0.parser = _SIRIUS_E_PARSER_ALL_DIAG +
                                    SIRIUS_PARSER_OFFSET_EGRESS;
            predParserMap0.priority = 32; /* orverride other SDK mapping */
            predParserMap0.predMask = _SIRIUS_I_PRED_ALL_IF_BITS;
            switch (intf) {
            case 0:
                predParserMap0.predState = 0; /* no bits set*/
                break;
            case 1:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF0_BIT;
                break;
            case 2:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF1_BIT;
                break;
            case 3:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF0_BIT |
                                            _SIRIUS_I_PRED_ALL_IF1_BIT);
                break;
            case 4:
                predParserMap0.predState = _SIRIUS_I_PRED_ALL_IF2_BIT;
                break;
            case 5:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF0_BIT |
                                            _SIRIUS_I_PRED_ALL_IF2_BIT);
                break;
            case 6:
                predParserMap0.predState = (_SIRIUS_I_PRED_ALL_IF1_BIT |
                                            _SIRIUS_I_PRED_ALL_IF2_BIT);
                break;
            /* coverity[dead_error_begin] */
            default:
                /* should never get here */
                return SOC_E_INTERNAL;
            } /* switch (idx) */
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_parser_map_add(unit,
                                                                    &predParserMap0,
                                                                    &predParserId));
        } /* if (interface is in diagnostic mode */
    } /* for (all interfaces) */

    /* turn on the interfaces */
    SOC_IF_ERROR_RETURN(READ_EP_INTERFACE0_CONFIGr(unit, &regval));
    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
    } else if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
      soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	  soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
    } 
    soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
    SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE0_CONFIGr(unit, regval));

    /* turn on interface0 stats for cpu */
    cpu_subport = 0;
    for (hg=0; hg < SB_FAB_DEVICE_SIRIUS_NUM_HG_LINE_PORTS; hg++) {	
	
	intf = SB_FAB_DEVICE_SIRIUS_HG0_INTF + hg;
        cpu_subport += SOC_SBX_SIRIUS_STATE(unit)->uNumExternalSubports[intf];
    }

    SOC_IF_ERROR_RETURN(READ_EP_INTERFACE0_PKT_XMT_CTRLr(unit, &regval));
    soc_reg_field_set(unit, EP_INTERFACE0_PKT_XMT_CTRLr, &regval, CHANNEL_NUM_SELf, TRUE);
    soc_reg_field_set(unit, EP_INTERFACE0_PKT_XMT_CTRLr, &regval, CHANNEL_NUM_VALUEf, cpu_subport);
    soc_reg_field_set(unit, EP_INTERFACE0_PKT_XMT_CTRLr, &regval, SUB_PORT_SELf, TRUE);
    soc_reg_field_set(unit, EP_INTERFACE0_PKT_XMT_CTRLr, &regval, SUB_PORT_VALUEf, cpu_subport);
    SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE0_PKT_XMT_CTRLr(unit, regval)); 

    if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE1_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE1_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE2_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE2_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE3_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE3_CONFIGr(unit, regval));
	
	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE4_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE4_CONFIGr(unit, regval));
    
	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE5_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE5_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE6_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, TRUE);
        soc_reg_field_set(unit, EP_INTERFACE0_CONFIGr, &regval, INSERT_2B_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE6_CONFIGr(unit, regval));

    } else if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE1_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE1_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE1_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE2_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE2_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE2_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE3_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE3_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE3_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE4_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode != SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE4_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE4_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE5_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE5_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE5_CONFIGr(unit, regval));

	SOC_IF_ERROR_RETURN(READ_EP_INTERFACE6_CONFIGr(unit, &regval));
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, ENABLE_PKT_MODf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_T_ENABLEf, TRUE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_ECN_ENABLEf, FALSE);
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, HDR_XLATE_ECT_ENABLEf, FALSE);
	if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_HYBRID) {
	    soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, INSERT_2B_ENABLEf, TRUE);
	}
	soc_reg_field_set(unit, EP_INTERFACE6_CONFIGr, &regval, EP_TO_PORT_INTF_ENABLEf, TRUE);
	SOC_IF_ERROR_RETURN(WRITE_EP_INTERFACE6_CONFIGr(unit, regval));
    }

    return rv;
}

int
soc_sirius_hw_xgs_remote_replication_range_set(int unit, int first, int last)
{
    if (SOC_SBX_IF_PROTOCOL_XGS == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
        if (SOC_E_FULL == soc_sirius_predicate_check_sdk(unit,
                                                         _SIRIUS_E_PRED_XGS_RREP +
                                                         SIRIUS_PREDICATE_OFFSET_EGRESS)) {
            SOC_IF_ERROR_RETURN(soc_sirius_predicate_set_sdk(unit,
                                                             _SIRIUS_E_PRED_XGS_RREP +
                                                             SIRIUS_PREDICATE_OFFSET_EGRESS,
                                                             ep_subport_id,
                                                             TRUE,
                                                             TRUE,
                                                             first,
                                                             last));
        }
    }
    return SOC_E_NONE;
}

static int
_soc_sirius_hw_init_ep( siriusInitParams_t *pInitParams)
{
    int32  unit = (int32) pInitParams->unit;
    ep_predictive_ranging_entry_t predicate;
    ep_hdr_parsing_ctrl_entry_t parser;
    ep_stats_ctrl_entry_t stats;
    int rv = SOC_E_NONE;
    int32 minOitt = 0;
    int32 maxOitt = 0;
    uint32 idx = 0;
    uint32 regval = 0;
    ep_dest_port_map_entry_t ep_entry;
    ep_oi2qb_map_entry_t oi_entry;
    soc_reg_t regId;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ep called.\n")));

    /*
     * Initialize EP has to before xport, move to step 0
     */

    SOC_IF_ERROR_RETURN(READ_EP_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, EP_CONFIGr, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_EP_CONFIGr(unit, regval));

    /*
     * Initialise Egress Processor (EP) Predicates to return zero
     */
    sal_memset(&predicate, 0, sizeof(ep_predictive_ranging_entry_t));
    soc_mem_field32_set(unit, EP_PREDICTIVE_RANGINGm, &predicate, HI_DATAf, 0xFFFF);
    soc_mem_field32_set(unit, EP_PREDICTIVE_RANGINGm, &predicate, LO_MASKf, 0x0);
    for (idx = 0; idx <= SOC_MEM_INFO(unit, EP_PREDICTIVE_RANGINGm).index_max; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_EP_PREDICTIVE_RANGINGm(unit, MEM_BLOCK_ANY, idx, &predicate));
    }

    /* initialise EP stats controls to zero */
    sal_memset(&stats, 0x00, sizeof(stats));
    for (idx = 0; idx < 16; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_EP_STATS_CTRLm(unit, COPYNO_ALL, idx, &stats));
    }

    /* initialise EP parsing controls to zero */
    sal_memset(&parser, 0x00, sizeof(parser));
    for (idx = 0; idx < 16; idx++) {
        SOC_IF_ERROR_RETURN(WRITE_EP_HDR_PARSING_CTRLm(unit, COPYNO_ALL, idx, &parser));
    }

    /* configure the predicates, stats, parsers we actually have as defaults */
    rv = soc_sirius_hw_update_crt(unit);

    if(!SAL_BOOT_BCMSIM) {
        minOitt = (SOC_SBX_CFG_SIRIUS(unit)->requeueMinPage) << 9;
        maxOitt = SOC_MEM_INFO(unit, EP_OI2QB_MAPm).index_max;
        if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_SBX) {
            sal_memset(&oi_entry, 0, sizeof(oi_entry));
            soc_mem_field32_set(unit, EP_OI2QB_MAPm, &oi_entry, QUEUE_BASEf, SIRIUS_Q_BASE_INVALID);
            for (idx = minOitt; idx <= maxOitt; idx++) {
                SOC_IF_ERROR_RETURN(WRITE_EP_OI2QB_MAPm(unit, MEM_BLOCK_ANY, idx, &oi_entry));
            }
        }
    }

    /* initialize dest mod/port to some default value using 4 fifo mode. */
    /* this will be later re-configured via APIs */
    sal_memset(&ep_entry, 0, sizeof(ep_entry));
    for (idx = 0; idx <= SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max; idx++) {
      if (SOC_SBX_CFG(unit)->fabric_egress_setup) {
	if (SOC_SBX_CFG(unit)->uInterfaceProtocol == SOC_SBX_IF_PROTOCOL_XGS) {
	  soc_mem_field32_set(unit, EP_DEST_PORT_MAPm, &ep_entry, QUEUEf, (idx / SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE));
	} else {
	  soc_mem_field32_set(unit, EP_DEST_PORT_MAPm, &ep_entry, QUEUEf, ((idx / SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE) << 8));
	}
      } else {
	/* requested to leave it blank when fabric_egress_setup is 0 */
	soc_mem_field32_set(unit, EP_DEST_PORT_MAPm, &ep_entry, QUEUEf, 0);	
      }
      SOC_IF_ERROR_RETURN(WRITE_EP_DEST_PORT_MAPm(unit, MEM_BLOCK_ANY, idx, &ep_entry));
    }

    /* set shaping bus length adjusts per port */
    for (idx = 0; idx < SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES; idx++) {
        switch (idx) {
        case 0:
            regId = EP_INTERFACE0_CONFIGr;
            break;
        case 1:
            regId = EP_INTERFACE1_CONFIGr;
            break;
        case 2:
            regId = EP_INTERFACE2_CONFIGr;
            break;
        case 3:
            regId = EP_INTERFACE3_CONFIGr;
            break;
        case 4:
            regId = EP_INTERFACE4_CONFIGr;
            break;
        case 5:
            regId = EP_INTERFACE5_CONFIGr;
            break;
        case 6:
            regId = EP_INTERFACE6_CONFIGr;
            break;
        /* coverity[dead_error_begin] */
        default:
            regId = -1;
        }
        if (-1 != regId) {
            SOC_IF_ERROR_RETURN(soc_reg32_read(unit, soc_reg_addr(unit, regId, REG_PORT_ANY, 0), &regval));
            soc_reg_field_set(unit, regId, &regval, SHAPING_BUS_LENGTH_ADJf, pInitParams->ep.shapingBusLengthAdj[idx]);
            SOC_IF_ERROR_RETURN(soc_reg32_write(unit, soc_reg_addr(unit, regId, REG_PORT_ANY, 0), regval));
        }
    }
    return rv;
}

static int
_soc_sirius_hw_init_es_flow_control_tables(siriusInitParams_t *pInitParams)
{
    int                                    rv = SOC_E_NONE;
    flow_control_base_table_entry_t        fc_base_table_entry;
    flow_control_state_table_entry_t       fc_state_table_entry;
    flow_control_translate_table_entry_t   fc_xlate_table_entry;
    flow_control_map_table_entry_t         fc_map_table_entry;
    int                                    index = 0;
    int32                                unit = (int32) pInitParams->unit;


    /* FLOW_CONTROL_BASE_TABLE */
    sal_memset(&fc_base_table_entry, 0, sizeof(flow_control_base_table_entry_t));
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry, ENf, 0);
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry, BASE_ADDRESSf, 0);
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry, NUM_PORTSf, 0);
    for (index = 0; index <= SOC_MEM_INFO(SIRIUS_UNIT, FLOW_CONTROL_BASE_TABLEm).index_max;
                                                                                     index++) {
        SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_BASE_TABLEm(unit, MEM_BLOCK_ANY,
                                                                  index, &fc_base_table_entry));
    }

    /* FLOW_CONTROL_STATE_TABLE */
    sal_memset(&fc_state_table_entry, 0, sizeof(flow_control_state_table_entry_t));
    soc_mem_field32_set(unit, FLOW_CONTROL_STATE_TABLEm, &fc_state_table_entry, FC_STATEf, 0xf);
    for (index = 0; index <= SOC_MEM_INFO(unit, FLOW_CONTROL_STATE_TABLEm).index_max; index++) {
        SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_STATE_TABLEm(unit, MEM_BLOCK_ANY,
                                                                  index, &fc_state_table_entry));
    }

    /* FLOW_CONTROL_TRANSLATE_TABLE */
    sal_memset(&fc_xlate_table_entry, 0, sizeof(flow_control_translate_table_entry_t));
    soc_mem_field32_set(unit, FLOW_CONTROL_TRANSLATE_TABLEm, &fc_xlate_table_entry,
                                                                              FC_STATE_XLATEf, 0);
    for (index = 0; index <= SOC_MEM_INFO(SIRIUS_UNIT, FLOW_CONTROL_TRANSLATE_TABLEm).index_max;
                                                                                       index++) {
        SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_TRANSLATE_TABLEm(unit, MEM_BLOCK_ANY,
                                                                  index, &fc_xlate_table_entry));
    }

    if(!SAL_BOOT_BCMSIM) {
    /* FLOW_CONTROL_MAP_TABLE */
    sal_memset(&fc_map_table_entry, 0, sizeof(flow_control_map_table_entry_t));

    soc_mem_field32_set(unit, FLOW_CONTROL_MAP_TABLEm, &fc_map_table_entry, PORT1_FC_INDEXf, 0);
    soc_mem_field32_set(unit, FLOW_CONTROL_MAP_TABLEm, &fc_map_table_entry, PORT0_FC_INDEXf, 0);
    
    
    for (index = 0; index <= SOC_MEM_INFO(unit, FLOW_CONTROL_MAP_TABLEm).index_max; index++) {
        SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_MAP_TABLEm(unit, MEM_BLOCK_ANY,
                                                          index, &fc_map_table_entry));
    }
    }
    
    return(rv);
}

static int
_soc_sirius_hw_init_es( siriusInitParams_t *pInitParams)
{
    int      rv = SOC_E_NONE;
    uint32   regval = 0;
    int32  unit = (int32) pInitParams->unit;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init es called.\n")));

    /* init sequence */

    /* take out of reset */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_CONFIGr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    /* init memory */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_CONFIGr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    while (!soc_reg_field_get(unit,ES_CONFIGr,regval,INIT_DONEf) && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
      sal_usleep(100);
      SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    }

    soc_reg_field_set(unit, ES_CONFIGr, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));




    /* TDM table
     *   Disabled at init time for now
     * Interface max shaper table
     *   Disabled at init time for now
     * Channel map table
     *   Connect up for all created subports
     * Channel shaper table
     *   Disabled
     * Channel Werr table
     *   Disabled
     * Subport map table
     *   Connect up for all created subports
     * Subport shaper table
     *   Disabled
     * Subport werr table
     *   Disabled
     * Fifo map table
     *   Connect up for all created subports. 4 Fifos for each subport
     * Fifo group map table
     *   Connect up for all created subports. 4 Fifos for each subport
     * Fifo shaper table 0
     *   Disabled
     * Fifo shaper table 1
     *   Disabled
     * Fifo shaper table 2
     *   Disabled
     * Fifo shaper table 3
     *   Disabled
     * Fifo werr table
     *   Disabled
     * Group max shaper table
     *   Disabled
     * Group member table
     *   Disabled
     * Following table are used by hardware and not required to be configured
     *  Flow control base table
     *  Flow control state table (state only)
     *  Flow control translate table
     *  Flow control map table
     */

    /*
     *  TDM_ENABLE----------------not related to TDM calendar
     *  REFRESH_ENABLE------------Shaper
     *  EF_TO_INF_PROP_ENABLE-----EF/non-EF??
     *  EF_TO_CHN_PROP_ENABLE-----EF/non-EF??
     *  GROUP_SHAPING_ENABLE------Group shaper
     *  PASSTHRU_MODE_ENABLE------sporster mode??
     */
    /* enable the block */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_CONFIGr, &regval, TDM_ENABLEf, 1);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, REFRESH_ENABLEf, 1);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, GROUP_SHAPING_ENABLEf, 1);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, EF_TO_INF_PROP_ENABLEf, 0);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, EF_TO_CHN_PROP_ENABLEf, 0);
    if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) {
        soc_reg_field_set(unit, ES_CONFIGr, &regval, PASSTHRU_MODE_ENABLEf, 1);
    } 
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    /* Initialize flow control/congestion register */
    SOC_IF_ERROR_RETURN(READ_ES_LL_FC_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_LL_INTF_ENABLEf, 0);   /* LL disabled */
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_MC_ENABLE_MERGEf, 0);  /* MC Merge off */
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_MSG_TYPEf, 0);         /* E2ECC */
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_XPORT_SELECTf, 1);     /* PP side */
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_ENABLEf, 1);           /* Enable FC */
    if (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode) {
	soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_MAX_PORT_ENABLEf, 1);        /* Max ports */
	soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_EVEN_PORT_STATE_MASKf, 0xC); /* Even port mask */
    } else {
	soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_MAX_PORT_ENABLEf, 0);
    }
    if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS) {
        soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_XPORT_SELECTf, 0); /* SFI side */
    } 
    SOC_IF_ERROR_RETURN(WRITE_ES_LL_FC_CONFIGr(unit, regval));

    /* Initialize flow control/congestion Tables */
    rv = _soc_sirius_hw_init_es_flow_control_tables(pInitParams);
    if (rv != BCM_E_NONE) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unit%d Init Flow Control Tables\n"), unit));
        return(rv);
    }

    return rv;
}

static int
_soc_sirius_hw_init_fd( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32  unit = (int32) pInitParams->unit;
    eg_fd_svt_entry_t svt_entry;
    eg_fd_fct_entry_t fct_entry;
    eg_fd_gmt_entry_t *gmtBuff;
    eg_fd_fifo_thresh_entry_t fifo_thresh;
    eg_fd_fifo_thresh_offset_red_entry_t thresh_offset_red;
    eg_fd_fifo_thresh_offset_yellow_entry_t thresh_offset_yellow;
    eg_fd_fifo_thresh_reset_offset_entry_t reset_offset;
    eg_fdm_port_regs_entry_t regs_entry;
    uint32 temp[5];
    soc_timeout_t timeout;
    uint32 nInitDone = 0;
    uint32 regval = 0;
    int i = 0;
    unsigned int min, mid, max;
    int32 non_ef, mc, ds_id, ds_id_region;
    uint16 dynamic = 0, thresh = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init fd called.\n")));

    /*
     * Take out of soft reset
     */
    SOC_IF_ERROR_RETURN(READ_FD_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FD_CONFIGr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_FD_CONFIGr(unit, regval));

    /*
     * Initialize FD Memory
     */
    SOC_IF_ERROR_RETURN(READ_FD_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_PER_PORT_DROP_COUNT1_SELf, 0x7);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_PER_PORT_DROP_COUNT2_SELf, 0x7);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FD_CONFIGr(unit, regval));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_timeout_init(&timeout, _sirius_init_timeout,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_FD_CONFIGr(unit, &regval));
            
        nInitDone = soc_reg_field_get(unit,FD_CONFIGr,regval,INIT_DONEf);
        if (nInitDone)
            break;
        }
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("FD Config init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    
    soc_reg_field_set(unit, FD_CONFIGr, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FD_CONFIGr(unit, regval));

    /* global FD configuration */
    SOC_IF_ERROR_RETURN(READ_FD_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_RED_DPf, 1);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_YELLOW_DPf, 2);
    soc_reg_field_set(unit,
                      FD_CONFIGr,
                      &regval,
                      FD_MAX_MVRf,
                      pInitParams->fd.mvrMaxSize - 1);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_UNIQUE_OIf, 1);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_EN_FR_INTERFACEf, 1);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_EN_FF_INTERFACEf, 1);
    soc_reg_field_set(unit, FD_CONFIGr, &regval, FD_EN_EB_INTERFACEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FD_CONFIGr(unit, regval));

    /* all ports are members of the hardware assisted LAGs */
    regval = 0xffffffff;
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG0_0r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG0_1r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG0_2r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG0_3r(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FD_LAG0_4r, &regval, LAG0_4f, 0xf);
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG0_4r(unit, regval));
    regval = 0xffffffff;
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG1_0r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG1_1r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG1_2r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG1_3r(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FD_LAG1_4r, &regval, LAG1_4f, 0xf);
    SOC_IF_ERROR_RETURN(WRITE_FD_LAG1_4r(unit, regval));

    /* enable receive on all ports */
    regval = 0xffffffff;
    SOC_IF_ERROR_RETURN(WRITE_FD_PORT_ENABLE_0r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_PORT_ENABLE_1r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_PORT_ENABLE_2r(unit, regval));
    SOC_IF_ERROR_RETURN(WRITE_FD_PORT_ENABLE_3r(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FD_PORT_ENABLE_4r, &regval, PORT_ENABLE_4f, 0xf);
    SOC_IF_ERROR_RETURN(WRITE_FD_PORT_ENABLE_4r(unit, regval));

    /* set up buffer count and limits */
    regval = 0;
    soc_reg_field_set(unit, FD_TOTAL_BUFFER_LIMITr, &regval, TOTAL_BUFFER_LIMITf, 0x7fff);
    SOC_IF_ERROR_RETURN(WRITE_FD_TOTAL_BUFFER_LIMITr(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FD_TOTAL_BUFFER_LIMIT_YELLOWr, &regval, TOTAL_BUFFER_LIMIT_YELLOWf, 0x7fff);
    SOC_IF_ERROR_RETURN(WRITE_FD_TOTAL_BUFFER_LIMIT_YELLOWr(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FD_TOTAL_BUFFER_LIMIT_REDr, &regval, TOTAL_BUFFER_LIMIT_REDf, 0x7fff);
    SOC_IF_ERROR_RETURN(WRITE_FD_TOTAL_BUFFER_LIMIT_REDr(unit, regval));

    /*
     * set global admission control thresholds
     * Global threshold
     */
     regval = 0;
     soc_reg_field_set(unit, FR_FLOW_CTL_GLOBALr, &regval, GLOBAL_THRESH_LOf, 0x7000);
     soc_reg_field_set(unit, FR_FLOW_CTL_GLOBALr, &regval, GLOBAL_THRESH_HIf, 0x7000);
     SOC_IF_ERROR_RETURN(WRITE_FR_FLOW_CTL_GLOBALr(unit, regval));
     /* Unicast threshold
      */
     regval = 0;
     soc_reg_field_set(unit, FR_FLOW_CTL_UNICASTr, &regval, UC_THRESH_LOf, 0x7000);
     soc_reg_field_set(unit, FR_FLOW_CTL_UNICASTr, &regval, UC_THRESH_HIf, 0x7000);
     SOC_IF_ERROR_RETURN(WRITE_FR_FLOW_CTL_UNICASTr(unit, regval));

    /*
     * Initialize the FIFO CLASS TABLE to always default to class 0
     */
    for (i=0; i <= (SOC_MEM_INFO(unit, EG_FD_FCTm).index_max * 16); i++) {
       /* ef is BIT0, mc is BIT13, we don't care sysport bits for now
        * for 4 fifos, UC-NON-EF is fifo 0
        */
        non_ef = (i & (1<<0))?0:1;
        mc = (i & (1<<13))?1:0;

        SOC_IF_ERROR_RETURN(READ_EG_FD_FCTm(unit, MEM_BLOCK_ANY, (i/16), &fct_entry));
        regval = soc_mem_field32_get(unit, EG_FD_FCTm, &fct_entry, FIFO_CLASSf);
        regval &= ~(0x3 << ((i%16) * 2));

        if (mc && (!SBX_FAB_IS_STANDARD_ESET_RESOURCE_MODE(unit)) &&
	    (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == FALSE)) {
            /* In this mode there are 4 internal resources allocated for 1 user eset */
            ds_id = (i & ~(1 << 13)) >> 1;

            for (ds_id_region = 0; ds_id_region < SOC_SBX_CFG(unit)->num_res_per_eset_spec; ds_id_region++) {
                if (ds_id < (SOC_SBX_CFG(unit)->num_ds_ids * (ds_id_region + 1))) {
                    regval |= (ds_id_region << ((i%16) * 2));
                    break;
                }
            }
        }
        else if (mc && SOC_SBX_CFG(unit)->bEgressMulticastFifoIndependentFlowControl &&
	    (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == FALSE)) {
            ds_id = (i & ~(1 << 13)) >> 1;
            if (ds_id < SOC_SBX_CFG(unit)->num_ds_ids) {
                regval |= (((mc << 1) + 0) << ((i%16) * 2));
            }
            else {
                regval |= (((mc << 1) + 1) << ((i%16) * 2));
            }
        } else {
	    regval |= (((mc<<1) + non_ef) << ((i%16) * 2));
	}
     
        soc_mem_field32_set(unit, EG_FD_FCTm, &fct_entry, FIFO_CLASSf, regval);
        SOC_IF_ERROR_RETURN(WRITE_EG_FD_FCTm(unit, MEM_BLOCK_ALL, (i/16), &fct_entry));
    }

    /* no ports in LAGs initially, so squelch nothing */
    temp[0] = 0xFFFFFFFF;
    temp[1] = 0xFFFFFFFF;
    temp[2] = 0xFFFFFFFF;
    temp[3] = 0xFFFFFFFF;
    temp[4] = 0x0000000F;
    for (i=0; i <= SOC_MEM_INFO(unit, EG_FD_SVTm).index_max; i++) {
      soc_EG_FD_SVTm_field_set(unit, &svt_entry, SVT_ENTRYf, temp);
      SOC_IF_ERROR_RETURN(WRITE_EG_FD_SVTm(unit, MEM_BLOCK_ALL, i, &svt_entry));
    }

    /*
     *  HW says entire GMT is initialised to all ones by init process, so all
     *  we want to do is set up the unicast sysports so they are unicast mode
     *  (and directed to port zero for now).
     */
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init fd.gmt\n")));
    min = (SOC_MEM_INFO(unit, EG_FD_GMTm).index_min);
    max = (SOC_MEM_INFO(unit, EG_FD_GMTm).index_max);
    mid = max - 4095;
    gmtBuff = soc_cm_salloc(unit,
                            sizeof(*gmtBuff) * (max - min + 1),
                            "GMT buffer for init");
    if (gmtBuff) {
        sal_memset(gmtBuff, 0x00, sizeof(*gmtBuff) * (max - min + 1));
        /* set for unicast to port 0 by default */
        regval = 0x3FF00;
        for (i = mid; i < max; i++) {
            soc_EG_FD_GMTm_field_set(unit,
                                     &(gmtBuff[i - min]),
                                     MVRPf,
                                     &(regval));
        }
        /* now make sure any cache is committed */
        rv = soc_cm_sflush(unit,
                                gmtBuff,
                                sizeof(*gmtBuff) * (max - min + 1));
        if (SOC_E_NONE == rv) {
            /* finally write the expected default table value */
            /*    coverity[negative_returns : FALSE]    */
            rv = soc_mem_write_range(unit,
                                          EG_FD_GMTm,
                                          COPYNO_ALL,
                                          min,
                                          max,
                                          gmtBuff);
        }
        soc_cm_sfree(unit, gmtBuff);
        if (SOC_E_NONE != rv) {
            return rv;
        }
    } else {
        return SOC_E_MEMORY;
    }

    /*
     *  We don't initialise the MDB because HW says it is initialised to all
     *  ones by the init process.  This sets it up so everything looks like a
     *  single-element sparse logical MVR with source knockout and no ports.
     */

    /* set all ports so fabric header mask = 0xFFFF and SID = target number */
    
    for (i=0; i <= SOC_MEM_INFO(unit, EG_FDM_PORT_REGSm).index_max; i++) {
        if (SOC_SBX_IF_PROTOCOL_XGS == SOC_SBX_CFG(unit)->uInterfaceProtocol) {
            soc_mem_field32_set(unit, EG_FDM_PORT_REGSm, &regs_entry, PORT_MASKf, 0xFFFF);
            soc_mem_field32_set(unit, EG_FDM_PORT_REGSm, &regs_entry, PORT_SIDf, (i & 0xFFFF));
        } else {
            soc_mem_field32_set(unit, EG_FDM_PORT_REGSm, &regs_entry, PORT_MASKf, 0xFFFC);
            soc_mem_field32_set(unit, EG_FDM_PORT_REGSm, &regs_entry, PORT_SIDf, (i & 0x3FFF) << 2);
        }
        SOC_IF_ERROR_RETURN(WRITE_EG_FDM_PORT_REGSm(unit, MEM_BLOCK_ALL, i, &regs_entry));
    }

    /* set all FIFOs to static threshold of 0x7FFF */
    
    dynamic = 0;
    thresh = 0x7fff;

    if (SOC_SBX_CFG_SIRIUS(unit)->thresh_drop_limit <=8) {
        dynamic = 1;
        thresh = SOC_SBX_CFG_SIRIUS(unit)->thresh_drop_limit;
    } else if (SOC_SBX_CFG_SIRIUS(unit)->thresh_drop_limit < 0x7fff) {
        thresh = SOC_SBX_CFG_SIRIUS(unit)->thresh_drop_limit;
    }

    for (i=0; i <= SOC_MEM_INFO(unit, EG_FD_FIFO_THRESHm).index_max; i++) {
      soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &fifo_thresh, DYNAMICf, dynamic);
      soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &fifo_thresh, FIFO_THRESHf, thresh);
      SOC_IF_ERROR_RETURN(WRITE_EG_FD_FIFO_THRESHm(unit, MEM_BLOCK_ALL, i, &fifo_thresh));
    }

    /* set all FIFOs so RED threshold is -0xFF (so 0x7F00) */
    
    for (i=0; i <= SOC_MEM_INFO(unit, EG_FD_FIFO_THRESH_OFFSET_REDm).index_max; i++) {
      soc_mem_field32_set(unit, EG_FD_FIFO_THRESH_OFFSET_REDm,
                          &thresh_offset_red, FIFO_THRESH_OFFSET_REDf, 0xff);
      SOC_IF_ERROR_RETURN(WRITE_EG_FD_FIFO_THRESH_OFFSET_REDm(unit, MEM_BLOCK_ALL, i, &thresh_offset_red));
    }

    /* set all FIFOs so YELLOW threshold is -0xFF (so 0x7F00) */
    
    for (i=0; i <= SOC_MEM_INFO(unit, EG_FD_FIFO_THRESH_OFFSET_YELLOWm).index_max; i++) {
      soc_mem_field32_set(unit, EG_FD_FIFO_THRESH_OFFSET_YELLOWm,
                          &thresh_offset_yellow, FIFO_THRESH_OFFSET_YELLOWf, 0xff);
      SOC_IF_ERROR_RETURN(WRITE_EG_FD_FIFO_THRESH_OFFSET_YELLOWm(unit, MEM_BLOCK_ALL, i, &thresh_offset_yellow));
    }

    /* set all FIFOs XON threshold to -0xFF (so 0x7F00) */
    
    for (i=0; i <= SOC_MEM_INFO(unit, EG_FD_FIFO_THRESH_RESET_OFFSETm).index_max; i++) {
      soc_mem_field32_set(unit, EG_FD_FIFO_THRESH_RESET_OFFSETm,
                          &reset_offset, FIFO_THRESH_RESET_OFFSETf, 0xff);
      SOC_IF_ERROR_RETURN(WRITE_EG_FD_FIFO_THRESH_RESET_OFFSETm(unit, MEM_BLOCK_ALL, i, &reset_offset));
    }

    return rv;
}

int soc_sirius_fd_unicast_gmt_set(int unit, int32 sysport, int32 port)
{

    uint32 uRegValue;
    int32 nIndex = 0x10000 | sysport;
    eg_fd_gmt_entry_t gmtEntry;

    if ( (sysport < 0) || (sysport >= 4096) ) {
        return SOC_E_PARAM;
    }

    if ( (port < 0) || (port >= SB_FAB_DEVICE_SIRIUS_MAX_PHYSICAL_PORTS) ) {
        return SOC_E_PARAM;
    }

    uRegValue = 0x3ff00 | port;

    /* entry for packet from QE80 */
    SOC_IF_ERROR_RETURN(READ_EG_FD_GMTm(unit, MEM_BLOCK_ANY, nIndex, &gmtEntry));
    soc_mem_field32_set(unit, EG_FD_GMTm, &gmtEntry, MVRPf, uRegValue);
    SOC_IF_ERROR_RETURN(WRITE_EG_FD_GMTm(unit, MEM_BLOCK_ANY, nIndex, &gmtEntry));

 
    /* entry for packet for QE2k */
    if (sysport >= 1024)
    {
        sysport = sysport & 0x3ff;
        nIndex = 0x10000 | sysport;
        
        SOC_IF_ERROR_RETURN(READ_EG_FD_GMTm(unit, MEM_BLOCK_ANY, nIndex, &gmtEntry));
        soc_mem_field32_set(unit, EG_FD_GMTm, &gmtEntry, MVRPf, uRegValue);
        SOC_IF_ERROR_RETURN(WRITE_EG_FD_GMTm(unit, MEM_BLOCK_ANY, nIndex, &gmtEntry));
    }

    return SOC_E_NONE;
}


int soc_sirius_fd_fct_set(int unit, int32 sysport, int32 ef, int32 mc, int32 fct)
{
    uint32 regval = 0;
    int32 index = 0;
    eg_fd_fct_entry_t fct_entry;

    if ( (sysport < 0) || (sysport >= 4096) ) {
	return SOC_E_PARAM;
    }

    index = ((mc << 13) | (sysport << 1) | (ef & 0x1));
    SOC_IF_ERROR_RETURN(READ_EG_FD_FCTm(unit, MEM_BLOCK_ANY, (index >> 4), &fct_entry));
    regval = soc_mem_field32_get(unit, EG_FD_FCTm, &fct_entry, FIFO_CLASSf);
    regval &= ~(0x3 << ((index % 16)*2));
    regval |= ((fct % SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE) << ((index % 16)*2));
    soc_mem_field32_set(unit, EG_FD_FCTm, &fct_entry, FIFO_CLASSf, regval);
    SOC_IF_ERROR_RETURN(WRITE_EG_FD_FCTm(unit, MEM_BLOCK_ALL, (index >> 4), &fct_entry));

    return SOC_E_NONE;
}

int soc_sirius_fd_fct_get(int unit, int32 sysport, int32 ef, int32 mc, int32 *fct)
{
    uint32 regval = 0;
    int32 index = 0;
    eg_fd_fct_entry_t fct_entry;

    if ( (sysport < 0) || (sysport >= 4096) ) {
	return SOC_E_PARAM;
    }

    index = ((mc << 13) | (sysport << 1) | (ef & 0x1));

    SOC_IF_ERROR_RETURN(READ_EG_FD_FCTm(unit, MEM_BLOCK_ANY, (index >> 4), &fct_entry));
    regval = soc_mem_field32_get(unit, EG_FD_FCTm, &fct_entry, FIFO_CLASSf);
    *fct = (regval >> ((index % 16)*2)) & 0x3;
    return SOC_E_NONE;
}

#define FF_FC_MEM_CACHE_BLOCK     4
#define FF_FC_MEM_CACHE_ENTRIES 360

static int soc_sirius_fc_mem_cfg_check(int unit, int mem) 
{
    ff_fc_config_entry_t ff_fc_cfg;
    int fifo = 0, free = 0;
    int limit[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE];
    int en[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE];
    int base[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE];

    for (fifo = 0; fifo < SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE; fifo++) {
        SOC_IF_ERROR_RETURN(READ_FF_FC_CONFIGm(unit, MEM_BLOCK_ANY, mem*4+fifo, &ff_fc_cfg));
        limit[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, LIMITf);
        base[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, BASEf);
        en[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, ENf);
    }

    if ((limit[0] == limit[1]) && (base[0] == base[1]) && (en[0] == en[1]))
        free++;

    if ((limit[2] == limit[3]) && (base[2] == base[3]) && (en[2] == en[3])) 
        free++;

    return free;
}


static int soc_sirius_fc_cfg_check(int unit, int port, int num_fifos)
{
    ff_fc_mem_config_entry_t ff_fc_mem_cfg;
    int index = 0, port_num, free = 0;

    /*
     * Verify that we have enough mem blocks available
     */

    for (index = 0; index <= SOC_MEM_INFO(unit, FF_FC_MEM_CONFIGm).index_max; index++) {
        SOC_IF_ERROR_RETURN(READ_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, index, &ff_fc_mem_cfg));
        port_num = soc_mem_field32_get(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf);

        if (0xFF == port_num) {
            free++;
        } else if ((port == port_num) && (num_fifos == 2)) {
            if (soc_sirius_fc_mem_cfg_check(unit, index) == 1)
                free++; 
        }
    }

    return free;
}


static int soc_sirius_mem_port_find(int unit, int port, int *mem)
{
    ff_fc_mem_config_entry_t ff_fc_mem_cfg;
    int index = 0, port_num;

    for (index = 0; index <= SOC_MEM_INFO(unit, FF_FC_MEM_CONFIGm).index_max; index++) {
        SOC_IF_ERROR_RETURN(READ_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, index, &ff_fc_mem_cfg));
        port_num = soc_mem_field32_get(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf);

        if (port_num == port) {
            *mem = index;
            return SOC_E_NONE;
        }
    }

    return SOC_E_NOT_FOUND;
}


static int soc_sirius_fc_mem_get(int unit, int port, int num_fifos, int *mem_block, int *offset) 
{
    ff_fc_config_entry_t ff_fc_cfg;
    ff_fc_mem_config_entry_t ff_fc_mem_cfg;
    int index = 0, fifo = 0;
    int port_num, limit[4], en[4], base[4];

    /*
     * Verify that we have enough mem blocks available
     */

    for (index = 0; index <= SOC_MEM_INFO(unit, FF_FC_MEM_CONFIGm).index_max; index++) {
        SOC_IF_ERROR_RETURN(READ_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, index, &ff_fc_mem_cfg));
        port_num = soc_mem_field32_get(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf);

        for (fifo = 0; fifo < SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE; fifo++) {
            SOC_IF_ERROR_RETURN(READ_FF_FC_CONFIGm(unit, MEM_BLOCK_ANY, index*4 + fifo, &ff_fc_cfg));
            limit[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, LIMITf);
            base[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, BASEf);
            en[fifo] = soc_mem_field32_get(unit, FF_FC_CONFIGm, &ff_fc_cfg, ENf);
        }

        *mem_block = index;
        *offset = 0;
        if ((port_num == port) && (num_fifos == 2)) {
            if ((limit[0] == limit[1]) && (base[0] == base[1]) && (en[0] == en[1])) {
                *offset = 0;
            }
            if ((limit[2] == limit[3]) && (base[2] == base[3]) && (en[2] == en[3])) {
                *offset = 2;
            }

            break;
        } else if (port_num == port) {
            for (fifo = 0; fifo < FF_FC_MEM_CACHE_BLOCK; fifo++) {
                if ((limit[fifo] == 1) && (en[fifo] == 1) && (base[fifo] == 0)) {
                    *offset = fifo;
                    break;
                }
            }
        } else if (0xFF == port_num) {
            break;
        }

    }
    return SOC_E_NONE;
}

/*
 * Function:
 *     soc_sirius_config_ff
 * Purpose:
 *     Recalculate memory configuration for
 *     FFM based on subport/speed configuration
 * Parameters:
 *     unit     - Device number
 *
 * Returns:
 *     SOC_E_NONE - Success
 *     SOC_E_XXX  - Failure
 */
int
soc_sirius_config_ff(uint32 unit, uint16 subport, uint8 egroup, uint8 flags)
{
    int rv = SOC_E_NONE;
    bcm_sbx_subport_info_t *sp_info;
    ff_fc_config_entry_t ff_fc_cfg;
    ff_fc_mem_config_entry_t ff_fc_mem_cfg;
    fc_credits_entry_t credit;
    fifo_map_table_entry_t fifo_entry;
    int fifo = 0, num_fifos = 0, num_grp = 0, grp_idx = 0;
    int segment = 0, base = 0, en = 0, index = 0, is_empty = 0;
    int fc_avail = 0, fc_curr_mem = 0, level0_node = 0;
    int a_blocks = 0, a_loop = 0, n_blocks = 0, mem_index = 0, port = 0, tmp = 0;
    int fifo_start = 0, fifo_limit = 0, mem_cnt = 0;
    int n_mems_needed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE];
    int port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE];
    int attach_id = -1, fcd = -1;

    /* subport id check */
    if (subport >= SB_FAB_DEVICE_SIRIUS_MAX_FABRIC_PORTS) {
        LOG_WARN(BSL_LS_SOC_COMMON,
                 (BSL_META("FF: unit %d invalid subport number %d\n"), unit, subport));
	return SOC_E_PARAM;
    }

    /* Port initialization check */
    if ( (SOC_SBX_STATE(unit)->port_state == NULL) ||
         (SOC_SBX_STATE(unit)->port_state->subport_info == NULL) ) {
        return SOC_E_INIT;
    }
	    
    sp_info = &(SOC_SBX_STATE(unit)->port_state->subport_info[subport]);

    if (sp_info == NULL) {
        LOG_INFO(BSL_LS_SOC_COMMON,
                 (BSL_META("ERROR: %s , Not initialized, unit %d\n"),
                  FUNCTION_NAME(), unit));
        return SOC_E_INIT;
    }	

    /*
     * If the info structure is not valid, then do nothing
     */
    if (sp_info->valid == FALSE) {
        return SOC_E_NONE;
    }

    level0_node = sp_info->egroup[egroup].es_scheduler_level0_node;
    port = level0_node / SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE;
    num_fifos = sp_info->egroup[egroup].num_fifos;
    num_grp = num_fifos /  SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE;
    if ((num_fifos % SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE) != 0) {
        num_grp ++;
    }

    if ((flags == FF_MEM_DELETE) || (flags == FF_MEM_UPDATE)) {

        /* 
         * If fifo currently in use, then disable fifo 
         */

        for (fifo = level0_node; fifo < level0_node + num_fifos; fifo++) {
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, fifo, &fifo_entry));
            if (soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf) == 0) 
                continue;

            /* Assert Flow Control */
            rv = soc_sirius_fifo_force_full_set(unit, fifo, TRUE);
            if (rv != BCM_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("%s: fifo %d flush failed, unit %d\n"),
                           FUNCTION_NAME(), fifo, unit));
                return rv;	
            }

            /* Check if fifo depth is zero i.e. empty */
            rv = soc_sirius_fifo_empty(unit, fifo, &is_empty);
            if (rv != BCM_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("%s: fifo empty check for fifo %d failed, unit %d\n"),
                           FUNCTION_NAME(), fifo, unit));
                return rv;
            }
            
            if (is_empty == FALSE) {
                /* Flush port */
                rv = soc_sirius_port_flush(unit, fifo);
                if (rv != SOC_E_NONE) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META("%s: fifo %d flush failed, unit %d\n"),
                               FUNCTION_NAME(), fifo, unit));
                    return rv;
                }
            }

            soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf, 0);
            SOC_IF_ERROR_RETURN(WRITE_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, fifo, &fifo_entry));
        }

        /* 
         *  Clear the memory tables
         */

        sal_memset(&ff_fc_mem_cfg, 0, sizeof(ff_fc_mem_config_entry_t));
        soc_mem_field32_set(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf, 0xff);

        sal_memset(&ff_fc_cfg, 0, sizeof(ff_fc_config_entry_t));
        soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, LIMITf, 1);
        soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, ENf, 1);

        /*
         * Free each configured memory block for this subport
         */
        for (index = 0; index < num_grp; index++) {
            
            while (SOC_E_NOT_FOUND != soc_sirius_mem_port_find(unit, port + index, &mem_index)) {

                fifo_start = 0;
                fifo_limit = SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_HW_SIZE;

                /*
                 * For 2 fifo, clear the appropriate entries only
                 */
                if (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == TRUE) {
                    fifo_limit /= 2;
                    if (subport & 0x1) 
                        fifo_start = 2;
                } else if (num_fifos % FF_FC_MEM_CACHE_BLOCK) {
                    fifo_limit /= 2;
                }
                
                for(fifo = fifo_start; fifo < fifo_limit; fifo++) {
                    SOC_IF_ERROR_RETURN(
                        WRITE_FF_FC_CONFIGm(unit, MEM_BLOCK_ANY, 
                                            mem_index * FF_FC_MEM_CACHE_BLOCK + fifo,
                                            &ff_fc_cfg));
                }
                
                /* For 2-FIFO allocation, check to see if an entry is still in use */
                
                if (soc_sirius_fc_mem_cfg_check(unit, mem_index) == 2) {
                    SOC_IF_ERROR_RETURN(WRITE_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, 
                                                                mem_index, &ff_fc_mem_cfg));
                }
            }
        }
            
        /* Reset FC_CREDIT entries for the fifos */
        sal_memset(&credit, 0, sizeof(fc_credits_entry_t));
        soc_mem_field32_set(unit, FC_CREDITSm, &credit, CREDITf, 360);
        for (index = level0_node; index < level0_node + num_fifos; index++) {
            fifo = index - level0_node;
            SOC_IF_ERROR_RETURN(WRITE_FC_CREDITSm(unit, MEM_BLOCK_ANY, index, &credit));
            if (flags == FF_MEM_DELETE) {
                sp_info->egroup[egroup].port_speed[fifo] = 0;
            }
        }
        
        /*
         * If we are deleting, then we're done. Otherwise, continue to allocate
         * the new memory cache.
         */
        if (flags == FF_MEM_DELETE) {
            sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] = 0;
            return rv;
        }
    }

    num_grp = 0;
    sal_memset(n_mems_needed, 0, sizeof(n_mems_needed));
    sal_memset(port_speed, 0, sizeof(port_speed));

    /*
     * Create fifos based on port speed
     */

    for (fifo = 0; fifo < num_fifos; fifo++) {

        /* 
         * Rate based on 182 entries necessary to support 1GB/s
         * and minimum allocation of 360 entries.
         */
        
	if (sp_info->egroup[egroup].port_speed[fifo] != 0) {
            port_speed[fifo] = (((sp_info->egroup[egroup].port_speed[fifo] * 182 / 1000)) / FF_FC_MEM_CACHE_ENTRIES) + 1;
            n_mems_needed[num_grp] += port_speed[fifo];
	} else {
            port_speed[fifo] = 0;
        }


        /* Check if memory overrun will occur */
        if ((fifo % FF_FC_MEM_CACHE_BLOCK) == 
            (FF_FC_MEM_CACHE_BLOCK - 1)) {
            if (n_mems_needed[num_grp] > 64) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("%s: FF_FC_MEM_CONFIG segment overrun, unit %d\n"),
                           FUNCTION_NAME(), unit));
                return SOC_E_RESOURCE;
            }
            num_grp++;
        }
    }

    /*
     * For non-aligned fifo counts, such as ExtendedPortMode,
     * update num_grp accordingly.
     */
    if ((fifo % FF_FC_MEM_CACHE_BLOCK) != 0)
        num_grp++;

    /*
     * Convert from blocks to mems
     */
    
    mem_cnt = 0;
    for (index = 0; index < num_grp; index++) {
        n_mems_needed[index] = n_mems_needed[index] / FF_FC_MEM_CACHE_BLOCK +
            (n_mems_needed[index] % FF_FC_MEM_CACHE_BLOCK ? 1 : 0);
        mem_cnt += n_mems_needed[index];
    }

    /*
     * Verify that we have enough mem blocks available
     */

    tmp = 0;
    for (index = 0; index < num_grp; index++) {
        fc_avail = soc_sirius_fc_cfg_check(unit, port+index, num_fifos);

        if (tmp < fc_avail) 
            tmp = fc_avail;
    }
    fc_avail = tmp;

    if (mem_cnt > fc_avail) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("%s: Memory resources unavailable, current usage %d"
                            " requested %d, unit %d\n"), FUNCTION_NAME(), unit, fc_avail, mem_cnt));
        return SOC_E_RESOURCE;
    }
    
    /*
     * Write the memory tables
     */
	
    LOG_VERBOSE(BSL_LS_SOC_MEM,
                (BSL_META("%s: Requested %d memory resources for"
                          " subport %d egroup %d level0 node %d, unit %d\n"), FUNCTION_NAME(), 
                 mem_cnt, subport, egroup, level0_node, unit));

    /*
     * For each group of 4 fifos, allocate cache buffers
     */
    for (grp_idx = 0; grp_idx < num_grp; grp_idx++) {
        segment = 0;
        while (n_mems_needed[grp_idx] > 0) {
            
            sal_memset(&ff_fc_mem_cfg, 0, sizeof(ff_fc_mem_config_entry_t));
            
            /* get an available memory. */
            SOC_IF_ERROR_RETURN(soc_sirius_fc_mem_get(unit, port + grp_idx, num_fifos, &fc_curr_mem, &fifo_start)); 

            /* Keep track of each memory configured for this subport */
            
            sal_memset(&ff_fc_mem_cfg, 0, sizeof(ff_fc_mem_config_entry_t));
            soc_mem_field32_set(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_SEGMENTf, segment);
            soc_mem_field32_set(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf, port + grp_idx);
            SOC_IF_ERROR_RETURN(WRITE_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, fc_curr_mem, &ff_fc_mem_cfg));
            
            /* Available blocks per memory */
            a_loop = 0;
            if ((SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == TRUE) && (num_fifos == 2)){
                a_blocks = (FF_FC_MEM_CACHE_BLOCK - 2) * FF_FC_MEM_CACHE_ENTRIES;
            } else {
                a_blocks = (FF_FC_MEM_CACHE_BLOCK - fifo_start) * FF_FC_MEM_CACHE_ENTRIES;
            }

            while ((a_blocks > 0) && (a_loop++ < FF_FC_MEM_CACHE_BLOCK)) {
                base = fifo_start;
                
                for (fifo = fifo_start; fifo < FF_FC_MEM_CACHE_BLOCK; fifo++) {
                    sal_memset(&ff_fc_cfg, 0, sizeof(ff_fc_config_entry_t));
                    
                    if (sp_info->egroup[egroup].port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] > 0) 
                        n_blocks = 
                          (((sp_info->egroup[egroup].port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] * 182 / 1000)) / 
                             FF_FC_MEM_CACHE_ENTRIES) + 1;
                    else
                        n_blocks = 0;


                    if (port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] > 0) {
                        if (a_blocks > 0) {
                            en = 1;
                            if ((port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] > 4) && ((a_blocks / FF_FC_MEM_CACHE_ENTRIES) >= 4)) {
                                a_blocks -= (4 * FF_FC_MEM_CACHE_ENTRIES);
                                port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] -= FF_FC_MEM_CACHE_BLOCK;
                            } else {
                                if ((a_blocks / FF_FC_MEM_CACHE_ENTRIES) < port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start]) {
                                    port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] -= (a_blocks / FF_FC_MEM_CACHE_ENTRIES);
                                    a_blocks = 0;
                                } else {
                                    a_blocks -= (port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] * FF_FC_MEM_CACHE_ENTRIES);
                                    port_speed[grp_idx * FF_FC_MEM_CACHE_BLOCK + fifo - fifo_start] = 0;
                                }
                            }
                        } else {
                            en = 0;
                        }
                    } else {
                        en = 0;
                    }
                    soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, ENf, en);
                    soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, BASEf, base);
                    soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, LIMITf, (n_blocks) ? n_blocks - 1 : 0);
                    
                    SOC_IF_ERROR_RETURN(
                        WRITE_FF_FC_CONFIGm(unit, MEM_BLOCK_ANY, 
                                            fc_curr_mem * FF_FC_MEM_CACHE_BLOCK + fifo,
                                            &ff_fc_cfg));
                    
                    base += n_blocks;
                }
            }
            n_mems_needed[grp_idx]--;
            segment++;
        }
    }

    /* Set up Credits per fifo */

    for (index = level0_node; index < level0_node + num_fifos; index++) {
        sal_memset(&credit, 0, sizeof(fc_credits_entry_t));
        
        fifo = index - level0_node;
        if (sp_info->egroup[egroup].port_speed[fifo] > 0) 
            n_blocks = 
                (((sp_info->egroup[egroup].port_speed[fifo] * 182 / 1000)) / 
                 FF_FC_MEM_CACHE_ENTRIES) + 1;
        else
            n_blocks = 0;
        
        soc_mem_field32_set(unit, FC_CREDITSm, &credit, CREDITf, 
                            (n_blocks) ? n_blocks * FF_FC_MEM_CACHE_ENTRIES - 1 : 0);
        SOC_IF_ERROR_RETURN(WRITE_FC_CREDITSm(unit, MEM_BLOCK_ANY, index, &credit));
    }

    /*
     * Configure flow control based on port speed
     */

    if (sp_info->egroup[egroup].ef_fcd == (uint16)BCM_INT_SBX_INVALID_FCD) {
        if ((num_fifos != 0) && SOC_SBX_CFG(unit)->bUcqResourceAllocationMode == FALSE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("%s subport %d egroup %d flow control domain not known\n"),
                       FUNCTION_NAME(), subport, egroup));
	    return SOC_E_PARAM;
        }
    } else {
        if (SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) {
            if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 1001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 0, 0xc300, 0x3FFF80); /* dt_mem_set(unit, EF, thresh0/thresh2 shared, thresh1/thresh3 shared) */
            } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 10001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 0, 0x5dc00, 0x3FFF80);
            } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 19001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 0, 0x9c400, 0x3FFF80);
            } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 40001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 0, 0x138800, 0x3FFF80);
            } else {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 0, 0x5dc00, 0x3FFF80);
            }
        } else { /* not independent flow control */
            if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 1001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd,  /* dt_mem_set(unit, EF, thresh0, thresh1) */
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x6180, 0xc300);
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].nef_fcd, /* dt_mem_set(unit, NEF, thresh2, thresh3) */
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x12480, 0x3fff80);

            } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 10001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x1f400, 0x3e800);
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].nef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x5dc00, 0x3fff80);
            }
            else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 19001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x3e800, 0x7d000);
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].nef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0xbb800, 0x3fff80);
            } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 40001) {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x3e800, 0x7d000);
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].nef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0xbb800, 0x3fff80);
            } else {
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].ef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_EF, 0x49700, 0x92e00);
                rv = soc_sirius_dt_mem_set(unit, sp_info->egroup[egroup].nef_fcd, 
                                           SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0xdc500, 0x3fff80);
            }
        }
    }

    if (flags == FF_MEM_UPDATE) { 
        if ((sp_info->flags & SBX_SUBPORT_FLAG_TRUNK_MCAST) == 0) {
            for (index = 0; index < num_fifos; index++) {
                if ((attach_id = sp_info->egroup[egroup].fcd[index]) != -1) {
                    fcd = ATTACH_ID_FCD_GET(attach_id);
                    if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 1001) {
                        rv = soc_sirius_dt_mem_set(unit, fcd, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0xc300, 0x3fff80);
                    } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 10001) {
                        rv = soc_sirius_dt_mem_set(unit, fcd, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x5dc00, 0x3fff80);
                    } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 19001) {
                        rv = soc_sirius_dt_mem_set(unit, fcd, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x9c400, 0x3fff80);
                    } else if (sp_info->egroup[egroup].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE] < 40001) {
                        rv = soc_sirius_dt_mem_set(unit, fcd, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x138800, 0x3fff80);
                    } else {
                        rv = soc_sirius_dt_mem_set(unit, fcd, SB_FAB_XCORE_COS_FIFO_UNICAST_NEF, 0x5dc00, 0x3fff80);
                    }
                }
            }
        }

        for (index = level0_node; index < level0_node + num_fifos; index++) {
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, index, &fifo_entry));
            soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf, 1);
            SOC_IF_ERROR_RETURN(WRITE_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, index, &fifo_entry));
            
            /* De-assert Flow Control */
            rv = soc_sirius_fifo_force_full_set(unit, index, FALSE);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("%s: fifo %d flush failed, unit %d\n"),
                           FUNCTION_NAME(), index, unit));
                return rv;	
            }
        }
    }
 
   return rv;
}


static int
_soc_sirius_hw_init_ff( siriusInitParams_t *pInitParams)
{
    int32  unit = (int32) pInitParams->unit;
    int rv = SOC_E_NONE;
    ff_fc_config_entry_t ff_fc_cfg;
    ff_fc_mem_config_entry_t ff_fc_mem_cfg;
    fc_credits_entry_t credit;
    soc_timeout_t timeout;
    uint32 nInitDone = 0;
    uint32 regval = 0;
    int index = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init ff called.\n")));

    /*
     * Take EP Core logic out of of  reset
     */

    SOC_IF_ERROR_RETURN(READ_FF_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FF_CONFIGr, &regval, SOFT_RESETf, 0);
    SOC_IF_ERROR_RETURN(WRITE_FF_CONFIGr(unit, regval));

    /*
     * Initialize FIFO Memory
     */

    SOC_IF_ERROR_RETURN(READ_FF_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FF_CONFIGr, &regval, INITf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FF_CONFIGr(unit, regval));

    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_timeout_init(&timeout, _sirius_init_timeout,0);
        while(!soc_timeout_check(&timeout)) {
            SOC_IF_ERROR_RETURN(READ_FF_CONFIGr(unit, &regval));
            
            nInitDone = soc_reg_field_get(unit,FF_CONFIGr,regval,INIT_DONEf);
            if (nInitDone)
                break;
        }
        
        if (!nInitDone) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("FF Config init done timeout\n")));
            if (!SAL_BOOT_QUICKTURN) {
                return SOC_E_TIMEOUT;
            }
        }
    }

    soc_reg_field_set(unit, FF_CONFIGr, &regval, INIT_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FF_CONFIGr(unit, regval));

    SOC_IF_ERROR_RETURN(READ_FF_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, FF_CONFIGr, &regval, FF_ENABLEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FF_CONFIGr(unit, regval));

    sal_memset(&ff_fc_cfg, 0, sizeof(ff_fc_config_entry_t));
    soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, LIMITf, 1);
    soc_mem_field32_set(unit, FF_FC_CONFIGm, &ff_fc_cfg, ENf, 1);
    for (index = 0; index <= SOC_MEM_INFO(unit, FF_FC_CONFIGm).index_max; index++) {
        SOC_IF_ERROR_RETURN(WRITE_FF_FC_CONFIGm(unit, MEM_BLOCK_ANY, index, &ff_fc_cfg));
    }

    sal_memset(&ff_fc_mem_cfg, 0, sizeof(ff_fc_mem_config_entry_t));
    soc_mem_field32_set(unit, FF_FC_MEM_CONFIGm, &ff_fc_mem_cfg, PORT_NUMf, 0xff);
    for (index = 0; index <= SOC_MEM_INFO(unit, FF_FC_MEM_CONFIGm).index_max; index++) {
        SOC_IF_ERROR_RETURN(WRITE_FF_FC_MEM_CONFIGm(unit, MEM_BLOCK_ANY, index, &ff_fc_mem_cfg));
    }

    sal_memset(&credit, 0, sizeof(fc_credits_entry_t));
    soc_mem_field32_set(unit, FC_CREDITSm, &credit, CREDITf, 360);
    for (index = 0; index <= SOC_MEM_INFO(unit, FC_CREDITSm).index_max; index++) {
        SOC_IF_ERROR_RETURN(WRITE_FC_CREDITSm(unit, MEM_BLOCK_ANY, index, &credit));
    }
    return rv;
}

STATIC int
_soc_sirius_xgxs_mdio_setup(int unit, int port)
{
    soc_reg_t reg = INVALIDr;
    uint32 rval;
    uint32 devad = 5;

#ifdef BCM_SIRIUS_SUPPORT
    if (SOC_IS_SBX_SIRIUS(unit)) {
        switch(port) {
        case  0: reg = CMIC_XGXS_MDIO_CONFIG_0r; break;
        case  1: reg = CMIC_XGXS_MDIO_CONFIG_1r; break;
        case  2: reg = CMIC_XGXS_MDIO_CONFIG_2r; break;
        case  3: reg = CMIC_XGXS_MDIO_CONFIG_3r; break;
        case  4: reg = CMIC_XGXS_MDIO_CONFIG_6r; break;
        case  5: reg = CMIC_XGXS_MDIO_CONFIG_7r; break;
        case  6: reg = CMIC_XGXS_MDIO_CONFIG_8r; break;
        case  7: reg = CMIC_XGXS_MDIO_CONFIG_9r; break;
        default: return SOC_E_PARAM;
        }
    }
#endif

    if (reg == INVALIDr) {
        return SOC_E_UNAVAIL;
    }

    rval = soc_pci_read(unit, soc_reg_addr(unit, reg, REG_PORT_ANY, 0));
    soc_reg_field_set(unit, reg, &rval, MD_DEVADf, devad);
    soc_reg_field_set(unit, reg, &rval, IEEE_DEVICES_IN_PKGf,
                      IS_HG_PORT(unit, port) ? 0x03 : 0x15);
    soc_pci_write(unit, soc_reg_addr(unit, reg, REG_PORT_ANY, 0), rval);

    return SOC_E_NONE;
}

static int
_soc_sirius_hw_init_xp( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 val=0, to_usec;
    uint64 val64=COMPILER_64_INIT(0,0);
    int port;
    int32  unit = (int32) pInitParams->unit;

#ifdef _NOT_DEFINED
    soc_reg_t reg;
    int addr, hc_idx;
    int hc_port[6]; /* any port in the hyperlite block */
    uint32 txd1g_map[6];
#endif

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init xp called.\n")));

    to_usec = SAL_BOOT_QUICKTURN ? (250 * MILLISECOND_USEC) :
                                   (10 * MILLISECOND_USEC);
 
    /* XPort and Hypercore reset sequence
     *    After the chip reset state machine is in the READY state and LCPLL is locked,
     *  Hypercore can be brought up. XPORT is brought up by CMICE and itself registers.
     *  Hypercore is brought up by XPORT registers. After LC PLLs locked,
     *  they generate the 156.25Mhz reference clock to Hypercore internal PLL.
     *    1. XPORT is under reset state and all XPORT register output the default value
     *  (for example MAC_XGXS_Ctrl), so HW_rstL, PwrDwn, IDDQ, rstb_pll and rstb_mdioregs
     *  are asserted. These signals force Hypercore into reset state. The TX and RX domain
     *  inside XPORT is also held under reset.
     *    2. Software writes to cmic_soft_reset_reg to deassert XPORT reset,
     *  so CPU can access the MAC_XGXS_Ctrl register in XPORT.
     *    3. Software writes to MAC_XGXS_Ctrl register to deassert PwrDwn and IDDQ.
     *    4. Wait for about 1ms, software writes to MAC_XGXS_Ctrl register to de-assert
     *  HW_RstL. During HW_RstL is asserted, clock output from Hypercore may have glitches.
     *  But since the XPORT logic (in TX and RX clock domain) is still under reset state,
     *  (MAC_XGXS_Ctrl.XPORT_RESET is still one) the clock glitches should not affect XPORT.
     *    5. Release the HW_RstL. It activates all internal clocks within the Hypercore.
     *  While Hypercore PLL is still under reset state, all Hypercore clocks are derived
     *  from reference clock from LC PLL.
     *    6. Software writes to MAC_XGXS_Ctrl register to deassert rstb_mdioregs.
     *  This brings the Hypercore mdio register up.
     *    7. Software writes to MAC_XGXS_Ctrl register to deassert rstb_pll.
     *  this brings the Hypercore internal PLL up.
     *    8. Until internal Hypercore PLL locked, Software writes MAC_XGXS_Ctrl register to
     *  deassert XPORT_RESET.
     *    9. Software writes to MAC_XGXS_Ctrl register to deassert TXFIFO_RST_N which
     *  drives txd10g_fifio_rstb and txd1g_fifo_rstb in Hypercore.
     *    10.10. When all the clocks between XPORT and Hypercore are established, software can enable the
     *  XPORT by setting TXEN and RXEN in MAC_Ctrl register.
     */
    SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(unit, &val));
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP0_RST_Lf, 0);/* XP0 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP1_RST_Lf, 0);/* XP1 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP2_RST_Lf, 0);/* XP2 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP3_RST_Lf, 0);/* XP3 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ0_RST_Lf, 0);     /* aliased to XP4 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ1_RST_Lf, 0);     /* aliased to XP5 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ2_RST_Lf, 0);     /* aliased to XP6 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ3_RST_Lf, 0);     /* aliased to XP7 */
    SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(unit, val));
    sal_usleep(to_usec);

    /* coverity[result_independent_of_operands] */
    SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(unit, &val));
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP0_RST_Lf, 1);/* XP0 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP1_RST_Lf, 1);/* XP1 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP2_RST_Lf, 1);/* XP2 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XP3_RST_Lf, 1);/* XP3 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ0_RST_Lf, 1);     /* aliased to XP4 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ1_RST_Lf, 1);     /* aliased to XP5 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ2_RST_Lf, 1);     /* aliased to XP6 */
    soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ3_RST_Lf, 1);     /* aliased to XP7 */
    /* coverity[result_independent_of_operands] */
    SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(unit, val));
    sal_usleep(to_usec);

    /* need to de-assert reset bits to allow register access */
#ifndef SIRIUS_BCMSIM_64BITS_REG_SUPPORT
    if (!SAL_BOOT_BCMSIM)
        /* BCMSIM model doesn't support 64bits registers access for now,
         * and MAC_INIT has some 64bits registers access. Disable it
         * for now
         */
#endif
    {   uint64 uuZero = COMPILER_64_INIT(0,0), uuOne = COMPILER_64_INIT(0,1);
        /* Make BIGMAC registers accesible */
        PBMP_HG_ITER(unit, port) {
            SOC_IF_ERROR_RETURN(READ_MAC_CTRLr(unit, port, &val64));
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXRESETf, uuZero);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXRESETf, uuZero);
            SOC_IF_ERROR_RETURN(WRITE_MAC_CTRLr(unit, port, val64));
        }

        PBMP_XE_ITER(unit, port) {
            SOC_IF_ERROR_RETURN(READ_MAC_CTRLr(unit, port, &val64));
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXRESETf, uuZero);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXRESETf, uuZero);
            SOC_IF_ERROR_RETURN(WRITE_MAC_CTRLr(unit, port, val64));
        }

        PBMP_GE_ITER(unit, port) {
            SOC_IF_ERROR_RETURN(READ_MAC_CTRLr(unit, port, &val64));
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXENf, uuOne);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, TXRESETf, uuZero);
            soc_reg64_field_set(unit, MAC_CTRLr, &val64, RXRESETf, uuZero);
            SOC_IF_ERROR_RETURN(WRITE_MAC_CTRLr(unit, port, val64));
        }

        /* Reset the fusion core for HiGig ports. Does nothing in sim */
        /* Fusioncore must be out of reset before we probe for XGXS PHY.
         * Otherwise, XGXS PHY will not respond.
         */
        PBMP_GX_ITER(unit, port) {
	    _soc_sirius_xgxs_mdio_setup(unit, port);
            /* coverity [check_return] */
	    soc_xgxs_reset(unit, port);
            val = 0;
            soc_reg_field_set(unit, XPORT_XGXS_NEWCTL_REGr,
                              &val, TXD1G_FIFO_RSTBf, 0xf);
            SOC_IF_ERROR_RETURN
                (WRITE_XPORT_XGXS_NEWCTL_REGr(unit, port, val));
	}

        if (pInitParams->bResetOnly) {
            return rv;
        }

    }

    /* xport mode */
    if (SOC_PBMP_NOT_NULL(PBMP_GE_ALL(unit)) ||
	SOC_PBMP_NOT_NULL(PBMP_XE_ALL(unit)) ||
        SOC_PBMP_NOT_NULL(PBMP_HG_ALL(unit))) {

        PBMP_HG_ITER(unit, port) {
            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_CONFIGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, XPORT_ENf, 1);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG_MODEf, 1);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG2_MODEf, 1);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_CONFIGr(unit, port, val));

            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_MODE_REGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, MODE_RBf, 1);
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, XPORT_MODE_BITSf, 1);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_MODE_REGr(unit, port, val));
        }
        PBMP_XE_ITER(unit, port) {
            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_CONFIGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, XPORT_ENf, 1);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG_MODEf, 0);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG2_MODEf, 0);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_CONFIGr(unit, port, val));

            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_MODE_REGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, MODE_RBf, 1);
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, XPORT_MODE_BITSf, 1);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_MODE_REGr(unit, port, val));
        }
        PBMP_GE_ITER(unit, port) {
            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_CONFIGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, XPORT_ENf, 1);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG_MODEf, 0);
            soc_reg_field_set(unit, XPORT_CONFIGr, &val, HIGIG2_MODEf, 0);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_CONFIGr(unit, port, val));

            val = 0;
            SOC_IF_ERROR_RETURN(READ_XPORT_MODE_REGr(unit, port, &val));
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, MODE_RBf, 1);
            soc_reg_field_set(unit, XPORT_MODE_REGr, &val, XPORT_MODE_BITSf, 2);
            SOC_IF_ERROR_RETURN(WRITE_XPORT_MODE_REGr(unit, port, val));
        }

    }

    return rv;
}

static int
_soc_sirius_hw_init_bp( siriusInitParams_t *pInitParams)
{
    int    unit = (int32) pInitParams->unit;
    uint32 val  = 0;
  
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "Sirius hardware init bp called.\n")));

    if (SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME_BYPASS ||
        SOC_SBX_CFG(unit)->bTmeMode == SOC_SBX_QE_MODE_TME) {
        SOC_IF_ERROR_RETURN(READ_BP_CONFIG0r(unit, &val));
        soc_reg_field_set(unit, BP_CONFIG0r, &val, SOFT_RESET_XP4f, 0);
        soc_reg_field_set(unit, BP_CONFIG0r, &val, SOFT_RESET_XP5f, 0);
        soc_reg_field_set(unit, BP_CONFIG0r, &val, SOFT_RESET_XP6f, 0);
        soc_reg_field_set(unit, BP_CONFIG0r, &val, SOFT_RESET_XP7f, 0);
        SOC_IF_ERROR_RETURN(WRITE_BP_CONFIG0r(unit, val)); 
    }

    return SOC_E_NONE;
}

static int
_soc_sirius_hw_init_hc( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init hc called.\n")));

    return rv;
}

static int
_soc_sirius_hw_init_cmic( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    soc_control_t       *soc;
    int                 reset;
    uint32              val=0, to_usec;
    uint16              dev_id;
    uint8               rev_id;
    int                 spl=0;
    uint32              reg;
    int32  unit = (int32) pInitParams->unit;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init cmic called.\n")));

    soc = SOC_CONTROL(unit);
    reset = (int)pInitParams->reset;

    /***********************************************************************/
    /* If the device has already been initialized before, perform some     */
    /* de-initialization to avoid stomping on existing activities.         */
    /***********************************************************************/
    if (SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        (void)soc_dma_abort(unit);
    }
    if (soc->soc_flags & SOC_F_INITED) {
        (void)soc_dma_abort(unit);             /* Turns off/clean up DMA */
        (void)soc_counter_stop(unit);          /* Stop counter collection */
#ifdef INCLUDE_MEM_SCAN
        (void)soc_mem_scan_stop(unit);         /* Stop memory scanner */
#endif

#ifdef  INCLUDE_I2C
        (void)soc_i2c_detach(unit);            /* Free up I2C driver mem */
#endif
    }

    soc_cm_get_id(unit, &dev_id, &rev_id);

    /* soc_sbx_info_config(unit,dev_id); moved to attach time*/

    soc_dcb_unit_init(unit);

    /***********************************************************************/
    /* Always be sure device has correct endian configuration before       */
    /* touching registers - device may not have been configured yet.       */
    /***********************************************************************/
    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_endian_config(unit);
    }

    /***********************************************************************/
    /* Always enable bursting before doing any more reads or writes        */
    /***********************************************************************/
    if (!SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        soc_pci_burst_enable(unit);
    }

    /***********************************************************************/
    /* Begin initialization from a known state (reset).                    */
    /***********************************************************************/
    /* Attach DMA */
    if ((rv = soc_dma_attach(unit, reset)) < 0) {
        return SOC_E_INTERNAL;
    }

    if (reset && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        /* Suspend IRQ polling while resetting */
        soc_ipoll_pause(unit);

        if (soc_property_get(unit, spn_SOC_SKIP_RESET, 0)) {
            LOG_WARN(BSL_LS_SOC_COMMON,
                     (BSL_META("soc_init: skipping hard reset\n")));
        } else {
            /* CPS reset problematic on PLI, the amount of time
             * to wait is not constant and may vary from machine
             * to machine. So, don't do it.
             */
            if (!SAL_BOOT_RTLSIM) {
                /* Block interrupts while setting the busy flag */
                spl = sal_splhi();
                SOC_CONTROL(unit)->soc_flags |= SOC_F_BUSY;

                /* Unblock interrupts */
                sal_spl(spl);

                /* CMIC reset */
                soc_pci_write(unit, CMIC_CONFIG,
                              soc_pci_read(unit, CMIC_CONFIG) | CC_RESET_CPS);

                /* delay after CMIC reset */
                if (soc_feature(unit, soc_feature_reset_delay) && !SAL_BOOT_QUICKTURN) {
                    sal_usleep(1000000);
                } else {
                    if (SAL_BOOT_QUICKTURN) {
                        sal_usleep(10 * MILLISECOND_USEC);
                    } else {
                        sal_usleep(1 * MILLISECOND_USEC);
                    }
                }
            }

            /* NOTE:
             * Sirius doesn't have ARL table, but we wait here anyhow just
             * to be safe. Tune it after everything is stablized.
             */
            if (SAL_BOOT_QUICKTURN) {
                sal_usleep(250 * MILLISECOND_USEC);
            } else {
                sal_usleep(10 * MILLISECOND_USEC);
            }

            /* Restore endian mode since the reset cleared it. */
            soc_endian_config(unit);

	    /* Following a CPS Reset, a dummy read will be required to any CMIC
	     * register to flush out the stale data that exists in PCIe core
	     */
	    soc_pci_read(unit, CMIC_CONFIG);
	    sal_usleep(1000);

            /* Restore bursting */
            soc_pci_burst_enable(unit);

            /* Synchronize cached interrupt mask */
            soc_intr_disable(unit, ~0);

            /* Block interrupts */
            spl = sal_splhi();
            SOC_CONTROL(unit)->soc_flags &= ~SOC_F_BUSY;
            /* Unblock interrupts */
            sal_spl(spl);

            /* Resume IRQ polling if active */
            soc_ipoll_continue(unit);

        }

        to_usec = SAL_BOOT_QUICKTURN ? (250 * MILLISECOND_USEC) : (10 * MILLISECOND_USEC);

	if (SOC_SBX_CFG(unit)->uClockSpeedInMHz == 405) {
  	    /* GNATS 31396:
	     *   CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2.M1DIV=8'd5
	     *   CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2.M2DIV=8'd7
	     *   CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_3.NDIV_INT=9'd81
	     *   CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_1.VCO_RNG=2'd1
	     * Then:
	     *   CMIC_MISC_CONTROL.CMIC_PLL_SET_DONE = 1
	     */
	    /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(READ_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2r(unit, &val));
	    soc_reg_field_set(unit, CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2r, &val, M1DIVf, 5);
	    soc_reg_field_set(unit, CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2r, &val, M2DIVf, 7);
        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(WRITE_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_2r(unit, val));

        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(READ_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_3r(unit, &val));
	    soc_reg_field_set(unit, CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_3r, &val, NDIV_INTf, 81);
        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(WRITE_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_3r(unit, val));

        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(READ_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_1r(unit, &val));
	    soc_reg_field_set(unit, CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_1r, &val, VCO_RNGf, 1);
        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(WRITE_CMIC_CORE_PLL0_CTRL_STATUS_REGISTER_1r(unit, val));

        /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(READ_CMIC_MISC_CONTROLr(unit, &val));
	    val |= (1<<10); /* CMIC_MISC_CONTROL fields not there?? */
	    /* coverity[result_independent_of_operands] */
	    SOC_IF_ERROR_RETURN(WRITE_CMIC_MISC_CONTROLr(unit, val));
	} else if (SOC_SBX_CFG(unit)->uClockSpeedInMHz == 400) {
	    /* default */
	} else {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("%s unsupported core clock %d\n"), FUNCTION_NAME(), SOC_SBX_CFG(unit)->uClockSpeedInMHz));
	    return SOC_E_PARAM;
	}


#ifdef NOTDEF
	/* Reset */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(unit, &val));
        soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ5_RST_Lf,
                          0);                                    /* XQ5 aliased to CHIP_RST_N */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(unit, val));
        sal_usleep(to_usec);
#endif

        /* Chip_reset_n, take all blocks out of reset in sirius */
        /* coverity[unsigned_compare] */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(unit, &val));
        soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, XQ5_RST_Lf,
                          1);                                    /* XQ5 aliased to CHIP_RST_N */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(unit, val));

        /* Take lc pll out of reset
         * LC pll reset sequence:
         *    there are two LC PLL in Sirius chip. They are brought up by CPU.
         *  After chip reset state machine is in READY state.
         *  CPU programs the CMIC register to deassert the LCPLL reset,
         *  wait for LCPLL lock about 300us. Then LC PLLs are up and running.
         *  They generate the 156.25 differential clock to 10 Hypercore.
         */
        soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XG_PLL0_RST_Lf,
                          1);
        soc_reg_field_set(unit, CMIC_SOFT_RESET_REGr, &val, CMIC_XG_PLL1_RST_Lf,
                          1);
        /* coverity[unsigned_compare] */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(unit, val));
        sal_usleep(to_usec);

#ifdef NOTDEF
        /* Bring EP block out of reset */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(SIRIUS_UNIT, &val));
        soc_reg_field_set(SIRIUS_UNIT, CMIC_SOFT_RESET_REGr, &val, CMIC_EP_RST_Lf, 0);
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(SIRIUS_UNIT, val));
#endif

        /* coverity[unsigned_compare] */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(READ_CMIC_SOFT_RESET_REGr(SIRIUS_UNIT, &val));
        soc_reg_field_set(SIRIUS_UNIT, CMIC_SOFT_RESET_REGr, &val, CMIC_EP_RST_Lf, 1);
        /* coverity[unsigned_compare] */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SOFT_RESET_REGr(SIRIUS_UNIT, val));

        /* Xport and DDR block reset are in soc init of corresponding blocks */

        /*
         * Sirius ring map based on sirius 0.6.0 label
         */
        val = 0x43222216;
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SBUS_RING_MAP_0r(unit, val));

        val = 0x61030444;
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SBUS_RING_MAP_1r(unit, val));

        val = 0x32220655;
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SBUS_RING_MAP_2r(unit, val));

        val = 0x00447513;
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SBUS_RING_MAP_3r(unit, val));

        val = 0x00777610;
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(WRITE_CMIC_SBUS_RING_MAP_4r(unit, val));
    }

    /***********************************************************************/
    /* Configure CMIC PCI registers correctly for driver operation.        */
    /*                                                                     */
    /* NOTE:  When interrupt driven, the internal SOC registers cannot     */
    /*        be accessed until the CMIC interrupts are enabled.           */
    /***********************************************************************/
    if (!SAL_BOOT_PLISIM && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        /*
         * Check that PCI memory space is mapped correctly by running a
         * quick diagnostic on the S-Channel message buffer.
         */
        /* coverity[result_independent_of_operands] */
        SOC_IF_ERROR_RETURN(soc_pci_test(unit));
    }

    if (soc_feature(unit, soc_feature_has_gbp) && !SOC_WARM_BOOT(unit) && !SOC_IS_DETACHING(unit)) {
        /*
         * Check that GBP OK bit is set, there could be a problem with
         * external SDRAM in which case a GBP fail message could be sent
         * which sets this bit.
         */

        if (!(soc_pci_read(unit, CMIC_SCHAN_CTRL) & SC_GBP_OK_TST)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META("soc_init: GBP currently FULL or UNAVAILABLE\n")));
            return SOC_E_INTERNAL;
        }
    }

    /*
     * Adjust the CMIC CONFIG register
     */
    reg = soc_pci_read(unit, CMIC_CONFIG);

    /*
     * Enable enhanced DMA modes:
     *  Scatter/gather, reload, and unaligned transfers
     *
     * Enable read and write bursts.
     *  Note: very fast CPUs (above ~500 MHz) may combine multiple
     *  memory operations into bursts.  The CMIC will hang if burst
     *  operations are not enabled.
     */
    reg |= (CC_SG_OPN_EN | CC_RLD_OPN_EN | CC_ALN_OPN_EN |
            CC_RD_BRST_EN | CC_WR_BRST_EN);

    if (SAL_BOOT_PLISIM) {
        /* Set interrupt polarity to active high */
        reg &= ~CC_ACT_LOW_INT;
    }
    soc_pci_write(unit, CMIC_CONFIG, reg);


    /*
     * Configure DMA channels.
     */
    if (soc_dma_init(unit) != 0) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("soc_init: unit %d DMA initialization failed\n"),
                   unit));
        return SOC_E_INTERNAL;
    }

    /*
     * PCI Bus Error and Parity Error Interrupts
     */
    soc_intr_enable(unit, IRQ_PCI_PARITY_ERR | IRQ_PCI_FATAL_ERR);

    /*
     * S-Channel Error Interrupt
     */
    soc_intr_enable(unit, IRQ_SCHAN_ERR);

    /*
     * S-Channel Operation Complete Interrupt.
     * This interrupt is enabled in soc_schan_op().
     *
     * The SCH_MSG_DONE bit must be cleared after chip reset, since it
     * defaults to 1.  Otherwise, the interrupt will occur as soon as
     * it's enabled.
     */
    soc_pci_write(unit, CMIC_SCHAN_CTRL, SC_MSG_DONE_CLR);
    /*
     * MIIM Operation Complete Interrupt
     * This interrupt is enabled in cmic_miim_read/write().
     *
     * The SCH_MIIM_OP_DONE bit must be cleared after chip reset, since
     * it defaults to 1.  Otherwise, the interrupt will occur as soon as
     * it's enabled.
     */
    soc_pci_write(unit, CMIC_SCHAN_CTRL, SC_MIIM_OP_DONE_CLR);

    /*
     * Link status updates, GBP Full Warning
     */

    if (soc_feature(unit, soc_feature_has_gbp) && soc->gbpFullEnable) {
        soc_intr_enable(unit, IRQ_GBP_FULL);
    }

    soc_intr_enable(unit, IRQ_LINK_STAT_MOD);


    return rv;
}

static int
_soc_sirius_hw_init_xmac( siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META("Sirius hardware init xmac called.\n")));

    return rv;
}

/* use uPort=REG_PORT_ANY if not required
 * use index=0 if not required */
/* not tested yet */
sbBool_t
sirius_reg_done_timeout(int unit,
                         uint32 uReg,
                         uint32 uPort,
                         uint32 index,
                         uint32 uDonefield,
                         uint32 uTimeout) {

    uint32 uRegaddr;
    uint32 uRegvalue = 0;
    uint32 uDone = 0;
    soc_timeout_t timeout;

    if (SOC_WARM_BOOT(unit) || SOC_IS_DETACHING(unit)) 
        return ( FALSE );

    uRegaddr = soc_reg_addr(unit,uReg,uPort,index);
    soc_timeout_init(&timeout, uTimeout,0);
    while(!soc_timeout_check(&timeout)) {
        SOC_IF_ERROR_RETURN(soc_reg32_read(unit,uRegaddr,&uRegvalue));

        uDone = soc_reg_field_get(unit,uReg,uRegvalue,uDonefield);
        if (uDone) {
            return ( FALSE );
        }
    }

    return ( TRUE );
}

static void
_soc_sirius_init_default_params(siriusInitParams_t *pInitParams) {
    int ci;
    int intf;
    int level;
    int link, sfi_port;

    int32  unit = (int32) pInitParams->unit;
    int32  timeslot;

    if (SAL_BOOT_QUICKTURN) {
        _sirius_init_timeout = 20000 * MILLISECOND_USEC;
    } else {
        _sirius_init_timeout = 20 * MILLISECOND_USEC;
    }

    _sirius_init_timeout = soc_property_get(unit, "sirius_init_timeout_in_usec", _sirius_init_timeout);

    /* CI parameters */
    pInitParams->uClockSpeedInMHz = SOC_SBX_CFG(unit)->uClockSpeedInMHz;
    pInitParams->uDdr3ClockMhz = SOC_SBX_CFG_SIRIUS(unit)->uDdr3ClockMhz;
    pInitParams->uDdr3NumMemories = SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumMemories;

    pInitParams->uMaxBuffer = 256*1024; /* default to 256K buffers */
    switch (pInitParams->uDdr3NumMemories) {
	case 10:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
	        /* 1Gbit memory with 5KB buffer size */
		pInitParams->uNumColBits = 1;
		pInitParams->uBufferSize = 5;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		/* 1Gbit memory with 10KB buffer size */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 10;
		pInitParams->uMaxBuffer = 128*1024;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 2048) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
	        /* 2Gbit memory with 10KB buffer size */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 10;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 8:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uNumColBits = 1;
		pInitParams->uBufferSize = 4;		    
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 8;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 6:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
	        /* 1Gbit memory with 3KB buffer size */
		pInitParams->uNumColBits = 1;
		pInitParams->uBufferSize = 3;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
	        /* 1Gbit memory with 6KB buffer size */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 6;
		pInitParams->uMaxBuffer = 128*1024;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 2048) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
	        /* 2Gbit memory with 6KB buffer size */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 6;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 5:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 5;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 4:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uNumColBits = 1;
		pInitParams->uBufferSize = 2;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 4;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 2048) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 4;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 4096) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 4096)) {
		pInitParams->uMaxBuffer = 128*1024; /* 128K buffers */
		pInitParams->uNumColBits = 3;
		pInitParams->uBufferSize = 8;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 3:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 2048) &&
        	(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uMaxBuffer = 128*1024; /* 128K buffers */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 3;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		pInitParams->uMaxBuffer = 128*1024; /* 128K buffers */
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 3;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 4096) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 4096)) {
		pInitParams->uMaxBuffer = 64*1024; /* 64K buffers */
		pInitParams->uNumColBits = 3;
		pInitParams->uBufferSize = 6;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	case 2:
	    if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		(SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uNumColBits = 1;
		pInitParams->uBufferSize = 1;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 1024) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 16384)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 2;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 2048) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 8192)) {
		pInitParams->uNumColBits = 2;
		pInitParams->uBufferSize = 2;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 4096) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 4096)) {
		pInitParams->uMaxBuffer = 128*1024; /* 128K buffers */
		pInitParams->uNumColBits = 3;
		pInitParams->uBufferSize = 4;
	    } else if ((SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns == 8192) &&
		       (SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows == 2048)) {
		pInitParams->uMaxBuffer = 64*1024; /* 64K buffers */
		pInitParams->uNumColBits = 4;
		pInitParams->uBufferSize = 8;
	    } else {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META("unsupported DDR config num/col/row ddr(%d)(%d)(%d))\n"),
                           pInitParams->uDdr3NumMemories,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumColumns,
                           SOC_SBX_CFG_SIRIUS(unit)->uDdr3NumRows));
		return;
	    }
	    break;
	default:
	    break;
    }

    SOC_SBX_CFG_SIRIUS(unit)->uMaxBuffers = pInitParams->uMaxBuffer;

    for (ci = 0; ci < pInitParams->uDdr3NumMemories; ci++ ) {
        /* may need more soc properties if some ci's require hw
         * and others use sw for now all either sw or hw
         */
        if (soc_property_get(unit,spn_SIRIUS_DDR_HW_TRAIN,1)) {
            pInitParams->ci[ci].bHwRunTimeDDRCalibration = TRUE;
        } else {
            pInitParams->ci[ci].bHwRunTimeDDRCalibration = FALSE;
        }
        pInitParams->ci[ci].bBringUp = TRUE;

        /* set CI specific init parameters here as needed.
         * Then program the appropriate CI_CONFIGx register
         * during ci init.
         */
	pInitParams->ci[ci].mem_grade = SOC_SBX_CFG_SIRIUS(unit)->uDdr3MemGrade; /* default to 0 */
    }

    /* TS parameters */
    if (soc_feature(unit, soc_feature_standalone) ||
        soc_feature(unit, soc_feature_hybrid) ) {
        pInitParams->ts.bBringUp = TRUE;

        pInitParams->ts.bEgressFifoIndependentFlowControl = SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl;
        pInitParams->ts.bDualLocalGrants = SOC_SBX_CFG_SIRIUS(unit)->bDualLocalGrants;

        
        pInitParams->ts.uLeafBgPeriod = 0;

	/* if in hybrid mode, start local sysport from the max fic sysports system support
	 * 2816 in polaris case
	 */
	/* pInitParams->ts.nSysportBase = SOC_SBX_CFG(unit)->num_sysports; */
	/* In the SS-PL system, it is also possible to have num_of_local_sysports=512.
	 * This is the Hybrid case and we need to allow for that, it probably doesn't
	 * impact your code as I imagine the local/fabric sides are disjoint but just
	 * in case I wanted to mention that.
	 */
	/* if in pure tme mode, start from same sysport so that it's easier to setup flow controls.
	 * this is not used in fic mode  
	 */
	pInitParams->ts.nSysportBase = SIRIUS_TS_LOCAL_SYSPORT_BASE;

        pInitParams->ts.b8kNodes = SOC_SBX_CFG_SIRIUS(unit)->b8kNodes;

        {
            /* Default config strategy:
             *   All levels are used, all available nodes are used.
             *   level 1 is configured to finish all nodes of that level in 256K cycles,
             *     regardless of the number of nodes in the system
             *   level 2 is configured to finish all nodes of that level in 128K cycles
             *   level 3 is configured to finish all nodes of that level in 32K cycles
             *   all other levels use max leak cycles to minmize memory bandwidth impact
             *   Level 1 support rate up to 12.8Gbps, assuming 400Mhz clock
             *   Level 2 support rate up to 25.6Gbps, assuming 400Mhz clock
             *   Level 3 support rate up to 102.4Gbps, assuming 400Mhz clock, which is higher than
             *          rate supported by sirius
             */
            pInitParams->ts.uNumTsNode[0] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[0];
            pInitParams->ts.bBypassLevel[0] = FALSE;     /* no bypass on leaf level */

            pInitParams->ts.uNumTsNode[1] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[1];
            if (pInitParams->ts.b8kNodes) {
                /* 8K level 1 Nodes */
                /* set the level 1 leak cycles to be 32 cycles, assuming all 8k nodes are used
                 * this will make the leak cycle 32*8K = 256K cycles = 2^18 cycles, given the creditor
                 * bucket size is 23 bits, this will restrict the rate to be less than 2^5 = 32bits/cycle
                 * which is equal to 12.8Gbps at level 1 creditor. Otherwise, without aperiodic update, the
                 * update cycle would be so long that each leak will exhaust the whole bucket.
                 */
                /* aperiodic leak is used to speed up the periodic update by leading ahead of scheduled
                 * periodic leak when system is idle, for level 1, set to 256 cycles for now, may
                 * need to be tuned later
                 */
                pInitParams->ts.bBypassLevel[1] = FALSE;     /* no bypass */
                pInitParams->ts.uLeakCycle[1] = 0x10;        /* 32 cycles */
                pInitParams->ts.uAperiodicInterval[1] = 0x8; /* 256 cycles */

            } else {
                /* 16K level 1 Nodes */
                /* set the level 1 leak cycles to be 16 cycles, which is the fastest it could go
                 * it can support upto 12.8Gbps at level 1 creditor.
                 */
                /* aperiodic leak set to 256 cycles for now, may need to be tuned later on
                 */
                pInitParams->ts.bBypassLevel[1] = FALSE;     /* no bypass */
                pInitParams->ts.uLeakCycle[1] = 0x0;         /* 16 cycles */
                pInitParams->ts.uAperiodicInterval[1] = 0x8; /* 256 cycles */

            }

            /* default to use all nodes available */
            pInitParams->ts.uNumTsNode[2] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[2];
            pInitParams->ts.bBypassLevel[2] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[2] = 0x10;        /* 32 cycles */
            pInitParams->ts.uAperiodicInterval[2] = 0x8; /* 256 cycles */

            pInitParams->ts.uNumTsNode[3] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[3];
            pInitParams->ts.bBypassLevel[3] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[3] = 0x10;        /* 32 cycles */
            pInitParams->ts.uAperiodicInterval[3] = 0x7; /* 128 cycles */

            pInitParams->ts.uNumTsNode[4] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[4];
            pInitParams->ts.bBypassLevel[4] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[4] = 0x1E;        /* 46 cycles */
            pInitParams->ts.uAperiodicInterval[4] = 0x7; /* 128 cycles */

            pInitParams->ts.uNumTsNode[5] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[5];
            pInitParams->ts.bBypassLevel[5] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[5] = 0x10;        /* 32 cycles */

            pInitParams->ts.uNumTsNode[6] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[6];
            pInitParams->ts.bBypassLevel[6] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[6] = 0x10;        /* 32 cycles */

            pInitParams->ts.uNumTsNode[7] = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[7];
            pInitParams->ts.bBypassLevel[7] = FALSE;     /* no bypass */
            pInitParams->ts.uLeakCycle[7] = 0x1E;        /* 46 cycles */

            for (level = 0; level < SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS; level++) {
                if (pInitParams->ts.uNumTsNode[level] == 0) {
                    pInitParams->ts.bBypassLevel[level] = TRUE;
                    pInitParams->ts.uLeakCycle[level] = 0x1E;
                }
            }
        }

        /* root interface plane and weight */
        for (intf = 0; intf <SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES; intf++) {
            pInitParams->ts.uInterfacePlane[intf] = SOC_SBX_CFG_SIRIUS(unit)->uInterfacePlane[intf];
            pInitParams->ts.uInterfaceWeight[intf] = SOC_SBX_CFG_SIRIUS(unit)->uInterfaceWeight[intf];
        }

    } else {
        pInitParams->ts.bBringUp = FALSE;
    }

    /* SCI/SFI parameters */
    if (!soc_feature(unit, soc_feature_standalone)) {
        /* don't bring up in TME mode */
        pInitParams->sf.bTmeOnly = FALSE;
        
        pInitParams->sc.bBringUp = TRUE;
        pInitParams->sc.uDefaultBmId = SOC_SBX_CFG(unit)->uActiveScId;
        pInitParams->sc.uQuadDone = 0;
        pInitParams->sc.uSerdesSpeed = SOC_SBX_CFG(unit)->uSerdesSpeed;
        pInitParams->sc.bSerdesEncoding = SOC_SBX_CFG(unit)->bSerdesEncoding;
        
        /* map links to itself */
        for (link = 0; link < SB_FAB_DEVICE_SIRIUS_LINKS; link++) {
            pInitParams->sc.uLinkEnRemap[link] = link;
        }
        
        for (link = 0; link < SB_FAB_DEVICE_SIRIUS_SFI_LINKS; link++) {
            pInitParams->sc.uLinkStatusRemap[link] = link;
        }
        for (link = SB_FAB_DEVICE_SIRIUS_SFI_LINKS; link < SB_FAB_DEVICE_SIRIUS_INTERNAL_LINKS; link++) {
            pInitParams->sc.uLinkStatusRemap[link] = 0x1f;
        }
        
        for (link = 0; link < SB_FAB_DEVICE_SIRIUS_LINKS; link++) {
            pInitParams->sc.uJitTolerance[link] = 20;
            pInitParams->sc.bEvenChannelOn[link] = TRUE;
            pInitParams->sc.bOddChannelOn[link] = TRUE;
        }
        
        pInitParams->sf.bBringUp = TRUE;
        
        for (sfi_port = 0; sfi_port < SB_FAB_DEVICE_SIRIUS_SFI_PORTS; sfi_port++) {
            /* default to enable all sfi ports */
            pInitParams->sf.uSfiPortEnable[sfi_port] = TRUE;
            
            /* default to remap to itself */
            pInitParams->sf.uSfiPortRemap[sfi_port] = sfi_port;
            
            /* default to 0 for idle frequency */
            pInitParams->sf.uSfiPortIdleFreq[sfi_port] = 0;
            
            /* default to no loopbacks for FIC mode, 
             * hybrid mode always loopback channel 44/45 (shared with scis), other ports
             * loopbacks done by port ability API
             */
            if ( (soc_feature(unit, soc_feature_hybrid)) &&
                 (sfi_port >= 44) ) {
                pInitParams->sf.uSfiPortLoopback[sfi_port] = TRUE;
            } else {
                pInitParams->sf.uSfiPortLoopback[sfi_port] = FALSE;
            }
            
            /* Disable odd channels if running 3125 and not in hybrid mode those channels are not used */
            if ((SOC_SBX_CFG(unit)->uSerdesSpeed == 3125) && (sfi_port%2==1 || sfi_port >= 44) && !(soc_feature(unit, soc_feature_hybrid))) {
                pInitParams->sf.uSfiPortEnable[sfi_port] = FALSE;
            } 
            
            /* follow the dv code, set port 44/45 to enable backpressure */
            if (sfi_port < (SB_FAB_DEVICE_SIRIUS_SFI_PORTS - 2)) {
                pInitParams->sf.uSfiPortBackpressure[sfi_port] = FALSE;
            } else {
                pInitParams->sf.uSfiPortBackpressure[sfi_port] = TRUE;
            }
        }
        
        /* By default, set to 3 errors in 255...will be overwritten later */
        pInitParams->uSiLsWindow = 255;
        pInitParams->uSiLsThreshold = 3;
        
    } else {
        if (!SAL_BOOT_BCMSIM && soc_property_get(unit, spn_DIAG_EMULATOR_PARTIAL_INIT, 0)) {
            pInitParams->sf.bBringUp = TRUE;
            pInitParams->sc.bBringUp = FALSE;        
            pInitParams->sf.bTmeOnly = TRUE;      
        } else {
            pInitParams->sf.bBringUp = TRUE;
            pInitParams->sc.bBringUp = TRUE;        
            pInitParams->sf.bTmeOnly = TRUE;
            
            for (sfi_port = 0; sfi_port < SB_FAB_DEVICE_SIRIUS_SFI_PORTS; sfi_port++) {
                /* default to enable all sfi ports */
                pInitParams->sf.uSfiPortEnable[sfi_port] = TRUE;
                
                /* default to remap to itself */
                pInitParams->sf.uSfiPortRemap[sfi_port] = sfi_port;
                
                /* default to no loopbacks (used in hybrid mode only) */
                pInitParams->sf.uSfiPortLoopback[sfi_port] = TRUE;
                
                /* follow the dv code, set port 44/45 to enable backpressure */
                if (sfi_port < (SB_FAB_DEVICE_SIRIUS_SFI_PORTS - 2)) {
                    pInitParams->sf.uSfiPortBackpressure[sfi_port] = FALSE;
                } else {
                    pInitParams->sf.uSfiPortBackpressure[sfi_port] = TRUE;
                }
            }
        }
    }
    
    /* qs params */
    pInitParams->nMaxVoq = SOC_SBX_CFG_SIRIUS(unit)->nMaxVoq;

    /* Default EPOCH calculation */
    timeslot = soc_sbx_fabric_get_timeslot_size(unit, 
                              soc_property_get(unit, spn_SIRIUS_LINKS, 
                                               SB_FAB_DEVICE_SIRIUS_SFI_LINKS),
                              SOC_SBX_CFG_QE2000(unit)->bHalfBus,
                              soc_feature(unit, soc_feature_hybrid));
    switch (SOC_SBX_CFG(unit)->uFabricConfig) {
        case SOC_SBX_SYSTEM_CFG_VPORT:
        case SOC_SBX_SYSTEM_CFG_VPORT_LEGACY:
        case SOC_SBX_SYSTEM_CFG_VPORT_MIX:
            pInitParams->uEpochSizeInNs = 
                     (SOC_SBX_CFG(unit)->epoch_length_in_timeslots * timeslot);
            break;

        case SOC_SBX_SYSTEM_CFG_DMODE: /* DMode (Default) - Bm3200 + Qe2000 */
        default:
            LOG_ERROR(BSL_LS_SOC_FABRIC,
                      (BSL_META_U(unit,
                                  "Unit %d unknown fabric_configuration=%d"),
                       unit, SOC_SBX_CFG(unit)->uFabricConfig));
    }

    /* Arrival Rate */
    pInitParams->uQmMaxArrivalRateMbs = SOC_SBX_CFG_SIRIUS(unit)->uQmMaxArrivalRateMbs;

    pInitParams->spMode =  SOC_SBX_CFG(unit)->sp_mode;

    /* EP per interface shaping bus length adjust */
    for (intf = 0; intf <SB_FAB_DEVICE_SIRIUS_MAX_SCHED_INTERFACES; intf++) {
        pInitParams->ep.shapingBusLengthAdj[intf] = SOC_SBX_CFG_SIRIUS(unit)->shapingBusLengthAdj[intf];
    }

    /* FD initialisation parameters */
    pInitParams->fd.mvrMaxSize = SOC_SBX_CFG_SIRIUS(unit)->mvrMaxSize;
}



/*
 * this function should not be called directly.
 * use macros defined in ddr23.h to access DDR23 phy registers
 */
int
phy_reg_ci_read(int unit, uint32 ci, uint32 reg_addr, uint32 *data)
{
    int rv = SOC_E_NONE;
    uint32 uCmd;

    uCmd = 0;
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_ACKf, 1);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_REQf, 1);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_RD_WR_Nf, 1);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_ADDRf, reg_addr);

    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_PHY_REG_CTRLr(unit, ci, uCmd));

    LOG_VERBOSE(BSL_LS_SOC_PHY,
                (BSL_META_U(unit,
                            "read ci %d phy addr 0x%x return 0x%x.\n"),
                 ci, reg_addr, *data));

    if (SAL_BOOT_BCMSIM || SAL_BOOT_QUICKTURN) {
        /* BCMSIM don't support DDR phys, return 0xFFFFFFFF so that
         * various config done bits will be set
         */
        *data = 0xFFFFFFFF;
    } else {
        if (sirius_reg_done_timeout(unit, CI_DDR_PHY_REG_CTRLr, ci,
                                    0, PHY_REG_ACKf, _sirius_init_timeout) ) {

            LOG_WARN(BSL_LS_SOC_COMMON,
                     (BSL_META_U(unit,
                                 "DDR PHY read CI%d timedout\n"),ci));
            return SOC_E_TIMEOUT;
        }

        SOC_IF_ERROR_RETURN(READ_CI_DDR_PHY_REG_DATAr(unit, ci, data));
    }

    return rv;
}

/*
 * this function should not be called directly.
 * use macros defined in ddr23.h to access DDR23 phy registers
 */
int
phy_reg_ci_write(int unit, uint32 ci, uint32 reg_addr, uint32 data)
{
    int rv = SOC_E_NONE;
    uint32 uCmd;

    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_PHY_REG_DATAr(unit, ci, data));

    uCmd = 0;
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_ACKf, 1);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_REQf, 1);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_RD_WR_Nf, 0);
    soc_reg_field_set(unit, CI_DDR_PHY_REG_CTRLr, &uCmd, PHY_REG_ADDRf, reg_addr);

    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_PHY_REG_CTRLr(unit, ci, uCmd));

    LOG_VERBOSE(BSL_LS_SOC_PHY,
                (BSL_META_U(unit,
                            "write ci %d phy addr 0x%x value 0x%x.\n"),
                 ci, reg_addr, data));
    if (!(SAL_BOOT_BCMSIM  || SAL_BOOT_QUICKTURN)) {
        if (sirius_reg_done_timeout(unit, CI_DDR_PHY_REG_CTRLr, ci,
                                    0, PHY_REG_ACKf, _sirius_init_timeout) ) {

            LOG_WARN(BSL_LS_SOC_COMMON,
                     (BSL_META_U(unit,
                                 "DDR PHY write CI%d timedout\n"),ci));
            return SOC_E_TIMEOUT;
        }
    }

    return rv;
}

/*
 * this function should not be called directly.
 * use macros defined in ddr23.h to access DDR23 phy registers
 */
int
phy_reg_ci_modify(int unit, uint32 ci, uint32 reg_addr, uint32 data, uint32 mask)
{
    int rv = SOC_E_NONE;
    uint32 tmp = 0, otmp;

    data = data & mask;

    SOC_IF_ERROR_RETURN(phy_reg_ci_read(unit, ci, reg_addr, &tmp));
    otmp = tmp;
    tmp &= ~(mask);
    tmp |= data;

    if (otmp != tmp) {
        SOC_IF_ERROR_RETURN
            (phy_reg_ci_write(unit, ci, reg_addr, tmp));
    }

    return rv;
}


/*
 * configure ts (ingress) node hierachy info
 *    level:            scheduler level 0-8
 *    node:             scheduler node. valid range depends on level and config
 *    parent:           parent node, assuming 1 level higher. SOC_SIRIUS_API_PARAM_NO_CHANGE if no change
 *    first_child:      first child node, SOC_SIRIUS_API_PARAM_NO_CHANGE if no change.
 *                      num_child = 0 if no child
 *    num_child:        0-8, SOC_SIRIUS_API_PARAM_NO_CHANGE if no change
 */
int
soc_sirius_ts_node_hierachy_config(int unit, uint32 level, uint32 node, int32 parent,
                                   int32 first_child, int32 num_child)
{
    int rv = SOC_E_NONE;
    l1_n2_entry_t l1_entry;
    l2_n2_entry_t l2_entry;
    l3_n2_entry_t l3_entry;
    l4_n2_entry_t l4_entry;
    l5_n2_entry_t l5_entry;
    l6_n2_entry_t l6_entry;
    l7_n2_entry_t l7_entry;

    /* Sanity check parameters */
    if ((level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if (level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s TS root node fix mapped to have 7 children\n"),
                   FUNCTION_NAME()));
        return SOC_E_PARAM;
    } else if (level == 0) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s TS leaf node %d fix mapped to level 1 node %d\n"),
                   FUNCTION_NAME(), node, (SOC_SBX_CFG_SIRIUS(unit)->b8kNodes)?(node/8):(node/4)));
        return SOC_E_PARAM;
    } else {
        if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                       node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
            return SOC_E_PARAM;
        }
        if ( (level == 1) && (num_child != 0) && (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) ) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s can not specify child for TS level %d node %d\n"), FUNCTION_NAME(),
                       level, node));
            return SOC_E_PARAM;
        }
        if ( parent != SOC_SIRIUS_API_PARAM_NO_CHANGE ) {
            if ( (level != 7) && ((parent < 0) || (parent >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level+1])) ) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "%s invalid TS parent node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                           parent, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level+1]));
                return SOC_E_PARAM;
            }
        }
    }

    if ( (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((num_child < 0) || (num_child > 8)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS number of child for node %d, valid range [0 - 8]\n"),
                   FUNCTION_NAME(), node));
        return SOC_E_PARAM;
    }

    if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        if ( (first_child < 0) || (first_child >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1]) ) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s invalid TS first child node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                       first_child, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1]));
            return SOC_E_PARAM;
        }
        if ( (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (num_child != 0) ) {
            if ( (first_child + num_child - 1) >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1] ) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "%s invalid TS last child node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                           (first_child + num_child - 1), SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1]));
                return SOC_E_PARAM;
            }
        }
    }

    /* read the node info 2 table for the level */
    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_N2m(unit, MEM_BLOCK_ANY, node, &l1_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_N2m, &l1_entry, PARENT_NODEf, parent);
                SOC_IF_ERROR_RETURN(WRITE_L1_N2m(unit, MEM_BLOCK_ANY, node, &l1_entry));
            }
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_N2m(unit, MEM_BLOCK_ANY, node, &l2_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_N2m, &l2_entry, PARENT_NODEf, parent);
            }
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_N2m, &l2_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L2_N2m, &l2_entry, FIRST_CHILD_NODEf,
					SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[1]-1);
                    soc_mem_field32_set(unit, L2_N2m, &l2_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L2_N2m, &l2_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_N2m(unit, MEM_BLOCK_ANY, node, &l2_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_N2m(unit, MEM_BLOCK_ANY, node, &l3_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_N2m, &l3_entry, PARENT_NODEf, parent);
            }
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_N2m, &l3_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L3_N2m, &l3_entry, FIRST_CHILD_NODEf, 0xFFF);
                    soc_mem_field32_set(unit, L3_N2m, &l3_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L3_N2m, &l3_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_N2m(unit, MEM_BLOCK_ANY, node, &l3_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_N2m(unit, MEM_BLOCK_ANY, node, &l4_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_N2m, &l4_entry, PARENT_NODEf, parent);
            }
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_N2m, &l4_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L4_N2m, &l4_entry, FIRST_CHILD_NODEf, 0x3FF);
                    soc_mem_field32_set(unit, L4_N2m, &l4_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L4_N2m, &l4_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_N2m(unit, MEM_BLOCK_ANY, node, &l4_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_N2m(unit, MEM_BLOCK_ANY, node, &l5_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_N2m, &l5_entry, PARENT_NODEf, parent);
            }
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_N2m, &l5_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L5_N2m, &l5_entry, FIRST_CHILD_NODEf, 0x107);
                    soc_mem_field32_set(unit, L5_N2m, &l5_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L5_N2m, &l5_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_N2m(unit, MEM_BLOCK_ANY, node, &l5_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_N2m(unit, MEM_BLOCK_ANY, node, &l6_entry));
            if (parent != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_N2m, &l6_entry, PARENT_NODEf, parent);
            }
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_N2m, &l6_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L6_N2m, &l6_entry, FIRST_CHILD_NODEf, 0x83);
                    soc_mem_field32_set(unit, L6_N2m, &l6_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L6_N2m, &l6_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_N2m(unit, MEM_BLOCK_ANY, node, &l6_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_N2m(unit, MEM_BLOCK_ANY, node, &l7_entry));
            if (first_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_N2m, &l7_entry, FIRST_CHILD_NODEf, first_child);
            }
            if (num_child != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_child == 0) {
                    /* set to point to the last node in the child level */
                    soc_mem_field32_set(unit, L7_N2m, &l7_entry, FIRST_CHILD_NODEf, 0x37);
                    soc_mem_field32_set(unit, L7_N2m, &l7_entry, LAST_CHILD_OFFSETf, 0);
                } else {
                    soc_mem_field32_set(unit, L7_N2m, &l7_entry, LAST_CHILD_OFFSETf, num_child - 1);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_N2m(unit, MEM_BLOCK_ANY, node, &l7_entry));
            break;
        /* coverity[dead_error_begin] */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported TS level %d, valid range [0 - %d]\n"),
                       FUNCTION_NAME(), level, SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS));
            break;
    }

    return rv;
}

/*
 * get ts (ingress) node hierachy info
 *    level:            scheduler level 0-8
 *    node:             scheduler node. valid range depends on level and config
 *    parent:           parent node, assuming 1 level higher. SOC_SIRIUS_API_PARAM_NO_CHANGE if no change
 *    first_child:      first child node, SOC_SIRIUS_API_PARAM_NO_CHANGE if no change.
 *                      num_child = 0 if no child
 *    num_child:        0-8, SOC_SIRIUS_API_PARAM_NO_CHANGE if no change
 */
int
soc_sirius_ts_node_hierachy_config_get(int unit, uint32 level, uint32 node, int32 *parent,
				       int32 *first_child, int32 *num_child)
{
    int rv = SOC_E_NONE;
    l1_n2_entry_t l1_entry;
    l2_n2_entry_t l2_entry;
    l3_n2_entry_t l3_entry;
    l4_n2_entry_t l4_entry;
    l5_n2_entry_t l5_entry;
    l6_n2_entry_t l6_entry;
    l7_n2_entry_t l7_entry;

    /* Sanity check parameters */
    if ((level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if (level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s TS root node fix mapped to have 7 children\n"),
                   FUNCTION_NAME()));
        return SOC_E_PARAM;
    } else if (level == 0) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s TS leaf node %d fix mapped to level 1 node %d\n"),
                   FUNCTION_NAME(), node, (SOC_SBX_CFG_SIRIUS(unit)->b8kNodes)?(node/8):(node/4)));
        return SOC_E_PARAM;
    } else {
        if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                       node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
            return SOC_E_PARAM;
        }
    }

    /* read the node info 2 table for the level */
    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_N2m(unit, MEM_BLOCK_ANY, node, &l1_entry));
            *parent = soc_mem_field32_get(unit, L1_N2m, &l1_entry, PARENT_NODEf);
	    *num_child = (SOC_SBX_CFG_SIRIUS(unit)->b8kNodes)?8:4;
	    *first_child = (SOC_SBX_CFG_SIRIUS(unit)->b8kNodes)?(node*8):(node*4);
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_N2m(unit, MEM_BLOCK_ANY, node, &l2_entry));
	    *parent = soc_mem_field32_get(unit, L2_N2m, &l2_entry, PARENT_NODEf);
            *first_child = soc_mem_field32_get(unit, L2_N2m, &l2_entry, FIRST_CHILD_NODEf);
	    if (*first_child == (SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[1]-1)) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L2_N2m, &l2_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
	    }
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_N2m(unit, MEM_BLOCK_ANY, node, &l3_entry));
            *parent = soc_mem_field32_get(unit, L3_N2m, &l3_entry, PARENT_NODEf);
	    *first_child = soc_mem_field32_get(unit, L3_N2m, &l3_entry, FIRST_CHILD_NODEf);
	    if (*first_child == 0xFFF) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L3_N2m, &l3_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
            }
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_N2m(unit, MEM_BLOCK_ANY, node, &l4_entry));
	    *parent = soc_mem_field32_get(unit, L4_N2m, &l4_entry, PARENT_NODEf);
	    *first_child = soc_mem_field32_get(unit, L4_N2m, &l4_entry, FIRST_CHILD_NODEf);
	    if (*first_child == 0x3FF) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L4_N2m, &l4_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
	    }
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_N2m(unit, MEM_BLOCK_ANY, node, &l5_entry));
	    *parent = soc_mem_field32_get(unit, L5_N2m, &l5_entry, PARENT_NODEf);
	    *first_child = soc_mem_field32_get(unit, L5_N2m, &l5_entry, FIRST_CHILD_NODEf);
	    if (*first_child == 0x107) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L5_N2m, &l5_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
	    }
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_N2m(unit, MEM_BLOCK_ANY, node, &l6_entry));
	    *parent = soc_mem_field32_get(unit, L6_N2m, &l6_entry, PARENT_NODEf);
	    *first_child = soc_mem_field32_get(unit, L6_N2m, &l6_entry, FIRST_CHILD_NODEf);
	    if (*first_child == 0x83) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L6_N2m, &l6_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
	    }
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_N2m(unit, MEM_BLOCK_ANY, node, &l7_entry));
	    *parent = 0;
	    *first_child = soc_mem_field32_get(unit, L7_N2m, &l7_entry, FIRST_CHILD_NODEf);
	    if (*first_child == 0x37) {
		*num_child = 0;
	    } else {
		*num_child = soc_mem_field32_get(unit, L7_N2m, &l7_entry, LAST_CHILD_OFFSETf);
		*num_child = *num_child + 1;
	    }
            break;
        /* coverity[dead_error_begin] */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported TS level %d, valid range [0 - %d]\n"),
                       FUNCTION_NAME(), level, SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS));
            break;
    }

    return rv;
}

static int
need_to_wait(int unit, 
	     int32 shape_rate, 
	     uint32 rate_mant, 
	     uint32 rate_exp, 
	     uint32 rate_mant_read, 
	     uint32 rate_exp_read)
{
    if ( (rate_mant_read==0) && (rate_exp_read==0)) {
        return 0;
    } else if ( (rate_exp_read == rate_exp) && (rate_mant_read == rate_mant)) {
        return 0;
    } else if ((rate_mant_read==0xff) && (rate_exp_read==0xf)) {
        return 0;
    }
    
    return 1;
}
/*
 * configure ts (ingress) node shaper info
 *    enable:            TRUE/FALSE
 *    shape_rate:        kbps, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *    max_burst:         in bits
 */
int
soc_sirius_ts_node_shaper_config(int unit, uint32 level, uint32 node, int32 enable,
                                   int32 shape_rate, int32 max_burst)
{
    int rv = SOC_E_NONE;
    l1_bp_entry_t l1_bp_entry;
    l2_bp_entry_t l2_bp_entry;
    l3_bp_entry_t l3_bp_entry;
    l4_bp_entry_t l4_bp_entry;
    l5_bp_entry_t l5_bp_entry;
    l6_bp_entry_t l6_bp_entry;
    l7_bp_entry_t l7_bp_entry;
    uint32 rate_mant, rate_exp;
    uint32 burst_mant, burst_exp;
    uint32 rate_mant_read, rate_exp_read;

    /* disable means set shape rate to 0 */
    /* hardware: max burst in bits, shape rate in bps and E+M format */

    /* Sanity check parameters */
    if ((level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    if (enable == FALSE) {
        shape_rate = 0;
        max_burst = 0;
    }

    if (shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
	rv = soc_sbx_fabric_util_num_to_mant_exp(unit, L1_BPm, SHAPER_RATE_MANTf, shape_rate,
                                                      &rate_mant, &rate_exp);
        if (rv != SOC_E_NONE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s failed to convert shaper rate 0x%x to mant/exp format\n"),
                       FUNCTION_NAME(), shape_rate));
            return SOC_E_PARAM;
        }
    }
    if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        rv = soc_sbx_fabric_util_num_to_mant_exp(unit, L1_BPm, SHAPER_MAXBURST_MANTf, max_burst,
                                                      &burst_mant, &burst_exp);
        if (rv != SOC_E_NONE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s failed to convert shaper max burst 0x%x to mant/exp format\n"),
                       FUNCTION_NAME(), max_burst));
            return SOC_E_PARAM;
        }
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_EXPf);
            if ( shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) {
		    soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_EXPf);
            if (shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) {
		    soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_EXPf);
            if ( shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) {
		    soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_EXPf);
            if ( shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) {
		    soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_EXPf);
            if (shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) { 
		    soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_EXPf);
            if (shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) { 
		if ( (enable == FALSE)  && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) { 
		    soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));
	    rate_mant_read = soc_mem_field32_get(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_MANTf);
	    rate_exp_read = soc_mem_field32_get(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_EXPf);
            if ( shape_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if ((enable == FALSE) && 
		    need_to_wait(unit, shape_rate, rate_mant, rate_exp, rate_mant_read, rate_exp_read)) { 
		    soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_RATE_EXPf, rate_exp);
            }
            if (max_burst != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_MAXBURST_MANTf, burst_mant);
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, SHAPER_MAXBURST_EXPf, burst_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for shaper \n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    return rv;
}

/*
 * configure ts (ingress) node creditor info
 *    enable:             TRUE/FALSE
 *    creditor_rate:      kbps, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *    profile_id:         creditor profile id (use #define for each level, 0-31)
 */
int
soc_sirius_ts_node_creditor_config(int unit, uint32 level, uint32 node, int32 enable,
                                   int32 creditor_rate, int32 profile_id)
{
    int rv = SOC_E_NONE;
    l1_bp_entry_t l1_bp_entry;
    l2_bp_entry_t l2_bp_entry;
    l3_bp_entry_t l3_bp_entry;
    l4_bp_entry_t l4_bp_entry;
    l5_bp_entry_t l5_bp_entry;
    l6_bp_entry_t l6_bp_entry;
    l7_bp_entry_t l7_bp_entry;
    uint32 rate_mant, rate_exp;
    l1_nm_entry_t l1_nm_entry;
    l2_nm_entry_t l2_nm_entry;
    l3_nm_entry_t l3_nm_entry;
    l4_nm_entry_t l4_nm_entry;
    l5_nm_entry_t l5_nm_entry;
    l6_nm_entry_t l6_nm_entry;
    l7_nm_entry_t l7_nm_entry;


    /* disable means set creditor rate to 0 */

    /* Sanity check parameters */
    if ((level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    if (enable == FALSE) {
        creditor_rate = 0;
    }

    if ( (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((profile_id < 0) || (profile_id > 31)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node profile %d, valid range [0 - 31]\n"), FUNCTION_NAME(),
                   profile_id));
        return SOC_E_PARAM;
    }

    if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        rv = soc_sbx_fabric_util_num_to_mant_exp(unit, L1_BPm, CREDITOR_RATE_MANTf, creditor_rate,
                                                      &rate_mant, &rate_exp);
        if (rv != SOC_E_NONE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s failed to convert creditor rate 0x%x to mant/exp format\n"),
                       FUNCTION_NAME(), creditor_rate));
            return SOC_E_PARAM;
        }
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));
		}
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L1_BPm, &l1_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L1_BPm(unit, MEM_BLOCK_ANY, node, &l1_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
                soc_mem_field32_set(unit, L1_NMm, &l1_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
            }
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));
		}
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L2_BPm, &l2_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_BPm(unit, MEM_BLOCK_ANY, node, &l2_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
                soc_mem_field32_set(unit, L2_NMm, &l2_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
            }
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));
		}
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L3_BPm, &l3_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_BPm(unit, MEM_BLOCK_ANY, node, &l3_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
                soc_mem_field32_set(unit, L3_NMm, &l3_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
            }
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));
		}
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L4_BPm, &l4_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_BPm(unit, MEM_BLOCK_ANY, node, &l4_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
                soc_mem_field32_set(unit, L4_NMm, &l4_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
            }
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));
		}
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L5_BPm, &l5_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_BPm(unit, MEM_BLOCK_ANY, node, &l5_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
                soc_mem_field32_set(unit, L5_NMm, &l5_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
            }
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));
		}
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L6_BPm, &l6_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_BPm(unit, MEM_BLOCK_ANY, node, &l6_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
                soc_mem_field32_set(unit, L6_NMm, &l6_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
            }
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));
            if (creditor_rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == FALSE) {
		    soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, CREDITOR_RATE_MANTf, 0xFF);
		    soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, CREDITOR_RATE_EXPf, 0xF);
		    SOC_IF_ERROR_RETURN(WRITE_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));
		}
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, CREDITOR_RATE_MANTf, rate_mant);
                soc_mem_field32_set(unit, L7_BPm, &l7_bp_entry, CREDITOR_RATE_EXPf, rate_exp);
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_BPm(unit, MEM_BLOCK_ANY, node, &l7_bp_entry));

            if (profile_id != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                SOC_IF_ERROR_RETURN(READ_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
                soc_mem_field32_set(unit, L7_NMm, &l7_nm_entry, NODE_PROFILE_PTRf, profile_id);
                SOC_IF_ERROR_RETURN(WRITE_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
            }
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for creditor \n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    return rv;
}

/*
 * configure ts (ingress) node creditor profile info
 *    profile_id:         creditor profile id (use #define for each level, 0-31)
 *    thresh1:            0-0xFFFF, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *    thresh2:            0-0xFFFF, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *    pri0-2:             0-0xF, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *    adopt_pri_mask:     0-0xFFFF, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 */
int
soc_sirius_ts_node_profile_config(int unit, int level, int index, int creditor_state_map, int adopt_pri_map,
                                  int pri2, int pri1, int pri0, int mult2, int mult1)
{
    l1_np_entry_t l1_np_entry;
    l2_np_entry_t l2_np_entry;
    l3_np_entry_t l3_np_entry;
    l4_np_entry_t l4_np_entry;
    l5_np_entry_t l5_np_entry;
    l6_np_entry_t l6_np_entry;
    l7_np_entry_t l7_np_entry;

    if ( (index < 0) || ( index > 31) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s node profile %d for level %d out of range 0-31\n"), FUNCTION_NAME(), index, level));
        return SOC_E_PARAM;
    }

    if ( (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (creditor_state_map > 0x7) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s creditor_state_map 0x%x out of range 0-0x7 \n"), FUNCTION_NAME(), creditor_state_map));
        return SOC_E_PARAM;
    }

    if ( (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (adopt_pri_map > 0xFFFF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s adopt_pri_map 0x%x out of range 0-0xFFFF \n"), FUNCTION_NAME(), adopt_pri_map));
        return SOC_E_PARAM;
    }

    if ( (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (pri2 > 0xF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s pri2 0x%x out of range 0-0xF \n"), FUNCTION_NAME(), pri2));
        return SOC_E_PARAM;
    }

    if ( (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (pri1 > 0xF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s pri1 0x%x out of range 0-0xF \n"), FUNCTION_NAME(), pri1));
        return SOC_E_PARAM;
    }

    if ( (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (pri0 > 0xF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s pri0 0x%x out of range 0-0xF \n"), FUNCTION_NAME(), pri0));
        return SOC_E_PARAM;
    }

    if ( (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (mult2 > 0xFFFF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s mult2 0x%x out of range 0-0xFFFF \n"), FUNCTION_NAME(), mult2));
        return SOC_E_PARAM;
    }

    if ( (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (mult1 > 0xFFFF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s mult1 0x%x out of range 0-0xFFFF \n"), FUNCTION_NAME(), mult1));
        return SOC_E_PARAM;
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_NPm(unit, MEM_BLOCK_ANY, index, &l1_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NPm, &l1_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L1_NPm(unit, MEM_BLOCK_ANY, index, &l1_np_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_NPm(unit, MEM_BLOCK_ANY, index, &l2_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NPm, &l2_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_NPm(unit, MEM_BLOCK_ANY, index, &l2_np_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_NPm(unit, MEM_BLOCK_ANY, index, &l3_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NPm, &l3_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_NPm(unit, MEM_BLOCK_ANY, index, &l3_np_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_NPm(unit, MEM_BLOCK_ANY, index, &l4_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NPm, &l4_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_NPm(unit, MEM_BLOCK_ANY, index, &l4_np_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_NPm(unit, MEM_BLOCK_ANY, index, &l5_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NPm, &l5_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_NPm(unit, MEM_BLOCK_ANY, index, &l5_np_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_NPm(unit, MEM_BLOCK_ANY, index, &l6_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NPm, &l6_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_NPm(unit, MEM_BLOCK_ANY, index, &l6_np_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_NPm(unit, MEM_BLOCK_ANY, index, &l7_np_entry));
            if (creditor_state_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, CREDITOR_STATE_MAPf, creditor_state_map);
            }
            if (adopt_pri_map != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, ADOPT_PRI_MAPf, adopt_pri_map);
            }
            if (pri2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, PRI2f, pri2);
            }
            if (pri1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, PRI1f, pri1);
            }
            if (pri0 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, PRI0f, pri0);
            }
            if (mult2 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, MULT2f, mult2);
            }
            if (mult1 != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NPm, &l7_np_entry, MULT1f, mult1);
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_NPm(unit, MEM_BLOCK_ANY, index, &l7_np_entry));
            break;
    }

    return SOC_E_NONE;
}

/*
 * configure ts (ingress) node child weight info
 *     child_offset:      0-7 child index.
 *     weight:            0-0x7F, SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 */
int
soc_sirius_ts_node_child_weight_config(int unit, uint32 level, uint32 node, int32 child_offset,
                                       int32 weight)
{
    int rv = SOC_E_NONE;
    l1_n1_entry_t l1_n1_entry;
    l2_n1_entry_t l2_n1_entry;
    l3_n1_entry_t l3_n1_entry;
    l4_n1_entry_t l4_n1_entry;
    l5_n1_entry_t l5_n1_entry;
    l6_n1_entry_t l6_n1_entry;
    l7_n1_entry_t l7_n1_entry;


    /* Sanity check parameters */
    if ((level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    if ( (child_offset < 0) || (child_offset > 7) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS child offset %d, valid range [0 - 7]\n"), FUNCTION_NAME(),
                   child_offset));
        return SOC_E_PARAM;
    }

    if (weight == SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        return SOC_E_NONE;
    } else if ( (weight < 0) || (weight > 0x3F) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid weight %d, range [0,0x3F]\n"), FUNCTION_NAME(), weight));
        return SOC_E_PARAM;
    }

    /* make sure weight 1 is not used */
    weight *= 2;

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_N1m(unit, MEM_BLOCK_ANY, node, &l1_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L1_N1m, &l1_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L1_N1m(unit, MEM_BLOCK_ANY, node, &l1_n1_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_N1m(unit, MEM_BLOCK_ANY, node, &l2_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L2_N1m, &l2_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_N1m(unit, MEM_BLOCK_ANY, node, &l2_n1_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_N1m(unit, MEM_BLOCK_ANY, node, &l3_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L3_N1m, &l3_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_N1m(unit, MEM_BLOCK_ANY, node, &l3_n1_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_N1m(unit, MEM_BLOCK_ANY, node, &l4_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L4_N1m, &l4_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_N1m(unit, MEM_BLOCK_ANY, node, &l4_n1_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_N1m(unit, MEM_BLOCK_ANY, node, &l5_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L5_N1m, &l5_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_N1m(unit, MEM_BLOCK_ANY, node, &l5_n1_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_N1m(unit, MEM_BLOCK_ANY, node, &l6_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L6_N1m, &l6_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_N1m(unit, MEM_BLOCK_ANY, node, &l6_n1_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_N1m(unit, MEM_BLOCK_ANY, node, &l7_n1_entry));
            switch (child_offset) {
                case 0:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT0f, weight);
                    break;
                case 1:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT1f, weight);
                    break;
                case 2:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT2f, weight);
                    break;
                case 3:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT3f, weight);
                    break;
                case 4:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT4f, weight);
                    break;
                case 5:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT5f, weight);
                    break;
                case 6:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT6f, weight);
                    break;
                case 7:
                    soc_mem_field32_set(unit, L7_N1m, &l7_n1_entry, CHILD_WEIGHT7f, weight);
                    break;
		    /* coverity[dead_error_begin] */
                default:
                    return SOC_E_PARAM;
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_N1m(unit, MEM_BLOCK_ANY, node, &l7_n1_entry));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for child weight \n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    return rv;
}

/*
 * configure ts (ingress) node bucket info
 *     node_type:         0: default, 1: leaf relay, 2: inner relay, 3: root relay
 *     bucket_type:       0: bucket, 1: multipath, 2: multipath master, 3: subtree
 *     bucket_table_pointer: pointer to the bucket resource
 */
int
soc_sirius_ts_node_mapping_config(int unit, int level, uint32 node, int32 node_type, int32 bucket_type,
                                  int32 bucket_table_pointer)
{
    int rv = SOC_E_NONE;
    l1_nm_entry_t l1_nm_entry;
    l2_nm_entry_t l2_nm_entry;
    l3_nm_entry_t l3_nm_entry;
    l4_nm_entry_t l4_nm_entry;
    l5_nm_entry_t l5_nm_entry;
    l6_nm_entry_t l6_nm_entry;
    l7_nm_entry_t l7_nm_entry;
    int child;


    /* Sanity check parameters */
    if ((level < 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    if ( (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((node_type < 0) || (node_type > 3)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node type %d, valid range [0 - 3]\n"), FUNCTION_NAME(),
                   node_type));
        return SOC_E_PARAM;
    }

    if ( (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((bucket_type < 0) || (bucket_type > 3)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS bucket type %d, valid range [0 - 3]\n"), FUNCTION_NAME(),
                   bucket_type));
        return SOC_E_PARAM;
    }

    if ( (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((bucket_table_pointer < 0) || (bucket_table_pointer >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS bucket table pointer %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   bucket_table_pointer, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]));
        return SOC_E_PARAM;
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NMm, &l1_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NMm, &l1_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L1_NMm, &l1_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NMm, &l2_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NMm, &l2_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L2_NMm, &l2_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NMm, &l3_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NMm, &l3_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L3_NMm, &l3_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NMm, &l4_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NMm, &l4_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L4_NMm, &l4_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NMm, &l5_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NMm, &l5_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L5_NMm, &l5_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NMm, &l6_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NMm, &l6_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L6_NMm, &l6_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
            if (node_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NMm, &l7_nm_entry, NODE_TYPEf, node_type);
            }
            if (bucket_type != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NMm, &l7_nm_entry, BUCKET_TYPEf, bucket_type);
            }
            if (bucket_table_pointer != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, L7_NMm, &l7_nm_entry, BUCKET_TABLE_PTRf, bucket_table_pointer);
            }
            SOC_IF_ERROR_RETURN(WRITE_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for node mapping \n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    /* For inner relay or root relay nodes, clear the Lx_N1 table, seems required
     * by hardware to make flat scheduler works properly. Lx_N1 table typically
     * has child weights, set all child weights to 0 to clear it.
     */
    if ((node_type == SIRIUS_TS_NODE_TYPE_INNER_RELAY) ||
	(node_type == SIRIUS_TS_NODE_TYPE_ROOT_RELAY)) {
	for (child = 0; child <= 7; child++) {
	    rv = soc_sirius_ts_node_child_weight_config(unit, level, node, child, 0);
	    if (rv != SOC_E_NONE) {
		LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "%s fail to clear ingress scheduler level %d node %d child weight, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));	    
		return rv;
	    }
	}
    }

    return rv;
}

/*
 * get ts (ingress) node bucket info
 *     node_type:         0: default, 1: leaf relay, 2: inner relay, 3: root relay
 *     bucket_type:       0: bucket, 1: multipath, 2: multipath master, 3: subtree
 *     bucket_table_pointer: pointer to the bucket resource
 */
int
soc_sirius_ts_node_mapping_config_get(int unit, int level, int node, int32 *node_type,
				      int32 *bucket_type, int32 *bucket_table_pointer)
{
    int rv = SOC_E_NONE;
    l1_nm_entry_t l1_nm_entry;
    l2_nm_entry_t l2_nm_entry;
    l3_nm_entry_t l3_nm_entry;
    l4_nm_entry_t l4_nm_entry;
    l5_nm_entry_t l5_nm_entry;
    l6_nm_entry_t l6_nm_entry;
    l7_nm_entry_t l7_nm_entry;

    /* Sanity check parameters */
    if ((level < 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L1_NMm, &l1_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L1_NMm, &l1_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L1_NMm, &l1_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L1_NMm(unit, MEM_BLOCK_ANY, node, &l1_nm_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L2_NMm, &l2_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L2_NMm, &l2_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L2_NMm, &l2_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L2_NMm(unit, MEM_BLOCK_ANY, node, &l2_nm_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L3_NMm, &l3_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L3_NMm, &l3_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L3_NMm, &l3_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L3_NMm(unit, MEM_BLOCK_ANY, node, &l3_nm_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L4_NMm, &l4_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L4_NMm, &l4_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L4_NMm, &l4_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L4_NMm(unit, MEM_BLOCK_ANY, node, &l4_nm_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L5_NMm, &l5_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L5_NMm, &l5_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L5_NMm, &l5_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L5_NMm(unit, MEM_BLOCK_ANY, node, &l5_nm_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L6_NMm, &l6_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L6_NMm, &l6_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L6_NMm, &l6_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L6_NMm(unit, MEM_BLOCK_ANY, node, &l6_nm_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
	    *node_type = soc_mem_field32_get(unit, L7_NMm, &l7_nm_entry, NODE_TYPEf);
	    *bucket_type = soc_mem_field32_get(unit, L7_NMm, &l7_nm_entry, BUCKET_TYPEf);
	    *bucket_table_pointer = soc_mem_field32_get(unit, L7_NMm, &l7_nm_entry, BUCKET_TABLE_PTRf);
            SOC_IF_ERROR_RETURN(WRITE_L7_NMm(unit, MEM_BLOCK_ANY, node, &l7_nm_entry));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for node mapping \n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    return rv;
}

/*
 * configure ts (ingress) node multipath linklist
 *     next_node: pointer to the next node in the multipath linklist
 *     last:      last node of multipath linklist
 */
int
soc_sirius_ts_node_multipath_config(int unit, int level, uint32 node, int32 next_node, int32 last)
{
    int rv = SOC_E_NONE;
    l2_ng_entry_t l2_ng_entry;
    l3_ng_entry_t l3_ng_entry;
    l4_ng_entry_t l4_ng_entry;
    l5_ng_entry_t l5_ng_entry;
    l6_ng_entry_t l6_ng_entry;
    
    /* Sanity check parameters */
    if ((level < 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    if ((next_node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS next node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   next_node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    switch (level) {
	case 2:
            SOC_IF_ERROR_RETURN(READ_L2_NGm(unit, MEM_BLOCK_ANY, node, &l2_ng_entry));
	    soc_mem_field32_set(unit, L2_NGm, &l2_ng_entry, MULTI_USEf, ((next_node << 1) | (last?1:0)));
            SOC_IF_ERROR_RETURN(WRITE_L2_NGm(unit, MEM_BLOCK_ANY, node, &l2_ng_entry));
	    break;
	case 3:
            SOC_IF_ERROR_RETURN(READ_L3_NGm(unit, MEM_BLOCK_ANY, node, &l3_ng_entry));
	    soc_mem_field32_set(unit, L3_NGm, &l3_ng_entry, MULTI_USEf, ((next_node << 1) | (last?1:0)));
            SOC_IF_ERROR_RETURN(WRITE_L3_NGm(unit, MEM_BLOCK_ANY, node, &l3_ng_entry));
	    break;
	case 4:
            SOC_IF_ERROR_RETURN(READ_L4_NGm(unit, MEM_BLOCK_ANY, node, &l4_ng_entry));
	    soc_mem_field32_set(unit, L4_NGm, &l4_ng_entry, MULTI_USEf, ((next_node << 1) | (last?1:0)));
            SOC_IF_ERROR_RETURN(WRITE_L4_NGm(unit, MEM_BLOCK_ANY, node, &l4_ng_entry));
	    break;
	case 5:
            SOC_IF_ERROR_RETURN(READ_L5_NGm(unit, MEM_BLOCK_ANY, node, &l5_ng_entry));
	    soc_mem_field32_set(unit, L5_NGm, &l5_ng_entry, MULTI_USEf, ((next_node << 1) | (last?1:0)));
            SOC_IF_ERROR_RETURN(WRITE_L5_NGm(unit, MEM_BLOCK_ANY, node, &l5_ng_entry));
	    break;
	case 6:
            SOC_IF_ERROR_RETURN(READ_L6_NGm(unit, MEM_BLOCK_ANY, node, &l6_ng_entry));
	    soc_mem_field32_set(unit, L6_NGm, &l6_ng_entry, MULTI_USEf, ((next_node << 1) | (last?1:0)));
            SOC_IF_ERROR_RETURN(WRITE_L6_NGm(unit, MEM_BLOCK_ANY, node, &l6_ng_entry));
	    break;
	default:
	    return SOC_E_PARAM;
    }

    return rv;
}


/*
 * init ts (ingress) node state memory (non-config parameter tables)
 */
int
soc_sirius_ts_node_state_init(int unit, int32 level, int32 node)
{
    int rv = SOC_E_NONE;
    l1_ng_entry_t l1_ng_entry;
    l2_ng_entry_t l2_ng_entry;
    l3_ng_entry_t l3_ng_entry;
    l4_ng_entry_t l4_ng_entry;
    l5_ng_entry_t l5_ng_entry;
    l6_ng_entry_t l6_ng_entry;
    l7_ng_entry_t l7_ng_entry;

    l1_bk_entry_t l1_bk_entry;
    l2_bk_entry_t l2_bk_entry;
    l3_bk_entry_t l3_bk_entry;
    l4_bk_entry_t l4_bk_entry;
    l5_bk_entry_t l5_bk_entry;
    l6_bk_entry_t l6_bk_entry;
    l7_bk_entry_t l7_bk_entry;

    l1_n0_entry_t l1_n0_entry;
    l2_n0_entry_t l2_n0_entry;
    l3_n0_entry_t l3_n0_entry;
    l4_n0_entry_t l4_n0_entry;
    l5_n0_entry_t l5_n0_entry;
    l6_n0_entry_t l6_n0_entry;
    l7_n0_entry_t l7_n0_entry;

    /* Sanity check parameters */
    if ((level < 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ((node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level])) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    }

    sal_memset(&l1_ng_entry, 0, sizeof(l1_ng_entry_t));
    sal_memset(&l2_ng_entry, 0, sizeof(l2_ng_entry_t));
    sal_memset(&l3_ng_entry, 0, sizeof(l3_ng_entry_t));
    sal_memset(&l4_ng_entry, 0, sizeof(l4_ng_entry_t));
    sal_memset(&l5_ng_entry, 0, sizeof(l5_ng_entry_t));
    sal_memset(&l6_ng_entry, 0, sizeof(l6_ng_entry_t));
    sal_memset(&l7_ng_entry, 0, sizeof(l7_ng_entry_t));

    sal_memset(&l1_bk_entry, 0, sizeof(l1_bk_entry_t));
    sal_memset(&l2_bk_entry, 0, sizeof(l2_bk_entry_t));
    sal_memset(&l3_bk_entry, 0, sizeof(l3_bk_entry_t));
    sal_memset(&l4_bk_entry, 0, sizeof(l4_bk_entry_t));
    sal_memset(&l5_bk_entry, 0, sizeof(l5_bk_entry_t));
    sal_memset(&l6_bk_entry, 0, sizeof(l6_bk_entry_t));
    sal_memset(&l7_bk_entry, 0, sizeof(l7_bk_entry_t));

    sal_memset(&l1_n0_entry, 0, sizeof(l1_n0_entry_t));
    sal_memset(&l2_n0_entry, 0, sizeof(l2_n0_entry_t));
    sal_memset(&l3_n0_entry, 0, sizeof(l3_n0_entry_t));
    sal_memset(&l4_n0_entry, 0, sizeof(l4_n0_entry_t));
    sal_memset(&l5_n0_entry, 0, sizeof(l5_n0_entry_t));
    sal_memset(&l6_n0_entry, 0, sizeof(l6_n0_entry_t));
    sal_memset(&l7_n0_entry, 0, sizeof(l7_n0_entry_t));

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(WRITE_L1_NGm(unit, MEM_BLOCK_ANY, node, &l1_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_BKm(unit, MEM_BLOCK_ANY, node, &l1_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_N0m(unit, MEM_BLOCK_ANY, node, &l1_n0_entry));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(WRITE_L2_NGm(unit, MEM_BLOCK_ANY, node, &l2_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_BKm(unit, MEM_BLOCK_ANY, node, &l2_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_N0m(unit, MEM_BLOCK_ANY, node, &l2_n0_entry));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(WRITE_L3_NGm(unit, MEM_BLOCK_ANY, node, &l3_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_BKm(unit, MEM_BLOCK_ANY, node, &l3_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_N0m(unit, MEM_BLOCK_ANY, node, &l3_n0_entry));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(WRITE_L4_NGm(unit, MEM_BLOCK_ANY, node, &l4_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_BKm(unit, MEM_BLOCK_ANY, node, &l4_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_N0m(unit, MEM_BLOCK_ANY, node, &l4_n0_entry));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(WRITE_L5_NGm(unit, MEM_BLOCK_ANY, node, &l5_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_BKm(unit, MEM_BLOCK_ANY, node, &l5_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_N0m(unit, MEM_BLOCK_ANY, node, &l5_n0_entry));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(WRITE_L6_NGm(unit, MEM_BLOCK_ANY, node, &l6_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L6_BKm(unit, MEM_BLOCK_ANY, node, &l6_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L6_N0m(unit, MEM_BLOCK_ANY, node, &l6_n0_entry));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(WRITE_L7_NGm(unit, MEM_BLOCK_ANY, node, &l7_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L7_BKm(unit, MEM_BLOCK_ANY, node, &l7_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L7_N0m(unit, MEM_BLOCK_ANY, node, &l7_n0_entry));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d for node state init \n"),
                       FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }

    return rv;
}

/*
 * configure qs queue to leaf node table
 *     queue:             0-64K queue ID
 *     mc:                0/1 multicast queues SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *     leaf_node:         0-64K leaf node ID.  SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 */
int
soc_sirius_qs_queue_to_leaf_node_set(int unit, uint32 queue, int32 mc, int32 leaf_node)
{
    int rv = SOC_E_NONE;
    queue_to_sc_0_entry_t q2sc_entry; /* same size and format anyhow, use entry 0 declaration */
    uint32 index;

    /* Sanity check parameters */
    if (queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid queue %d\n"), FUNCTION_NAME(), queue));
        return SOC_E_PARAM;
    }

    if (leaf_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        if ( (leaf_node < 0) || (leaf_node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[0]) ) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s invalid leaf node %d\n"), FUNCTION_NAME(), leaf_node));
            return SOC_E_PARAM;
        }
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        index = queue;
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    if (mc != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, MULTICASTf, (mc?1:0));
    }

    if (leaf_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, SYSPORTf, (leaf_node>>4) );
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, COSf, (leaf_node & 0xF));
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    return rv;
}

/*
 * get qs queue to leaf node table info
 *     queue:             0-64K queue ID
 *     mc:                0/1 multicast queues 
 *     sysport:           0-4K sysport ID.
 *     cos                0-15 COS
 */
int
soc_sirius_qs_queue_to_leaf_node_get(int unit, uint32 queue, int32 *mc, int32 *leaf_node)
{
    int rv = SOC_E_NONE;
    queue_to_sc_0_entry_t q2sc_entry; /* same size and format anyhow, use entry 0 declaration */
    uint32 index = 0, sysport = 0, cos = 0;

    /* Sanity check parameters */
    if (queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid queue %d\n"), FUNCTION_NAME(), queue));
        return SOC_E_PARAM;
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        index = queue;
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    if (mc)
      *mc = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, MULTICASTf);
    sysport = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, SYSPORTf);
    cos = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, COSf);
    if (leaf_node)
      *leaf_node = sysport << 4 | cos;

    return rv;
}

/*
 * configure qs queue to sysport/cos table
 *     queue:             0-64K queue ID
 *     mc:                0/1 multicast queues SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *     sysport:           0-2816 sysport       SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 *     cos:               0-15 cos level       SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 */
int
soc_sirius_qs_queue_to_sysport_cos_set(int unit, uint32 queue, int32 mc, int32 sysport, int32 cos)
{
    int rv = SOC_E_NONE;
    queue_to_sc_0_entry_t q2sc_entry; /* same size and format anyhow, use entry 0 declaration */
    uint32 index;

    /* Sanity check parameters */
    if (queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid queue %d\n"), FUNCTION_NAME(), queue));
        return SOC_E_PARAM;
    }

    if (sysport >= 4096) {
      LOG_ERROR(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s invalid sysport id %d\n"), FUNCTION_NAME(), sysport));
      return SOC_E_PARAM;
    }

    if (cos >= 16) {
      LOG_ERROR(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s invalid COS %d\n"), FUNCTION_NAME(), cos));
      return SOC_E_PARAM;
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        index = queue;
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    if (mc != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, MULTICASTf, (mc?1:0));
    }

    if (sysport != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, SYSPORTf, sysport );
    }

    if (cos != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        soc_mem_field32_set(unit, QUEUE_TO_SC_0m, &q2sc_entry, COSf, cos);
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        SOC_IF_ERROR_RETURN(WRITE_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    return rv;
}


/*
 * get qs queue to sysport/cos table info
 *     queue:             0-64K queue ID
 *     mc:                0/1 multicast queues 
 *     sysport:           0-4K sysport ID.
 *     cos                0-15 COS
 */
int
soc_sirius_qs_queue_to_sysport_cos_get(int unit, uint32 queue, int32 *mc, int32 *sysport, int32 *cos)
{
    int rv = SOC_E_NONE;
    queue_to_sc_0_entry_t q2sc_entry; /* same size and format anyhow, use entry 0 declaration */
    uint32 index;

    /* Sanity check parameters */
    if (queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid queue %d\n"), FUNCTION_NAME(), queue));
        return SOC_E_PARAM;
    }

    if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4)) {
        index = queue;
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_0m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_1m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else if (queue < (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4)) {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 2 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_2m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    } else {
        index = queue - (SB_FAB_DEVICE_SIRIUS_NUM_QUEUES * 3 / 4);
        SOC_IF_ERROR_RETURN(READ_QUEUE_TO_SC_3m(unit, MEM_BLOCK_ANY, index, &q2sc_entry));
    }

    if (mc)
      *mc = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, MULTICASTf);
    if (sysport)
      *sysport = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, SYSPORTf);
    if (cos)
      *cos = soc_mem_field32_get(unit, QUEUE_TO_SC_0m, &q2sc_entry, COSf);

    return rv;
}
/*
 * configure qs sysport to node table (S2N)
 *     node
 *     sysport:           0-2816 sysport            
 */
int
soc_sirius_qs_sysport_to_node_set(int unit, int32 sysport, int32 node)
{
    int rv = SOC_E_NONE;
    sysport_to_node_entry_t s2n_entry; 
    uint32 index;

    /* Sanity check parameters */
    if ((uint32) sysport >= 4096) {
      LOG_ERROR(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s invalid sysport id %d\n"), FUNCTION_NAME(), sysport));
      return SOC_E_PARAM;
    }

    
    if (sysport == -1) {
        return rv;
    }

    index = sysport;
    SOC_IF_ERROR_RETURN(READ_SYSPORT_TO_NODEm(unit, MEM_BLOCK_ANY, index, &s2n_entry));
    soc_mem_field32_set(unit, SYSPORT_TO_NODEm, &s2n_entry, S2N_NODEf, node);
    SOC_IF_ERROR_RETURN(WRITE_SYSPORT_TO_NODEm(unit, MEM_BLOCK_ANY, index, &s2n_entry));

    return rv;
}



/*
 * configure qs sysport to queue table (S2Q)
 *     base_queue:        0-64k queue ID
 *     mc:                0/1 multicast queues
 *     sysport:           0-2816 sysport            
 */
int
soc_sirius_qs_sysport_to_queue_set(int unit, int32 mc, int32 sysport, int32 base_queue)
{
    int rv = SOC_E_NONE;
    sysport_to_queue_entry_t s2q_entry; 
    uint32 index;

    /* Sanity check parameters */
    if (base_queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s queue out of range %d\n"), FUNCTION_NAME(), base_queue));
        return SOC_E_PARAM;
    }

    if ((uint32) sysport >= 4096) {
      LOG_ERROR(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s invalid sysport id %d\n"), FUNCTION_NAME(), sysport));
      return SOC_E_PARAM;
    }

    
    if (sysport == -1) {
        return rv;
    }

    index = (mc << 12) | sysport;
    SOC_IF_ERROR_RETURN(READ_SYSPORT_TO_QUEUEm(unit, MEM_BLOCK_ANY, index, &s2q_entry));
    soc_mem_field32_set(unit, SYSPORT_TO_QUEUEm, &s2q_entry, S2Q_BASE_QUEUEf, base_queue);
    SOC_IF_ERROR_RETURN(WRITE_SYSPORT_TO_QUEUEm(unit, MEM_BLOCK_ANY, index, &s2q_entry));

    return rv;
}



/*
 * configure qs leaf node to queue table
 *     node:              leaf node ID
 *     queue:             0-64K queue ID
 */
int
soc_sirius_qs_leaf_node_to_queue_set(int unit, uint32 leaf_node, uint32 queue)
{
    int rv = SOC_E_NONE;
    leafnode_to_queue_entry_t ln2q_entry;

    if (leaf_node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[0]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid leaf node %d\n"), FUNCTION_NAME(), leaf_node));
        return SOC_E_PARAM;
    }

    /* low 2 bits of queue and leaf node has to match */
    if ((queue != 0) && ((queue & 0x3) != (leaf_node & 0x3)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s leaf node 0x%x low 2 bits not matching queue 0x%x low 2 bits\n"),
                   FUNCTION_NAME(), leaf_node, queue));
        return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, (leaf_node >> 2), &ln2q_entry));
    soc_mem_field32_set(unit, LEAFNODE_TO_QUEUEm, &ln2q_entry, LN2Q_BASE_QUEUEf, (queue >> 2));
    SOC_IF_ERROR_RETURN(WRITE_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, (leaf_node >> 2), &ln2q_entry));

    return rv;
}

/*
 * get configure qs leaf node to queue table
 *     node:              leaf node ID
 *     queue:             0-64K queue ID
 */
int
soc_sirius_qs_leaf_node_to_queue_get(int unit, uint32 leaf_node, uint32 *queue)
{
    int rv = SOC_E_NONE;
    leafnode_to_queue_entry_t ln2q_entry;

    if (leaf_node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[0]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid leaf node %d\n"), FUNCTION_NAME(), leaf_node));
        return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, (leaf_node >> 2), &ln2q_entry));
    *queue = soc_mem_field32_get(unit, LEAFNODE_TO_QUEUEm, &ln2q_entry, LN2Q_BASE_QUEUEf);
    *queue = (*queue << 2) + (leaf_node & 0x3);

    return rv;
}

/*
 * configure qs baa leak table
 *     queue:             0-64K queue ID
 */
int
soc_sirius_qs_baa_rate_set(int unit, uint32 queue, uint32 mant, uint32 exp)
{
    int rv = SOC_E_NONE;
    int table_index;
    baa_leak_a0_entry_t baa_leak_a0_entry;
    baa_leak_b0_entry_t baa_leak_b0_entry;
    soc_mem_t           mem_a, mem_b;

    if (queue >= SB_FAB_DEVICE_SIRIUS_NUM_QUEUES) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid queue %d\n"), FUNCTION_NAME(), queue));
        return SOC_E_PARAM;
    }

    if ( (mant > 0xFF) || (exp > 0xF) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s mant %d exp %d out of range\n"),
                   FUNCTION_NAME(), mant, exp));
	return SOC_E_PARAM;
    }

    switch (queue % 4) {
	case 0:
	    mem_a = BAA_LEAK_A0m;
	    mem_b = BAA_LEAK_B0m;
	    break;
	case 1:
	    mem_a = BAA_LEAK_A1m;
	    mem_b = BAA_LEAK_B1m;
	    break;
	case 2:
	    mem_a = BAA_LEAK_A2m;
	    mem_b = BAA_LEAK_B2m;
	    break;
	case 3:
	    mem_a = BAA_LEAK_A3m;
	    mem_b = BAA_LEAK_B3m;
	    break;
	    /* coverity[dead_error_begin] */
	default:
	    /* impossible */
	    return BCM_E_INTERNAL;
    }
    table_index = queue / 4;

    /* update table a */
    SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem_a, MEM_BLOCK_ALL, table_index, &baa_leak_a0_entry));
    soc_mem_field32_set(unit, mem_a, &baa_leak_a0_entry, BAA_RATE_MANTf, mant);
    soc_mem_field32_set(unit, mem_a, &baa_leak_a0_entry, BAA_RATE_EXPf, exp);
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem_a, MEM_BLOCK_ALL, table_index, &baa_leak_a0_entry));

    /* update table b */
    SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem_b, MEM_BLOCK_ALL, table_index, &baa_leak_b0_entry));
    soc_mem_field32_set(unit, mem_b, &baa_leak_b0_entry, BAA_RATE_MANTf, mant);
    soc_mem_field32_set(unit, mem_b, &baa_leak_b0_entry, BAA_RATE_EXPf, exp);
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem_b, MEM_BLOCK_ALL, table_index, &baa_leak_b0_entry));

    return rv;
}

/*
 * configure qs leaf node destination
 *     node:              leaf node ID
 *     fifo:              fifo ID          SOC_SIRIUS_API_PARAM_NO_CHANGE means unchange
 */
int
soc_sirius_ts_leaf_node_dest_fifo_set(int unit, uint32 leaf_node, int32 fifo)
{
    int rv = SOC_E_NONE;
    lf_qd_entry_t qd_entry;

    if (leaf_node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[0]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid leaf node %d\n"), FUNCTION_NAME(), leaf_node));
        return SOC_E_PARAM;
    }

    if (fifo == SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        return SOC_E_NONE;
    }

    if (fifo > 0x1FF) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid fifo %d\n"), FUNCTION_NAME(), fifo));
        return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_LF_QDm(unit, MEM_BLOCK_ANY, (leaf_node >> 2), &qd_entry));

    switch (leaf_node & 0x3) {
        case 0:
            soc_mem_field32_set(unit, LF_QDm, &qd_entry, DESTINATION0f, fifo);
            break;
        case 1:
            soc_mem_field32_set(unit, LF_QDm, &qd_entry, DESTINATION1f, fifo);
            break;
        case 2:
            soc_mem_field32_set(unit, LF_QDm, &qd_entry, DESTINATION2f, fifo);
            break;
        case 3:
            soc_mem_field32_set(unit, LF_QDm, &qd_entry, DESTINATION3f, fifo);
            break;
    }

    SOC_IF_ERROR_RETURN(WRITE_LF_QDm(unit, MEM_BLOCK_ANY, (leaf_node >> 2), &qd_entry));

    return rv;
}


/*
 * configure ts level
 *     level:             level 0-8
 *     bypass:
 *     num_node:
 *     leak_cycle:
 *     aperiodic cycle:
 */
int
soc_sirius_ts_level_config(int unit, int level, int bypass, int num_node, int leak_cycle,
                           int aperiodic_interval)
{
    uint32 uRegValue;

    if ( (level <= 0) || (level >= SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS ) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s level %d not configurable\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if ( (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) && ((leak_cycle < 0) || (leak_cycle > 0x1F)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid leak cycle %d\n"), FUNCTION_NAME(), leak_cycle));
        return SOC_E_PARAM;
    } else if (leak_cycle == 0x1F) {
        /* forcing leak always on */
        leak_cycle = 0x1E;
    }

    if ( (level > 4) && (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s aperiodic interval not apply to level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    } else {
        if ( (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
             ((aperiodic_interval < 0) || (aperiodic_interval > 0xF)) ) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s invalid aperiodic interval %d\n"), FUNCTION_NAME(), aperiodic_interval));
            return SOC_E_PARAM;
        } else if (aperiodic_interval == 0xF) {
            /* forcing aperiodic interval always on */
            aperiodic_interval = 0xE;
        }
    }

    if (num_node == 0) {
        bypass = TRUE;
        num_node = 1;
    }

    switch (level) {
        case 1:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL1_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL1_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL1_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x4000) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 1 only suport upto 16K nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL1_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            if (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL1_CONFIG0r, &uRegValue, APERIODIC_INTERVALf, aperiodic_interval );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL1_CONFIG0r(unit, uRegValue));
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL2_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL2_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL2_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x1000) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 2 only suport upto 4K nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL2_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            if (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL2_CONFIG0r, &uRegValue, APERIODIC_INTERVALf, aperiodic_interval );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL2_CONFIG0r(unit, uRegValue));
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL3_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL3_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL3_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x400) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 3 only suport upto 1K nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL3_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            if (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL3_CONFIG0r, &uRegValue, APERIODIC_INTERVALf, aperiodic_interval );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL3_CONFIG0r(unit, uRegValue));
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL4_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL4_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL4_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x108) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 4 only suport upto 264 nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL4_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            if (aperiodic_interval != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL4_CONFIG0r, &uRegValue, APERIODIC_INTERVALf, aperiodic_interval );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL4_CONFIG0r(unit, uRegValue));
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL5_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL5_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL5_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x84) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 5 only suport upto 132 nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL5_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL5_CONFIG0r(unit, uRegValue));
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL6_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL6_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL6_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x38) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 6 only suport upto 56 nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL6_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL6_CONFIG0r(unit, uRegValue));
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_TS_LEVEL7_CONFIG0r(unit, &uRegValue));
            if (bypass != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL7_CONFIG0r, &uRegValue, BYPASS_LEVELf, (bypass?1:0) );
            }
            if (leak_cycle != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_reg_field_set(unit, TS_LEVEL7_CONFIG0r, &uRegValue, LEAK_CYCLESf, leak_cycle );
            }
            if (num_node != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                if (num_node > 0x7) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "%s level 7 only suport upto 7 nodes\n"), FUNCTION_NAME()));
                    return SOC_E_PARAM;
                }
                soc_reg_field_set(unit, TS_LEVEL7_CONFIG0r, &uRegValue, LAST_NODEf, num_node-1 );
            }
            SOC_IF_ERROR_RETURN(WRITE_TS_LEVEL7_CONFIG0r(unit, uRegValue));
            break;
        case 0:
            /* leaf */
        case 8:
            /* root */
        /* coverity[dead_error_begin] */
        default:
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%s unsupported level %d\n"), FUNCTION_NAME(), level));
            return SOC_E_PARAM;
    }
    return SOC_E_NONE;

}

/*
 * configure ts fullmap
 *     full:           flow_control domain for full status
 *     level:          level of allocated ingress scheduler
 *     node:           node of allocated ingress scheduler
 */
int
soc_sirius_ts_fullmap_config(int unit, int full, int level, int node)
{
    rt_fs_entry_t rt_fs_cfg;

    if ( (full < 0) || (full > SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s full status index %d out of range [0, %d]\n"),
                   FUNCTION_NAME(), full, (SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS - 1)));
        return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_RT_FMm(unit, MEM_BLOCK_ANY, full, &rt_fs_cfg));
    if ( (level >= 4) && (level <= 7) && (node >= 0) && (node < SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]) ) {
        /* mapped and enabled */
        soc_mem_field32_set(unit, RT_FMm, &rt_fs_cfg, FULL_ENABLEf, 1);
        soc_mem_field32_set(unit, RT_FMm, &rt_fs_cfg, FULL_LEVELf, (level - 4));
        soc_mem_field32_set(unit, RT_FMm, &rt_fs_cfg, FULL_NODEf, node);
    } else {
        /* unmapped and disabled */
        soc_mem_field32_set(unit, RT_FMm, &rt_fs_cfg, FULL_ENABLEf, 0);
    }
    SOC_IF_ERROR_RETURN(WRITE_RT_FMm(unit, MEM_BLOCK_ANY, full, &rt_fs_cfg));
    return SOC_E_NONE;
}

/*
 * adjust the child weight in parent node's lx_n1 when a child node is 
 * swapped with last child or child nodes are shifted
 *   op = 0, move last child to first child, shift all others
 *   op = 1, move first child to last child, shift all others
 *   op = 2, swap a child node with another child, other childs unchanged
 *   target_child1, target_child2 only valid when op=2
 */
int
soc_sirius_ts_child_weight_update(int unit, int level, int node, 
				  int num_child, int op,
				  int target_child1, int target_child2)
{
     soc_mem_t mem[9] = {0, L1_N1m, L2_N1m, L3_N1m, L4_N1m,
			 L5_N1m, L6_N1m, L7_N1m, 0};
     uint32    mem_val[SOC_MAX_MEM_WORDS];
     soc_field_t child_weight_f[8] = {CHILD_WEIGHT0f, CHILD_WEIGHT1f, CHILD_WEIGHT2f, CHILD_WEIGHT3f,
				      CHILD_WEIGHT4f, CHILD_WEIGHT5f, CHILD_WEIGHT6f, CHILD_WEIGHT7f};
     int i = 0;
     int temp_weight = 0;
     int last_offset = 0;

     if((num_child <= 0) || (num_child > 8) || (level <= 0) ||
	 (level >= SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS))
     {
        return SOC_E_PARAM;
     }
     
     /* read from hw */
     SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));

     last_offset = num_child-1;
     switch (op) {
	 case 0:
	     temp_weight = soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[last_offset]);
	     
	     for(i = last_offset; i > 0; i--) {
		 soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[i],
				     soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[i-1]));
	     }
	     
	     soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[0],temp_weight);
	     break;
	 case 1:
	     temp_weight = soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[0]);
        
	     for(i = 0; i < last_offset; i++) {
		 soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[i],
				     soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[i+1]));
	     }

	     soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[last_offset],temp_weight);
	     break;
	 case 2:
	     if ((target_child1 > last_offset) || (target_child2 > last_offset)) {
		 return SOC_E_PARAM;
	     } else {
		 temp_weight = soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[target_child1]);

		 soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[target_child1],
				     soc_mem_field32_get(unit, mem[level], mem_val, child_weight_f[target_child2]));

		 soc_mem_field32_set(unit, mem[level], mem_val, child_weight_f[target_child2], temp_weight);
	     }
	     break;
	 default:
	     return SOC_E_PARAM;
     }

     /* write to memory */
     SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));

     return SOC_E_NONE;
 
}

/*
 * clone all config params of a ts node to another node in the same level
 *     level:          level of original ingress scheduler
 *                     valid range [1-5]
 *     orig_node:      node of original ingress scheduler
 *     dest_node:      node of ingress scheduler clone destination
 * tables 
 * leaf nodes, LF_QD, queue_to_sc, LF_QP(init to 0, will affect scheduler)
 * L1_NM/NG/BP/N1/N2(copied), L1_BK/N0(init to 0), L1_NP no change 
 * L2_NM/NG/BP/N1/N2(copied), L2_BK/N0(init to 0), L2_NP no change 
 * L3_NM/NG/BP/N1/N2(copied), L3_BK/N0(init to 0), L3_NP no change 
 * L4_NM/NG/BP/N1/N2(copied), L4_BK/N0/FS/FL(init to 0), L4_NP no change 
 * L5_NM/NG/BP/N1/N2(copied), L5_BK/N0/FS/FL(init to 0), L5_NP no change 
 * L5 nodes don't allow moving if mapped to a fabric port (no need for
 *  dynmaic port changes)
 * L6/L7 nodes are not allowed to be shifted
 */
int
soc_sirius_ts_node_clone(int unit, int level, int orig_node, int dest_node)
{
    int rv = SOC_E_NONE;
    l1_nm_entry_t l1_nm_entry;
    l2_nm_entry_t l2_nm_entry;
    l3_nm_entry_t l3_nm_entry;
    l4_nm_entry_t l4_nm_entry;
    l5_nm_entry_t l5_nm_entry;

    l1_ng_entry_t l1_ng_entry;
    l2_ng_entry_t l2_ng_entry;
    l3_ng_entry_t l3_ng_entry;
    l4_ng_entry_t l4_ng_entry;
    l5_ng_entry_t l5_ng_entry;

    l1_bp_entry_t l1_bp_entry;
    l2_bp_entry_t l2_bp_entry;
    l3_bp_entry_t l3_bp_entry;
    l4_bp_entry_t l4_bp_entry;
    l5_bp_entry_t l5_bp_entry;

    l1_bk_entry_t l1_bk_entry;
    l2_bk_entry_t l2_bk_entry;
    l3_bk_entry_t l3_bk_entry;
    l4_bk_entry_t l4_bk_entry;
    l5_bk_entry_t l5_bk_entry;

    l1_n0_entry_t l1_n0_entry;
    l2_n0_entry_t l2_n0_entry;
    l3_n0_entry_t l3_n0_entry;
    l4_n0_entry_t l4_n0_entry;
    l5_n0_entry_t l5_n0_entry;

    l1_n1_entry_t l1_n1_entry;
    l2_n1_entry_t l2_n1_entry;
    l3_n1_entry_t l3_n1_entry;
    l4_n1_entry_t l4_n1_entry;
    l5_n1_entry_t l5_n1_entry;

    l1_n2_entry_t l1_n2_entry;
    l2_n2_entry_t l2_n2_entry;
    l3_n2_entry_t l3_n2_entry;
    l4_n2_entry_t l4_n2_entry;
    l5_n2_entry_t l5_n2_entry;

    lf_qd_entry_t lf_qd_entry;
    lf_qp_entry_t lf_qp_entry;

    /* NOTE: all 4 queue_to_sc tables are same size and format anyhow, use entry 0 declaration */
    leafnode_to_queue_entry_t ln2q_entry;
    int32 base_queue1, base_queue2, queue, mc, node, handle;

    rt_fs_entry_t rt_fs_cfg;
    bcm_sbx_subport_info_t *sp_info = NULL;
    int32 node_type, bucket_type, bucket;

    /* sanity check level/node range */
    switch (level) {
	case 0:
	    /* these nodes only move relative to their parents in L1 */
            return SOC_E_PARAM;
	    break;
	case 1:
	    /* copy L1_NM/NG/BP/N1/N2 */
            SOC_IF_ERROR_RETURN(READ_L1_NMm(unit, MEM_BLOCK_ANY, orig_node, &l1_nm_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_NMm(unit, MEM_BLOCK_ANY, dest_node, &l1_nm_entry));

            SOC_IF_ERROR_RETURN(READ_L1_NGm(unit, MEM_BLOCK_ANY, orig_node, &l1_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_NGm(unit, MEM_BLOCK_ANY, dest_node, &l1_ng_entry));

            SOC_IF_ERROR_RETURN(READ_L1_BPm(unit, MEM_BLOCK_ANY, orig_node, &l1_bp_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_BPm(unit, MEM_BLOCK_ANY, dest_node, &l1_bp_entry));

            SOC_IF_ERROR_RETURN(READ_L1_N1m(unit, MEM_BLOCK_ANY, orig_node, &l1_n1_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_N1m(unit, MEM_BLOCK_ANY, dest_node, &l1_n1_entry));

            SOC_IF_ERROR_RETURN(READ_L1_N2m(unit, MEM_BLOCK_ANY, orig_node, &l1_n2_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_N2m(unit, MEM_BLOCK_ANY, dest_node, &l1_n2_entry));

	    /* init L1_BK/N0 to 0 */
	    sal_memset(&l1_bk_entry, 0, sizeof(l1_bk_entry_t));
	    sal_memset(&l1_n0_entry, 0, sizeof(l1_n0_entry_t));
	    sal_memset(&lf_qp_entry, 0, sizeof(lf_qp_entry_t));

            SOC_IF_ERROR_RETURN(WRITE_L1_BKm(unit, MEM_BLOCK_ANY, orig_node, &l1_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_BKm(unit, MEM_BLOCK_ANY, dest_node, &l1_bk_entry));

            SOC_IF_ERROR_RETURN(WRITE_L1_N0m(unit, MEM_BLOCK_ANY, orig_node, &l1_n0_entry));
            SOC_IF_ERROR_RETURN(WRITE_L1_N0m(unit, MEM_BLOCK_ANY, dest_node, &l1_n0_entry));

	    /* copy LF_QD, update leafnode_to_queue and queue_to_sc tables, these
	     * tables are really fix mapped to level 1 nodesg 
	     */
	    if (SOC_SBX_CFG_SIRIUS(unit)->b8kNodes) {
		/* each level 1 node has 2 lf_qd, lf_qp entry */

		/* copy lf_qd */
		SOC_IF_ERROR_RETURN(READ_LF_QDm(unit, MEM_BLOCK_ANY, orig_node*2, &lf_qd_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QDm(unit, MEM_BLOCK_ANY, dest_node*2, &lf_qd_entry));

		SOC_IF_ERROR_RETURN(READ_LF_QDm(unit, MEM_BLOCK_ANY, orig_node*2+1, &lf_qd_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QDm(unit, MEM_BLOCK_ANY, dest_node*2+1, &lf_qd_entry));

		/* copy lf_qp */
		SOC_IF_ERROR_RETURN(READ_LF_QPm(unit, MEM_BLOCK_ANY, orig_node*2, &lf_qp_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QPm(unit, MEM_BLOCK_ANY, dest_node*2, &lf_qp_entry));

		SOC_IF_ERROR_RETURN(READ_LF_QPm(unit, MEM_BLOCK_ANY, orig_node*2+1, &lf_qp_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QPm(unit, MEM_BLOCK_ANY, dest_node*2+1, &lf_qp_entry));

		/* copy leaf_to_queue */
		SOC_IF_ERROR_RETURN(READ_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, orig_node*2, &ln2q_entry));
		base_queue1 = soc_mem_field32_get(unit, LEAFNODE_TO_QUEUEm, &ln2q_entry, LN2Q_BASE_QUEUEf);
		base_queue1 = (base_queue1 << 2);
		SOC_IF_ERROR_RETURN(WRITE_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, dest_node*2, &ln2q_entry));
		
		SOC_IF_ERROR_RETURN(READ_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, orig_node*2+1, &ln2q_entry));
		base_queue2 = soc_mem_field32_get(unit, LEAFNODE_TO_QUEUEm, &ln2q_entry, LN2Q_BASE_QUEUEf);
		base_queue2 = (base_queue2 << 2);
		SOC_IF_ERROR_RETURN(WRITE_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, dest_node*2+1, &ln2q_entry));

		/* update queue_to_sc */
                if (0xFFFC != base_queue1) {
                    for (queue = base_queue1; queue < (base_queue1 + 4); queue++) {
                        rv = soc_sirius_qs_queue_to_leaf_node_get(unit, queue, &mc, &node);
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                        rv = soc_sirius_qs_queue_to_leaf_node_set(unit, queue, mc,
                                                                  (dest_node*2)*4 + (queue & 0x3));
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                    }
                }
                if (0xFFFC != base_queue2) {
                    for (queue = base_queue2; queue < (base_queue2 + 4); queue++) {
                        rv = soc_sirius_qs_queue_to_leaf_node_get(unit, queue, &mc, &node);
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                        rv = soc_sirius_qs_queue_to_leaf_node_set(unit, queue, mc,
                                                                  (dest_node*2+1)*4 + (queue & 0x3));
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                    }
                }

	    } else {
		/* copy lf_qd */
		SOC_IF_ERROR_RETURN(READ_LF_QDm(unit, MEM_BLOCK_ANY, orig_node, &lf_qd_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QDm(unit, MEM_BLOCK_ANY, dest_node, &lf_qd_entry));	    

		/* clear lf_qp */
		SOC_IF_ERROR_RETURN(WRITE_LF_QPm(unit, MEM_BLOCK_ANY, orig_node, &lf_qp_entry));
		SOC_IF_ERROR_RETURN(WRITE_LF_QPm(unit, MEM_BLOCK_ANY, dest_node, &lf_qp_entry));

		/* copy leaf_to_queue */
		SOC_IF_ERROR_RETURN(READ_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, orig_node, &ln2q_entry));
		base_queue1 = soc_mem_field32_get(unit, LEAFNODE_TO_QUEUEm, &ln2q_entry, LN2Q_BASE_QUEUEf);
		base_queue1 = (base_queue1 << 2);
		SOC_IF_ERROR_RETURN(WRITE_LEAFNODE_TO_QUEUEm(unit, MEM_BLOCK_ANY, dest_node, &ln2q_entry));
		
		/* update queue_to_sc */
                if (0xFFFC != base_queue1) {
                    for (queue = base_queue1; queue < (base_queue1 + 4); queue++) {
                        rv = soc_sirius_qs_queue_to_leaf_node_get(unit, queue, &mc, &node);
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                        rv = soc_sirius_qs_queue_to_leaf_node_set(unit, queue, mc,
                                                                  dest_node*4 + (queue & 0x3));
                        if (rv != SOC_E_NONE) {
                            return rv;
                        }
                    }
                }
            }
	    break;
	case 2:
	    /* copy L2_NM/NG/BP/N1/N2 */
            SOC_IF_ERROR_RETURN(READ_L2_NMm(unit, MEM_BLOCK_ANY, orig_node, &l2_nm_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_NMm(unit, MEM_BLOCK_ANY, dest_node, &l2_nm_entry));

            SOC_IF_ERROR_RETURN(READ_L2_NGm(unit, MEM_BLOCK_ANY, orig_node, &l2_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_NGm(unit, MEM_BLOCK_ANY, dest_node, &l2_ng_entry));

            SOC_IF_ERROR_RETURN(READ_L2_BPm(unit, MEM_BLOCK_ANY, orig_node, &l2_bp_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_BPm(unit, MEM_BLOCK_ANY, dest_node, &l2_bp_entry));

            SOC_IF_ERROR_RETURN(READ_L2_N1m(unit, MEM_BLOCK_ANY, orig_node, &l2_n1_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_N1m(unit, MEM_BLOCK_ANY, dest_node, &l2_n1_entry));

            SOC_IF_ERROR_RETURN(READ_L2_N2m(unit, MEM_BLOCK_ANY, orig_node, &l2_n2_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_N2m(unit, MEM_BLOCK_ANY, dest_node, &l2_n2_entry));

	    /* init L2_BK/N0 to 0 */
	    sal_memset(&l2_bk_entry, 0, sizeof(l2_bk_entry_t));
	    sal_memset(&l2_n0_entry, 0, sizeof(l2_n0_entry_t));

            SOC_IF_ERROR_RETURN(WRITE_L2_BKm(unit, MEM_BLOCK_ANY, orig_node, &l2_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_BKm(unit, MEM_BLOCK_ANY, dest_node, &l2_bk_entry));

            SOC_IF_ERROR_RETURN(WRITE_L2_N0m(unit, MEM_BLOCK_ANY, orig_node, &l2_n0_entry));
            SOC_IF_ERROR_RETURN(WRITE_L2_N0m(unit, MEM_BLOCK_ANY, dest_node, &l2_n0_entry));

	    break;
	case 3:
	    /* copy L3_NM/NG/BP/N1/N2 */
            SOC_IF_ERROR_RETURN(READ_L3_NMm(unit, MEM_BLOCK_ANY, orig_node, &l3_nm_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_NMm(unit, MEM_BLOCK_ANY, dest_node, &l3_nm_entry));

            SOC_IF_ERROR_RETURN(READ_L3_NGm(unit, MEM_BLOCK_ANY, orig_node, &l3_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_NGm(unit, MEM_BLOCK_ANY, dest_node, &l3_ng_entry));

            SOC_IF_ERROR_RETURN(READ_L3_BPm(unit, MEM_BLOCK_ANY, orig_node, &l3_bp_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_BPm(unit, MEM_BLOCK_ANY, dest_node, &l3_bp_entry));

            SOC_IF_ERROR_RETURN(READ_L3_N1m(unit, MEM_BLOCK_ANY, orig_node, &l3_n1_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_N1m(unit, MEM_BLOCK_ANY, dest_node, &l3_n1_entry));

            SOC_IF_ERROR_RETURN(READ_L3_N2m(unit, MEM_BLOCK_ANY, orig_node, &l3_n2_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_N2m(unit, MEM_BLOCK_ANY, dest_node, &l3_n2_entry));

	    /* init L3_BK/N0 to 0 */
	    sal_memset(&l3_bk_entry, 0, sizeof(l3_bk_entry_t));
	    sal_memset(&l3_n0_entry, 0, sizeof(l3_n0_entry_t));

            SOC_IF_ERROR_RETURN(WRITE_L3_BKm(unit, MEM_BLOCK_ANY, orig_node, &l3_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_BKm(unit, MEM_BLOCK_ANY, dest_node, &l3_bk_entry));

            SOC_IF_ERROR_RETURN(WRITE_L3_N0m(unit, MEM_BLOCK_ANY, orig_node, &l3_n0_entry));
            SOC_IF_ERROR_RETURN(WRITE_L3_N0m(unit, MEM_BLOCK_ANY, dest_node, &l3_n0_entry));
	    break;
	case 4:
	    /* copy L4_NM/NG/BP/N1/N2 */
            SOC_IF_ERROR_RETURN(READ_L4_NMm(unit, MEM_BLOCK_ANY, orig_node, &l4_nm_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_NMm(unit, MEM_BLOCK_ANY, dest_node, &l4_nm_entry));

            SOC_IF_ERROR_RETURN(READ_L4_NGm(unit, MEM_BLOCK_ANY, orig_node, &l4_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_NGm(unit, MEM_BLOCK_ANY, dest_node, &l4_ng_entry));

            SOC_IF_ERROR_RETURN(READ_L4_BPm(unit, MEM_BLOCK_ANY, orig_node, &l4_bp_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_BPm(unit, MEM_BLOCK_ANY, dest_node, &l4_bp_entry));

            SOC_IF_ERROR_RETURN(READ_L4_N1m(unit, MEM_BLOCK_ANY, orig_node, &l4_n1_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_N1m(unit, MEM_BLOCK_ANY, dest_node, &l4_n1_entry));

            SOC_IF_ERROR_RETURN(READ_L4_N2m(unit, MEM_BLOCK_ANY, orig_node, &l4_n2_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_N2m(unit, MEM_BLOCK_ANY, dest_node, &l4_n2_entry));

	    /* init L4_BK/N0 to 0 */
	    sal_memset(&l4_bk_entry, 0, sizeof(l4_bk_entry_t));
	    sal_memset(&l4_n0_entry, 0, sizeof(l4_n0_entry_t));

            SOC_IF_ERROR_RETURN(WRITE_L4_BKm(unit, MEM_BLOCK_ANY, orig_node, &l4_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_BKm(unit, MEM_BLOCK_ANY, dest_node, &l4_bk_entry));

            SOC_IF_ERROR_RETURN(WRITE_L4_N0m(unit, MEM_BLOCK_ANY, orig_node, &l4_n0_entry));
            SOC_IF_ERROR_RETURN(WRITE_L4_N0m(unit, MEM_BLOCK_ANY, dest_node, &l4_n0_entry));
	    break;
	case 5:
	    /* copy L5_NM/NG/BP/N1/N2 */
            SOC_IF_ERROR_RETURN(READ_L5_NMm(unit, MEM_BLOCK_ANY, orig_node, &l5_nm_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_NMm(unit, MEM_BLOCK_ANY, dest_node, &l5_nm_entry));

            SOC_IF_ERROR_RETURN(READ_L5_NGm(unit, MEM_BLOCK_ANY, orig_node, &l5_ng_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_NGm(unit, MEM_BLOCK_ANY, dest_node, &l5_ng_entry));

            SOC_IF_ERROR_RETURN(READ_L5_BPm(unit, MEM_BLOCK_ANY, orig_node, &l5_bp_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_BPm(unit, MEM_BLOCK_ANY, dest_node, &l5_bp_entry));

            SOC_IF_ERROR_RETURN(READ_L5_N1m(unit, MEM_BLOCK_ANY, orig_node, &l5_n1_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_N1m(unit, MEM_BLOCK_ANY, dest_node, &l5_n1_entry));

            SOC_IF_ERROR_RETURN(READ_L5_N2m(unit, MEM_BLOCK_ANY, orig_node, &l5_n2_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_N2m(unit, MEM_BLOCK_ANY, dest_node, &l5_n2_entry));

	    /* init L5_BK/N0 to 0 */
	    sal_memset(&l5_bk_entry, 0, sizeof(l5_bk_entry_t));
	    sal_memset(&l5_n0_entry, 0, sizeof(l5_n0_entry_t));

            SOC_IF_ERROR_RETURN(WRITE_L5_BKm(unit, MEM_BLOCK_ANY, orig_node, &l5_bk_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_BKm(unit, MEM_BLOCK_ANY, dest_node, &l5_bk_entry));

            SOC_IF_ERROR_RETURN(WRITE_L5_N0m(unit, MEM_BLOCK_ANY, orig_node, &l5_n0_entry));
            SOC_IF_ERROR_RETURN(WRITE_L5_N0m(unit, MEM_BLOCK_ANY, dest_node, &l5_n0_entry));

	    /* update Full mapping if the level 5 node is mapped to a fabric port */
	    for (handle = 0; handle < SB_FAB_DEVICE_SIRIUS_MAX_FC_DOMAINS; handle++) {
		SOC_IF_ERROR_RETURN(READ_RT_FMm(unit, MEM_BLOCK_ANY, handle, &rt_fs_cfg));
		if (soc_mem_field32_get(unit, RT_FMm, &rt_fs_cfg, FULL_ENABLEf)) {
		    if ((1 == soc_mem_field32_get(unit, RT_FMm, &rt_fs_cfg, FULL_LEVELf)) &&
			(orig_node == soc_mem_field32_get(unit, RT_FMm, &rt_fs_cfg, FULL_NODEf))) {
			/* the node is mapped to a flow control domain/sysport */
			rv = soc_sirius_ts_fullmap_config(unit, handle, 5, dest_node);
			if (rv != SOC_E_NONE) {
			    return rv;
			}
			/* update subport info */
			sp_info = &(SOC_SBX_STATE(unit)->port_state->subport_info[handle]);
			if (sp_info->ts_scheduler_node != orig_node) {
			    return SOC_E_INTERNAL;
			} else {
			    sp_info->ts_scheduler_node = dest_node;
			}
		    }
		}
	    }
	    break;
	default:
	    return SOC_E_UNAVAIL;
    }

    /* if regular node, multipath master or flat scheduler master, then the 
     * L1_NM.bucket_table_ptr is same as new node ID. multipath slave or
     * flat scheduler slave should use bucket_table_ptr from orig_node
     */
    rv = soc_sirius_ts_node_mapping_config_get(unit, level, orig_node,
					       &node_type, &bucket_type, &bucket);
    if (rv != SOC_E_NONE) {
	LOG_ERROR(BSL_LS_SOC_COMMON,
		  (BSL_META_U(unit,
			      "ERROR: %s, failed to get child level %d node %d bucket info,  Unit(%d)\n"),
		   FUNCTION_NAME(), level, orig_node, unit));
	return rv;
    }

    if ((bucket_type == SIRIUS_TS_BUCKET_TYPE_BUCKET) ||
	(bucket_type == SIRIUS_TS_BUCKET_TYPE_MULTIPATH_MASTER) ||
	((bucket_type == SIRIUS_TS_BUCKET_TYPE_SUBTREE) && (bucket == orig_node))) {
	rv = soc_sirius_ts_node_mapping_config(unit, level, dest_node,
					       SOC_SIRIUS_API_PARAM_NO_CHANGE,
					       SOC_SIRIUS_API_PARAM_NO_CHANGE,
					       dest_node);
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
	              (BSL_META_U(unit,
	                          "ERROR: %s, failed to set child level %d node %d bucket info,  Unit(%d)\n"),
	               FUNCTION_NAME(), level, dest_node, unit));
	    return rv;
	}	
    }

    return rv;
}

/*
 * Read current priority of a node. Support level 0 to Root
 * for root level, read RT_ST table
 */
int
soc_sirius_ts_node_get_pri(int unit, int level, int node, uint32 *pri)
{
    int rv = SOC_E_NONE;
    lf_qp_entry_t lf_qp_entry;
    l1_n0_entry_t l1_n0_entry;
    l2_n0_entry_t l2_n0_entry;
    l3_n0_entry_t l3_n0_entry;
    l4_n0_entry_t l4_n0_entry;
    l5_n0_entry_t l5_n0_entry;
    l6_n0_entry_t l6_n0_entry;
    l7_n0_entry_t l7_n0_entry;
    rt_st_entry_t rt_st_entry;
    soc_field_t lf_qp_fields[4] = {PRI0f, PRI1f, PRI2f, PRI3f};

    /* Sanity check parameters */
    if ((level < 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d\n"), FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    if (((level < SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) &&
	 (node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   level, node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]-1));
        return SOC_E_PARAM;
    } else if ((level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) && 
	       (node > SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1]-1)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s invalid TS level %d node %d, valid range [0 - %d]\n"), FUNCTION_NAME(),
                   level, node, SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level-1]-1));
        return SOC_E_PARAM;	
    }

    *pri = 0;
    switch (level) {
        case 0:
            SOC_IF_ERROR_RETURN(READ_LF_QPm(unit, MEM_BLOCK_ANY, node/4, &lf_qp_entry));
	    *pri = soc_mem_field32_get(unit, LF_QPm, &lf_qp_entry, lf_qp_fields[node%4]);
            break;
        case 1:
            SOC_IF_ERROR_RETURN(READ_L1_N0m(unit, MEM_BLOCK_ANY, node, &l1_n0_entry));
	    *pri = soc_mem_field32_get(unit, L1_N0m, &l1_n0_entry, CURRENT_PRIf);
            break;
        case 2:
            SOC_IF_ERROR_RETURN(READ_L2_N0m(unit, MEM_BLOCK_ANY, node, &l2_n0_entry));
	    *pri = soc_mem_field32_get(unit, L2_N0m, &l2_n0_entry, CURRENT_PRIf);
            break;
        case 3:
            SOC_IF_ERROR_RETURN(READ_L3_N0m(unit, MEM_BLOCK_ANY, node, &l3_n0_entry));
	    *pri = soc_mem_field32_get(unit, L3_N0m, &l3_n0_entry, CURRENT_PRIf);
            break;
        case 4:
            SOC_IF_ERROR_RETURN(READ_L4_N0m(unit, MEM_BLOCK_ANY, node, &l4_n0_entry));
	    *pri = soc_mem_field32_get(unit, L4_N0m, &l4_n0_entry, CURRENT_PRIf);
            break;
        case 5:
            SOC_IF_ERROR_RETURN(READ_L5_N0m(unit, MEM_BLOCK_ANY, node, &l5_n0_entry));
	    *pri = soc_mem_field32_get(unit, L5_N0m, &l5_n0_entry, CURRENT_PRIf);
            break;
        case 6:
            SOC_IF_ERROR_RETURN(READ_L6_N0m(unit, MEM_BLOCK_ANY, node, &l6_n0_entry));
	    *pri = soc_mem_field32_get(unit, L6_N0m, &l6_n0_entry, CURRENT_PRIf);
            break;
        case 7:
            SOC_IF_ERROR_RETURN(READ_L7_N0m(unit, MEM_BLOCK_ANY, node, &l7_n0_entry));
	    *pri = soc_mem_field32_get(unit, L7_N0m, &l7_n0_entry, CURRENT_PRIf);
            break;
        case 8:
	    SOC_IF_ERROR_RETURN(READ_RT_STm(unit, MEM_BLOCK_ANY, node, &rt_st_entry));
	    *pri = soc_mem_field32_get(unit, RT_STm, &rt_st_entry, CHILD_PRIf);
            break;
    }

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s, level %d node %d current pri is %d\n"),
                 FUNCTION_NAME(), level, node, *pri));
    return rv;
}

/*
 * Regenerate priorities (Lx_N0, RT_ST) of a node. Support level 1 to Root level
 * for Root level, write RT_ST table
 */
int
soc_sirius_ts_node_regenerate_pri(int unit, int level, int node, uint32 *new_pri, uint32 bubble_up)
{
    int rv = SOC_E_NONE;
    uint32 child_pri, current_child, current_pri;
    int32 parent, child, first_child, num_child;
    soc_mem_t mem[9] = {LF_QPm, L1_N0m, L2_N0m, L3_N0m, L4_N0m,
			L5_N0m, L6_N0m, L7_N0m, RT_STm};
    uint32    mem_val[SOC_MAX_MEM_WORDS];
    soc_field_t child_pri_fields[8] = {CHILD_PRI0f, CHILD_PRI1f, CHILD_PRI2f, CHILD_PRI3f,
				       CHILD_PRI4f, CHILD_PRI5f, CHILD_PRI6f, CHILD_PRI7f};
    int debug = 0;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s: called \n"), FUNCTION_NAME()));

    if ((level <= 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s can not regenerate priority on TS level %d\n"),
                   FUNCTION_NAME(), level));
        return SOC_E_PARAM;
    }

    /* read from hw */
    SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    
    if (level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) {
	rv = soc_sirius_ts_node_get_pri(unit, level-1, node, &child_pri);
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "soc_sirius_ts_node_get_pri return error %d, l=%d\n"), rv, level));
	    return rv;
	}
	soc_mem_field32_set(unit, mem[level], mem_val, CHILD_PRIf, child_pri);
	SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
	sal_usleep(100);
	SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
	
	LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META_U(unit,
                                "%s: change root level current_pri to %d, l=%d n=%d\n"),
                     FUNCTION_NAME(), child_pri, level, node));
	
	if (new_pri != NULL) {
	    *new_pri = child_pri;
	}
	return rv;
    }
    
    /* get the hierachy info */
    rv = soc_sirius_ts_node_hierachy_config_get(unit, level, node, &parent,
						&first_child, &num_child);
    if (rv != SOC_E_NONE) {
	return rv;
    }

    /* regenerate the child pris for level 1-7 */
    current_child = 0;
    current_pri = 0;
    for (child = first_child; child < first_child+8; child++) {
        if (child >= first_child+num_child) {
	    child_pri = 0;
	} else {
	    /* read child pri */
	    rv = soc_sirius_ts_node_get_pri(unit, level-1, child, &child_pri);
	    if (rv != SOC_E_NONE) {
	        return rv;
	    }
	}

	/* update child_pri field */
	soc_mem_field32_set(unit, mem[level], mem_val, child_pri_fields[child-first_child],
			    child_pri);
				
	/* recalculate current_child, current_pri */
	if (child_pri > current_pri) {
	    current_pri = child_pri;
	    current_child = child-first_child;
	}	
    }

    /* make sure no child has child_pri equal to current_pri to prevent 
     * message filtering when the node is unshaped later
     */
    for (child = first_child; child < first_child+num_child; child++) {
	/* update child_pri field */
        child_pri = soc_mem_field32_get(unit, mem[level], mem_val, child_pri_fields[child-first_child]);
				
	/* recalculate current_child, current_pri */
	if (child_pri && (child_pri == current_pri)) {
	    soc_mem_field32_set(unit, mem[level], mem_val, child_pri_fields[child-first_child],
				child_pri+1);
	}	
    }

    /* update current_child, current_pri field */    
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s: change current_pri to %d current_child to %d, l=%d node=%d\n"),
                 FUNCTION_NAME(), current_pri, current_child, level, node));

    soc_mem_field32_set(unit, mem[level], mem_val, CURRENT_PRIf, current_pri);
    soc_mem_field32_set(unit, mem[level], mem_val, CURRENT_CHILDf, current_child);
    if (new_pri != NULL) {
	*new_pri = current_pri;
    }

    /* write to memory */
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    sal_usleep(100);
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s, level %d node %d current pri is %d\n"),
                 FUNCTION_NAME(), level, node, current_pri));

    /* read back and dump info */
    if (debug) {
	SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
	current_pri = soc_mem_field32_get(unit, mem[level], mem_val, CURRENT_PRIf);
	current_child = soc_mem_field32_get(unit, mem[level], mem_val, CURRENT_CHILDf);
	LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META_U(unit,
                                "%s: read back current_pri to %d current_child to %d, l=%d node=%d\n"),
                     FUNCTION_NAME(), current_pri, current_child, level, node));    
	for (child = first_child; child < first_child+num_child; child++) {
	    child_pri = soc_mem_field32_get(unit, mem[level], mem_val, child_pri_fields[child-first_child]);
	    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                        (BSL_META_U(unit,
                                    "%s: read back child %d pri %d, l=%d node=%d\n"),
                         FUNCTION_NAME(), child, child_pri, level, node));    
	}
    }

    if (bubble_up && (level<8)) {
        if (level==7) {
	    parent = node;
        }
        rv = soc_sirius_ts_node_regenerate_pri(unit, level+1, parent, NULL, bubble_up);
    }
    
    return rv;
}

/*
 * Regenerate priorities (Lx_N0, RT_ST) when a child node has priority change.
 * return new current priority of the node.
 * Support level 1 to Root level for Root level, write RT_ST table
 */
int
soc_sirius_ts_node_update_child_pri(int unit, int level, int node, int child,
				    uint32 child_pri, uint32 *new_pri)
{
    int rv = SOC_E_NONE;
    uint32 current_child, current_pri;
    int32 parent, first_child, num_child, tmp_node;
    soc_mem_t mem[9] = {LF_QPm, L1_N0m, L2_N0m, L3_N0m, L4_N0m,
			L5_N0m, L6_N0m, L7_N0m, RT_STm};
    uint32    mem_val[SOC_MAX_MEM_WORDS];
    soc_field_t child_pri_fields[8] = {CHILD_PRI0f, CHILD_PRI1f, CHILD_PRI2f, CHILD_PRI3f,
				       CHILD_PRI4f, CHILD_PRI5f, CHILD_PRI6f, CHILD_PRI7f};

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s: called \n"), FUNCTION_NAME()));

    if ((level <= 0) || (level > SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s can not update child %d priority on TS level %d node %d\n"),
                   FUNCTION_NAME(), child, level, node));
        return SOC_E_PARAM;
    }

    /* read from hw */
    SOC_IF_ERROR_RETURN(soc_mem_read(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    
    if (level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) {
	soc_mem_field32_set(unit, mem[level], mem_val, CHILD_PRIf, child_pri);
	SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
	*new_pri = child_pri;
	LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s, level %d node %d current pri is %d\n"),
                   FUNCTION_NAME(), level, node, child_pri));
	return rv;
    }
    
    /* get the hierachy info */
    rv = soc_sirius_ts_node_hierachy_config_get(unit, level, node, &parent,
						&first_child, &num_child);
    if (rv != SOC_E_NONE) {
	return rv;
    }

    if ((child < first_child) || (child > first_child+num_child)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s node %d not a child of TS level %d node %d\n"),
                   FUNCTION_NAME(), child, level, node));	
	return SOC_E_PARAM;
    }

    /* update child_pri field */
    soc_mem_field32_set(unit, mem[level], mem_val, child_pri_fields[child-first_child], child_pri);	

    /* recalculate current_child, current_pri, don't trust existing current_child/pri read
     * from memory as it might not be matching with all child_pris.
     */
    current_pri = 0;
    current_child = 0;
    for (tmp_node = 0; tmp_node < num_child; tmp_node++) {
	child_pri = soc_mem_field32_get(unit, mem[level], mem_val, child_pri_fields[tmp_node]);
	if (child_pri > current_pri) {
	    current_pri = child_pri;
	    current_child = tmp_node;
	}
    }
    /* update current_child, current_pri field */
    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s: change current_pri to %d\n"),FUNCTION_NAME(), current_pri));
    soc_mem_field32_set(unit, mem[level], mem_val, CURRENT_PRIf, current_pri);
    soc_mem_field32_set(unit, mem[level], mem_val, CURRENT_CHILDf, current_child);
    *new_pri = current_pri;

    /* write to memory */
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    sal_usleep(100);
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));
    sal_usleep(100);
    SOC_IF_ERROR_RETURN(soc_mem_write(unit, mem[level], MEM_BLOCK_ANY, node, mem_val));

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "%s, level %d node %d current pri is %d current child is %d\n"),
                 FUNCTION_NAME(), level, node, current_pri, current_child));
    return rv;
}

int
soc_sirius_scheduler_init(int unit, int level, int node, int egress)
{
    int rv = SOC_E_NONE;
    int child, parent;

    if (egress) {
        if ( (level < 0) || (level >= SB_FAB_DEVICE_SIRIUS_NUM_ES_LEVELS) ) {
            return SOC_E_INTERNAL;
        }
    } else {
        if ( (level < 0) || (level >= SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) ) {
            return SOC_E_INTERNAL;
        }
    }

    if (egress) {
        if ( (level >= SIRIUS_ES_LEVEL_FIFO) && (level <= SIRIUS_ES_LEVEL_CHANNEL) ) {
            /* init to disabled shaper/scheduler, hierachy unconnected */
            rv = soc_sirius_es_node_shaper_config(unit, level, node, TRUE /*min shaper*/,
                                                  FALSE /*disable*/, 0, 0, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d min shaper, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }
        }

        if ( (level >= SIRIUS_ES_LEVEL_FIFO) && (level <= SIRIUS_ES_LEVEL_INTERFACE) ) {
            rv = soc_sirius_es_node_shaper_config(unit, level, node, FALSE /*max shaper*/,
                                                  FALSE /*disable*/, 0, 0, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d max shaper, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }
        }

        if ( (level >= SIRIUS_ES_LEVEL_FIFO) && (level <= SIRIUS_ES_LEVEL_CHANNEL) ) {
            rv = soc_sirius_es_node_scheduler_config(unit, level, node, TRUE /*min scheduler*/,
                                                     SIRIUS_ES_SCHEDULER_MODE_WERR, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d min scheduler, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }

            rv = soc_sirius_es_node_scheduler_config(unit, level, node, FALSE /*max scheduler*/,
                                                     SIRIUS_ES_SCHEDULER_MODE_WERR, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d max scheduler, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }

            if (level == SIRIUS_ES_LEVEL_FIFO) {
		if ((node % 4) == 0) {
		    /* use the last subport node since the default one won't work unless has uniq map_index */
		    rv = soc_sirius_es_node_hierachy_config(unit, level, node, FALSE /*disabled*/,
							    0, 0, (SB_FAB_DEVICE_SIRIUS_NUM_EGRESS_SCHEDULER_L1-1),
							    FALSE /*non-EF*/);
		} else {
		    rv = soc_sirius_es_node_hierachy_config(unit, level, node, FALSE /*disabled*/,
							    SOC_SIRIUS_API_PARAM_NO_CHANGE,
							    SOC_SIRIUS_API_PARAM_NO_CHANGE,
							    SOC_SIRIUS_API_PARAM_NO_CHANGE,
							    FALSE /*non-EF*/);
		}
            } else if (level == SIRIUS_ES_LEVEL_SUBPORT) {
                rv = soc_sirius_es_node_hierachy_config(unit, level, node, FALSE /*disabled*/,
                                                        0, 0, SOC_SIRIUS_API_PARAM_NO_CHANGE,
                                                        SOC_SIRIUS_API_PARAM_NO_CHANGE);
            } else {
	        /* if (level == SIRIUS_ES_LEVEL_CHANNEL) { */
                rv = soc_sirius_es_node_hierachy_config(unit, level, node, FALSE /*disabled*/,
                                                        0, SOC_SIRIUS_API_PARAM_NO_CHANGE,
                                                        SOC_SIRIUS_API_PARAM_NO_CHANGE,
                                                        SOC_SIRIUS_API_PARAM_NO_CHANGE);
            }

            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d hierachy, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }
        }

	if ( level == SIRIUS_ES_LEVEL_FIFO ) {
	    rv = soc_sirius_es_node_group_shaper_member_config(unit, 0, node, FALSE);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init es level %d node %d group shaper, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }
	}
    } else {
        if (node >= SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level]) {
            /* requested node is out of range */
            return SOC_E_INTERNAL;
        }

        /* init to default node, bucket type, node profile 0 (adopt all), bucket table pointer
         * point to itself, shaper/creditor disabled, parent/child point to last node in the level
         */
        if ((level > 0) && (level < SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS)) {
            rv = soc_sirius_ts_node_mapping_config(unit, level, node, SIRIUS_TS_NODE_TYPE_DEFAULT,
                                                   SIRIUS_TS_BUCKET_TYPE_BUCKET, node);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init level %d node %d node mapping, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }

            rv = soc_sirius_ts_node_shaper_config(unit, level, node, FALSE,/* disabled */
                                                  0, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init level %d node %d shaper, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }

            rv = soc_sirius_ts_node_creditor_config(unit, level, node, FALSE,
                                                    0, SIRIUS_TS_NODE_PROFILE_TEMPLATE_AF0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init level %d node %d creditor, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }

            for (child = 0; child <= 7; child++) {
                rv = soc_sirius_ts_node_child_weight_config(unit, level, node, child, 0);
                if (rv != SOC_E_NONE) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "ERROR: %s, can not init level %d node %d child %d weight, Unit(%d)\n"),
                               FUNCTION_NAME(), level, node, child, unit));
                    return rv;
                }
            }

            if (level != 7) {
                parent = SOC_SBX_CFG_SIRIUS(unit)->uNumTsNode[level+1]-1;
            } else {
                parent = 0;
            }
            rv = soc_sirius_ts_node_hierachy_config(unit, level, node, parent, 0, 0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init level %d node %d hierachy, Unit(%d)\n"),
                           FUNCTION_NAME(), level, node, unit));
                return rv;
            }
        } else if (level == 0) {
            /* leaf node, set the destination fifo to be 0, can not set to a large value since
             * it would be treated as a multicast fifo
             */
            rv = soc_sirius_ts_leaf_node_dest_fifo_set(unit, node, 0x0);
            if (rv != SOC_E_NONE) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "ERROR: %s, can not init leaf node %d, Unit(%d)\n"),
                           FUNCTION_NAME(), node, unit));
                return rv;
            }
            /* coverity[dead_error_line] */
        } else if (level == SB_FAB_DEVICE_SIRIUS_NUM_TS_LEVELS) {
            /* root */
            /* do nothing?? */
        }
    }

    return rv;

}

/*
 * configure es node shaper
 *     level:             SIRIUS_ES_LEVEL_INTERFACE
 *                        SIRIUS_ES_LEVEL_CHANNEL
 *                        SIRIUS_ES_LEVEL_SUBPORT
 *                        SIRIUS_ES_LEVEL_FIFO
 *     node:              node number (different meaning depends on level)
 *     min:               TRUE: min shaper FALSE: max shaper
 *     enable:            TRUE: enable     FALSE: disable
 *     rate:              rate in kbits/second
 *     threshold:         in bits
 *  SOC_SIRIUS_API_PARAM_NO_CHANGE means the particular config will not be changed
 */
int
soc_sirius_es_node_shaper_config(int unit, int level, int node, int min, int enable,
                                 int rate, int threshold, int tick_select)
{
    int rv = SOC_E_NONE;
    uint32 rate_mant = 0, rate_exp = 0, rate_me = 0;
    uint32 burst_mant = 0, burst_exp = 0, burst_me = 0;
    uint32 min_threshold = 0;
    uint64 min_threshold64 = COMPILER_64_INIT(0,0);
    group_max_shaper_table_entry_t group_shaper_entry;
    interface_max_shaper_table_entry_t intf_entry;
    channel_shaper_table_entry_t channel_entry;
    subport_shaper_table_entry_t subport_entry;
    fifo_shaper_table_0_entry_t fifo_0_entry;
    /* assuming fifo0-3 shaper have same format
       fifo_shaper_table_1_entry_t fifo_1_entry;
       fifo_shaper_table_2_entry_t fifo_2_entry;
       fifo_shaper_table_3_entry_t fifo_3_entry;
    */

    if ( (level != SIRIUS_ES_LEVEL_GROUP_SHAPER) && 
	 ((level < SIRIUS_ES_LEVEL_FIFO) || (level > SIRIUS_ES_LEVEL_INTERFACE)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es level %d for shaper config. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (node < 0) ||
	 ((level == SIRIUS_ES_LEVEL_GROUP_SHAPER) && (node >= 100)) ||
         ((level == SIRIUS_ES_LEVEL_FIFO) && (node > SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_SUBPORT) && (node > SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_CHANNEL) && (node > SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_INTERFACE) && (node >= 7)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es node %d on level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, level, unit));
        return SOC_E_PARAM;
    }

    if ( (level == SIRIUS_ES_LEVEL_INTERFACE) &&
         (min == TRUE) &&
	 (enable == TRUE) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, min shaper not supported on es level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if (enable == FALSE) {
        rate = 0;
        threshold = 0;
    }

    if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
        uint64 uuTmp;
	/* convert to mant/exp format */
	rv = soc_sbx_fabric_util_num_to_mant_exp(unit, SUBPORT_SHAPER_TABLEm, MIN_REF_RATEf, rate,
						 &rate_mant, &rate_exp);
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "ERROR: %s, es %s shaper rate conversion failed. Unit(%d)\n"),
                       FUNCTION_NAME(), (min)?"min":"max", unit));
	    return rv;
	}

	/* no longer allow caller to select tick_select, SDK pick tick_select based on rate_exp so that
	 * full burst size range (2MB) could be used low rate should have large tick_select to have better accuracy.
	 */
	if (rate == 0) {
	    tick_select = 0;
	} else if (rate_exp <= 1) {
	    tick_select = 9;
	} else if (rate_exp >= 7) {
	    /* this would make sure the burst size could be larger than 128K bytes */
	    tick_select = 0;
	} else {
	    tick_select = 10 - rate_exp - 4;
	}

	/* make sure threshold is at least 3 refresh cycles worth of bits, 
	 * refresh cycle is 1.95us, which is 499/256 
	 */
	COMPILER_64_ZERO(min_threshold64);
        COMPILER_64_SET(uuTmp, 0, rate * 3 * 499);
        COMPILER_64_SHL(uuTmp, tick_select);
	COMPILER_64_ADD_64(min_threshold64, uuTmp);
	rv = soc_sbx_div64(min_threshold64, (256 * 1000), &min_threshold);
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
	              (BSL_META_U(unit,
	                          "ERROR: %s failed to calculate min_threshold from rate of %d kbps\n"),
	               FUNCTION_NAME(), rate));
            return(rv);
	}
	if ((threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) && (threshold < min_threshold)) {
	    threshold = min_threshold;
	}
    }

    if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
	rv = soc_sbx_fabric_util_num_to_mant_exp(unit, SUBPORT_SHAPER_TABLEm, MIN_THLDf, threshold,
						 &burst_mant, &burst_exp);
	if (rv != SOC_E_NONE) {
	    LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "ERROR: %s, es %s shaper threshold conversion failed. Unit(%d)\n"),
                       FUNCTION_NAME(), (min)?"min":"max", unit));
	    return rv;
	}
    }

#define MAX_RR_CLR 0x3FFF

    /* programe tick_sel, enable, ref_rate and threshold */
    switch (level) {
        case SIRIUS_ES_LEVEL_INTERFACE:
	    if (min == TRUE) {
		/* no interface min shaper */
		break;
	    }
            SOC_IF_ERROR_RETURN(READ_INTERFACE_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &intf_entry));
            if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		if (enable == 0) {
		    /* set MAX_REF_RATE high to allow congestion to clear before disabling */
		    soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, MAX_REF_RATEf, MAX_RR_CLR);
		    SOC_IF_ERROR_RETURN(WRITE_INTERFACE_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &intf_entry));
		    sal_usleep(100);
		}
                soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, ENf, (enable)?1:0);
                soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, MAX_BKTf, 0);
            }
            if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, MAX_REF_RATEf, rate_me);
            }
            if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, TICK_SELf, tick_select);
	    }
            if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                soc_mem_field32_set(unit, INTERFACE_MAX_SHAPER_TABLEm, &intf_entry, MAX_THLDf, burst_me);
            }
            SOC_IF_ERROR_RETURN(WRITE_INTERFACE_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &intf_entry));
            break;
        case SIRIUS_ES_LEVEL_CHANNEL:
            SOC_IF_ERROR_RETURN(READ_CHANNEL_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            if (min) {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, EN_MINf, (enable)?1:0);
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MIN_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MIN_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, TICK_SELf, tick_select);
		}
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MIN_THLDf, burst_me);
                }
            } else {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		    if (enable == 0) {
			/* set MAX_REF_RATE high to allow congestion to clear before disabling */
			soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MAX_REF_RATEf, MAX_RR_CLR);
			SOC_IF_ERROR_RETURN(WRITE_CHANNEL_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
			sal_usleep(100);
		    }
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, EN_MAXf, (enable)?1:0);
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MAX_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MAX_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, TICK_SELf, tick_select);
		}
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, CHANNEL_SHAPER_TABLEm, &channel_entry, MAX_THLDf, burst_me);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_CHANNEL_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
            SOC_IF_ERROR_RETURN(READ_SUBPORT_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            if (min) {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, EN_MINf, (enable)?1:0);
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MIN_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MIN_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, TICK_SELf, tick_select);
		}
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MIN_THLDf, burst_me);
                }
            } else {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		    if (enable == 0) {
			/* set MAX_REF_RATE high to allow congestion to clear before disabling */
			soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MAX_REF_RATEf, MAX_RR_CLR);
			SOC_IF_ERROR_RETURN(WRITE_SUBPORT_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
			sal_usleep(100);
		    }
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, EN_MAXf, (enable)?1:0);
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MAX_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MAX_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, TICK_SELf, tick_select);
		}
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, SUBPORT_SHAPER_TABLEm, &subport_entry, MAX_THLDf, burst_me);
                }
            }
            SOC_IF_ERROR_RETURN(WRITE_SUBPORT_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            break;
        case SIRIUS_ES_LEVEL_FIFO:
            if (node < 132) {
                SOC_IF_ERROR_RETURN(READ_FIFO_SHAPER_TABLE_0m(unit, MEM_BLOCK_ANY, node, &fifo_0_entry));
            } else if (node < 264) {
                SOC_IF_ERROR_RETURN(READ_FIFO_SHAPER_TABLE_1m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            } else if (node < 396) {
                SOC_IF_ERROR_RETURN(READ_FIFO_SHAPER_TABLE_2m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            } else {
                SOC_IF_ERROR_RETURN(READ_FIFO_SHAPER_TABLE_3m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            }

            if (min) {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, EN_MINf, (enable)?1:0);
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MIN_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MIN_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, TICK_SELf, tick_select);
		}
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MIN_THLDf, burst_me);
                }
            } else {
                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		    if (enable == 0) {
			/* set MAX_REF_RATE high to allow congestion to clear before disabling */
			soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MAX_REF_RATEf, MAX_RR_CLR);
			if (node < 132) {
			    SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_0m(unit, MEM_BLOCK_ANY, node, &fifo_0_entry));
			} else if (node < 264) {
			    SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_1m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
			} else if (node < 396) {
			    SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_2m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
			} else {
			    SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_3m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
			}
			sal_usleep(100);
		    }
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, EN_MAXf, (enable)?1:0);
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MAX_BKTf, 0);
                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MAX_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, TICK_SELf, tick_select);
		} 
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, FIFO_SHAPER_TABLE_0m, &fifo_0_entry, MAX_THLDf, burst_me);
                }
            }

            if (node < 132) {
                SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_0m(unit, MEM_BLOCK_ANY, node, &fifo_0_entry));
            } else if (node < 264) {
                SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_1m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            } else if (node < 396) {
                SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_2m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            } else {
                SOC_IF_ERROR_RETURN(WRITE_FIFO_SHAPER_TABLE_3m(unit, MEM_BLOCK_ANY, node % 132, &fifo_0_entry));
            }
            break;
	case SIRIUS_ES_LEVEL_GROUP_SHAPER:
	    /* group shaper */
	    if (min) {
		/* no min group shaper */
		return SOC_E_UNAVAIL;
	    } else {
		SOC_IF_ERROR_RETURN(READ_GROUP_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_shaper_entry));

                if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
		    if (enable == 0) {
			/* set MAX_REF_RATE high to allow congestion to clear before disabling */
			soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, MAX_REF_RATEf, MAX_RR_CLR);
			SOC_IF_ERROR_RETURN(WRITE_GROUP_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_shaper_entry));
			/* read back */
			SOC_IF_ERROR_RETURN(READ_GROUP_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_shaper_entry));
			/* wait a while till it no longer shapes */
			sal_usleep(1000);
		    }
                    soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, ENf, (enable)?1:0);
                    soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, MAX_BKTf, 0);

                }
                if (rate != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    rate_me = ((rate_mant & 0x3FF) | ((rate_exp & 0xF) << 10));
                    soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, MAX_REF_RATEf, rate_me);
                }
		if (tick_select != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, TICK_SELf, tick_select);
		} 
                if (threshold != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                    burst_me = ((burst_mant & 0x7F) | ((burst_exp & 0xF) << 7));
                    soc_mem_field32_set(unit, GROUP_MAX_SHAPER_TABLEm, &group_shaper_entry, MAX_THLDf, burst_me);
                }

                SOC_IF_ERROR_RETURN(WRITE_GROUP_MAX_SHAPER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_shaper_entry));
	    }
	    break;
        /* coverity[dead_error_begin] */
        default:
            return SOC_E_INTERNAL;
    }

    return rv;
}

/*
 * configure es hierachy
 *     level:             SIRIUS_ES_LEVEL_CHANNEL
 *                        SIRIUS_ES_LEVEL_SUBPORT
 *                        SIRIUS_ES_LEVEL_FIFO
 *     node:              node number (different meaning depends on level)
 *     enable:            TRUE: enable the node
 *     intf:              interface the node is on (apply to channel, subport and fifo level only)
 *     channel:           channel the node is on (apply to subport and fifo level only)
 *     subport:           subport the node is on (apply to fifo level only)
 *     ef:                is fifo EF type (apply to fifo level only)
 *  SOC_SIRIUS_API_PARAM_NO_CHANGE means the particular config will not be changed
 */
int
soc_sirius_es_node_hierachy_config(int unit, int level, int node, int enable, int intf,
                                   int channel, int subport, int ef)
{
    int rv = SOC_E_NONE;
    channel_map_table_entry_t channel_entry;
    subport_map_table_entry_t subport_entry;
    fifo_map_table_entry_t fifo_entry;
    fifo_group_map_table_entry_t fifo_group_entry;

    if ( (level < SIRIUS_ES_LEVEL_FIFO) || (level > SIRIUS_ES_LEVEL_CHANNEL) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es level %d for hierachy config. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (node < 0) ||
         ((level == SIRIUS_ES_LEVEL_FIFO) && (node > SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_SUBPORT) && (node > SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_CHANNEL) && (node > SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es node %d on level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, level, unit));
        return SOC_E_PARAM;
    }

    if ( ((level == SIRIUS_ES_LEVEL_CHANNEL) && ( (channel != SOC_SIRIUS_API_PARAM_NO_CHANGE) ||
                                                  (subport != SOC_SIRIUS_API_PARAM_NO_CHANGE) ||
                                                  (ef != SOC_SIRIUS_API_PARAM_NO_CHANGE) )) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es level %d can not specify channel, subport or ef. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }


    if ( ((level == SIRIUS_ES_LEVEL_SUBPORT) && ( (subport != SOC_SIRIUS_API_PARAM_NO_CHANGE) ||
                                                  (ef != SOC_SIRIUS_API_PARAM_NO_CHANGE) )) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es level %d can not specify, subport or ef. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (intf != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((intf < 0) || (intf >= 7)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es invalid interface %d, valid range [0-6]. Unit(%d)\n"),
                   FUNCTION_NAME(), intf, unit));
        return SOC_E_PARAM;
    }

    if ( (channel != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((channel < 0) || (channel >= 132)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es invalid channel %d, valid range [0-131]. Unit(%d)\n"),
                   FUNCTION_NAME(), channel, unit));
        return SOC_E_PARAM;
    }

    if ( (subport != SOC_SIRIUS_API_PARAM_NO_CHANGE) &&
         ((subport < 0) || (subport >= 132)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es invalid subport %d, valid range [0-131]. Unit(%d)\n"),
                   FUNCTION_NAME(), subport, unit));
        return SOC_E_PARAM;
    }

    switch (level) {
        case SIRIUS_ES_LEVEL_CHANNEL:
            SOC_IF_ERROR_RETURN(READ_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, CHANNEL_MAP_TABLEm, &channel_entry, ENf, (enable)?1:0);
            }
            if (intf != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, CHANNEL_MAP_TABLEm, &channel_entry, INFf, intf);
            }
            SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
            SOC_IF_ERROR_RETURN(READ_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, ENf, (enable)?1:0);
            }
            if (intf != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, INFf, intf);
            }
            if (channel != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, CHNf, channel);
            }
            SOC_IF_ERROR_RETURN(WRITE_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            break;
        case SIRIUS_ES_LEVEL_FIFO:
            /* individual fifo config */
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));
            if (enable != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf, (enable)?1:0);
            }
            if (ef != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, EFf, (ef)?1:0);
            }
            SOC_IF_ERROR_RETURN(WRITE_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));

            /* 
	     * FIFO_GROUP_MAP_TABLE entries correlate 1:4 directly with FIFO+MAP_TABLE entries.
	     * Therefore, The information stored in FIFO_GROUP_MAP_TABLE 0 directly affects
	     * FIFO_MAP_TABLE entries 0-3 and information stored in FIFO_GROUP_MAP_TABLE 2 
	     * affects FIFO_MAP_TABLE entries 8-11. This is fixed by the h/w.
	     */
            node >>= 2;
            SOC_IF_ERROR_RETURN(READ_FIFO_GROUP_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_group_entry));
            if (intf != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, INFf, intf);
            }
            if (channel != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, CHNf, channel);
            }
            if (subport != SOC_SIRIUS_API_PARAM_NO_CHANGE) {
                soc_mem_field32_set(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, SPTf, subport);
            }
            SOC_IF_ERROR_RETURN(WRITE_FIFO_GROUP_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_group_entry));
            break;
        /* coverity[dead_error_begin] */
        default:
            return SOC_E_INTERNAL;
    }

    return rv;
}


/*
 * For now, this function is for warmboot only
 */
int
soc_sirius_es_node_hierachy_config_get(int unit, int level, int node, int* enable,
				       int *intf, int *channel, int *subport,
				       int *index, int *ef)
{
    int rv = SOC_E_NONE;
    channel_map_table_entry_t channel_entry;
    subport_map_table_entry_t subport_entry;
    fifo_map_table_entry_t fifo_entry;
    fifo_group_map_table_entry_t fifo_group_entry;

    if ( (level < SIRIUS_ES_LEVEL_FIFO) || (level > SIRIUS_ES_LEVEL_ROOT) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es level %d for hierachy config. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (node < 0) ||
         ((level == SIRIUS_ES_LEVEL_FIFO) && (node > SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_SUBPORT) && (node > SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_CHANNEL) && (node > SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es node %d on level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, level, unit));
        return SOC_E_PARAM;
    }

    if ((enable == NULL) || (intf == NULL) || (channel == NULL) ||
	(subport == NULL) || (index == NULL) || (ef == NULL)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, require to pass back all info. Unit(%d)\n"),
                   FUNCTION_NAME(), unit));
        return SOC_E_INTERNAL;
    }

    switch (level) {
        case SIRIUS_ES_LEVEL_ROOT:
	    *enable = TRUE;
	    *intf = -1;
	    *subport = -1;
	    *channel = -1;
	    *index = -1;
	    *ef = FALSE;	    
	    break;
        case SIRIUS_ES_LEVEL_INTERFACE:
	    *enable = TRUE;
	    *intf = node;
	    *subport = -1;
	    *channel = -1;
	    *index = -1;
	    *ef = FALSE;	    
	    break;
        case SIRIUS_ES_LEVEL_CHANNEL:
            SOC_IF_ERROR_RETURN(READ_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
	    *enable = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, ENf);
	    *intf = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, INFf);
	    *subport = -1;
	    *channel = -1;
	    *index = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, MAP_INDEXf);
	    *ef = FALSE;
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
            SOC_IF_ERROR_RETURN(READ_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
	    *enable = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, ENf);
	    *intf = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, INFf);
	    *channel = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, CHNf);
	    *subport = -1;
	    *index = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &channel_entry, MAP_INDEXf);
	    *ef = FALSE;
            break;
        case SIRIUS_ES_LEVEL_FIFO:
            /* individual fifo config */
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));
	    *enable = soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf);
	    *ef = soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, EFf);

	    /* fifo group config */
	    node >>= 2;
            SOC_IF_ERROR_RETURN(READ_FIFO_GROUP_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_group_entry));
	    *intf = soc_mem_field32_get(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, INFf);
	    *channel = soc_mem_field32_get(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, CHNf);
	    *subport = soc_mem_field32_get(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, SPTf);
	    *index = soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, MAP_INDEXf);
            break;
        /* coverity[dead_error_begin:FALSE] */
        default:
            return SOC_E_INTERNAL;
    }

    return rv;
}

/*
 * configure es scheduler
 *     level:             SIRIUS_ES_LEVEL_CHANNEL
 *                        SIRIUS_ES_LEVEL_SUBPORT
 *                        SIRIUS_ES_LEVEL_FIFO
 *     node:              node number (different meaning depends on level)
 *     min:               TRUE: min creditor FALSE: max creditor
 *     mode:              SIRIUS_ES_SCHEDULER_MODE_SP
 *                        SIRIUS_ES_SCHEDULER_MODE_WERR
 *     param:             when mode is SP. priority of fifo in the subport
 *                        when mode is RR/WERR. weight of fifo in the subport
 *  SOC_SIRIUS_API_PARAM_NO_CHANGE means the particular config will not be changed
 */
int
soc_sirius_es_node_scheduler_config(int unit, int level, int node, int min,
                                    int mode, int param)
{
    int rv = SOC_E_NONE;
    channel_map_table_entry_t channel_entry;
    subport_map_table_entry_t subport_entry;
    fifo_map_table_entry_t fifo_entry;

    channel_werr_table_entry_t channel_werr_entry;
    subport_werr_table_entry_t subport_werr_entry;
    fifo_werr_table_entry_t fifo_werr_entry;


    if ( (level < SIRIUS_ES_LEVEL_FIFO) || (level > SIRIUS_ES_LEVEL_CHANNEL) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es level %d for hierachy config. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (node < 0) ||
         ((level == SIRIUS_ES_LEVEL_FIFO) && (node > SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_SUBPORT) && (node > SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_CHANNEL) && (node > SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es node %d on level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, level, unit));
        return SOC_E_PARAM;
    }

    if ( (mode == SIRIUS_ES_SCHEDULER_MODE_SP) && ((param < 0) || (param >= 0x3F)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es strict pri mode invalid priority %d, valid range [0-63]. Unit(%d)\n"),
                   FUNCTION_NAME(), param, unit));
        return SOC_E_PARAM;
    }

    if ( (mode == SIRIUS_ES_SCHEDULER_MODE_WERR) && ((param < 0) || (param >= 0x7F)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, es werr mode invalid weight %d, valid range [0-127]. Unit(%d)\n"),
                   FUNCTION_NAME(), param, unit));
        return SOC_E_PARAM;
    }

    switch (level) {
        case SIRIUS_ES_LEVEL_CHANNEL:
            SOC_IF_ERROR_RETURN(READ_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            if (min) {
                soc_mem_field32_set(unit, CHANNEL_MAP_TABLEm, &channel_entry, MIN_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            } else {
                soc_mem_field32_set(unit, CHANNEL_MAP_TABLEm, &channel_entry, MAX_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            }

            if (mode == SIRIUS_ES_SCHEDULER_MODE_SP) {
                soc_mem_field32_set(unit, CHANNEL_MAP_TABLEm, &channel_entry, MAP_INDEXf, param);
            } else {
                SOC_IF_ERROR_RETURN(READ_CHANNEL_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_werr_entry));
                soc_mem_field32_set(unit, CHANNEL_WERR_TABLEm, &channel_werr_entry, WEIGHTf, param);
                SOC_IF_ERROR_RETURN(WRITE_CHANNEL_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_werr_entry));
            }
            SOC_IF_ERROR_RETURN(WRITE_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
            SOC_IF_ERROR_RETURN(READ_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            if (min) {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, MIN_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            } else {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, MAX_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            }

            if (mode == SIRIUS_ES_SCHEDULER_MODE_SP) {
                soc_mem_field32_set(unit, SUBPORT_MAP_TABLEm, &subport_entry, MAP_INDEXf, param);
            } else {
                SOC_IF_ERROR_RETURN(READ_SUBPORT_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_werr_entry));
                soc_mem_field32_set(unit, SUBPORT_WERR_TABLEm, &subport_werr_entry, WEIGHTf, param);
                SOC_IF_ERROR_RETURN(WRITE_SUBPORT_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_werr_entry));
            }
            SOC_IF_ERROR_RETURN(WRITE_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
            break;
        case SIRIUS_ES_LEVEL_FIFO:
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));
            if (min) {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, MIN_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            } else {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, MAX_SPf,
                                    (mode == SIRIUS_ES_SCHEDULER_MODE_SP)?1:0);
            }

            if (mode == SIRIUS_ES_SCHEDULER_MODE_SP) {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, MAP_INDEXf, param);
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, EFf, 0);

            } else if (mode == SIRIUS_ES_SCHEDULER_MODE_WERR) {
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, EFf, 0);
                SOC_IF_ERROR_RETURN(READ_FIFO_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_werr_entry));
                soc_mem_field32_set(unit, FIFO_WERR_TABLEm, &fifo_werr_entry, WEIGHTf, param);
                SOC_IF_ERROR_RETURN(WRITE_FIFO_WERR_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_werr_entry));
            }
            else { /* SIRIUS_ES_SCHEDULER_MODE_EF */
                soc_mem_field32_set(unit, FIFO_MAP_TABLEm, &fifo_entry, EFf, 1);
            }
            SOC_IF_ERROR_RETURN(WRITE_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));
            break;
        /* coverity[dead_error_begin] */
        default:
            return SOC_E_INTERNAL;
    }

    return rv;

}

int
soc_sirius_es_node_get_info(int unit, int level, int node, int *parent, int *index)
{
    int rv = SOC_E_NONE;
    int enable = FALSE;
    channel_map_table_entry_t channel_entry;
    subport_map_table_entry_t subport_entry;
    fifo_group_map_table_entry_t fifo_group_entry;
    fifo_map_table_entry_t fifo_entry;

    if ( (level < SIRIUS_ES_LEVEL_FIFO) || (level > SIRIUS_ES_LEVEL_CHANNEL) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es level %d for hierachy config. Unit(%d)\n"),
                   FUNCTION_NAME(), level, unit));
        return SOC_E_PARAM;
    }

    if ( (node < 0) ||
         ((level == SIRIUS_ES_LEVEL_FIFO) && (node > SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_SUBPORT) && (node > SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max)) ||
         ((level == SIRIUS_ES_LEVEL_CHANNEL) && (node > SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max)) ) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es node %d on level %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, level, unit));
        return SOC_E_PARAM;
    }

    switch (level) {
        case SIRIUS_ES_LEVEL_CHANNEL:
            SOC_IF_ERROR_RETURN(READ_CHANNEL_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &channel_entry));
	    enable = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, ENf);
            if (enable) {
                *parent = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, INFf);
		*index = soc_mem_field32_get(unit, CHANNEL_MAP_TABLEm, &channel_entry, MAP_INDEXf);
            } else {
		*parent = -1;
		*index = -1;
		rv = SOC_E_NOT_FOUND;
	    }
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
            SOC_IF_ERROR_RETURN(READ_SUBPORT_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &subport_entry));
	    enable = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, ENf);
            if (enable) {
                *parent = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, CHNf);
                *index = soc_mem_field32_get(unit, SUBPORT_MAP_TABLEm, &subport_entry, MAP_INDEXf);
            } else {
		*parent = -1;
		*index = -1;
		rv = SOC_E_NOT_FOUND;
	    }
            break;
        case SIRIUS_ES_LEVEL_FIFO:
            /* individual fifo config */
            SOC_IF_ERROR_RETURN(READ_FIFO_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_entry));
	    enable = soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, ENf);

            /* fifo group directly associated with fifo_map by ratio of 1:4 */
            node >>= 2;
            SOC_IF_ERROR_RETURN(READ_FIFO_GROUP_MAP_TABLEm(unit, MEM_BLOCK_ANY, node, &fifo_group_entry));
            if (enable) {
                *parent = soc_mem_field32_get(unit, FIFO_GROUP_MAP_TABLEm, &fifo_group_entry, SPTf);
		*index = soc_mem_field32_get(unit, FIFO_MAP_TABLEm, &fifo_entry, MAP_INDEXf);
            } else {
		*parent = -1;
		*index = -1;
		rv = SOC_E_NOT_FOUND;
	    }
            break;
	    /* coverity[dead_error_begin] */
        default:
            return SOC_E_INTERNAL;
    }

    return rv;
}

int
soc_sirius_es_node_group_shaper_member_config(int unit, int group, int node, int enable)
{
    int rv = SOC_E_NONE;
    group_member_table_entry_t group_member_entry;
    
    if ((enable != FALSE) && 
	((group < 0) || (group >= SB_FAB_DEVICE_SIRIUS_NUM_EGRESS_GROUP_SHAPER))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es group shaper %d. Unit(%d)\n"),
                   FUNCTION_NAME(), group, unit));
	return SOC_E_PARAM;
    }

    if (enable == FALSE) {
	group = 0;
    }

    if ((node < 0) || (node >= SB_FAB_DEVICE_SIRIUS_NUM_EGRESS_SCHEDULER_L0)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, invalid es group shaper member node %d. Unit(%d)\n"),
                   FUNCTION_NAME(), node, unit));
	return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_GROUP_MEMBER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_member_entry));
    soc_mem_field32_set(unit, GROUP_MEMBER_TABLEm, &group_member_entry, ENf, enable?1:0);
    soc_mem_field32_set(unit, GROUP_MEMBER_TABLEm, &group_member_entry, GROUP_NUMf, group);
    SOC_IF_ERROR_RETURN(WRITE_GROUP_MEMBER_TABLEm(unit, MEM_BLOCK_ANY, node, &group_member_entry));
    
    return rv;
}

/*
 * soc_sirius_es_root_scheduler_config
 * Parameters
 *     nIntf:             maximum interfaces
 *     intf_weight:       weights associated with each interface
 *
 * Comments
 *     Currently handling weight of 0/1. Need to be later enhanced.
 *     intf 7 is the dummy interface used for dummy entries
 */
static sirius_tdm_table_entry_info_t  sirius_es_tdm_4x20_1[114] =
{
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_CPU_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,1},
};

static sirius_tdm_table_entry_info_t  sirius_es_tdm_4x10_2x20_1[114] =
{
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_CPU_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,1},
};

static sirius_tdm_table_entry_info_t  sirius_es_tdm_2x20_2x20_1[114] =
{
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_CPU_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,1},
};

static sirius_tdm_table_entry_info_t  sirius_es_tdm_2x24_1[48] =
{
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_CPU_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,1},
};

/*
 * Following is the TDM table to support 2*24G + 2*20G.
 * 2*24G supports 24*1G interfaces on each of the 2 HiGig's.
 * 2*20G supports 2*10G interfaces on each of the 2 HiGig's.
 * The following Table is based on 2*20G to be supported on HG0/HG1 and
 * 2*48G be supported on HG2/HG3. A local copy of this table will be
 * modified when the configuration is on different HiGig interfaces.
 */

static sirius_tdm_table_entry_info_t  sirius_es_tdm_2x24_2x20_1[128] =
{                                         /*slot #*/
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  1  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  2  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  3  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  4  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  5  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  6  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  7  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  8  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  9  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  10  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  11  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  12  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  13  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  14  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  15  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  16  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  17  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  18  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  19  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  20  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  21  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  22  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  23  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  24  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  25  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     0, 0},  /*  26  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  27  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  28  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  29  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  30  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  31  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  32  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  33  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     0, 0},  /*  34  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  35  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  36  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  37  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  38  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  39  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  40  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  41  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  42  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  43  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  44  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  45  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  46  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  47  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  48  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  49  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  50  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  51  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  52  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  53  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  54  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  55  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  56  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  57  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  58  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  59  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  60  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  61  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  62  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  63  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     0, 0},  /*  64  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  65  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  66  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  67  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  68  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  69  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  70  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  71  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     0, 0},  /*  72  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  73  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  74  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  75  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  76  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  77  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  78  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  79  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  80  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  81  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  82  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  83  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  84  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  85  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  86  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  87  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  88  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  89  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  90  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  91  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  92  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  93  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  94  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  95  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  96  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  97  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  98  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  99  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  100  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  101  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     0, 0},  /*  102  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  103  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  104  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  105  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  106  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  107  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  108  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  109  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     0, 0},  /*  110  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  111  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  112  */
    {SB_FAB_DEVICE_SIRIUS_CPU_INTF,     1, 0},  /*  113  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  114  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  115  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  116  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  117  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  118  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  119  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  120  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  121  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  122  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  123  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   1, 0},  /*  124  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  125  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  126  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  127  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 1}   /*  128  */
};

/* 
 *  This TDM table supports the following configurations:
 *      4x11G Xports + 25G RQ0 + 11G RQ1
 *      4x11G Xports + 12G RQ0 + 24G RQ1
 *      4x11G Xports + 11G RQ0 + 25G RQ1
 *  Note: CPU port is not supported in these configurations
 */
static sirius_tdm_table_entry_info_t sirius_es_tdm_5x11_1x25[30] =
{                                               /*slot #*/
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  1  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  2  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  3  */
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,     0, 0},  /*  4  */
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,     1, 0},  /*  5  */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  6  */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  7  */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     0, 0},  /*  8  */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  9  */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     0, 0},  /*  10 */
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,     1, 0},  /*  11 */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  12 */
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,     1, 0},  /*  13 */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  14 */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     1, 0},  /*  15 */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     0, 0},  /*  16 */
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,     1, 0},  /*  17 */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  18 */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     1, 0},  /*  19 */
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,     0, 0},  /*  20 */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     1, 0},  /*  21 */
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,     0, 0},  /*  22 */
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,     1, 0},  /*  23 */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 0},  /*  24 */
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,     1, 0},  /*  25 */
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,     0, 0},  /*  26 */
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,     1, 0},  /*  27 */
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,     0, 0},  /*  28 */
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,     1, 0},  /*  29 */
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,   0, 1}   /*  30 */
};

/* 
 *  This TDM table supports the following configurations:
 *      4x11G Xports + 2x18G RQ ports
 *  Note: CPU port is not supported in these configurations
 */
static sirius_tdm_table_entry_info_t  sirius_es_tdm_4x11_2x18[112] =
{
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG2_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_HG3_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_DUMMY_INTF,0,0},
    {SB_FAB_DEVICE_SIRIUS_RQ0_INTF,  1,0},
    {SB_FAB_DEVICE_SIRIUS_RQ1_INTF,  0,1}
};

typedef struct soc_sirius_es_tdm_table_list_entry_s {
    char                            *name;
    sirius_tdm_table_entry_info_t   *table;
    int                             size; /* number of entries in table */
}soc_sirius_es_tdm_table_list_entry_t;

static soc_sirius_es_tdm_table_list_entry_t soc_sirius_es_tdm_table_list[] = {
    {spn_BCM8823X_4X20_1, sirius_es_tdm_4x20_1, 
     sizeof(sirius_es_tdm_4x20_1)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_4X10_2X20_1, sirius_es_tdm_4x10_2x20_1, 
     sizeof(sirius_es_tdm_4x10_2x20_1)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_2X20_2X20_1, sirius_es_tdm_2x20_2x20_1, 
     sizeof(sirius_es_tdm_2x20_2x20_1)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_2X24_1, sirius_es_tdm_2x24_1, 
     sizeof(sirius_es_tdm_2x24_1)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_2X24_2X20_1, sirius_es_tdm_2x24_2x20_1, 
     sizeof(sirius_es_tdm_2x24_2x20_1)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_4X11_1X25_1X11, sirius_es_tdm_5x11_1x25, 
     sizeof(sirius_es_tdm_5x11_1x25)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_4X11_1X12_1X24, sirius_es_tdm_5x11_1x25, 
     sizeof(sirius_es_tdm_5x11_1x25)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_4X11_1X11_1X25, sirius_es_tdm_5x11_1x25, 
     sizeof(sirius_es_tdm_5x11_1x25)/sizeof(sirius_tdm_table_entry_info_t)},
    {spn_BCM8823X_4X11_2X18, sirius_es_tdm_4x11_2x18, 
     sizeof(sirius_es_tdm_4x11_2x18)/sizeof(sirius_tdm_table_entry_info_t)}
};

static int soc_sirius_es_tdm_table_count = 
    sizeof(soc_sirius_es_tdm_table_list)/
    sizeof(soc_sirius_es_tdm_table_list_entry_t);

int
soc_sirius_es_root_scheduler_config_dynamic(int unit)
{
    int rv = SOC_E_NONE;
    tdm_table_entry_t tdm_entry;
    bcm_sbx_subport_info_t *sp_info = NULL;
    sirius_tdm_table_entry_info_t *tdm_entry_info=NULL;
    int tdm_index;
    int num_entry = 0;
    int tdm_enable;
    int higig, num_higig, intf, port;
    uint regval;
    int req_ports_valid;
    int is_88g = 0;
    int agg_bw, rq_bw, num_subports, subport, rq_ports_bw_same, speed;
    int hg_port_speeds_line_side[SB_FAB_DEVICE_SIRIUS_NUM_HG_LINE_PORTS];
    int rq_port_speeds_line_side[SB_FAB_DEVICE_SIRIUS_NUM_REQUEUE_PORTS];
    int remapped_intf[SB_FAB_DEVICE_SIRIUS_DUMMY_INTF + 1];
    int num_24g_intfs, idx;
    
    /* Instead of using an algorithm to compute the TDM table based on the interface
     *  speed, use Hardware defined senerios, which in theory should cover all
     *  possible cases
     * Scenario 0: 4*20G Xport, 1G CPU
     * Scenario 1: 4*10G Xport, 2*20G RQ, 1G CPU
     * Scenario 2: 2*20G Xport, 2*20G RQ, 1G CPU
     * Scenario 3: 2*24G Xport, 1G CPU
     * Scenario 4: 2*24G and 2*20G Xport, 1G CPU
     * Scenario 5: 4x11G Xport + 25G RQ0 + 11G RQ1
     * Scenario 6: 4x11G Xport + 12G RQ0 + 24G RQ1
     * Scenario 7: 4x11G Xport + 11G RQ0 + 25G RQ1
     * Scenario 8: 4x11G Xport + 2x18G RQ
     */

    for(idx = 0; idx < (SB_FAB_DEVICE_SIRIUS_DUMMY_INTF + 1); idx++) {
        remapped_intf[idx] = idx; /* remap to itself */
    }

    /*
     *  Figure out whether requeue ports are included.  This is based upon the
     *  actual configuration, rather than some supposition from the particular
     *  mode that is in use, since it is possible to use requeue in more than
     *  one of the possible device modes, but it is also possible to not use
     *  requeue in those modes.
     */
    rq_bw = 0;
    num_higig = 0;
    for (higig = 0;
         higig < SB_FAB_DEVICE_SIRIUS_NUM_REQUEUE_PORTS;
         higig++) {
        rq_port_speeds_line_side[higig] = 0;
        intf = higig + SB_FAB_DEVICE_SIRIUS_RQ0_INTF;
        num_subports = SOC_SBX_SIRIUS_STATE(unit)->uNumInternalSubports[intf];
        num_subports += SOC_SBX_SIRIUS_STATE(unit)->uNumExternalSubports[intf];
        if (num_subports > 0) {
            num_higig++;
            for (subport = 0; 
                 (subport < SB_FAB_DEVICE_SIRIUS_MAX_FABRIC_PORTS) && (num_subports > 0); 
                 subport++) {
                sp_info = &(SOC_SBX_STATE(unit)->port_state->subport_info[subport]);
                if ((sp_info == NULL) || (sp_info->valid == FALSE))
                    continue;
                if (BCM_GPORT_IS_MODPORT(sp_info->parent_gport))
                    port = BCM_GPORT_MODPORT_PORT_GET(sp_info->parent_gport);
                else if (BCM_GPORT_IS_EGRESS_MODPORT(sp_info->parent_gport)) 
                    port = BCM_GPORT_EGRESS_MODPORT_PORT_GET(sp_info->parent_gport);
                else
                    continue;
                if (IS_REQ_PORT(unit, port) && (higig == SOC_PORT_OFFSET(unit, port))) {
                    /* Min supported speed on a sub-port is 1G */
                    speed = sp_info->egroup[0].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE];
                    rq_port_speeds_line_side[higig] += ((speed > 0) ? speed : 1000);
                    num_subports--;
                }
            }
            rq_bw += rq_port_speeds_line_side[higig];
            if (rq_port_speeds_line_side[higig] > 25000) {
                LOG_CLI((BSL_META_U(unit,
                                    "ERROR: %s: Requeue %d total subport speed %d >"
                                    " max speed 20000\n"),
                         FUNCTION_NAME(),
                         higig,
                         rq_port_speeds_line_side[higig]));
                return SOC_E_CONFIG;
            }
        }
    }
    req_ports_valid = (num_higig > 0);
    rq_ports_bw_same = 1;
    if (req_ports_valid && (rq_bw < 40000)) {
        /* This maps to sirius_es_tdm_5x11_1x25. Check if RQ IFs need remap */
        if (rq_port_speeds_line_side[0] > rq_port_speeds_line_side[1]) {
            /* The default sirius_es_tdm_5x11_1x25 is for RQ0 < RQ1. 
             * Current configuration is different. So, remap RQ1 with RQ0. 
             */
            remapped_intf[SB_FAB_DEVICE_SIRIUS_RQ0_INTF] = 
                SB_FAB_DEVICE_SIRIUS_RQ1_INTF;
            remapped_intf[SB_FAB_DEVICE_SIRIUS_RQ1_INTF] = 
                SB_FAB_DEVICE_SIRIUS_RQ0_INTF;
        }
        if (rq_port_speeds_line_side[0] != rq_port_speeds_line_side[1]) {
            rq_ports_bw_same = 0;
        }
    }

    is_88g = 0;
    num_higig = 0;
    agg_bw = 0;
    for (higig=0; higig < SB_FAB_DEVICE_SIRIUS_NUM_HG_LINE_PORTS; higig++) {
        hg_port_speeds_line_side[higig] = 0;
        intf = SB_FAB_DEVICE_SIRIUS_HG0_INTF + higig;
        num_subports = SOC_SBX_SIRIUS_STATE(unit)->uNumExternalSubports[intf];
        if (num_subports > 0) {
            /* TDM table specifications are based on HG0 & HG1 being the first 
             * two interfaces...actual configuration can be different. If so,
             * remapped_intf is used to override the interface
             */
            remapped_intf[(num_higig + SB_FAB_DEVICE_SIRIUS_HG0_INTF)] = intf;
            num_higig++;
            for (subport = 0; 
                 (subport < SB_FAB_DEVICE_SIRIUS_MAX_FABRIC_PORTS) && (num_subports > 0); 
                 subport++) {
                sp_info = &(SOC_SBX_STATE(unit)->port_state->subport_info[subport]);
                if ((sp_info == NULL) || (sp_info->valid == FALSE))
                    continue;
                if (BCM_GPORT_IS_MODPORT(sp_info->parent_gport))
                    port = BCM_GPORT_MODPORT_PORT_GET(sp_info->parent_gport);
                else if (BCM_GPORT_IS_EGRESS_MODPORT(sp_info->parent_gport)) 
                    port = BCM_GPORT_EGRESS_MODPORT_PORT_GET(sp_info->parent_gport);
                else
                    continue;
                if (IS_HG_PORT(unit, port) && (higig == SOC_PORT_OFFSET(unit, port))) {
                    /* Min supported speed on a sub-port is 1G */
                    speed = sp_info->egroup[0].port_speed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE];
                    hg_port_speeds_line_side[higig] += ((speed > 0) ? speed : 1000);
                }
                hg_port_speeds_line_side[higig] += 
                (SOC_SBX_CFG_SIRIUS(unit)->uSubportSpeed[SB_FAB_DEVICE_SIRIUS_FIFO_GROUP_MAX_SIZE]);
                num_subports--;
            }
            agg_bw += hg_port_speeds_line_side[higig];
        }
    }

    if (agg_bw > 80000 /* 80G */) {
        num_24g_intfs = 0;
        for (higig=0; higig<SB_FAB_DEVICE_SIRIUS_NUM_HG_LINE_PORTS; higig++) {
            if (hg_port_speeds_line_side[higig] >= 24000) {
                if (num_24g_intfs >= 2) {
                    LOG_CLI((BSL_META_U(unit,
                                        "ERROR: %s: Found %d ports with >24G total "
                                        "subport speed. Max supported are 2 ports \n"),
                             FUNCTION_NAME(), (num_24g_intfs + 1)));
                    return SOC_E_CONFIG;
                }
                num_24g_intfs++;
            }
        }
        /* For 2x24G+2x20G, TDM table defined is based on HG0 and HG1 being 24G
         * interfaces. Its possible to run with other configuration. See if TDM
         * table needs to re-map interfaces
         */
        if (hg_port_speeds_line_side[2 /* HG2 */] >= 24000) {
            /* HG2 BW is > 24G. see if HG0 can be remapped with HG2 */
            if (hg_port_speeds_line_side[0 /* HG0 */] < 24000) {
                /* remap HG0 <-> HG2 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG0_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG2_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG2_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG0_INTF;
            } else {
                /* remap HG1 <-> HG2 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG1_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG2_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG2_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG1_INTF;
            }
        }
        if (hg_port_speeds_line_side[3 /* HG3 */] >= 24000) {
            if (hg_port_speeds_line_side[1 /* HG1 */] < 24000) {
                /* remap HG1 <-> HG3 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG3_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG1_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG1_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG3_INTF;
            } else {
                /* remap HG0 <-> HG3 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG3_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG0_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG0_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG3_INTF;
            }
        }

        is_88g = 1; /* mark 88G flag as true */
    }

    if (req_ports_valid) {
        if (num_higig <= 2) {
            /* 2*20G Xport, 2*20G RQ, 1G CPU */
            tdm_entry_info = sirius_es_tdm_2x20_2x20_1;
            num_entry = sizeof(sirius_es_tdm_2x20_2x20_1)/
                        sizeof(sirius_tdm_table_entry_info_t);
        } else if (rq_bw < 40000) {
            if (rq_ports_bw_same) {
                /* 4*11G Xport + 2*18G requeue ports */
                tdm_entry_info = sirius_es_tdm_4x11_2x18;
                num_entry = sizeof(sirius_es_tdm_4x11_2x18)/
                            sizeof(sirius_tdm_table_entry_info_t);
            } else {
                /* 4*11G Xport + 36G requeue ports (11+25 or 12+24 or 25+11) */
                tdm_entry_info = sirius_es_tdm_5x11_1x25;
                num_entry = sizeof(sirius_es_tdm_5x11_1x25)/
                            sizeof(sirius_tdm_table_entry_info_t);
            }
        } else {
            /* 
             * 4 Xports and 40G aggregate for requeue ports
             * 4*10G Xport, 2*20G RQ, 1G CPU 
             */
            tdm_entry_info = sirius_es_tdm_4x10_2x20_1;
            num_entry = sizeof(sirius_es_tdm_4x10_2x20_1)/
                        sizeof(sirius_tdm_table_entry_info_t);
        }
    } else {
        /* no requeue ports */
        if (num_higig <= 2) {
            /* 2*24G Xport, 1G CPU */
            tdm_entry_info = sirius_es_tdm_2x24_1;
            num_entry = sizeof(sirius_es_tdm_2x24_1)/
                        sizeof(sirius_tdm_table_entry_info_t);
        } else if (is_88g) {
            /* 88G TDM 2x24 + 2x20 + 1G CPU */
            tdm_entry_info = sirius_es_tdm_2x24_2x20_1;
            num_entry = sizeof(sirius_es_tdm_2x24_2x20_1)/
                        sizeof(sirius_tdm_table_entry_info_t);
        } else {
            /* 4*20G Xport, 1G CPU */
            tdm_entry_info = sirius_es_tdm_4x20_1;
            num_entry = sizeof(sirius_es_tdm_4x20_1)/
                        sizeof(sirius_tdm_table_entry_info_t);
        }
    }

    /* have to disable TDM to allow TDM table update */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    tdm_enable = soc_reg_field_get(unit, ES_CONFIGr, regval, TDM_ENABLEf);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, TDM_ENABLEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    for (tdm_index = 0; tdm_index < num_entry; tdm_index++) {
        SOC_IF_ERROR_RETURN(READ_TDM_TABLEm(unit, MEM_BLOCK_ANY, tdm_index, 
                                            &tdm_entry));
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, END_FLAGf, 
                            tdm_entry_info[tdm_index].end);
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, START_FLAGf, 
                            tdm_entry_info[tdm_index].sop);
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, INTERFACE_NUMf, 
                            remapped_intf[tdm_entry_info[tdm_index].intf]);

        SOC_IF_ERROR_RETURN(WRITE_TDM_TABLEm(unit, MEM_BLOCK_ANY, tdm_index, 
                                             &tdm_entry));
    }
    /* reset the rest of entries */
    for (;tdm_index < soc_mem_index_max(unit, TDM_TABLEm); tdm_index++) {
        sal_memset(&tdm_entry, 0, sizeof(tdm_entry));
        SOC_IF_ERROR_RETURN(WRITE_TDM_TABLEm(unit, MEM_BLOCK_ANY, tdm_index, 
                                             &tdm_entry));
    }

    /* restore the tdm_enable */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_CONFIGr, &regval, TDM_ENABLEf, tdm_enable);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    return(rv);
}

/*
 * Note that this function returns SOC_E_NONE only when a valid 
 * ES (TDM) table is configured and successfully programmed. 
 * SOC_E_* should be treated as STATIC configuration not done 
 * rather than as error. 
*/
int
soc_sirius_es_root_scheduler_config_static(int unit)
{
    int     idx, hg_idx, intf, val, tdm_table_size, tdm_enable;
    int     remapped_intf[SB_FAB_DEVICE_SIRIUS_DUMMY_INTF + 1];
    char    *p_tdm_table_name = NULL;
    uint32  regval;
    sirius_tdm_table_entry_info_t   *p_tdm_table = NULL;
    tdm_table_entry_t               tdm_entry;


    if (SOC_SBX_CFG_SIRIUS(unit)->is_static_es) {
        /* if static, ES is already programmed. Skip the rest */
        return SOC_E_NONE;
    }

    val = 0;
    tdm_table_size = 0;
    /* figure out which tdm table to select */
    for (idx = 0; idx < soc_sirius_es_tdm_table_count; idx++) {
        val = soc_property_get(unit, soc_sirius_es_tdm_table_list[idx].name,0);
        if (val) {
            p_tdm_table_name = soc_sirius_es_tdm_table_list[idx].name;
            p_tdm_table = soc_sirius_es_tdm_table_list[idx].table;
            tdm_table_size = soc_sirius_es_tdm_table_list[idx].size;
            break;
        }
    }
    if (idx >= soc_sirius_es_tdm_table_count) {
        /* static ES not configured. */
        return SOC_E_CONFIG;
    }
    if ((p_tdm_table == NULL) || (p_tdm_table_name == NULL)) {
        /* Null ptr checks */
        return SOC_E_INTERNAL;
    }
    /* A Valid Static ES (TDM) table configured. Continue with programming */

    /* reset the remap table */
    for(idx = 0; idx < (SB_FAB_DEVICE_SIRIUS_DUMMY_INTF + 1); idx++) {
        remapped_intf[idx] = idx; /* map to itself */
    }
    /* special checks for some TDM tables to adjust for interface properties */
    if ((p_tdm_table == sirius_es_tdm_2x20_2x20_1) ||
        (p_tdm_table == sirius_es_tdm_2x24_1)) {
        /* 
         * TDM table specifications are based on HG0 & HG1 being the first 
         * two interfaces...actual configuration can be different. If so,
         * remapped_intf is used to override the interface
         */
        hg_idx = 0;
        for (idx = 0; idx < SB_FAB_DEVICE_SIRIUS_NUM_HG_LINE_PORTS; idx++) {
            intf = SB_FAB_DEVICE_SIRIUS_HG0_INTF + idx;
            if (SOC_SBX_SIRIUS_STATE(unit)->uNumExternalSubports[intf] > 0) {
                remapped_intf[hg_idx + SB_FAB_DEVICE_SIRIUS_HG0_INTF] = intf;
                hg_idx++;
            }
        }
    } else if (p_tdm_table == sirius_es_tdm_2x24_2x20_1) {
        /* The default TDM table assumes HG0 & HG1 are 24G. If different,
         * the interfaces in TDM table should be re-mapped
         */
        switch (val) {
            case 1:
                /* 24-24-20-20 no remapping */
                break;
            case 2:
                /* 24-20-24-20 remap HG1 & HG2 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG1_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG2_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG2_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG1_INTF;
                break;
            case 3:
                /* 24-20-20-24 remap HG1 & HG3 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG1_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG3_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG3_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG1_INTF;
                break;
            case 4:
                /* 20-24-24-20 remap HG0 & HG2 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG0_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG2_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG2_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG0_INTF;
                break;
            case 5:
                /* 20-24-20-24 remap HG0 & HG3 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG0_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG3_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG3_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG0_INTF;
                break;
            case 6:
                /* 20-20-24-24 remap HG0-HG2 & HG1-HG3 */
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG0_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG2_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG2_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG0_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG1_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG3_INTF;
                remapped_intf[SB_FAB_DEVICE_SIRIUS_HG3_INTF] = 
                    SB_FAB_DEVICE_SIRIUS_HG1_INTF;
                break;
            default:
                LOG_CLI((BSL_META_U(unit,
                                    "ERROR: invalid value (%d) for TDM table soc "
                                    "property (%s) \n"), val, p_tdm_table_name));
                return SOC_E_CONFIG;
                break;
        }
    } else if (!strncmp(p_tdm_table_name, spn_BCM8823X_4X11_1X25_1X11, 
                        sizeof(spn_BCM8823X_4X11_1X25_1X11))) {
        remapped_intf[SB_FAB_DEVICE_SIRIUS_RQ0_INTF] = 
            SB_FAB_DEVICE_SIRIUS_RQ1_INTF;
        remapped_intf[SB_FAB_DEVICE_SIRIUS_RQ1_INTF] = 
            SB_FAB_DEVICE_SIRIUS_RQ0_INTF;
    }

    /* have to disable TDM to allow TDM table update */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    tdm_enable = soc_reg_field_get(unit, ES_CONFIGr, regval, TDM_ENABLEf);
    soc_reg_field_set(unit, ES_CONFIGr, &regval, TDM_ENABLEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));

    for (idx = 0; idx < tdm_table_size; idx++) {
        SOC_IF_ERROR_RETURN(READ_TDM_TABLEm(unit, MEM_BLOCK_ANY, idx, 
                                            &tdm_entry));
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, END_FLAGf, 
                            p_tdm_table[idx].end);
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, START_FLAGf, 
                            p_tdm_table[idx].sop);
        soc_mem_field32_set(unit, TDM_TABLEm, &tdm_entry, INTERFACE_NUMf, 
                            remapped_intf[p_tdm_table[idx].intf]);

        SOC_IF_ERROR_RETURN(WRITE_TDM_TABLEm(unit, MEM_BLOCK_ANY, idx, 
                                             &tdm_entry));
    }
    /* reset the rest of entries */
    for (;idx < soc_mem_index_max(unit, TDM_TABLEm); idx++) {
        sal_memset(&tdm_entry, 0, sizeof(tdm_entry));
        SOC_IF_ERROR_RETURN(WRITE_TDM_TABLEm(unit, MEM_BLOCK_ANY, idx, 
                                             &tdm_entry));
    }
    /* restore the tdm_enable */
    SOC_IF_ERROR_RETURN(READ_ES_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_CONFIGr, &regval, TDM_ENABLEf, tdm_enable);
    SOC_IF_ERROR_RETURN(WRITE_ES_CONFIGr(unit, regval));
  
    /* if success, set the static ES indicator to 1 */ 
    SOC_SBX_CFG_SIRIUS(unit)->is_static_es = 1;

    return SOC_E_NONE;
}

int
soc_sirius_es_root_scheduler_config(int unit)
{
    int rv;

    /* check for static configuration first */
    rv = soc_sirius_es_root_scheduler_config_static(unit);
    if (SOC_SUCCESS(rv)) {
        /* if successful, return */
        return rv;
    }
    /* static configuration failed, try dynamic */
    rv = soc_sirius_es_root_scheduler_config_dynamic(unit);

    return rv;
}

/*
 * return first available map_index for children of a ES node
 */
int
soc_sirius_es_node_map_index_first_available(int unit, int level, int node, int *index) {
    int rv = SOC_E_NONE;
    int parent, child_level, child_node, child_index, max_node;
    int bitpos;
    SHR_BITDCLNAME(mapmask, 64);

    /* clear bitmask */
    SHR_BITCLR_RANGE(mapmask, 0, 64);

    switch (level) {
        case SIRIUS_ES_LEVEL_INTERFACE:
	    max_node = SOC_MEM_INFO(unit, CHANNEL_MAP_TABLEm).index_max;
	    break;
        case SIRIUS_ES_LEVEL_CHANNEL:
	    max_node = SOC_MEM_INFO(unit, SUBPORT_MAP_TABLEm).index_max;
            break;
        case SIRIUS_ES_LEVEL_SUBPORT:
	    max_node = SOC_MEM_INFO(unit, FIFO_MAP_TABLEm).index_max;
	    /* map index is from 0-15, set high bits to be unavail */
	    SHR_BITSET_RANGE(mapmask, 16, 48);
            break;
	default:
	    rv = SOC_E_INTERNAL;
	    return rv;
    }

    child_level = level - 1;

    for (child_node = 0; child_node < max_node; child_node++) {
	/* go through all nodes to find all with matching parent */
	rv = soc_sirius_es_node_get_info(unit, child_level, child_node,
					 &parent, &child_index);
	if (rv == SOC_E_NONE) {
	    if (parent == node) {
		if (SHR_BITGET(mapmask, child_index)) {
		    LOG_WARN(BSL_LS_SOC_COMMON,
                             (BSL_META_U(unit,
                                         "map_index %d on level %d node %d already used\n"),
                              child_index, child_level, child_node));
		}
		SHR_BITSET(mapmask, child_index);
	    }
	} else if (rv == SOC_E_NOT_FOUND) {
	    /* ignore if the node is not connected to any parent */
	    continue;
	} else {
	    /* real error */
	    return rv;
	}
    }

    /* find the first bit not set */
    *index = -1;
    rv = SOC_E_NOT_FOUND;
    for (bitpos = 0; bitpos < 64; bitpos++) {
	if (SHR_BITGET(mapmask, bitpos) == 0) {
	    *index = bitpos;
	    rv = SOC_E_NONE;
	    break;
	}
    }

    return rv;
}


/***********************************************
 * Write to a HyperCore phy register.
 *  For registers above address location 0x001f this function will load the
 *  base address of the block containing the given register unless it is
 *  already set.
 *  For broadcast writes users should use the soc_sirius_mdio_hc_broadcast_write function.
 */
int soc_sirius_mdio_hc_write(int unit, uint32 uPhyAddr, uint32 uLane, uint32 uRegAddr, uint32 uData) {
    uint32 uBlkBaseAddr;
    uint32 uRegOffset;
    int status;

    /*  HC register address space is only 16 bits. */
    if (uRegAddr > 0xffff) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Address must be less than or equal to 0xffff\n")));
        return SOC_E_PARAM;
    }
    /* 0x3ff is broadcast to all lanes */
    if (uLane > 0x3ff) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Invalid lane (0-3 or 0x3ff for broadcast)\n")));
        return SOC_E_PARAM;
    }
    if (uPhyAddr == 0x1f) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Use soc_sirius_mdio_broadcast_write for broadcast writes to HC's instead\n")));
        return SOC_E_PARAM;
    }

    /* Set the requested lane */
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0xfff0);
    if (status) {
        return status;
    }
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, (HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0x000f) | (0x1<<4), uLane );
    if (status) {
        return status;
    }

#if 000
    if (uRegAddr <= 0x1f) { /* direct write */

        status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, uRegAddr, uData);
        if (status) {
            return status;
        }

    } else {  /* indirect write */
#endif

    {
        uBlkBaseAddr = uRegAddr & 0x0000fff0;

        /*  New block so set the block base address. */
        /*  This pointer to the phy block resides at location 0x1f within */
        /*  the HC phy.  Each block contains at most 16 registers (i.e. each block */
        /*  has a 4 bit address space). */
        status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, uBlkBaseAddr);

        if (status) {
            return status;
        }

        /*  The register offset within the block is given in */
        /*  lower 4 bits. */
        uRegOffset = uRegAddr & 0xf;

        if (uRegAddr > 0xf) {
            /*  Set bit[4] to tell the HC to use the block base address */
            /*  register (within the HC) to select the block for this register. */
            uRegOffset = uRegOffset | (0x1<<4);
        }

        status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, uRegOffset, uData);
        if (status) {
            return status;
        }
    }
#if 000
    /* Go back to lane 0 */
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0xfff0);
    if (status) {
        return status;
    }
    _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, (HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0x000f) | (0x1<<4), 0 );
    if (status) {
        return status;
    }
#endif

    return SOC_E_NONE;
}

/***********************************************
 *  Read from a HyperCore phy register.
 *  For registers above address location 0x001f this function will load the
 *  base address of the block containing the given register unless it is
 *  already set.
 */
int soc_sirius_mdio_hc_read(int unit, uint32 uPhyAddr, uint32 uLane, uint32 uRegAddr, uint32 *pReadData) {
    uint32 uBlkBaseAddr;
    uint32 uRegOffset;
    int status;

    /*  HC register address space is only 16 bits. */
    if (uRegAddr > 0xffff) {
        return SOC_E_PARAM;
    }

    /* 0x3ff is broadcast to all lanes */
    if (uLane > 0x3ff) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Invalid lane (0-3 or 0x3ff for broadcast)\n")));
        return SOC_E_PARAM;
    }

    if (pReadData == NULL) {
        return SOC_E_PARAM;
    }

    /* Set the requested lane */
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0xfff0);
    if (status) {
        return status;
    }
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, (HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0x000f) | (0x1<<4), uLane );
    if (status) {
        return status;
    }
#if 000
    if (uRegAddr <= 0x1f) { /* direct read */

        status = _soc_sirius_mdio_hc_cl22_read(unit, uPhyAddr, uRegAddr, pReadData);
        if (status) {
            return status;
        }

    } else { /* indirect read */
#endif
    {
        uBlkBaseAddr = uRegAddr & 0x0000fff0;

        /*  New block so set the block base address. */
        /*  This pointer to the phy block resides at location 0x1f within */
        /*  the HC phy.  Each block contains at most 16 registers (i.e. each block */
        /*  has a 4 bit address space). */
        status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, uBlkBaseAddr);

        if (status) {
            return status;
        }

        /*  The register offset within the block is given in */
        /*  lower 4 bits. */
        uRegOffset = uRegAddr & 0xf;

        if (uRegAddr > 0xf) {
            /*  Set bit[4] to tell the HC to use the block base address */
            /*  register (within the HC) to select the block for this register. */
            uRegOffset = uRegOffset | (0x1<<4);
        }

        status = _soc_sirius_mdio_hc_cl22_read(unit, uPhyAddr, uRegOffset, pReadData);
        if (status) {
            return status;
        }
    }
#if 0000
    /* Go back to lane 0 */
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, 0x1f, HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0xfff0);
    if (status) {
        return status;
    }
    status = _soc_sirius_mdio_hc_cl22_write(unit, uPhyAddr, (HW_SIRIUS_HYPERCORE_AER_LANE_SELECT & 0x000f) | (0x1<<4), 0 );
    if (status) {
        return status;
    }
#endif
    return SOC_E_NONE;
}


/***********************************************
 *  Broadcast write to all enabled HyperCore's.
 *  For broadcast writes to indirect reg's we need to
 *  make sure that the base address register in EACH
 *  HC is set to the write address.
 */
int
soc_sirius_mdio_hc_broadcast_write(int unit, uint32 uRegAddr, uint32 uWrData)
{
    uint32 uBlkBaseAddr;
    uint32 uRegOffset;
    const uint32 HC_BCAST_PHY_ID = 0x1f;
    int status;

    /*  HC register address space is only 16 bits. */
    if (uRegAddr > 0xffff) {
        return SOC_E_PARAM;
    }

    if (uRegAddr <= 0x1f) {
        /*
         * direct broadcast write
         */
        status = _soc_sirius_mdio_hc_cl22_write(unit, HC_BCAST_PHY_ID, uRegAddr, uWrData);

        if (status) {
            return status;
        }

    } else {
        /*
         * indirect broadcast write
         */
        uBlkBaseAddr = uRegAddr & 0x0000fff0;

        /*  New block so broadcast the block base address. */
        status = _soc_sirius_mdio_hc_cl22_write(unit, HC_BCAST_PHY_ID, 0x1f, uBlkBaseAddr);

        if (status) {
            return status;
        }
        /*  The register offset within the block is given in */
        /*  lower 4 bits. */
        uRegOffset = uRegAddr & 0xf;
        /*  Set bit[4] to tell the HC to use the block base address */
        /*  register (within the HC) to select the block for this register. */
        uRegOffset = uRegOffset | (0x1<<4);

        status =_soc_sirius_mdio_hc_cl22_write(unit, HC_BCAST_PHY_ID, uRegOffset, uWrData);

        if (status) {
            return status;
        }

    }
    return SOC_E_NONE;
}

/***********************************************
 *  Write to a register in the HyperCore phy over the PI MDIO
 *  interface using clause 22 protocol.
 *  This is a base (low level) function for writing to the HC's.
 *  Users should typically use the soc_sirius_mdio_hc_write function for normal writes.
 */
static int
_soc_sirius_mdio_hc_cl22_write(int unit, uint32 uPhyAddr, uint32 uRegAddr, uint32 uData)
{
    int rv = SOC_E_NONE;
    uint8  phy_id, phy_reg_addr;
    uint16 phy_wr_data;

    /*  phy address is only 5 bits
     *  reg address is only 5 bits
     *  write data is only 16 bits
     */
#if 000
    if ( (uPhyAddr > 0x1f) || (uRegAddr > 0x1f) || (uData > 0xffff) ) {
        return SOC_E_PARAM;
    }
#endif

    /* convert to encoded phy_id */
    phy_id = (uint8)(uPhyAddr & 0x1F);
    phy_id |= 0x80; /* indicate internal mdio bus */

    phy_reg_addr = (uint8)(uRegAddr & 0x1F);

    phy_wr_data = (uint16)(uData & 0xFFFF);

    if (SAL_BOOT_BCMSIM) {
        /* BCMSIM don't support Hypercore phys, do nothing when running against BCMSIM model
         */
    } else {
        /* put on right encoding for Phy ID, sirius only supports internal mdio bus */
        rv = soc_miim_write(unit, phy_id, phy_reg_addr, phy_wr_data);
    }

    LOG_VERBOSE(BSL_LS_SOC_SOCMEM,
                (BSL_META_U(unit,
                            "soc_sirius_mdio_hc_cl22_write. uPhyAddr 0x%x uRegAddr 0x%x, uData 0x%x\n"), uPhyAddr, uRegAddr, uData));

    return rv;
}


/***********************************************
 *  Read from a register in the HyperCore phy over the PI MDIO
 *  interface using clause 22 protocol.
 *  This is a base (low level) function for reading from the HC's.
 *  Users should typically use the soc_sirius_mdio_hc_read function for normal reads.
 */
static int
_soc_sirius_mdio_hc_cl22_read(int unit, uint32 uPhyAddr, uint32 uRegAddr, uint32 *pReadData)
{
    int rv = SOC_E_NONE;
    uint8  phy_id, phy_reg_addr;
    uint16 phy_rd_data;

 #if 000
    /*  phy address is only 5 bits
     *  reg address is only 5 bits
     */
    if ( (uPhyAddr > 0x1f) || (uRegAddr > 0x1f) ) {
        return SOC_E_PARAM;
    }
#endif

    /* convert to encoded phy_id */
    phy_id = (uint8)(uPhyAddr & 0x1F);
    phy_id |= 0x80; /* indicate internal mdio bus */

    phy_reg_addr = (uint8)(uRegAddr & 0x1F);

    if (SAL_BOOT_BCMSIM) {
        /* BCMSIM don't support Hypercore phys,  return 0xFFFFFFFF so that
         * various done bits will be set
         */
        phy_rd_data = 0xFFFF;
    } else {
        rv = soc_miim_read(unit, phy_id, phy_reg_addr, &phy_rd_data);
    }

    *pReadData = phy_rd_data;

    return rv;
}

int
soc_sirius_si_to_port(int unit, int32 nSi, bcm_port_t *port)
{
 
    int rv = SOC_E_NONE;

    /*          gigE                */
    /* si0      port 31             */
    /* si1      port 32             */
    /* si2      port  9             */
    /* si3      port 10             */
    /* si4      port 11             */
    /* si5      port 12             */
    /* si6      port 13             */
    /* si7      port 14             */
    /* si8      port 15             */
    /* si9      port 16             */
    /* si10     port 17             */
    /* si11     port 18             */
    /* si12     port 19             */
    /* si12     port 19             */
    /* si12     port 19             */
    /* si12     port 19             */
    /* si12     port 19             */
    /* si12     port 19             */
    switch (nSi) {
	case (0):
	    *port = 31;
	    break;
	case (1):
	    *port = 32;
	    break;
	case (2):
	case (3):
	case (4):
	case (5):
	case (6):
	case (7):
	case (8):
	case (9):
	case (10):
	case (11):
	case (12):
	case (13):
	case (14):
	case (15):
	case (16):
	case (17):
	case (18):
	case (19):
	case (20):
	case (21):
	case (22):
	case (23):
	    *port = nSi + 7;
	    break;
	default:
	    LOG_CLI((BSL_META_U(unit,
                                "Invalid si port(%d) range(0-23)\n"), nSi));
	    rv = SOC_E_PARAM;
	    break;
    }
    return rv;
}

int
soc_sirius_serdes_phyaddr(int unit, int32 nSi, uint32 *uPhyAddr, uint32 *uLaneAddr)
{
    if ( (nSi < 0) || (nSi >= 24) ) {
        LOG_CLI((BSL_META_U(unit,
                            "SI(%d) out of range [0-23] for sirius\n"), nSi));
        return SOC_E_PARAM;
    }

    /* si0-3   mapped to Hc4 lane 0-3, phy_id 4
     * si4-7   mapped to Hc5 lane 0-3, phy_id 5
     * si8-11  mapped to Hc6 lane 0-3, phy_id 6
     * si12-15 mapped to Hc7 lane 0-3, phy_id 7
     * si16-19 mapped to Hc8 lane 0-3, phy_id 8
     * si20-23 mapped to Hc9 lane 0-3, phy_id 9
     */
    *uPhyAddr = (nSi / 4) + 4;
    *uLaneAddr = (nSi % 4);

    return SOC_E_NONE;
}

/* Always set the speed, then the encoding checks are done during encoding set */
int
soc_sirius_hc_speed_set(int unit, int32 nSi, uint32 uSerdesSpeed)
{
    soc_port_t port;
    soc_sirius_si_to_port(unit, nSi, &port);
    return soc_phyctrl_speed_set(unit, port, uSerdesSpeed);
}


/* Always set the speed, then the encoding checks are done during encoding set */
int soc_sirius_hc_encoding_set(int unit, int32 nSi, int32 bSerdesEncoding)
{
    int speed;
    int32 encoding;
    soc_port_t port;
    uint regval;

    SOC_IF_ERROR_RETURN(soc_sirius_si_to_port(unit, nSi, &port));    

    encoding = bSerdesEncoding;

    SOC_IF_ERROR_RETURN
        (soc_phyctrl_speed_get(unit, port, &speed));

    if ((encoding) && (speed==6500)) {
	LOG_CLI((BSL_META_U(unit,
                            "Invalid encoding scheme, 8b10b with 6.5G SI(%d)\n"), port));
	return SOC_E_PARAM;
    }
    if ((!encoding) && (speed==3125)) {
	LOG_CLI((BSL_META_U(unit,
                            "Invalid encoding scheme, 64b66 with 3.125G SI(%d)\n"), port));
	return SOC_E_PARAM;
    }

    if (encoding) {

	if (nSi < 12) {
	    SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_CONFIG0r(unit, nSi, &regval));
	    soc_reg_field_set(unit, SC_TOP_SI_CONFIG0r, &regval, RX_BYTE_SWAPf, 1);
	    soc_reg_field_set(unit, SC_TOP_SI_CONFIG0r, &regval, TX_BYTE_SWAPf, 1);
	    SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_CONFIG0r(unit, nSi, regval));
	} else {
	    SOC_IF_ERROR_RETURN(READ_SI_CONFIG0r(unit, (nSi - 12), &regval));
	    soc_reg_field_set(unit, SI_CONFIG0r, &regval, RX_BYTE_SWAPf, 1);
	    soc_reg_field_set(unit, SI_CONFIG0r, &regval, TX_BYTE_SWAPf, 1);
	    SOC_IF_ERROR_RETURN(WRITE_SI_CONFIG0r(unit, (nSi - 12), regval));
	}

	SOC_IF_ERROR_RETURN
            (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_ENCODING,
                                     phyControlEncoding8b10b));

	if (speed == 6250) {
	    /* Enable scrambler */
            SOC_IF_ERROR_RETURN
                (soc_phyctrl_control_set(unit, port, 
                                         SOC_PHY_CONTROL_SCRAMBLER, 1));
	} else {
	    /* Disable 8b10b scrambler only used at 6.25G */
            SOC_IF_ERROR_RETURN
                (soc_phyctrl_control_set(unit, port, 
                                         SOC_PHY_CONTROL_SCRAMBLER, 0));
        }
    } else {

	if (nSi < 12) {
	    SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_CONFIG0r(unit, nSi, &regval));
	    soc_reg_field_set(unit, SC_TOP_SI_CONFIG0r, &regval, RX_BYTE_SWAPf, 0);
	    soc_reg_field_set(unit, SC_TOP_SI_CONFIG0r, &regval, TX_BYTE_SWAPf, 0);
	    SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_CONFIG0r(unit, nSi, regval));
	} else {
	    SOC_IF_ERROR_RETURN(READ_SI_CONFIG0r(unit, (nSi - 12), &regval));
	    soc_reg_field_set(unit, SI_CONFIG0r, &regval, RX_BYTE_SWAPf, 0);
	    soc_reg_field_set(unit, SI_CONFIG0r, &regval, TX_BYTE_SWAPf, 0);
	    SOC_IF_ERROR_RETURN(WRITE_SI_CONFIG0r(unit, (nSi - 12), regval));
	}

        SOC_IF_ERROR_RETURN
            (soc_phyctrl_control_set(unit, port, SOC_PHY_CONTROL_ENCODING,
                                     phyControlEncoding64b66b));

        /* Disable 8b10b scrambler only used at 6.25G */
        SOC_IF_ERROR_RETURN
            (soc_phyctrl_control_set(unit, port, 
                                     SOC_PHY_CONTROL_SCRAMBLER, 0));
        
    }
    return SOC_E_NONE;
}

int
soc_sirius_ability_matching_speed_set(int unit, int32 nSi, int ability)
{
    int rv = SOC_E_NONE;
    uint32 uSerdesSpeed;
    int32 bSerdesEncoding;

    /* update configuration */
    switch (ability) {
        case BCM_PORT_ABILITY_DUAL_SFI:
        case BCM_PORT_ABILITY_SFI_SCI:
        case BCM_PORT_ABILITY_DUAL_SFI_LOCAL:
            uSerdesSpeed = SOC_SBX_CFG(unit)->uSerdesSpeed;
            bSerdesEncoding = SOC_SBX_CFG(unit)->bSerdesEncoding;
            break;

        case BCM_PORT_ABILITY_SCI:

	    /* For Sirius control links, always take the speed/encoding from backplane */
	    /* no need to check the protocol here (we are always protocol 3)           */
	    uSerdesSpeed = SOC_SBX_CFG(unit)->uSerdesSpeed;
            bSerdesEncoding = SOC_SBX_CFG(unit)->bSerdesEncoding;
	    break;

        case BCM_PORT_ABILITY_SFI:
            uSerdesSpeed = 3125;
            bSerdesEncoding = TRUE;
            break;

        default:
            return(SOC_E_PARAM);
    }

    LOG_VERBOSE(BSL_LS_SOC_PORT,
                (BSL_META_U(unit,
                            "nSi(%d) speed(%d) encoding(%s)\n"), nSi,
                 uSerdesSpeed, bSerdesEncoding?"8b10b":"64b66b"));

#ifdef SCI_SPEED_SUPPORT
    LOG_CLI((BSL_META_U(unit,
                        "si(%d) speed(%d) encoding(%s)\n"), nSi, uSerdesSpeed, bSerdesEncoding?"8b10b":"64b66b"));
#endif

    /* Set speed */
    rv = soc_sirius_hc_speed_set(unit, nSi, uSerdesSpeed);
    if (rv) {
      return rv;
    }

    /* Set encoding */
    rv = soc_sirius_hc_encoding_set(unit, nSi, bSerdesEncoding);
    if (rv) {
      return rv;
    }

    /* Set drive strength and equalization */
    SOC_IF_ERROR_RETURN(soc_sirius_config_linkdriver(unit, nSi,&(SOC_SBX_CFG_SIRIUS(unit)->linkDriverConfig[nSi])));

    return(rv);
}

static int
soc_sirius_init_si_step0(int unit, uint nSi, int force_speed, int lane_mode, siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    uint32 regval = 0;
    int disable = 0;

    if ( (nSi >= SB_FAB_DEVICE_SIRIUS_LINKS) ) {
        return SOC_E_PARAM;
    }

    if ( (lane_mode != SS_HC_LANE_MODE_HALF_SPEED) &&
         (lane_mode != SS_HC_LANE_MODE_FULL_SPEED) ) {
        return SOC_E_PARAM;
    }

    if ( (force_speed < 0x00) || (force_speed >= 0x13) ) {
        return SOC_E_PARAM;
    }

    /* enable RX_MSM_LBA_DEBUG */
    if ( nSi < 12 ) {
        SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_DEBUG1r(unit, nSi, &regval));
        soc_reg_field_set(unit, SC_TOP_SI_DEBUG1r, &regval, RX_MSM_LBA_DEBUGf, 1);
        SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_DEBUG1r(unit, nSi, regval));
    } else {
        SOC_IF_ERROR_RETURN(READ_SI_DEBUG1r(unit, (nSi - 12), &regval));
        soc_reg_field_set(unit, SI_DEBUG1r, &regval, RX_MSM_LBA_DEBUGf, 1);
        SOC_IF_ERROR_RETURN(WRITE_SI_DEBUG1r(unit, (nSi - 12), regval));
    }

    /* set default speed and lane_mode */
    if ( nSi < 12 ) {
        SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_PLL_CONFIGr(unit, nSi, &regval));
        if( (nSi % SS_SI_PER_HC) == 0 ) {
            /* only first si (lane 0) of shared Hypercore set the default speed */
            soc_reg_field_set(unit, SC_TOP_SI_SD_PLL_CONFIGr, &regval, FORCE_SPEED_STRAPf, force_speed);
        }
        soc_reg_field_set(unit, SC_TOP_SI_SD_PLL_CONFIGr, &regval, LANE_MODE_STRAPf, lane_mode);
        SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_PLL_CONFIGr(unit, nSi, regval));
    } else {
        SOC_IF_ERROR_RETURN(READ_SI_SD_PLL_CONFIGr(unit, (nSi - 12), &regval));
        if( (nSi % SS_SI_PER_HC) == 0 ) {
            /* only first si (lane 0) of shared Hypercore set the default speed */
            soc_reg_field_set(unit, SI_SD_PLL_CONFIGr, &regval, FORCE_SPEED_STRAPf, force_speed);
        }
        soc_reg_field_set(unit, SI_SD_PLL_CONFIGr, &regval, LANE_MODE_STRAPf, lane_mode);
        SOC_IF_ERROR_RETURN(WRITE_SI_SD_PLL_CONFIGr(unit, (nSi - 12), regval));
    }

    if (pInitParams->sf.bTmeOnly) {
        disable = TRUE;
    }

    if ( nSi < 12 ) {
      SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_CONFIGr(unit, nSi, &regval));
      soc_reg_field_set(unit, SC_TOP_SI_SD_CONFIGr, &regval, RX_PWRDWNf, disable);
      soc_reg_field_set(unit, SC_TOP_SI_SD_CONFIGr, &regval, TX_PWRDWNf, disable);
      soc_reg_field_set(unit, SC_TOP_SI_SD_CONFIGr, &regval, TX_FIFO_RESETf, disable);
      SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_CONFIGr(unit, nSi, regval));

      SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_CONFIG0r(unit, nSi, &regval));
      soc_reg_field_set(unit, SC_TOP_SI_CONFIG0r, &regval, L2R_TX_LOS_SELECTf, 1);
      SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_CONFIG0r(unit, nSi, regval));
    } else {
      SOC_IF_ERROR_RETURN(READ_SI_SD_CONFIGr(unit, (nSi - 12), &regval));
      soc_reg_field_set(unit, SI_SD_CONFIGr, &regval, RX_PWRDWNf, disable);
      soc_reg_field_set(unit, SI_SD_CONFIGr, &regval, TX_PWRDWNf, disable);
      soc_reg_field_set(unit, SI_SD_CONFIGr, &regval, TX_FIFO_RESETf, disable);
      SOC_IF_ERROR_RETURN(WRITE_SI_SD_CONFIGr(unit, (nSi - 12), regval));

      SOC_IF_ERROR_RETURN(READ_SI_CONFIG0r(unit, (nSi - 12), &regval));
      soc_reg_field_set(unit, SI_CONFIG0r, &regval, L2R_TX_LOS_SELECTf, 1);
      SOC_IF_ERROR_RETURN(WRITE_SI_CONFIG0r(unit, (nSi - 12), regval));
    }

    return rv;
}

static int
soc_sirius_init_si_step1(int unit, uint nSi, siriusInitParams_t *pInitParams)
{
    int rv = SOC_E_NONE;
    int32  nTimeoutInUsec;
    int32  nInitDone;
    soc_timeout_t timeout;
    uint32 regval = 0;

    /* if first link in the quad, and never initialized before */
    if( ((nSi % SS_SI_PER_HC) == 0) && !(pInitParams->sc.uQuadDone & (1<<nSi)) ) {

        /*  deassert pwrdwn_pll */
        if ( nSi < 12 ) {
            SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_RESETr(unit, nSi, &regval));
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, PWRDWN_PLLf, 0);
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, IDDQf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_RESETr(unit, nSi, regval));
        } else {
            SOC_IF_ERROR_RETURN(READ_SI_SD_RESETr(unit, (nSi - 12), &regval));
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, PWRDWN_PLLf, 0);
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, IDDQf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SI_SD_RESETr(unit, (nSi - 12), regval));
        }

        /*  deassert iddq and write back */
        if ( nSi < 12 ) {
            SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_RESETr(unit, nSi, &regval));
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, IDDQf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_RESETr(unit, nSi, regval));
        } else {
            SOC_IF_ERROR_RETURN(READ_SI_SD_RESETr(unit, (nSi - 12), &regval));
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, IDDQf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SI_SD_RESETr(unit, (nSi - 12), regval));
        }

        /* deassert hw_reset and write back */
        if ( nSi < 12 ) {
            SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_RESETr(unit, nSi, &regval));
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, HW_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_RESETr(unit, nSi, regval));
        } else {
            SOC_IF_ERROR_RETURN(READ_SI_SD_RESETr(unit, (nSi - 12), &regval));
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, HW_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SI_SD_RESETr(unit, (nSi - 12), regval));
        }

        /* deassert mdioregs_reset */
        if ( nSi < 12 ) {
            SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_RESETr(unit, nSi, &regval));
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, MDIOREGS_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_RESETr(unit, nSi, regval));
        } else {
            SOC_IF_ERROR_RETURN(READ_SI_SD_RESETr(unit, (nSi - 12), &regval));
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, MDIOREGS_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SI_SD_RESETr(unit, (nSi - 12), regval));
        }

        /* deassert pll_reset and write back */
        if ( nSi < 12 ) {
            SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_RESETr(unit, nSi, &regval));
            soc_reg_field_set(unit, SC_TOP_SI_SD_RESETr, &regval, PLL_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SC_TOP_SI_SD_RESETr(unit, nSi, regval));
        } else {
            SOC_IF_ERROR_RETURN(READ_SI_SD_RESETr(unit, (nSi - 12), &regval));
            soc_reg_field_set(unit, SI_SD_RESETr, &regval, PLL_RESETf, 0);
            SOC_IF_ERROR_RETURN(WRITE_SI_SD_RESETr(unit, (nSi - 12), regval));
        }

	if(!SAL_BOOT_BCMSIM && !SOC_IS_DETACHING(unit)) {
        /* Check pll lock status */
        nTimeoutInUsec = _sirius_init_timeout * 10;
        nInitDone = 0;
        soc_timeout_init(&timeout, nTimeoutInUsec,0);
        while(!soc_timeout_check(&timeout)) {
            if ( nSi < 12 ) {
                SOC_IF_ERROR_RETURN(READ_SC_TOP_SI_SD_STATUSr(unit, nSi, &regval));
                nInitDone = soc_reg_field_get(unit, SC_TOP_SI_SD_STATUSr, regval, TX_PLL_LOCKf);
            } else {
                SOC_IF_ERROR_RETURN(READ_SI_SD_STATUSr(unit, (nSi - 12), &regval));
                nInitDone = soc_reg_field_get(unit, SI_SD_STATUSr, regval, TX_PLL_LOCKf);
            }

            if (nInitDone) {
                break;
            }
        }

	if (!nInitDone) {
	  LOG_ERROR(BSL_LS_SOC_COMMON,
                    (BSL_META_U(unit,
                                "nSi%02d TX PLL lock timeout\n"), nSi));
	}
	}

        /* mark this quad as done */
        pInitParams->sc.uQuadDone |= (1<<nSi);
    }
    return rv;
}
static int
soc_sirius_ingress_rate_info_dealloc(int unit)
{
    int rv = SOC_E_NONE;


    if (shaper_info[unit] == NULL) {
        return(rv);
    }
    if (shaper_info[unit]->basic_rate_info != NULL) {
        sal_free(shaper_info[unit]->basic_rate_info);
    }
    if (shaper_info[unit]->burst_size_info != NULL) {
        sal_free(shaper_info[unit]->burst_size_info);
    }
    sal_free(shaper_info[unit]);

    return(rv);
}

static int
soc_sirius_ingress_rate_info_alloc(int unit)
{
    int          rv = SOC_E_NONE;
    uint32       exponent, mantissa, denominator = 1;
    uint64     numerator;
    uint32       uRate = 0;
    int          i;


    /* allocate shaper info */
    shaper_info[unit] = sal_alloc(sizeof(siriusIngressShaperInfo_t),
                                                            "Sirius_Ingress_Shaper");
    if (shaper_info[unit] == NULL) {
        return(SOC_E_MEMORY);
    }
    sal_memset(shaper_info[unit], 0, sizeof(siriusIngressShaperInfo_t));

    /* allocate rate info */
    shaper_info[unit]->basic_rate_info = sal_alloc(
                    sizeof(siriusIngressRateInfo_t) * (SIRIUS_INGRESS_SHAPER_MAX_EXPONENT + 1),
                                                                           "Sirius_Ingress_Rate");
    if (shaper_info[unit]->basic_rate_info == NULL) {
        rv = SOC_E_MEMORY;
        goto err;
    }

    /* allocate burst info */
    shaper_info[unit]->burst_size_info = sal_alloc(
                    sizeof(siriusIngressRateInfo_t) * (SIRIUS_INGRESS_SHAPER_MAX_EXPONENT + 1),
                                                                          "Sirius_Ingress_Burst");
    if (shaper_info[unit]->burst_size_info == NULL) {
        rv = SOC_E_MEMORY;
        goto err;
    }

    /* initialize rate info */
    for (i = 0, mantissa = SIRIUS_INGRESS_SHAPER_MIN_MANTISSA;
                           mantissa <= SIRIUS_INGRESS_SHAPER_MIN_MANTISSA; mantissa++) {
        for (exponent = SIRIUS_INGRESS_SHAPER_MIN_EXPONENT;
                           exponent <= SIRIUS_INGRESS_SHAPER_MAX_EXPONENT; exponent++) {
            COMPILER_64_SET(numerator,0,SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_DEN_MHZ);
            COMPILER_64_UMUL_32(numerator, mantissa);
            COMPILER_64_UMUL_32(numerator, SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER);
            /* numerator *= SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER * mantissa;*/
            denominator = (1 << exponent) * ((1 * SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER) /
                                                    SOC_SBX_CFG(unit)->uClockSpeedInMHz);

	    if (soc_sbx_div64(numerator, denominator, &uRate) == -1) {
	      rv = SOC_E_INTERNAL;
	      goto err;
	    }

            shaper_info[unit]->basic_rate_info[i].rate     = uRate;
            shaper_info[unit]->basic_rate_info[i].exponent = exponent;
            shaper_info[unit]->basic_rate_info[i].mantissa = mantissa;
            i++;
        }
    }

    /* initialize burst info */
    for (i = 0, mantissa = SIRIUS_INGRESS_SHAPER_MIN_MANTISSA;
                           mantissa <= SIRIUS_INGRESS_SHAPER_MIN_MANTISSA; mantissa++) {
        for (exponent = SIRIUS_INGRESS_SHAPER_MIN_EXPONENT;
                           exponent <= SIRIUS_INGRESS_SHAPER_MAX_EXPONENT; exponent++) {

            shaper_info[unit]->burst_size_info[i].rate = (1 << exponent);
            shaper_info[unit]->burst_size_info[i].exponent = exponent;
            shaper_info[unit]->burst_size_info[i].mantissa = mantissa;
            i++;
        }
    }

    return(rv);

err:
    soc_sirius_ingress_rate_info_dealloc(unit);
    return(rv);
}

static int
soc_sirius_get_ingress_rate(int unit, uint32 rate, int *index,
                                          uint32 *rate_mantissa, uint32 *rate_exponent)
{
    int       rv = SOC_E_NONE;
    int       i;
    uint32  last_mantissa = -1, last_exponent = -1, cur_mantissa = -1, cur_exponent;
    uint64  last_rate_diff = COMPILER_64_INIT(-1,-1), cur_rate_diff, uuTmp;

    for (i = 0; i < (SIRIUS_INGRESS_SHAPER_MAX_EXPONENT + 1); i++) {
        cur_mantissa = (rate * 1000) / shaper_info[unit]->basic_rate_info[i].rate;
        cur_exponent = shaper_info[unit]->basic_rate_info[i].exponent;
        if ( (cur_mantissa > SIRIUS_INGRESS_SHAPER_MAX_MANTISSA) ||
                               (cur_mantissa == (SIRIUS_INGRESS_SHAPER_MIN_MANTISSA - 1)) ) {
            continue;
        }
        COMPILER_64_SET(cur_rate_diff, 0, rate);
        COMPILER_64_UMUL_32(cur_rate_diff, 1000);
        COMPILER_64_SET(uuTmp, 0, shaper_info[unit]->basic_rate_info[i].rate);
        COMPILER_64_UMUL_32(uuTmp, cur_mantissa);
        COMPILER_64_SUB_64(cur_rate_diff, uuTmp);
        /* cur_rate_diff = (rate * 1000) - (shaper_info[unit]->basic_rate_info[i].rate * cur_mantissa);*/

        if (last_mantissa == -1) {
            last_mantissa = cur_mantissa;
            last_exponent = cur_exponent;
            last_rate_diff = cur_rate_diff;
        }
        else if (COMPILER_64_LT(cur_rate_diff,last_rate_diff)) {
            last_mantissa = cur_mantissa;
            last_exponent = cur_exponent;
            last_rate_diff = cur_rate_diff;
        }

        if (COMPILER_64_IS_ZERO(cur_rate_diff)) {
            break;
        }
    }
    if (last_mantissa == -1) {
        rv = SOC_E_PARAM;
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d Ingress Shaper Rate not found\n"), unit));
        return(rv);
    }
    else {
        (*index) = i;
        (*rate_mantissa) = last_mantissa;
        (*rate_exponent) = last_exponent;
        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META_U(unit,
                                "Closest Rate: %d Kbps rate: %d Kbps, mantissa: %d, exponent: %d\n"),
                     rate, 
                     ((shaper_info[unit]->basic_rate_info[i].rate * last_mantissa)/1000),
                     last_mantissa, last_exponent));
    }

    return(rv);
}

static int
soc_sirius_get_ingress_burst_size(int unit, uint32 rate,
                                          uint32 *burst_mantissa, uint32 *burst_exponent)
{
    int      rv = SOC_E_NONE;
    int      processing_time, i;
    uint32 burst_size = 0;
    uint32 last_mantissa = -1, last_exponent = -1, cur_mantissa = -1, cur_exponent;
    uint32 last_rate_diff = -1, cur_rate_diff;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "\n\nCalculating default burst size, rate: %d\n"), (unsigned int)rate));

    processing_time = (SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER * SIRIUS_MAX_SHAPER_QUEUES) /
                                                     SOC_SBX_CFG(unit)->uClockSpeedInMHz;
    burst_size = (rate * processing_time) / (1000 * 1000 * 1000);
    burst_size = burst_size / SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER2;

    LOG_VERBOSE(BSL_LS_SOC_COMMON,
                (BSL_META_U(unit,
                            "Processing time: %d ns, burst size: %d bps\n"),
                 (processing_time)/SIRIUS_INGRESS_SHAPER_CLOCK_CYCLE_SCALER2, burst_size));

    for (i = 0; i < (SIRIUS_INGRESS_SHAPER_MAX_EXPONENT + 1); i++) {
	cur_mantissa = burst_size / shaper_info[unit]->burst_size_info[i].rate;
        cur_exponent = shaper_info[unit]->burst_size_info[i].exponent;
        if ( (cur_mantissa > SIRIUS_INGRESS_SHAPER_MAX_MANTISSA) ||
                         (cur_mantissa == (SIRIUS_INGRESS_SHAPER_MIN_MANTISSA - 1)) ) {
            continue;
        }
        cur_rate_diff = burst_size - shaper_info[unit]->burst_size_info[i].rate * cur_mantissa;

        if (last_mantissa == -1) {
            last_mantissa = cur_mantissa;
            last_exponent = cur_exponent;
            last_rate_diff = cur_rate_diff;
        }
        else if (cur_rate_diff < last_rate_diff) {
            last_mantissa = cur_mantissa;
            last_exponent = cur_exponent;
            last_rate_diff = cur_rate_diff;
        }

        if (cur_rate_diff == 0) {
            break;
        }
    }
    if (last_mantissa == -1) {
        rv = SOC_E_PARAM;
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d Ingress Burst Size not found\n"), unit));
        return(rv);
    }
    else {
        (*burst_mantissa) = last_mantissa;
        (*burst_exponent) = last_exponent;

        LOG_VERBOSE(BSL_LS_SOC_COMMON,
                    (BSL_META_U(unit,
                                "Closest BurstSize: %d bps burstSize: %d bps, mantissa: %d, exponent: %d\n"),
                     burst_size,
                     (shaper_info[unit]->burst_size_info[i].rate * last_mantissa),
                     last_mantissa, last_exponent));
    }

    return(rv);
}

int 
soc_sirius_get_ingress_rate_info(int unit, uint32 rate,
                                 uint32 *rate_mantissa, uint32 *rate_exponent,
                                 uint32 *burst_mantissa, uint32 *burst_exponent)
{
    int rv = SOC_E_NONE;
    int index;


    if (shaper_info[unit] == NULL) {
        rv = soc_sirius_ingress_rate_info_alloc(unit);
        if (rv != SOC_E_NONE) {
            return(rv);
        }
    }

    rv = soc_sirius_get_ingress_rate(unit, rate, &index, rate_mantissa, rate_exponent);
    if (rv != SOC_E_NONE) {
        return(rv);
    }

    rv = soc_sirius_get_ingress_burst_size(unit,
                        shaper_info[unit]->basic_rate_info[index].rate * (*rate_mantissa),
                        burst_mantissa, burst_exponent);
    if (rv != SOC_E_NONE) {
        return(rv);
    }

    return(rv);
}

int
soc_sirius_queue_min_util_set(int unit, int32 nQueue, int template)
{
    int                     rv = SOC_E_NONE;
    int32                   reg_queue_index, reg_queue_off;
    soc_mem_t               mem;
    soc_field_t             field;
    qdepth_thresh0_entry_t  qdepth_thresh;


    if (nQueue < (32 * 1024)) {
        reg_queue_index = nQueue;
        mem = QDEPTH_THRESH0m;
    }
    else { /* 32k - (64k - 1) */
        reg_queue_index = nQueue - (32 * 1024);
        mem = QDEPTH_THRESH1m;
    }
    reg_queue_off = reg_queue_index & 3;
    reg_queue_index = reg_queue_index >> 2;

    switch (reg_queue_off) {
        case 0:
            field = THRESH0f;
            break;

        case 1:
            field = THRESH1f;
            break;

        case 2:
            field = THRESH2f;
            break;

        case 3:
        default:
            field = THRESH3f;
            break;
    }

    BCM_IF_ERROR_RETURN(soc_mem_read(unit, mem, MEM_BLOCK_ALL, reg_queue_index, &qdepth_thresh));
    soc_mem_field32_set(unit, mem, &qdepth_thresh, field, template);
    BCM_IF_ERROR_RETURN(soc_mem_write(unit, mem, MEM_BLOCK_ALL, reg_queue_index, &qdepth_thresh));

    return(rv);
}

int
soc_sirius_queue_min_util_get(int unit, int32 nQueue, int *template)
{
    int                     rv = SOC_E_NONE;
    int32                   reg_queue_index, reg_queue_off;
    soc_mem_t               mem;
    soc_field_t             field;
    qdepth_thresh0_entry_t  qdepth_thresh;


    if (nQueue < (32 * 1024)) {
        reg_queue_index = nQueue;
        mem = QDEPTH_THRESH0m;
    }
    else { /* 32k - (64k - 1) */
        reg_queue_index = nQueue - (32 * 1024);
        mem = QDEPTH_THRESH1m;
    }
    reg_queue_off = reg_queue_index & 3;
    reg_queue_index = reg_queue_index >> 2;

    switch (reg_queue_off) {
        case 0:
            field = THRESH0f;
            break;

        case 1:
            field = THRESH1f;
            break;

        case 2:
            field = THRESH2f;
            break;

        case 3:
        default:
            field = THRESH3f;
            break;
    }

    BCM_IF_ERROR_RETURN(soc_mem_read(unit, mem, MEM_BLOCK_ALL, reg_queue_index, &qdepth_thresh));
    (*template) = soc_mem_field32_get(unit, mem, &qdepth_thresh, field);

    return(rv);
}

int
soc_sirius_queue_max_age_set(int unit, int32 nQueue, int template)
{
    int                     rv = SOC_E_NONE;
    int32                   reg_queue_index, reg_queue_off;
    soc_field_t             field;
    ager_threshold_entry_t  ager_thresh;


    reg_queue_index = nQueue / 32;
    reg_queue_off = nQueue % 32;
    field = sirius_age_thresh_field[reg_queue_off];

    BCM_IF_ERROR_RETURN(soc_mem_read(unit, AGER_THRESHOLDm, MEM_BLOCK_ALL,
                                             reg_queue_index, &ager_thresh));
    soc_mem_field_set(unit, AGER_THRESHOLDm, (uint32 *)&ager_thresh, field, (uint32 *)&template);
    BCM_IF_ERROR_RETURN(soc_mem_write(unit, AGER_THRESHOLDm, MEM_BLOCK_ALL,
                                             reg_queue_index, &ager_thresh));

    return(rv);
}

int
soc_sirius_queue_max_age_get(int unit, int32 nQueue, int *template)
{
    int                     rv = SOC_E_NONE;
    int32                   reg_queue_index, reg_queue_off;
    soc_field_t             field;
    ager_threshold_entry_t  ager_thresh;


    reg_queue_index = nQueue / 32;
    reg_queue_off = nQueue % 32;
    field = sirius_age_thresh_field[reg_queue_off];

    BCM_IF_ERROR_RETURN(soc_mem_read(unit, AGER_THRESHOLDm, MEM_BLOCK_ALL,
                                             reg_queue_index, &ager_thresh));
    soc_mem_field_get(unit, AGER_THRESHOLDm, (uint32 *)&ager_thresh, field, (uint32 *)template);

    return(rv);
}

int
soc_sirius_template_min_util_adjust(int unit, int util, int *hwUtil)
{
    uint32 util_fld_whole, util_fld_fract, util_tick;

    /*
     *  Any value outside of 0%..399% is invalid.
     *
     *  It seems that 0% might be valid, indicating that the Sirius should never
     *  wait to send a partial timeslot, so we allow it.
     */
    if ((0 > util) || (399 < util)) {
        return SOC_E_PARAM;
    }

    /*
     *  This computes the value that *should* be written to hardware.
     *
     *  This value is used in the cache for a few reasons:
     *    - it is easier to recover for easy-reload
     *    - it is easier to consolidate equivalent but different values
     *
     *  In addition, it exposes the hardware granularity to the user, so he
     *  knows what to expect more accurately.
     *
     *  Thankfully, Sirius represents these values in terms of percentage of
     *  timeslot, and calculates based upon internal timeslot size (or at
     *  least, the spec indicates so).  This saves us from having to do special
     *  calculations based upon queue destination.
     */
    if (util > 0) {
        util_fld_whole = util / 100;
        util_fld_fract = (util % 100) << 8;
        util_tick = 400;
        util_fld_fract = (util_fld_fract / util_tick) +
                         ((util_fld_fract % util_tick) ? 1 : 0);
    }
    else {
        util_fld_whole = 0;
        util_fld_fract = 0;
    }
    if (0x3F < util_fld_fract) {
        util_fld_fract = 0x3F;
    }
    *hwUtil = (util_fld_whole << 6) | util_fld_fract;
    return SOC_E_NONE;
}

int
soc_sirius_template_min_util_recall(int unit, int hwUtil, int *util)
{
    uint32 util_fld_whole, util_fld_fract;

    /*
     *  This computes the value that *should* have been provided by the user.
     *
     *  The hardware value is used in the cache, and this provides a value to
     *  the BCM layer that will select the value in hardware.
     */
    util_fld_whole = (hwUtil >> 6) & 0x03;
    util_fld_fract = hwUtil & 0x3F;
    *util = (util_fld_whole * 100) + ((util_fld_fract * 400) >> 8);
    return SOC_E_NONE;
}

int
soc_sirius_template_min_util_set(int unit, int32 template, int hwUtil)
{
    int                     rv = SOC_E_NONE;
    uint32                  reg_value = 0;

    SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
             soc_reg_addr(unit, queue_depth_reg[template].reg, REG_PORT_ANY, 0), &reg_value));
    soc_reg_field_set(unit,
             queue_depth_reg[template].reg, &reg_value, queue_depth_reg[template].fld0, hwUtil);
    SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
             soc_reg_addr(unit, queue_depth_reg[template].reg, REG_PORT_ANY, 0), reg_value));

    return(rv);
}

int
soc_sirius_template_max_age_recall(int unit, int hwAge, int *age)
{
    uint32       age_tick;

    /*
     *  This flips the hardware age value back into the BCM layer format. This
     *  is so we have hardware accurate values in the cache, and can reload
     *  based upon the values in the hardware.  It also helps to consolidate
     *  profiles that map to the same hardware values, since there are probably
     *  more possible settings than hardware values.  Plus, it has the, uh,
     *  'advantage' of exposing the actual in-use value so the user knows what
     *  to expect.
     */
    age_tick = SIRIUS_CLOCK_CYCLE_SCALER / SOC_SBX_CFG(unit)->uClockSpeedInMHz;
    age_tick = (age_tick * SIRIUS_CLOCK_CYCLE_AGER_TICK) / (1000 * SIRIUS_CLOCK_CYCLE_SCALER2);
    *age = hwAge * age_tick;
    return SOC_E_NONE;
}

int
soc_sirius_template_max_age_adjust(int unit, int age, int *hwAge)
{
    uint32       age_tick, age_fld;

    /*
     *  This computes the value that would be written to hardware,.  This is so
     *  we have hardware accurate values in the cache, and can reload based
     *  upon the values in the hardware.  It also helps to consolidate profiles
     *  that map to the same hardware values, since there are probably more
     *  possible settings than hardware values.  Plus, it has the, uh,
     *  'advantage' of exposing the actual in-use value so the user knows what
     *  to expect.
     */
    age_tick = SIRIUS_CLOCK_CYCLE_SCALER / SOC_SBX_CFG(unit)->uClockSpeedInMHz;
    age_tick = (age_tick * SIRIUS_CLOCK_CYCLE_AGER_TICK) / (1000 * SIRIUS_CLOCK_CYCLE_SCALER2);
    if (age > 0)  {
        age_fld = (age / age_tick) + (((age % age_tick) == 0) ? 0 : 1);
    }
    else {
        age_fld = 0;
    }
    if (age_fld > 0x1F) {
        age_fld = 0x1F;
    }
    *hwAge = age_fld;
    return SOC_E_NONE;
}

int
soc_sirius_template_max_age_set(int unit, int32 template, int hwAge)
{
    int          rv = SOC_E_NONE;
    uint32       reg_value = 0;

    if (hwAge > 0x1F) {
        return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(soc_reg32_read(unit,
             soc_reg_addr(unit, ager_thresh_reg[template].reg, REG_PORT_ANY, 0), &reg_value));
    soc_reg_field_set(unit,
             ager_thresh_reg[template].reg, &reg_value, ager_thresh_reg[template].fld0, hwAge);
    soc_reg_field_set(unit,
             ager_thresh_reg[template].reg, &reg_value, ager_thresh_reg[template].fld1, hwAge);
    SOC_IF_ERROR_RETURN(soc_reg32_write(unit,
             soc_reg_addr(unit, ager_thresh_reg[template].reg, REG_PORT_ANY, 0), reg_value));

    return(rv);
}

int
soc_sirius_es_fc_base_table_set(int unit, int module, int max_ports, int base, int is_enable)
{
    int                                    rv = SOC_E_NONE;
    flow_control_base_table_entry_t        fc_base_table_entry;
    int                                    maximum_ports, base_addrress;


    if (is_enable) {
	maximum_ports = max_ports; /* force max ports moved to caller */
        base_addrress = base;
    }
    else {
        maximum_ports = 0;
        base_addrress = 0;
    }
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry, ENf, is_enable);
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry,
                                                                BASE_ADDRESSf, base_addrress);
    soc_mem_field32_set(unit, FLOW_CONTROL_BASE_TABLEm, &fc_base_table_entry,
                                                                NUM_PORTSf, maximum_ports);
    SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_BASE_TABLEm(unit, MEM_BLOCK_ANY,
                                                                module, &fc_base_table_entry));

    return(rv); 
}

int
soc_sirius_es_fc_base_table_get(int unit, int module, int *max_ports, int *base, int *is_enable)
{
    int                                    rv = SOC_E_NONE;
    flow_control_base_table_entry_t        fc_base_table_entry;


    SOC_IF_ERROR_RETURN(READ_FLOW_CONTROL_BASE_TABLEm(unit, MEM_BLOCK_ANY,
                                                               module, &fc_base_table_entry));
    (*is_enable) = soc_FLOW_CONTROL_BASE_TABLEm_field32_get(unit, &fc_base_table_entry, ENf);
    (*base) = soc_FLOW_CONTROL_BASE_TABLEm_field32_get(unit, &fc_base_table_entry, BASE_ADDRESSf);
    (*max_ports) = soc_FLOW_CONTROL_BASE_TABLEm_field32_get(unit, &fc_base_table_entry, NUM_PORTSf);

    return(rv); 
}

int
soc_sirius_es_fc_map_table_set(int unit, int port, int fifo_base, int fc_state_index)
{
    int                                    rv = SOC_E_NONE;
    flow_control_map_table_entry_t         fc_map_table_entry;
    int                                    port_index, is_odd_index;
    uint32    regval;
    uint16    dev_id;
    uint8     rev_id;
    uint8     hcfc_enable = 0;
    soc_cm_get_id(unit, &dev_id, &rev_id);
    
    if (rev_id >= BCM88230_C0_REV_ID) {
        SOC_IF_ERROR_RETURN(READ_QM_HCFC_CONFIG0r(unit, &regval));
        hcfc_enable = soc_reg_field_get(unit, QM_HCFC_CONFIG0r, regval, HCFC_ENABLEf);
    }
    if (hcfc_enable)
        is_odd_index = ((port + 1) % 2);
    else
        is_odd_index = (port % 2);
    
    port_index = port / 2;
    SOC_IF_ERROR_RETURN(READ_FLOW_CONTROL_MAP_TABLEm(unit, MEM_BLOCK_ANY,
                                                              port_index, &fc_map_table_entry));
    if (is_odd_index) {
        soc_FLOW_CONTROL_MAP_TABLEm_field32_set(unit, &fc_map_table_entry,
                                                              PORT1_FC_INDEXf, fc_state_index);
    }
    else {
        soc_FLOW_CONTROL_MAP_TABLEm_field32_set(unit, &fc_map_table_entry,
                                                              PORT0_FC_INDEXf, fc_state_index);
    }

    SOC_IF_ERROR_RETURN(WRITE_FLOW_CONTROL_MAP_TABLEm(unit, MEM_BLOCK_ANY,
                                                              port_index, &fc_map_table_entry));

    return(rv); 
}

int
soc_sirius_es_fc_map_table_get(int unit, int port, int fifo_base, int *fc_state_index)
{
    int                                    rv = SOC_E_NONE;
    flow_control_map_table_entry_t         fc_map_table_entry;
    int                                    port_index, is_odd_index;


    port_index = port / 2;
    is_odd_index = (port % 2);
    SOC_IF_ERROR_RETURN(READ_FLOW_CONTROL_MAP_TABLEm(unit, MEM_BLOCK_ANY,
                                                              port_index, &fc_map_table_entry));
    if (is_odd_index) {
        (*fc_state_index) = soc_FLOW_CONTROL_MAP_TABLEm_field32_get(unit,
                                                       &fc_map_table_entry, PORT1_FC_INDEXf);
    }
    else {
        (*fc_state_index) = soc_FLOW_CONTROL_MAP_TABLEm_field32_get(unit,
                                                       &fc_map_table_entry, PORT0_FC_INDEXf);
    }

    return(rv); 
}

int
soc_sirius_es_fc_mc_merge_set(int unit, int mc_merge_enable)
{
    int       rv = SOC_E_NONE;
    uint32    regval = 0;


    SOC_IF_ERROR_RETURN(READ_ES_LL_FC_CONFIGr(unit, &regval));
    soc_reg_field_set(unit, ES_LL_FC_CONFIGr, &regval, FC_MC_ENABLE_MERGEf,
                                            ((mc_merge_enable == TRUE) ? 1 : 0));
    SOC_IF_ERROR_RETURN(WRITE_ES_LL_FC_CONFIGr(unit, regval));

    return(rv); 
}


int
soc_sirius_es_fc_mc_merge_get(int unit, int *mc_merge_enable)
{
    int       rv = SOC_E_NONE;
    uint32    regval = 0;


    SOC_IF_ERROR_RETURN(READ_ES_LL_FC_CONFIGr(unit, &regval));
    (*mc_merge_enable) = soc_reg_field_get(unit, ES_LL_FC_CONFIGr, regval, FC_MC_ENABLE_MERGEf);

    return(rv); 
}

int 
soc_sirius_ci_ddr_verify(int unit, int ci) {
    int rv = SOC_E_NONE;
    int ddr_iter, mode, loop, done;
    uint32 uData, uStartAddr, uStepSize, uDDRBurstSize;

    /* test with 16 iteration, run all 4 modes */
    ddr_iter = 16;
    uStartAddr = 0;
    uStepSize = 1;
    uDDRBurstSize = 0x10000;

    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_ITERr(unit,ci,ddr_iter));
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_STARTr(unit,ci,uStartAddr));
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_STEPr(unit,ci,uStepSize));
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_BURSTr(unit,ci,uDDRBurstSize));

    for (mode = 0; mode < 4; mode++) {
	/* clean up */
	SOC_IF_ERROR_RETURN(READ_CI_DDR_TESTr(unit,ci,&uData));
	soc_reg_field_set(unit,CI_DDR_TESTr,&uData,MODEf,mode);
	soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_DONEf,1);      /* W1TC */
	soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_TESTf,0);      /* clear */
	soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_TEST_FAILf,1); /* W1TC */
	SOC_IF_ERROR_RETURN(WRITE_CI_DDR_TESTr(unit,ci,uData));

	/* set ram_test - to start the test */
	SOC_IF_ERROR_RETURN(READ_CI_DDR_TESTr(unit,ci,&uData));
	soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_TESTf,1);
	SOC_IF_ERROR_RETURN(WRITE_CI_DDR_TESTr(unit,ci,uData));

	done = FALSE;
	for (loop = 0; loop < 10; loop++) {
	    /* sleep 0.1 second */
	    sal_usleep(100000);

	    /* check if done */
	    SOC_IF_ERROR_RETURN(READ_CI_DDR_TESTr(unit,ci,&uData));
	    done = soc_reg_field_get(unit,CI_DDR_TESTr,uData,RAM_DONEf);

	    if (done == TRUE) {
		rv = soc_reg_field_get(unit,CI_DDR_TESTr,uData,RAM_TEST_FAILf);
		if (rv == 1) {
		    /* failed, just return */
		    return SOC_E_FAIL;
		} else {
		    /* ok, move on to next mode */
		    done = TRUE;
		    break;
		}
	    }
	}

	/* verify result */
	if (done == FALSE) {
	    return SOC_E_TIMEOUT;
	}
    }

    /* passed all modes, clean up */
    SOC_IF_ERROR_RETURN(READ_CI_DDR_TESTr(unit,ci,&uData));
    soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_DONEf,1);      /* W1TC */
    soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_TESTf,0);      /* clear */
    soc_reg_field_set(unit,CI_DDR_TESTr,&uData,RAM_TEST_FAILf,1); /* W1TC */
    SOC_IF_ERROR_RETURN(WRITE_CI_DDR_TESTr(unit,ci,uData));
    return SOC_E_NONE;
}

/*
 * This sets the burst sizes in case of back-pressure asserted by QM or CI
 */
int32
soc_sirius_bp_burst_size_bytes_set(int unit)
{
    int     rv;
    uint32  ts, opt_packlets_unused;
    uint32  ddr_bw, ddr_cong_bw, ddr_cong_bs, reg_value;

    ts = 0;
    opt_packlets_unused = 0;
    rv = soc_sbx_fabric_get_timeslot_optimized(unit, &ts, 
                                               &opt_packlets_unused);
    if (SOC_FAILURE(rv)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s: Unable to calculate optimized Timeslot"
                              " value\n"), FUNCTION_NAME()));
        return rv;
    }

    rv = soc_sirius_ddr_bandwidth_get(unit, &ddr_bw, &ddr_cong_bw);
    if (SOC_FAILURE(rv)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Could not get Sirius DDR bandwidth info. \n")));
        return rv;
    }
    ddr_cong_bs = (ddr_cong_bw * ts)/(2 * 8 * 16); /* in 16B lanes */

    /* QM_BP_BURST_SIZEf is 10 bits and is in 16B lines */
    ddr_cong_bs &= 0x3ff;
    reg_value = 0;
    soc_reg_field_set(unit, GG_QM_BP_BSAr, &reg_value, QM_BP_BURST_SIZEf, 
                      ddr_cong_bs);

    /* program all 4 with the same value */
    SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSAr(unit, reg_value));
    SOC_IF_ERROR_RETURN(WRITE_GG_QM_BP_BSBr(unit, reg_value));
    SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSAr(unit, reg_value));
    SOC_IF_ERROR_RETURN(WRITE_GG_CI_BP_BSBr(unit, reg_value));

    if (soc_property_get(unit, spn_BACKPLANE_SERDES_SPEED, 6500) == 6500){
        WRITE_GG_QM_BP_BSAr(unit,374);
        WRITE_GG_QM_BP_BSBr(unit,374);
        WRITE_GG_CI_BP_BSAr(unit,374);
        WRITE_GG_CI_BP_BSBr(unit,374);
    }else{
        WRITE_GG_QM_BP_BSAr(unit,379);
        WRITE_GG_QM_BP_BSBr(unit,379);
        WRITE_GG_CI_BP_BSAr(unit,379);
        WRITE_GG_CI_BP_BSBr(unit,379);
    }
    return rv;
}

int32
soc_sirius_ts_burst_size_bytes_get(int unit, int els, int node_type,
                                   int channels, int *value)
{
    int     rv, qe2k_links, ss_links;
    uint32  ts, link_speed, opt_packlets, opt_packlets_rounddown;
    uint32  ddr_bw, ddr_cong_bw, ddr_limited_bs, numerator, denominator;
    int num_plane = 2;

    if (!value) {
        return SOC_E_PARAM;
    }

    rv = soc_sbx_fabric_get_timeslot_optimized(unit, &ts, &opt_packlets);
    if (SOC_FAILURE(rv)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "%s: Unable to calculate optimized Timeslot"
                              " value\n"), FUNCTION_NAME()));
        return rv;
    }

    /* calculate optimized packlets per channel
     * Roundup (linkrate * encoding * base_TS - TS-HDR * 8 - 16 * 2)/17 * 8
     * 1000 --> is because link_speed is in Mbps 
     * NOTE: this is calculating the opt_packlets_rounddown vs opt_packlets 
     *       which is rounded up 
             */
    link_speed = SOC_SBX_CFG(unit)->uSerdesSpeed;
    if (link_speed == 6500) {
        link_speed = 6560; /* 6500 is really 6.56Gbps */
    }
    if (link_speed > 3125) {
        link_speed /= 2; /* if speed > 3.125Gbps, then its dual channel */
	num_plane = 2;
    } else {
        num_plane = 1;
    }
    numerator = (link_speed * ts * 
                 (SOC_SBX_CFG(unit)->bSerdesEncoding? 8 : 64));
    numerator /= (SOC_SBX_CFG(unit)->bSerdesEncoding? 10 : 66);
    numerator -= ((SB_FAB_DEVICE_BM9600_FABRIC_HEADER_LENGTH *8 + 16*2)*1000);
    denominator = (17 * 8 * 1000);
    opt_packlets_rounddown = numerator/denominator;

    rv = soc_sirius_ddr_bandwidth_get(unit, &ddr_bw, &ddr_cong_bw);
    if (SOC_FAILURE(rv)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "Could not get Sirius DDR bandwidth info. \n")));
        return rv;
    }
    /* in multiples of 16 Bytes */
    ddr_limited_bs = (((ddr_bw * ts)/(num_plane * 8 * 16)) * 16);

    /* This is the maximum number of links for any QE2K type node */
    qe2k_links = soc_property_get(unit, spn_QE2K_LINKS, 
                                  SB_FAB_DEVICE_QE2000_SFI_LINKS);
    /* This is the maximum number of links for any Sirius type node */
    ss_links = soc_property_get(unit, spn_SIRIUS_LINKS, 
                                SB_FAB_DEVICE_SIRIUS_SFI_LINKS);

    if (els) {
        if (channels > SB_FAB_DEVICE_SIRIUS_SFI_LINKS) {
            channels = SB_FAB_DEVICE_SIRIUS_SFI_LINKS;
        }
        *value = opt_packlets * channels * 16;
    } else {
    if (node_type == SIRIUS_NODE_TYPE_QE2K) {
            /* Note this value is computed correctly only when fabric
             * configuration is VPORT_MIX. Which is fine because Sirius should 
             * have traffic egressing to QE2K type nodes only in such config
             */ 
            *value = opt_packlets_rounddown * qe2k_links * 16;
    } else {
            *value = opt_packlets * ss_links * 16;
        }
    }
    if (*value > ddr_limited_bs) {
        /* pick smaller of the two. Smaller ddr_limited_bs means burst size
         * is limited by Sirius DDR bandwidth
         */
        *value = ddr_limited_bs;
    }

    return rv;
}

soc_sirius_ddr_bw_table_entry_t sirius_ddr_bw_table[] =
/*DDR-Num   DDR-Speed   DDR-BW-Gbps DDR-Congestion-BW-Gbps */
{{10,       667,        109,        90},
 {6,        667,        64,         53},
 {3,        667,        32,         26},
 {10,       533,        91,         77},
 {6,        533,        53,         44},
 {3,        533,        30,         26},
};
#define SOC_SIRIUS_BW_TABLE_SIZE  \
        (sizeof(sirius_ddr_bw_table)/sizeof(soc_sirius_ddr_bw_table_entry_t))

int 
soc_sirius_ddr_bandwidth_get(int unit, uint32 *ddr_bw, uint32 *ddr_cong_bw)
{
    int                             i, ddr_num, ddr_mhz;
    soc_sirius_ddr_bw_table_entry_t entry;

    /* Look at config properties rather than SOC_SBX_SIRIUS_CFG.
       Default to 10 ddr_num and 667 MHz */
    ddr_num = soc_property_get(unit, spn_EXT_RAM_PRESENT, 10);
    ddr_mhz = soc_property_get(unit, spn_SIRIUS_DDR3_CLOCK_MHZ, 667);

    for (i=0; i<SOC_SIRIUS_BW_TABLE_SIZE; i++) {
        entry = sirius_ddr_bw_table[i];
        if ((entry.ddr_num == ddr_num) && (entry.ddr_mhz == ddr_mhz)) {
            *ddr_bw = entry.ddr_bw;
            *ddr_cong_bw = entry.ddr_cong_bw;
            return SOC_E_NONE;
        }
    }

    return SOC_E_INTERNAL;
}

/* allocate COS_MAP blocks (bcm_fabric_qsel_offset) */
int
soc_sirius_cos_map_block_allocate(int unit,
                                  uint32 flags,
                                  unsigned int *cosMapBlock)
{
    unsigned int idx;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META("unit %d not initialised properly\n"), unit));
        return SOC_E_INIT;
    }
    if (!cosMapBlock) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "cosMapBlock argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    if (!(flags & SIRIUS_COS_MAP_BLOCK_FLAGS_INGRESS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d only supports ingress cos_map_block\n"),
                   unit));
        return SOC_E_PARAM;
    }
    if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_WITH_ID) {
        /* caller specified which block */
        idx = *cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
        if (idx >= SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "%d is invalid %s cos_map_block ID on unit %d\n"),
                       *cosMapBlock,
                       (flags & SIRIUS_PREDICATE_FLAGS_INGRESS)?"ingress":"egress",
                       unit));
            return SOC_E_NOT_FOUND;
        }
        if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_REPLACE) {
            if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d cos_map_block %d not in use; can't"
                                       " replace it\n"),
                           unit,
                           *cosMapBlock));
                return SOC_E_NOT_FOUND;
            }
            if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_SDK) {
                if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk & (1 << idx))) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d cos_map_block %d not in use by"
                                           " SDK; can not replace for SDK\n"),
                               unit,
                               *cosMapBlock));
                    return SOC_E_EXISTS;
                }
            } else { /* if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_SDK) */
                if (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk & (1 << idx)) {
                    LOG_WARN(BSL_LS_SOC_COMMON,
                             (BSL_META_U(unit,
                                         "unit %d cos_map_block %d in use by SDK"
                                          " directly replaced by application\n"),
                              unit,
                              *cosMapBlock));
                }
            } /* if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_SDK) */
        } else {
            if (0 != (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d cos_map_block %d in use; must"
                                       " replace it\n"),
                           unit,
                           *cosMapBlock));
                return SOC_E_EXISTS;
            }
        }
    } else {
        /* need to look for a free block */
        if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_REPLACE) {
            /* must specify which one if replcaing */
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d requires WITH_ID with REPLACE\n"),
                       unit));
            return SOC_E_PARAM;
        }
        for (idx = 0;
             idx < SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS;
             idx++) {
            if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
                /* this one is free */
                break;
            }
        }
        if (idx >= SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d has no available cos_map_block\n"),
                       unit));
            return SOC_E_RESOURCE;
        }
    }
    /* set this one as in use */
    SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps |= (1 << idx);
    if (flags & SIRIUS_COS_MAP_BLOCK_FLAGS_SDK) {
        SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk |= (1 << idx);
    } else {
        SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk &= ~(1 << idx);
    }
    /* return this one */
    *cosMapBlock = idx + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    return SOC_E_NONE;
}

/* free COS_MAP blocks (bcm_fabric_qsel_offset) */
int
soc_sirius_cos_map_block_free(int unit,
                              unsigned int cosMapBlock)
{
    unsigned int idx;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    idx = cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not in use\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    if (0 != SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[idx]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is still being"
                               " referenced\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_FULL;
    }
    /* mark it free */
    SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps &= (~(1 << idx));
    SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk &= ~(1 << idx);
    return SOC_E_NONE;
}

/* check a COS_MAP block (bcm_fabric_qsel_offset) */
int
soc_sirius_cos_map_block_check(int unit,
                               unsigned int cosMapBlock)
{
    unsigned int idx;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    idx = cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
        /* it is free */
        return SOC_E_EMPTY;
    } else {
        /* it is in use */
        return SOC_E_FULL;
    }
}

/* check a COS_MAP block (bcm_fabric_qsel_offset) for SDK ownership */
int
soc_sirius_cos_map_block_check_sdk(int unit,
                                   unsigned int cosMapBlock)
{
    unsigned int idx;

    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    idx = cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapsSdk & (1 << idx))) {
        /* it is free */
        return SOC_E_EMPTY;
    } else {
        /* it is in use */
        return SOC_E_FULL;
    }
}

/* given a COS_MAP block, find the next one that is in use */
int
soc_sirius_cos_map_block_next(int unit,
                              unsigned int current,
                              unsigned int *next)
{
    int result = SOC_E_NOT_FOUND;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!next) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "next argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    do {
        /* figure out next COS_MAP block to examine */
        if (current >= ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS +
                         SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) * 2)) {
            /* very large number; go to first ingress COS_MAP block */
            current = SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
#if (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS)
        } else if (current < SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) {
            /* below ingress; go to first ingress predicate */
            current = SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
#endif /* (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) */
        } else if (
#if (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS)
                   (current >= SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) */
                   (current < ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1) +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS))) {
            /* within ingress; look at next ingress */
            current++;
        } else {
            /* at/after end of ingress but not large enough to wrap */
            break;
        }
        if (
#if (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS)
            (current >= SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS) */
            (current < (SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS +
                        SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS))) {
            /* check ingress  */
            if (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 <<
                                                          (current -
                                                           SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        }
    } while ((SOC_E_NOT_FOUND == result));
    if (SOC_E_NONE == result) {
        *next = current;
    }
    return result;
}

/* write values to an entry in a COS_MAP block */
int
soc_sirius_cos_map_block_entry_set(int unit,
                                   unsigned int cosMapBlock,
                                   unsigned int entryIndex,
                                   unsigned int entryValue)
{
    unsigned int idx;
    unsigned int entry;
    int result;
    uint32 regVal = 0;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    idx = cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not in use\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    if (entryIndex > 15) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d only supports cos_map_block entries"
                               " 0..15\n"),
                   unit));
        return SOC_E_PARAM;
    }
    if (entryValue > 15) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d only supports cos_map_block entry"
                               " values 0..15\n"),
                   unit));
        return SOC_E_PARAM;
    }
    /*
     *  Init code earlier in this file states index into the COS_MAP table has
     *  COS_PROFILE as lower two bits and COS as upper 4 bits.  Compute the
     *  entry in the table based upon this formula.
     */
    entry = (entryIndex << 2) | idx;
    /* read register with the desired entry */
    result = soc_reg32_read(unit,
                            soc_reg_addr(unit,
                                         cosMapRegs[entry][0],
                                         REG_PORT_ANY,
                                         0),
                            &regVal);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to access unit %d cos_map_block %d entry %d:"
                               " %d (%s)\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS,
                   entryIndex,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    /* update only the specific entry */
    soc_reg_field_set(unit,
                      cosMapRegs[entry][0],
                      &regVal,
                      cosMapRegs[entry][1],
                      entryValue);
    /* then write the register back */
    result = soc_reg32_write(unit,
                             soc_reg_addr(unit,
                                          cosMapRegs[entry][0],
                                          REG_PORT_ANY,
                                          0),
                             regVal);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to write unit %d cos_map_block %d entry %d:"
                               " %d (%s)\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS,
                   entryIndex,
                   result,
                   _SHR_ERRMSG(result)));
    }
    return result;
}

/* write values to an entry in a COS_MAP block, if SDK owns it */
int
soc_sirius_cos_map_block_entry_set_sdk(int unit,
                                       unsigned int cosMapBlock,
                                       unsigned int entryIndex,
                                       unsigned int entryValue)
{
    if (SOC_E_FULL != soc_sirius_cos_map_block_check_sdk(unit, cosMapBlock)) {
        /* SDK does not own it */
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not in use by SDK\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    return soc_sirius_cos_map_block_entry_set(unit,
                                              cosMapBlock,
                                              entryIndex,
                                              entryValue);
}

/* read values from an entry in a COS_MAP block */
int
soc_sirius_cos_map_block_entry_get(int unit,
                                   unsigned int cosMapBlock,
                                   unsigned int entryIndex,
                                   unsigned int *entryValue)
{
    unsigned int idx;
    unsigned int entry;
    uint32 regVal = 0;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    if (!entryValue) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "entryValue argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    idx = cosMapBlock - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not in use\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    if (entryIndex > 15) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d only supports cos_map_block entries"
                               " 0..15\n"),
                   unit));
        return SOC_E_PARAM;
    }
    /*
     *  Init code earlier in this file states index into the COS_MAP table has
     *  COS_PROFILE as lower two bits and COS as upper 4 bits.  Compute the
     *  entry in the table based upon this formula.
     */
    entry = (entryIndex << 2) | idx;
    /* read register with the desired entry */
    result = soc_reg32_read(unit,
                            soc_reg_addr(unit,
                                         cosMapRegs[entry][0],
                                         REG_PORT_ANY,
                                         0),
                            &regVal);
    if (SOC_E_NONE == result) {
        /* read the specific entry */
        *entryValue = soc_reg_field_get(unit,
                                        cosMapRegs[entry][0],
                                        regVal,
                                        cosMapRegs[entry][1]);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to read unit %d cos_map_block %d entry %d:"
                               " %d (%s)\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS,
                   entryIndex,
                   result,
                   _SHR_ERRMSG(result)));
    }
    return result;
}

/* allocate queue_map table segment (qsel) */
int
soc_sirius_queue_map_block_allocate(int unit,
                                    uint32 flags,
                                    unsigned int base,
                                    unsigned int size,
                                    unsigned int *queueMapBlock)
{
    unsigned int freeQSStart[SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 2];
    unsigned int freeQSEnd[SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 2];
    soc_sbx_sirius_state_t *sir = SOC_SBX_SIRIUS_STATE(unit);
    unsigned int queueSegFirst = base;
    unsigned int queueSegEnd;
    unsigned int queueSegSize;
    unsigned int queueMapTemp;
    unsigned int idx;
    unsigned int offset;
    unsigned int queue;
    uint32 regval = 0;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!queueMapBlock) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "queueMapBlock argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    if (!(flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d only supports ingress queue_map_block\n"),
                   unit));
        return SOC_E_PARAM;
    }
    if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID) {
        /* caller specified which block */
        idx = *queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
        if ((idx > SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) ||
            (0 == idx)){
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_map_block ID %d is not valid on"
                                   " unit %d\n"),
                       *queueMapBlock,
                       unit));
            return SOC_E_NOT_FOUND;
        }
        if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_REPLACE) {
            if (0 == (sir->ingressQueueMaps & (1 << idx))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d queue_map_block %d is not in use;"
                                       " can't replace\n"),
                           unit,
                           *queueMapBlock));
                return SOC_E_NOT_FOUND;
            }
            if ((0 != sir->ingressQueueMapIntRefs[idx - 1]) &&
                (size != sir->ingressQueueMapSize[idx - 1])) {
                
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d queue_map_block %d is in use, so"
                                       " the size can not be changed\n"),
                           unit,
                           *queueMapBlock));
                return SOC_E_CONFIG;
            }
            if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK) {
                if (0 == (sir->ingressQueueMapsSdk & (1 << idx))) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d queue map block %d is not in"
                                           " use by SDK; can not replace to SDK\n"),
                               unit,
                               *queueMapBlock));
                    return SOC_E_EXISTS;
                }
            } else { /* if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK) */
                if (sir->ingressQueueMapsSdk & (1 << idx)) {
                    LOG_WARN(BSL_LS_SOC_COMMON,
                             (BSL_META_U(unit,
                                         "unit %d queue map block %d directly"
                                          " replaced by application\n"),
                              unit,
                              *queueMapBlock));
                }
            } /* if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK) */
        } else {
            if (0 != (sir->ingressQueueMaps & (1 << idx))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d queue_map_block %d is in use;"
                                       " must replace\n"),
                           unit,
                           *queueMapBlock));
                return SOC_E_EXISTS;
            }
        }
    } else { /* if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID) */
        /* need to look for a free block */
        if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_REPLACE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d requires WITH_ID with REPLACE\n"),
                       unit));
            return SOC_E_PARAM;
        }
        for (idx = 1;
             idx <= SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS;
             idx++) {
            if (0 == (sir->ingressQueueMaps & (1 << idx))) {
                /* this one is free */
                break;
            }
        }
        if (idx > SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d has no available queue_map_segment\n"),
                       unit));
            return SOC_E_RESOURCE;
        }
    } /* if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_WITH_ID) */
    queueMapTemp = idx;
    /*
     *  Okay, now we have a queue_map segment selected.  We need to figure out
     *  what parts of the queue_map table are available.
     */
    freeQSStart[0] = 0;
    freeQSEnd[0] = 65535;
    for (idx = 1;
         idx < (SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 2);
         idx++) {
        freeQSStart[idx] = ~0;
        freeQSEnd[idx] = ~0;
    }
    /* scan queue map segments to determine list of free blocks */
    for (idx = 0;
         idx < SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS;
         idx++) {
        if (0 == (sir->ingressQueueMaps & (1 << (idx + 1)))) {
            /* this one is not in use; skip it */
            continue;
        }
        if (queueMapTemp - 1 == idx) {
            /*
             *  We only get this far if reallocating (a new alloc will not be
             *  in use and already skipped).  When reallocating, we ignore the
             *  existing config for the block and treat it as new alloc.
             */
            continue;
        }
        /* get parameters for this queue_map block */
        queueSegFirst = sir->ingressQueueMapAddr[idx];
        queueSegSize = sir->ingressQueueMapSize[idx];
        queueSegEnd = queueSegFirst + queueSegSize - 1;
        for (offset = 0;
             offset < (SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 1);
             offset++) {
            if ((queueSegFirst <= freeQSStart[offset]) &&
                (queueSegEnd >= freeQSEnd[offset])) {
                /* this segment covers this entire 'free' block */
                for (queue = offset;
                     queue < (SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 1);
                     queue++) {
                    freeQSStart[queue] = freeQSStart[queue + 1];
                    freeQSEnd[queue] = freeQSEnd[queue + 1];
                }
                offset--; /* check the new entry at this offset */
            } else if ((queueSegFirst <= freeQSStart[offset]) &&
                       (queueSegEnd >= freeQSStart[offset])) {
                /* this segment covers the first part of the block */
                freeQSStart[offset] = queueSegEnd + 1;
            } else if ((queueSegFirst <= freeQSEnd[offset]) &&
                       (queueSegEnd >= freeQSEnd[offset])) {
                /* this segment covers the end part of the block */
                freeQSEnd[offset] = queueSegFirst - 1;
            } else if ((queueSegFirst >= freeQSStart[offset]) &&
                       (queueSegEnd <= freeQSEnd[offset])) {
                /* this segment covers something in the middle */
                for (queue = SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS;
                     queue > offset;
                     queue--) {
                    freeQSStart[queue] = freeQSStart[queue - 1];
                    freeQSEnd[queue] = freeQSEnd[queue - 1];
                }
                /* this essentially splits this block */
                freeQSEnd[offset] = queueSegFirst - 1;
                freeQSStart[offset + 1] = queueSegEnd + 1;
                offset--; /* check the new entry at this offset */
            }
        } /* for (all possible free list segments) */
    } /* for (all queue map segments) */
    /* scan list of free blocks for one that's big enough */
    for (idx = 0;
         idx < (SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS + 1);
         idx++) {
        queueSegSize = (freeQSEnd[idx] - freeQSStart[idx]) + 1;
        if (queueSegSize >= size) {
            /* this block will do */
            queueSegFirst = freeQSStart[idx];
            queueSegSize = size;
            queueSegEnd = (queueSegFirst + queueSegSize) - 1;
            break;
        } else {
            /* don't want this block (too small) */
            queueSegSize = 0;
        }
    } /* for (all possible free list segments) */
    if (!queueSegSize) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d does not have a large enough block of"
                               " queue_map space available\n"),
                   unit));
        return SOC_E_RESOURCE;
    }
    /* now program the base address into the segment register */
    
    result = soc_reg32_read(unit,
                            soc_reg_addr(unit,
                                         queueSegRegs[queueMapTemp - 1][0],
                                         REG_PORT_ANY,
                                         0),
                            &regval);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to access unit %d queue_map_segment %d:"
                               " %d (%s)\n"),
                   unit,
                   queueMapTemp,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    soc_reg_field_set(unit,
                      queueSegRegs[queueMapTemp - 1][0],
                      &regval,
                      queueSegRegs[queueMapTemp - 1][1],
                      (queueSegFirst - base) & 0xFFFF);
    result = soc_reg32_write(unit,
                             soc_reg_addr(unit,
                                          queueSegRegs[queueMapTemp - 1][0],
                                          REG_PORT_ANY,
                                          0),
                             regval);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to write unit %d queue_map_segment %d:"
                               " %d (%s)\n"),
                   unit,
                   queueMapTemp,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    /* if we go to here, the write was successful, so update alloc & data */
    sir->ingressQueueMaps |= (1 << queueMapTemp);
    if (flags & SIRIUS_QUEUE_MAP_BLOCK_FLAGS_SDK) {
        sir->ingressQueueMapsSdk |= (1 << queueMapTemp);
    } else {
        sir->ingressQueueMapsSdk &= ~(1 << queueMapTemp);
    }
    sir->ingressQueueMapBase[queueMapTemp - 1] = base;
    sir->ingressQueueMapSize[queueMapTemp - 1] = size;
    sir->ingressQueueMapAddr[queueMapTemp - 1] = (queueSegFirst - base) & 0xFFFF;
    /* return this segment */
    *queueMapBlock = queueMapTemp + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    return SOC_E_NONE;
}

/* free a queue_map table segment (qsel) */
int
soc_sirius_queue_map_block_free(int unit,
                                unsigned int queueMapBlock)
{
    queue_map_entry_t *qme = NULL;
    unsigned int idx;
    unsigned int count;
    uint32 regval;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "queue_map_block %d not valid on unit %d\n"),
                   queueMapBlock,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    queueMapBlock -= SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << queueMapBlock))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is already free\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    queueMapBlock--;
    if (0 != SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapRefs[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is still being"
                               " referenced\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS));
        return SOC_E_FULL;
    }
    /* clear its contents (to avoid confusing the accounting) */
    count = SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock];
    qme = soc_cm_salloc(unit, sizeof(*qme) * count, "raw queue_map entry data");
    if (!qme) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to allocate buffer to clear unit %d"
                               " queue_map_block %d\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS));
        return SOC_E_RESOURCE;
    }
    sal_memset(qme,0x00, sizeof(*qme) * count);
    for (idx = 0;
         idx < count;
         idx++) {
        soc_mem_field32_set(unit,
                            QUEUE_MAPm,
                            &(qme[idx]),
                            COS_PROFILEf,
                            0);
        soc_mem_field32_set(unit,
                            QUEUE_MAPm,
                            &(qme[idx]),
                            QID_BASEf,
                            SIRIUS_Q_BASE_INVALID);
    }
    result = soc_cm_sflush(unit, qme, sizeof(*qme) * count);
    if (SOC_E_NONE == result) {
        /*    coverity[negative_returns : FALSE]    */
        result = soc_mem_write_range(unit,
                                     QUEUE_MAPm,
                                     MEM_BLOCK_ALL,
                                     SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[queueMapBlock],
                                     SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[queueMapBlock] +
                                     count - 1,
                                     qme);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to commit processor cache in prep to clear"
                               " unit %d queue_map_block %d: %d (%s)\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS,
                   result,
                   _SHR_ERRMSG(result)));
    }
    /* clear its address */
    if (SOC_E_NONE == result) {
        result = soc_reg32_read(unit,
                                soc_reg_addr(unit,
                                             queueSegRegs[queueMapBlock][0],
                                             REG_PORT_ANY,
                                             0),
                                &regval);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to access unit %d queue_map_block %d:"
                                   " %d (%s)\n"),
                       unit,
                       queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    if (SOC_E_NONE == result) {
        soc_reg_field_set(unit,
                          queueSegRegs[queueMapBlock][0],
                          &regval,
                          queueSegRegs[queueMapBlock][1],
                          0);
        result = soc_reg32_write(unit,
                                 soc_reg_addr(unit,
                                              queueSegRegs[queueMapBlock][0],
                                              REG_PORT_ANY,
                                              0),
                                 regval);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d queue_map_block %d:"
                                   " %d (%s)\n"),
                       unit,
                       queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_FLAGS_INGRESS,
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    /* mark it free */
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps &= (~(1 << (queueMapBlock + 1)));
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapsSdk &= (~(1 << (queueMapBlock + 1)));
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[queueMapBlock] = 0;
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[queueMapBlock] = 0;
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock] = 0;
    SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapIntRefs[queueMapBlock] = 0;
    /* its references into COS_MAP are no longer valid */
    for (regval = 0;
         regval < SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS;
         regval++) {
        SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[regval] -=
            SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapCosMapRefs[queueMapBlock][regval];
    }
    if (qme) {
        soc_cm_sfree(unit, qme);
    }
    return SOC_E_NONE;
}

/* check queue_map block */
int
soc_sirius_queue_map_block_check(int unit,
                                 unsigned int queueMapBlock)
{
    unsigned int idx;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "queue_map_block %d not valid on unit %d\n"),
                   queueMapBlock,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << idx))) {
        /* it is free */
        return SOC_E_EMPTY;
    } else {
        /* it is in use */
        return SOC_E_FULL;
    }
}

/* check queue_map block for SDK */
int
soc_sirius_queue_map_block_check_sdk(int unit,
                                     unsigned int queueMapBlock)
{
    unsigned int idx;

    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "queue_map_block %d not valid on unit %d\n"),
                   queueMapBlock,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapsSdk & (1 << idx))) {
        /* it is free */
        return SOC_E_EMPTY;
    } else {
        /* it is in use */
        return SOC_E_FULL;
    }
}

/* get parameters for a queue_map segment (qsel) */
int
soc_sirius_queue_map_block_get(int unit,
                               unsigned int queueMapBlock,
                               unsigned int *base,
                               unsigned int *size)
{
    unsigned int idx;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "queue_map_block %d not valid on unit %d\n"),
                   queueMapBlock,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is not in use\n"),
                   queueMapBlock,
                   unit));
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    idx--;
    *base = SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx];
    *size = SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx];
    return SOC_E_NONE;
}

/* given a QUEUE_MAP block, find the next one that is in use */
int
soc_sirius_queue_map_block_next(int unit,
                                unsigned int current,
                                unsigned int *next)
{
    int result = SOC_E_NOT_FOUND;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    do {
        /* figure out next QUEUE_MAP block to examine */
        if (current >= ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
                         SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) * 2)) {
            /* very large number; go to first ingress QUEUE_MAP block */
            current = SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
#if (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)
        } else if (current < SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) {
            /* below ingress; go to first ingress QUEUE_MAP block */
            current = SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
#endif /* (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) */
        } else if (
#if (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)
                   (current >= SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) */
                   (current < (SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS))) {
            /* within ingress; look at next ingress */
            current++;
        } else {
            /* at/after end of ingress but not large enough to wrap */
            break;
        }
        if (
#if (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)
            (current >= SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS) */
            (current <= (SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
                        SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS))) {
            /* check ingress  */
            if (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 <<
                                                              (current -
                                                               SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        }
    } while ((SOC_E_NOT_FOUND == result));
    if (SOC_E_NONE == result) {
        *next = current;
    }
    return result;
}

/* write an entry to a queue_map segment */
int
soc_sirius_queue_map_block_entry_set(int unit,
                                     unsigned int queueMapBlock,
                                     unsigned int offset,
                                     unsigned int cosMapBlock,
                                     unsigned int queueId)
{
    queue_map_entry_t qme;
    unsigned int oldCosMapBlock;
    unsigned int oldQueueId;
    unsigned int idx;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not valid\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cosMapBlock) ||
        ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
          SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cosMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d not valid\n"),
                   unit,
                   cosMapBlock));
        return SOC_E_NOT_FOUND;
    }
    cosMapBlock -= SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMaps &
              (1 << cosMapBlock))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d cos_map_block %d is not in use\n"),
                   unit,
                   cosMapBlock + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    if (queueId >= SIRIUS_Q_BASE_INVALID) {
        /* invalid queue ID */
        return SOC_E_PARAM;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is not in use\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    idx--;
    if (offset < SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " below base offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset -= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx];
    if (offset >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset += SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[idx];
    offset &= 0xFFFF;
    /* now we know where in queue_map to look, and it is valid */
    result = READ_QUEUE_MAPm(unit,
                             MEM_BLOCK_ANY,
                             offset,
                             &qme);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to read unit %d queue_map %d: %d (%s)\n"),
                   unit,
                   offset,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    oldCosMapBlock = soc_mem_field32_get(unit,
                                         QUEUE_MAPm,
                                         &qme,
                                         COS_PROFILEf);
    oldQueueId = soc_mem_field32_get(unit,
                                     QUEUE_MAPm,
                                     &qme,
                                     QID_BASEf);
    soc_mem_field32_set(unit,
                        QUEUE_MAPm,
                        &qme,
                        COS_PROFILEf,
                        cosMapBlock);
    soc_mem_field32_set(unit,
                        QUEUE_MAPm,
                        &qme,
                        QID_BASEf,
                        queueId);
    result = WRITE_QUEUE_MAPm(unit,
                              MEM_BLOCK_ALL,
                              offset,
                              &qme);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to write unit %d queue_map %d: %d (%s)\n"),
                   unit,
                   offset,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    if (SIRIUS_Q_BASE_INVALID != oldQueueId) {
        /* account for removal of old queue reference to COS_MAP */
        (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[oldCosMapBlock])--;
        (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapCosMapRefs[idx][oldCosMapBlock])--;
        (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapIntRefs[idx])--;
    }
    if (SIRIUS_Q_BASE_INVALID != queueId) {
        /* account for addition of new queue reference to COS_MAP */
        (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[cosMapBlock])++;
        (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapCosMapRefs[idx][cosMapBlock])++;
        (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapIntRefs[idx])++;
    }
    return SOC_E_NONE;
}

/* write an entry to a queue_map segment for SDK */
int
soc_sirius_queue_map_block_entry_set_sdk(int unit,
                                         unsigned int queueMapBlock,
                                         unsigned int offset,
                                         unsigned int cosMapBlock,
                                         unsigned int queueId)
{
    if (SOC_E_FULL != soc_sirius_queue_map_block_check_sdk(unit, queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not in use by SDK\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    return soc_sirius_queue_map_block_entry_set(unit,
                                                queueMapBlock,
                                                offset,
                                                cosMapBlock,
                                                queueId);
}

/* read an entry from a queue_map segment */
int
soc_sirius_queue_map_block_entry_get(int unit,
                                     unsigned int queueMapBlock,
                                     unsigned int offset,
                                     unsigned int *cosMapBlock,
                                     unsigned int *queueId)
{
    queue_map_entry_t qme;
    unsigned int idx;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not valid\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    if ((!cosMapBlock) || (!queueId)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "cosMapBlock and queueId must not be NULL\n")));
        return SOC_E_PARAM;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << idx))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is not in use\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    idx--;
    if (offset < SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " below base offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset -= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx];
    if (offset >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset += SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[idx];
    offset &= 0xFFFF;
    /* now we know where in queue_map to look, and it is valid */
    result = READ_QUEUE_MAPm(unit,
                             MEM_BLOCK_ANY,
                             offset,
                             &qme);
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to read unit %d queue_map %d: %d (%s)\n"),
                   unit,
                   offset,
                   result,
                   _SHR_ERRMSG(result)));
        return result;
    }
    *cosMapBlock = (soc_mem_field32_get(unit,
                                        QUEUE_MAPm,
                                        &qme,
                                        COS_PROFILEf) +
                    SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS);
    *queueId = soc_mem_field32_get(unit,
                                   QUEUE_MAPm,
                                   &qme,
                                   QID_BASEf);
    return SOC_E_NONE;
}

/* write a bunch of entries to a queue_map segment */
int
soc_sirius_queue_map_block_entry_multi_set(int unit,
                                           unsigned int queueMapBlock,
                                           unsigned int offset,
                                           unsigned int count,
                                           const unsigned int *cosMapBlock,
                                           const unsigned int *queueId)
{
    queue_map_entry_t *qme = NULL;
    queue_map_entry_t *qmeold = NULL;
    unsigned int index;
    unsigned int cmb;
    unsigned int qi;
    int result = SOC_E_NONE;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not valid\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    queueMapBlock -= SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << queueMapBlock))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is not in use\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    queueMapBlock--;
    if (offset < SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " below base offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset -= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[queueMapBlock];
    if (offset >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    if ((offset + count) >
        SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d final offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset + count - 1));
        return SOC_E_PARAM;
    }
    offset += SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[queueMapBlock];
    offset &= 0xFFFF;
    if (count) {
        if ((!cosMapBlock) || (!queueId)) {
            /* not valid to specify nonzero entries but no data */
            return SOC_E_PARAM;
        }
    }
    /* so the static parameters are okay, alloc the memory cell */
    qme = soc_cm_salloc(unit,
                        sizeof(*qme) * count,
                        "raw queue_map entry data");
    if (!qme) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to allocate working new buffer\n")));
        result = SOC_E_RESOURCE;
    }
    if (SOC_E_NONE == result) {
        qmeold = soc_cm_salloc(unit,
                               sizeof(*qmeold) * count,
                               "old raw queue_map entry data");
        if (!qmeold) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to allocate working old buffer\n")));
            result = SOC_E_RESOURCE;
        }
    }
    /* build new data */
    if (SOC_E_NONE == result) {
        sal_memset(qme, 0x00, sizeof(*qme) * count);
        for (index = 0; index < count; index++) {
            cmb = cosMapBlock[index];
            qi = queueId[index];
            /* coverity[unsigned_compare] */
            if ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS > cmb) ||
                ((SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS - 1 +
                  SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS) < cmb)) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d cos_map_block %d is not in use\n"),
                           unit,
                           cmb + SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS));
                result = SOC_E_NOT_FOUND;
                break;
            }
            cmb -= SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
            if (qi >= SIRIUS_Q_BASE_INVALID) {
                /* invalid queue ID */
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d queue %d is not valid\n"),
                           unit,
                           qi));
                result = SOC_E_PARAM;
                break;
            }
            soc_mem_field32_set(unit,
                                QUEUE_MAPm,
                                &(qme[index]),
                                COS_PROFILEf,
                                cosMapBlock[index]);
            soc_mem_field32_set(unit,
                                QUEUE_MAPm,
                                &(qme[index]),
                                QID_BASEf,
                                queueId[index]);
        }
    }
    /* read current data */
    if (SOC_E_NONE == result) {
        result = soc_cm_sinval(unit, qmeold, sizeof(*qmeold) * count);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to invalidate cache prior to read"
                                   " of old queue data: %d (%s)\n"),
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    if (SOC_E_NONE == result) {
        result = soc_mem_read_range(unit,
                                    QUEUE_MAPm,
                                    MEM_BLOCK_ANY,
                                    offset,
                                    offset + count - 1,
                                    qmeold);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to read old value of unit %d queue_map"
                                   " entries %d..%d: %d (%s)\n"),
                       unit,
                       offset,
                       offset + count - 1,
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    /* commit new data */
    if (SOC_E_NONE == result) {
        result = soc_cm_sflush(unit, qme, sizeof(*qme) * count);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to flush cache prior to write"
                                   " of new queue data: %d (%s)\n"),
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    if (SOC_E_NONE == result) {
        /*    coverity[negative_returns : FALSE]    */
        result = soc_mem_write_range(unit,
                                     QUEUE_MAPm,
                                     MEM_BLOCK_ALL,
                                     offset,
                                     offset + count - 1,
                                     qme);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write new value of unit %d queue_map"
                                   " entries %d..%d: %d (%s)\n"),
                       unit,
                       offset,
                       offset + count - 1,
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    /* accounting */
    if (SOC_E_NONE == result) {
        for (index = 0; index < count; index++) {
            cmb = soc_mem_field32_get(unit,
                                      QUEUE_MAPm,
                                      &(qmeold[index]),
                                      COS_PROFILEf);
            qi = soc_mem_field32_get(unit,
                                     QUEUE_MAPm,
                                     &(qmeold[index]),
                                     QID_BASEf);
            if (SIRIUS_Q_BASE_INVALID != qi) {
                /* account for removal of old queue reference to COS_MAP */
                (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[cmb])--;
                (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapCosMapRefs[queueMapBlock][cmb])--;
            }
            cmb = cosMapBlock[index] - SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS;
            if (SIRIUS_Q_BASE_INVALID != queueId[index]) {
                /* account for addition of new queue reference to COS_MAP */
                (SOC_SBX_SIRIUS_STATE(unit)->ingressCosMapRefs[cmb])++;
                (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapCosMapRefs[queueMapBlock][cmb])++;
            }
        }
    }
    /* dispose of temporary resources */
    if (qme) {
        soc_cm_sfree(unit, qme);
    }
    if (qmeold) {
        soc_cm_sfree(unit, qmeold);
    }
    /* return our result */
    return result;
}

/* write a bunch of entries to a queue_map segment for SDK */
int
soc_sirius_queue_map_block_entry_multi_set_sdk(int unit,
                                               unsigned int queueMapBlock,
                                               unsigned int offset,
                                               unsigned int count,
                                               const unsigned int *cosMapBlock,
                                               const unsigned int *queueId)
{
    if (SOC_E_FULL != soc_sirius_queue_map_block_check_sdk(unit, queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not in use by SDK\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    return soc_sirius_queue_map_block_entry_multi_set(unit,
                                                      queueMapBlock,
                                                      offset,
                                                      count,
                                                      cosMapBlock,
                                                      queueId);
}

/* read a bunch of entries from a queue_map segment */
int
soc_sirius_queue_map_block_entry_multi_get(int unit,
                                           unsigned int queueMapBlock,
                                           unsigned int offset,
                                           unsigned int count,
                                           unsigned int *cosMapBlock,
                                           unsigned int *queueId)
{
    queue_map_entry_t *qmeold = NULL;
    unsigned int index;
    int result = SOC_E_NONE;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d not valid\n"),
                   unit,
                   queueMapBlock));
        return SOC_E_NOT_FOUND;
    }
    queueMapBlock -= SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << queueMapBlock))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d is not in use\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS));
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    queueMapBlock--;
    if (offset < SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " below base offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    offset -= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[queueMapBlock];
    if (offset >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset));
        return SOC_E_PARAM;
    }
    if (offset + count > SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[queueMapBlock]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d queue_map_block %d final offset %d is"
                               " above max offset\n"),
                   unit,
                   queueMapBlock + SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS,
                   offset + count - 1));
        return SOC_E_PARAM;
    }
    offset += SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[queueMapBlock];
    offset &= 0xFFFF;
    if (count) {
        if ((!cosMapBlock) || (!queueId)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "not valid to request data but have NULL"
                                   " pointers to buffers\n")));
            return SOC_E_PARAM;
        }
    }
    /* so the static parameters are okay, alloc the memory cell */
    qmeold = soc_cm_salloc(unit,
                           sizeof(*qmeold) * count,
                           "old raw queue_map entry data");
    if (!qmeold) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to allocate working buffer\n")));
        result = SOC_E_RESOURCE;
    }
    /* read current data */
    if (SOC_E_NONE == result) {
        result = soc_cm_sinval(unit, qmeold, sizeof(*qmeold) * count);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to invalidate cache prior to read"
                                   " of queue data: %d (%s)\n"),
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    if (SOC_E_NONE == result) {
        result = soc_mem_read_range(unit,
                                    QUEUE_MAPm,
                                    MEM_BLOCK_ANY,
                                    offset,
                                    offset + count - 1,
                                    qmeold);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to read value of unit %d queue_map"
                                   " entries %d..%d: %d (%s)\n"),
                       unit,
                       offset,
                       offset + count - 1,
                       result,
                       _SHR_ERRMSG(result)));
        }
    }
    /* copy new data to caller's buffers */
    if (SOC_E_NONE == result) {
        for (index = 0; index < count; index++) {
            cosMapBlock[index] = soc_mem_field32_get(unit,
                                                     QUEUE_MAPm,
                                                     &(qmeold[index]),
                                                     COS_PROFILEf);
            queueId[index] = soc_mem_field32_get(unit,
                                                 QUEUE_MAPm,
                                                 &(qmeold[index]),
                                                 QID_BASEf);
        }
    }
    /* dispose of temporary resources */
    if (qmeold) {
        soc_cm_sfree(unit, qmeold);
    }
    /* return our result */
    return result;
}

/* given an entry in a queue_map segment, find the next one */
int
soc_sirius_queue_map_block_entry_next(int unit,
                                      unsigned int queueMapBlock,
                                      unsigned int current,
                                      unsigned int *next)
{
    queue_map_entry_t qme;
    unsigned int idx;
    int count;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS >= queueMapBlock) ||
        ((SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS) < queueMapBlock)) {
        /* not in the correct range for ingress */
        return SOC_E_NOT_FOUND;
    }
    idx = queueMapBlock - SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS;
    if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMaps & (1 << idx))) {
        /* it is not in use */
        return SOC_E_NOT_FOUND;
    }
    /* looking up information is zero based */
    idx--;
    if (current < SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx]) {
        /* offset is below the base offset for the segment */
        current = 0;
    } else {
        /* offset is within the segment range */
        current -= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx];
        /* but want to start looking at next */
        current++;
    }
    count = SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx];
    if (current >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx] * 2) {
        /* offset is beyond the limit for the segment */
        current = 0;
    } else if (current >= SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapSize[idx]) {
        /* past end but not far enough to assume wrap is intended */
        return SOC_E_NOT_FOUND;
    } else {
        /* within the segment so adjust how far to scan */
        count -= current;
    }
    current += SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[idx];
    /* now we have current location in queue_map; look for next one */
    for (;
         count > 0;
         current = (current + 1) & 0xFFFF, count--) {
        SOC_IF_ERROR_RETURN(READ_QUEUE_MAPm(unit,
                                            MEM_BLOCK_ANY,
                                            current,
                                            &qme));
        if (SIRIUS_Q_BASE_INVALID != soc_mem_field32_get(unit, QUEUE_MAPm, &qme, QID_BASEf)) {
            /* found one */
            break;
        }
    }
    if (count > 0) {
        /* found one */
        *next = (current +
                 SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapBase[idx] -
                 SOC_SBX_SIRIUS_STATE(unit)->ingressQueueMapAddr[idx]);
        return SOC_E_NONE;
    } else {
        return SOC_E_NOT_FOUND;
    }
}

int
soc_sirius_parser_allocate(int unit,
                           uint32 flags,
                           unsigned int *parserId)
{
    uint16 *parsers;
    uint16 *parsersSdk;
    unsigned int pid;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!parserId) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "parserId argument must not be NULL pointer\n")));
        return SOC_E_PARAM;
    }
    pid = *parserId;
    if (((SIRIUS_PARSER_FLAGS_INGRESS | SIRIUS_PARSER_FLAGS_EGRESS) ==
         (flags & (SIRIUS_PARSER_FLAGS_INGRESS |
                   SIRIUS_PARSER_FLAGS_EGRESS))) ||
        (0 == (flags & (SIRIUS_PARSER_FLAGS_INGRESS |
                        SIRIUS_PARSER_FLAGS_EGRESS)))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "parser must be either ingress or egress\n")));
        return SOC_E_PARAM;
    }
    if (flags & SIRIUS_PARSER_FLAGS_INGRESS) {
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsers);
        parsersSdk = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsersSdk);
        pid -= SIRIUS_PARSER_OFFSET_INGRESS;
    } else { /* if (flags & SIRIUS_PARSER_FLAGS_INGRESS) */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsers);
        parsersSdk = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsersSdk);
        pid -= SIRIUS_PARSER_OFFSET_EGRESS;
    } /* if (flags & SIRIUS_PARSER_FLAGS_INGRESS) */
    if (flags & SIRIUS_PARSER_FLAGS_WITH_ID) {
        /* caller specified ID */
        /* coverity[unsigned_compare] */
        if ((0 > pid) || (SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS <= pid)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d parser ID %d is not valid\n"),
                       unit,
                       *parserId));
            return SOC_E_PARAM;
        }
        if (flags & SIRIUS_PARSER_FLAGS_REPLACE) {
            if (0 == ((*parsers) & (1 << pid))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d parser %d is not in use; can't"
                                       " replace it\n"),
                           unit,
                           *parserId));
                return SOC_E_NOT_FOUND;
            }
            if (flags & SIRIUS_PARSER_FLAGS_SDK) {
                if (0 == ((*parsersSdk) & (1 << pid))) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d parser %d is not in use by SDK;"
                                           " can not assign to SDK\n"),
                               unit,
                               *parserId));
                    return SOC_E_EXISTS;
                }
            } else { /* if (flags & SIRIUS_PARSER_FLAGS_SDK) */
                if ((*parsersSdk) & (1 << pid)) {
                    LOG_WARN(BSL_LS_SOC_COMMON,
                             (BSL_META_U(unit,
                                         "unit %d parser %d diretly replaced"
                                          " by application\n"),
                              unit,
                              *parserId));
                }
            } /* if (flags & SIRIUS_PARSER_FLAGS_SDK) */
        } else { /* if (flags & SIRIUS_PARSER_FLAGS_REPLACE) */
            if (0 != ((*parsers) & (1 << pid))) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d parser %d is already in use;"
                                       " can't allocate it\n"),
                           unit,
                           *parserId));
                return SOC_E_EXISTS;
            }
        } /* if (flags & SIRIUS_PARSER_FLAGS_REPLACE) */
    } else { /* if (flags & SIRIUS_PARSER_FLAGS_WITH_ID) */
        /* caller did not specify ID */
        if (flags & SIRIUS_PARSER_FLAGS_REPLACE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d requires WITH_ID with REPLACE\n"),
                       unit));
            return SOC_E_PARAM;
        }
        for (pid = 0; SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS > pid; pid++) {
            if (0 == ((*parsers) & (1 << pid))) {
                /* found an available one */
                break;
            }
        }
        if (SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS <= pid) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to find free %s parser on unit %d\n"),
                       (flags & SIRIUS_PARSER_FLAGS_EGRESS)?"egress":"ingress",
                       unit));
            return SOC_E_RESOURCE;
        }
    } /* if (flags & SIRIUS_PARSER_FLAGS_WITH_ID) */
    (*parsers) |= (1 << pid);
    if (flags & SIRIUS_PARSER_FLAGS_SDK) {
        (*parsersSdk) |= (1 << pid); /* SDK */
    } else {
        (*parsersSdk) &= ~(1 << pid); /* not SDK */
    }
    if (flags & SIRIUS_PARSER_FLAGS_INGRESS) {
        *parserId = pid + SIRIUS_PARSER_OFFSET_INGRESS;
    } else { /* if (flags & SIRIUS_PARSER_FLAGS_INGRESS) */
        *parserId = pid + SIRIUS_PARSER_OFFSET_EGRESS;
    } /* if (flags & SIRIUS_PARSER_FLAGS_INGRESS) */
    return SOC_E_NONE;
}

int
soc_sirius_parser_free(int unit,
                       unsigned int parserId)
{
    uint16 *parsers;
    uint16 *parsersSdk;
    int *refs;
    unsigned int pid = parserId;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PARSER_OFFSET_INGRESS <= parserId) &&
        ((SIRIUS_PARSER_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates ingress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsers);
        parsersSdk = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsersSdk);
        refs = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParserRefs[0]);
        parserId -= SIRIUS_PARSER_OFFSET_INGRESS;
    } else if ((SIRIUS_PARSER_OFFSET_EGRESS <= parserId) &&
               ((SIRIUS_PARSER_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates egress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsers);
        parsersSdk = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsersSdk);
        refs = &(SOC_SBX_SIRIUS_STATE(unit)->egressParserRefs[0]);
        parserId -= SIRIUS_PARSER_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d is not valid\n"),
                   unit,
                   parserId));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*parsers) & (1 << parserId))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser %d is not in use\n"),
                   unit,
                   pid));
        return SOC_E_NOT_FOUND;
    }
    if (0 != refs[parserId]) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser %d is still being referenced\n"),
                   unit,
                   pid));
        return SOC_E_FULL;
    }
    (*parsers) &= ~(1 << parserId);
    (*parsersSdk) &= ~(1 << parserId);
    return SOC_E_NONE;
}

int
soc_sirius_parser_check(int unit,
                        unsigned int parserId)
{
    uint16 *parsers;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PARSER_OFFSET_INGRESS <= parserId) &&
        ((SIRIUS_PARSER_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates ingress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsers);
        parserId -= SIRIUS_PARSER_OFFSET_INGRESS;
    } else if ((SIRIUS_PARSER_OFFSET_EGRESS <= parserId) &&
               ((SIRIUS_PARSER_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates egress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsers);
        parserId -= SIRIUS_PARSER_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d is not valid\n"),
                   unit,
                   parserId));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*parsers) & (1 << parserId))) {
        /* this predicate is not allocated */
        return SOC_E_EMPTY;
    } else {
        /* this predicate is allocated */
        return SOC_E_FULL;
    }
}

int
soc_sirius_parser_check_sdk(int unit,
                            unsigned int parserId)
{
    uint16 *parsers;

    /* coverity[unsigned_compare] */
    if ((SIRIUS_PARSER_OFFSET_INGRESS <= parserId) &&
        ((SIRIUS_PARSER_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates ingress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsersSdk);
        parserId -= SIRIUS_PARSER_OFFSET_INGRESS;
    } else if ((SIRIUS_PARSER_OFFSET_EGRESS <= parserId) &&
               ((SIRIUS_PARSER_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates egress */
        parsers = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsersSdk);
        parserId -= SIRIUS_PARSER_OFFSET_EGRESS;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d is not valid\n"),
                   unit,
                   parserId));
        return SOC_E_NOT_FOUND;
    }

    if (0 == ((*parsers) & (1 << parserId))) {
        /* this predicate is not allocated */
        return SOC_E_EMPTY;
    } else {
        /* this predicate is allocated */
        return SOC_E_FULL;
    }
}

int
soc_sirius_parser_set(int unit,
                      unsigned int parserId,
                      const soc_sirius_parser_info_t *parserInfo)
{
    frame_parsing_entry_t ingressParser;
    ep_hdr_parsing_ctrl_entry_t egressParser;
    ep_stats_ctrl_entry_t statsCfg;
    int result;
    unsigned int pid = parserId;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!parserInfo) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "parserInfo pointer must not be NULL\n")));
        return SOC_E_PARAM;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PARSER_OFFSET_INGRESS <= parserId) &&
        ((SIRIUS_PARSER_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates ingress */
        if (0 == (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_INGRESS)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "parser definition must be INGRESS for"
                                   " ingress parser %d on unit %d\n"),
                       parserId,
                       unit));
            return SOC_E_PARAM;
        }
        parserId -= SIRIUS_PARSER_OFFSET_INGRESS;
        sal_memset(&ingressParser, 0x00, sizeof(ingressParser));
        if (SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS >=
            (parserInfo->ingress.segmentSel -
             SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS)) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SEGMENT_SELf,
                                parserInfo->ingress.segmentSel -
                                SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "segmentSel on unit %d ingress must be 0..%d\n"),
                       unit,
                       SB_FAB_DEVICE_SIRIUS_CONFIG_QUEUE_SEGMENTS));
            return SOC_E_PARAM;
        }
        if (SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS >
            (parserInfo->ingress.cosProfile -
             SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS)) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                DEFAULT_COS_PROFILEf,
                                parserInfo->ingress.cosProfile -
                                SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "cosProfile on unit %d ingress must be 0..%d\n"),
                       unit,
                       SB_FAB_DEVICE_SIRIUS_CONFIG_COS_MAP_BLOCKS - 1));
            return SOC_E_PARAM;
        }
        if (0x3F > parserInfo->ingress.queue_byte0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_BYTE_OFFSET0f,
                                parserInfo->ingress.queue_byte0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_byte0 on unit %d ingress"
                                   " must be 0..62\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->ingress.queue_bit0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_BIT_OFFSET0f,
                                parserInfo->ingress.queue_bit0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_bit0 on unit %d ingress"
                                   " must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x11 > parserInfo->ingress.queue_length0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_LENGTH0f,
                                parserInfo->ingress.queue_length0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_length0 on unit %d ingress"
                                   " must be 0..16\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x3F > parserInfo->ingress.queue_byte1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_BYTE_OFFSET1f,
                                parserInfo->ingress.queue_byte1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_byte1 on unit %d ingress"
                                   " must be 0..62\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->ingress.queue_bit1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_BIT_OFFSET1f,
                                parserInfo->ingress.queue_bit1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_bit1 on unit %d ingress"
                                   " must be 0..7)\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x10 > parserInfo->ingress.queue_length1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                Q_LENGTH1f,
                                parserInfo->ingress.queue_length1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "queue_length1 on unit %d ingress"
                                   " must be 0..15\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x10 < (parserInfo->ingress.queue_length0 +
                    parserInfo->ingress.queue_length1)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "total queue length on unit %d ingress"
                                   " must be 0..16\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x3F > parserInfo->ingress.cos_byte) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                COS_BYTE_OFFSETf,
                                parserInfo->ingress.cos_byte);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "cos_byte on unit %d ingress"
                                   " must be 0..62\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (5 > parserInfo->ingress.cos_bit) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                COS_BIT_OFFSETf,
                                parserInfo->ingress.cos_bit);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "cos_bit on unit %d ingress must be 0..4\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0 > parserInfo->ingress.dp) {
            /* no override DP */
        } else if (4 > parserInfo->ingress.dp) {
            /* override DP is valid */
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                DEFAULT_DPf,
                                parserInfo->ingress.dp);
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_DPf,
                                TRUE);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "dp on unit %d ingress must be negative to"
                                   " disable override, or 0..3 to override\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0 > parserInfo->ingress.ecn) {
            /* no override ECN */
        } else if (4 > parserInfo->ingress.ecn) {
            /* override ECN is valid */
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                DEFAULT_ECNf,
                                parserInfo->ingress.ecn);
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_ECNf,
                                TRUE);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "ecn on unit %d ingress must be negative to"
                                   " disable override, or 0..3 to override\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x3F > parserInfo->ingress.stat_byte0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_BYTE_OFFSET0f,
                                parserInfo->ingress.stat_byte0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_byte0 on unit %d ingress"
                                   " must be 0..62\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->ingress.stat_bit0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_BIT_OFFSET0f,
                                parserInfo->ingress.stat_bit0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_bit0 on unit %d ingress"
                                   " must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (16 > parserInfo->ingress.stat_length0) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_LENGTH0f,
                                parserInfo->ingress.stat_length0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_length0 on unit %d ingress"
                                   " must be 0..15\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0x3F > parserInfo->ingress.stat_byte1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_BYTE_OFFSET1f,
                                parserInfo->ingress.stat_byte1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_byte1 on unit %d ingress"
                                   " must be 0..62\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->ingress.stat_bit1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_BIT_OFFSET1f,
                                parserInfo->ingress.stat_bit1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_bit1 on unit %d ingress"
                                   " must be 0..7)\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (16 > parserInfo->ingress.stat_length1) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                SL_LENGTH1f,
                                parserInfo->ingress.stat_length1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "stat_length1 on unit %d ingress"
                                   " must be 0..15\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (16 < (parserInfo->ingress.stat_length0 +
                  parserInfo->ingress.stat_length1)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "combined length ot stats on unit %d ingress"
                                   " must be 0..16\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_QUEUE_DEFAULT) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_INDEXf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_USE_COS_MAP) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                COS_ENABLEf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_USE_TAG_OFFSET) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                OFFSET_ENABLEf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_OVERWRITE_DEST) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                OVERWRITE_DESTf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_LENGTH_ADJUST) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_LEN_ADJ_IDXf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_CLEAR_TEST_BIT) {
            soc_mem_field32_set(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                TEST_DISABLEf,
                                TRUE);
        }
        if (parserInfo->ingress.flags & (~(SIRIUS_PARSER_FLAGS_INGRESS |
                                           SIRIUS_PARSER_FLAGS_WITH_ID |
                                           SIRIUS_PARSER_FLAGS_REPLACE |
                                           SIRIUS_PARSER_FLAGS_QUEUE_DEFAULT |
                                           SIRIUS_PARSER_FLAGS_USE_COS_MAP |
                                           SIRIUS_PARSER_FLAGS_USE_TAG_OFFSET |
                                           SIRIUS_PARSER_FLAGS_OVERWRITE_DEST |
                                           SIRIUS_PARSER_FLAGS_LENGTH_ADJUST |
                                           SIRIUS_PARSER_FLAGS_CLEAR_TEST_BIT |
                                           SIRIUS_PARSER_FLAGS_SDK))) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unsupported flags %08X of %08X for unit %d"
                                   " ingress specified\n"),
                       parserInfo->ingress.flags,
                       (SIRIUS_PARSER_FLAGS_INGRESS |
                       SIRIUS_PARSER_FLAGS_WITH_ID |
                       SIRIUS_PARSER_FLAGS_REPLACE |
                       SIRIUS_PARSER_FLAGS_QUEUE_DEFAULT |
                       SIRIUS_PARSER_FLAGS_USE_COS_MAP |
                       SIRIUS_PARSER_FLAGS_USE_TAG_OFFSET |
                       SIRIUS_PARSER_FLAGS_OVERWRITE_DEST |
                       SIRIUS_PARSER_FLAGS_LENGTH_ADJUST |
                       SIRIUS_PARSER_FLAGS_CLEAR_TEST_BIT |
                       SIRIUS_PARSER_FLAGS_SDK),
                       unit));
            return SOC_E_PARAM;
        }
        result = soc_mem_write(unit,
                               FRAME_PARSINGm,
                               MEM_BLOCK_ALL,
                               parserId,
                               &ingressParser);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d parser %d: %d (%s)\n"),
                       unit,
                       pid,
                       result,
                       _SHR_ERRMSG(result)));
        }
        return result;
    } else if ((SIRIUS_PARSER_OFFSET_EGRESS <= parserId) &&
               ((SIRIUS_PARSER_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates egress */
        if (0 == (parserInfo->ingress.flags & SIRIUS_PARSER_FLAGS_EGRESS)) {
            /* must be ingress parser */
            return SOC_E_PARAM;
        }
        parserId -= SIRIUS_PARSER_OFFSET_EGRESS;
        /* first set up stats entry */
        sal_memset(&statsCfg, 0x00, sizeof(statsCfg));
        if (32 > parserInfo->egress.stat0_segment) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_SEGMENTf,
                                parserInfo->egress.stat0_segment);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_segment must be 0..31\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.stat0_source0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_META0_SELf,
                                parserInfo->egress.stat0_source0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_source0 must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.stat0_offset0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_OFFSET0f,
                                parserInfo->egress.stat0_offset0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_offset0 must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (18 > parserInfo->egress.stat0_length0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_LENGTH0f,
                                parserInfo->egress.stat0_length0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_legnth0 must be 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.stat0_source1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_META1_SELf,
                                parserInfo->egress.stat0_source1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_source1 must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.stat0_offset1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_OFFSET1f,
                                parserInfo->egress.stat0_offset1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_offset1 must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (18 > parserInfo->egress.stat0_length1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_META1_SELf,
                                parserInfo->egress.stat0_length1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_length1 must be 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (17 < (parserInfo->egress.stat0_length0 +
                  parserInfo->egress.stat0_length1)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0 combined length must be"
                                   " 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (parserInfo->egress.flags &
            SIRIUS_PARSER_FLAGS_STAT0_ADJ_PER_PACKET) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_PER_FRAME_ADJf,
                                TRUE);
        }
        if ((-127 > parserInfo->egress.stat0_adjust) ||
            (127 < parserInfo->egress.stat0_adjust)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat0_adjust must"
                                   " be -127..127\n"),
                       unit));
            return SOC_E_PARAM;
        } else if (0 > parserInfo->egress.stat0_adjust) {
            /* negative but hardware is sign+absolute */
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_ADJUSTf,
                                0x80 | (-(parserInfo->egress.stat0_adjust)));
        } else {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_ADJUSTf,
                                parserInfo->egress.stat0_adjust);
        }
        if (32 > parserInfo->egress.stat1_segment) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_SEGMENTf,
                                parserInfo->egress.stat1_segment);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_segment must be 0..31\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.stat1_source0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_META0_SELf,
                                parserInfo->egress.stat1_source0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_source0 must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.stat1_offset0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_OFFSET0f,
                                parserInfo->egress.stat1_offset0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_offset0 must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (18 > parserInfo->egress.stat1_length0) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_LENGTH0f,
                                parserInfo->egress.stat1_length0);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_legnth0 must be 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.stat1_source1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_META1_SELf,
                                parserInfo->egress.stat1_source1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_source1 must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.stat1_offset1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_OFFSET1f,
                                parserInfo->egress.stat1_offset1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_offset1 must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (18 > parserInfo->egress.stat1_length1) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_META1_SELf,
                                parserInfo->egress.stat1_length1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_length1 must be 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (17 < (parserInfo->egress.stat1_length0 +
                  parserInfo->egress.stat1_length1)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1 combined length must be"
                                   " 0..17\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (parserInfo->egress.flags &
            SIRIUS_PARSER_FLAGS_STAT1_ADJ_PER_PACKET) {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_PER_FRAME_ADJf,
                                TRUE);
        }
        if ((-127 > parserInfo->egress.stat1_adjust) ||
            (127 < parserInfo->egress.stat1_adjust)) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d egress stat1_adjust must"
                                   " be -127..127\n"),
                       unit));
            return SOC_E_PARAM;
        } else if (0 > parserInfo->egress.stat1_adjust) {
            /* negative but hardware is sign+absolute */
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_ADJUSTf,
                                0x80 | (-(parserInfo->egress.stat1_adjust)));
        } else {
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_ADJUSTf,
                                parserInfo->egress.stat1_adjust);
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_STAT_COMBINE) {
            if (17 < (parserInfo->egress.stat0_length0 +
                      parserInfo->egress.stat0_length1 +
                      parserInfo->egress.stat1_length0 +
                      parserInfo->egress.stat1_length1)) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d total stat length must be 0..17"
                                       " when combining stat0 and stat1\n"),
                           unit));
                return SOC_E_PARAM;
            }
            if (parserInfo->egress.stat0_segment !=
                parserInfo->egress.stat1_segment) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d stat0_segment and stat1_segment"
                                       " must be identical when combining stat0"
                                       " and stat1\n"),
                           unit));
                return SOC_E_PARAM;
            }
            soc_mem_field32_set(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                COMBINEf,
                                TRUE);
        }
        /* then set up the frame parser */
        sal_memset(&egressParser, 0x00, sizeof(egressParser));
        if (32 > parserInfo->egress.oi_write_byte) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                OI_WR_OFFSETf,
                                parserInfo->egress.oi_write_byte);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d oi_write_byte must be 0..31\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (25 > parserInfo->egress.oi_write_length) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                OI_WR_LENGTHf,
                                parserInfo->egress.oi_write_length);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d oi_write_length must be 0..24\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (64 > parserInfo->egress.lengthAdj_nybble) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                LEN_ADJ_OFFSETf,
                                parserInfo->egress.lengthAdj_nybble);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d legnthAdj_nybble must be 0..63\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (5 > parserInfo->egress.lengthAdj_length) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                LEN_ADJ_LENGTHf,
                                parserInfo->egress.lengthAdj_length);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d lengthAdj_length must be 0..4\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (3 > parserInfo->egress.requeueSel) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                REQ_OI_SELf,
                                parserInfo->egress.requeueSel);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d does not support requeue_sel %d\n"),
                       unit,
                       parserInfo->egress.requeueSel));
            return SOC_E_PARAM;
        }
        if (32 > parserInfo->egress.oi_read_byte) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                OI_RD_OFFSETf,
                                parserInfo->egress.oi_read_byte);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d oi_read_byte must be 0..31\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (25 > parserInfo->egress.oi_read_length) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                OI_RD_LENGTHf,
                                parserInfo->egress.oi_read_length);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d oi_read_length must be 0..24\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.oi_index_offset) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                OI_INDEX_OFFSETf,
                                parserInfo->egress.oi_index_offset);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d oi_index_offset must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (256 > parserInfo->egress.fcos_bit) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                FCOS_OFFSETf,
                                parserInfo->egress.fcos_bit);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d fcos_bit must be 0..255\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.fcos_length) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                FCOS_LENGTHf,
                                parserInfo->egress.fcos_length);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d fcos_length must be 0..7\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0 > parserInfo->egress.eh_bit) {
            /* don't clear EH bit */
        } else if (128 > parserInfo->egress.eh_bit) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                EH_OFFSETf,
                                parserInfo->egress.eh_bit);
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                EH_LENGTHf,
                                TRUE);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d eh_bit must be negative to disable"
                                   " clearing, or positive bit offset of bit to"
                                   " clear\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (32 > parserInfo->egress.queue_write_byte) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                Q_WR_OFFSETf,
                                parserInfo->egress.queue_write_byte);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d queue_write_byte must be 0..31\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (25 > parserInfo->egress.queue_write_length) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                Q_WR_LENGTHf,
                                parserInfo->egress.queue_write_length);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d queue_write_length must be 0..24\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (17 > parserInfo->egress.hdrRemove_bytes) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                HDR_REMOVE_LENGTHf,
                                parserInfo->egress.hdrRemove_bytes);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d hdrRemove_bytes must be 0..16\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0 > parserInfo->egress.fourByteRemove_quadbyte) {
            /* don't remove bytes */
        } else if (8 > parserInfo->egress.fourByteRemove_quadbyte) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                FOUR_BYTE_REMOVE_OFFSETf,
                                parserInfo->egress.fourByteRemove_quadbyte);
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                FOUR_BYTE_REMOVE_ENABLEf,
                                TRUE);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d fourByteRemove_quadbyte must be"
                                   " negative to disable, or 0..7 to indicate"
                                   " which quadbyte to remove\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (0 > parserInfo->egress.mp_bit) {
            /* don't clear bit */
        } else if (512 > parserInfo->egress.mp_bit) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                MP_OFFSETf,
                                parserInfo->egress.mp_bit);
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                XGS_MP_CLEARf,
                                TRUE);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d mp_bit must be negative to disable,"
                                   "or 0..511 to indicate which bit to clear\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if (8 > parserInfo->egress.insertSel) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                INSERT_2B_SELf,
                                (parserInfo->egress.insertSel >> 1) & 3);
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                INSERT_2B_EXTENDf,
                                parserInfo->egress.insertSel & 1);
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d does not support insert_sel %d\n"),
                       unit,
                       parserInfo->egress.insertSel));
            return SOC_E_PARAM;
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                MC_TBL_LKUPf,
                                TRUE);
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                MC_CLEARf,
                                TRUE);
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                LEN_ADJ_ON_SHAPINGf,
                                TRUE);
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                REQ_TBL_LKUPf,
                                TRUE);
        }
        if (parserInfo->egress.flags & SIRIUS_PARSER_FLAGS_XGS_MODE) {
            soc_mem_field32_set(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                XGS_MODEf,
                                TRUE);
        }
        if (parserInfo->egress.flags & (~(SIRIUS_PARSER_FLAGS_EGRESS |
                                          SIRIUS_PARSER_FLAGS_WITH_ID |
                                          SIRIUS_PARSER_FLAGS_REPLACE |
                                          SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID |
                                          SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                                          SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                                          SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                                          SIRIUS_PARSER_FLAGS_XGS_MODE |
                                          SIRIUS_PARSER_FLAGS_STAT0_ADJ_PER_PACKET |
                                          SIRIUS_PARSER_FLAGS_STAT1_ADJ_PER_PACKET |
                                          SIRIUS_PARSER_FLAGS_STAT_COMBINE |
                                          SIRIUS_PARSER_FLAGS_SDK))) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unsupported flags %08X of %08X for unit %d"
                                   " egress specified\n"),
                       parserInfo->ingress.flags,
                       (SIRIUS_PARSER_FLAGS_EGRESS |
                       SIRIUS_PARSER_FLAGS_WITH_ID |
                       SIRIUS_PARSER_FLAGS_REPLACE |
                       SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID |
                       SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT |
                       SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING |
                       SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID |
                       SIRIUS_PARSER_FLAGS_XGS_MODE |
                       SIRIUS_PARSER_FLAGS_STAT0_ADJ_PER_PACKET |
                       SIRIUS_PARSER_FLAGS_STAT1_ADJ_PER_PACKET |
                       SIRIUS_PARSER_FLAGS_STAT_COMBINE |
                       SIRIUS_PARSER_FLAGS_SDK),
                       unit));
            return SOC_E_PARAM;
        }
        result = soc_mem_write(unit,
                               EP_HDR_PARSING_CTRLm,
                               MEM_BLOCK_ALL,
                               parserId,
                               &egressParser);
        if (SOC_E_NONE == result) {
            result = soc_mem_write(unit,
                                   STATSCFGm,
                                   MEM_BLOCK_ALL,
                                   parserId,
                                   &statsCfg);
            if (SOC_E_NONE != result) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unable to write unit %d statscfg %d:"
                                       " %d (%s)\n"),
                           unit,
                           parserId,
                           result,
                           _SHR_ERRMSG(result)));
            }
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d ep_hdr_parsing_ctrl %d:"
                                   " %d (%s)\n"),
                       unit,
                       parserId,
                       result,
                       _SHR_ERRMSG(result)));
        }
        return result;
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d is not valid\n"),
                   unit,
                   pid));
        return SOC_E_NOT_FOUND;
    }
}

int
soc_sirius_parser_set_sdk(int unit,
                          unsigned int parserId,
                          const soc_sirius_parser_info_t *parserInfo)
{
    if (SOC_E_FULL != soc_sirius_parser_check_sdk(unit, parserId)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d not in use by SDK\n"),
                   unit,
                   parserId));
        return SOC_E_NOT_FOUND;
    }
    return soc_sirius_parser_set(unit, parserId, parserInfo);
}

int
soc_sirius_parser_get(int unit,
                      unsigned int parserId,
                      soc_sirius_parser_info_t *parserInfo)
{
    frame_parsing_entry_t ingressParser;
    ep_hdr_parsing_ctrl_entry_t egressParser;
    ep_stats_ctrl_entry_t statsCfg;
    signed int temp;
    int result;
    unsigned int pid = parserId;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!parserInfo) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "parserInfo pointer must not be NULL\n")));
        return SOC_E_PARAM;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PARSER_OFFSET_INGRESS <= parserId) &&
        ((SIRIUS_PARSER_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates ingress */
        parserId -= SIRIUS_PARSER_OFFSET_INGRESS;
        sal_memset(&ingressParser, 0x00, sizeof(ingressParser));
        result = soc_mem_read(unit,
                              FRAME_PARSINGm,
                              MEM_BLOCK_ALL,
                              parserId,
                              &ingressParser);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to read unit %d parser %d: %d (%s)\n"),
                       unit,
                       pid,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        }
        sal_memset(parserInfo, 0x00, sizeof(*parserInfo));
        parserInfo->ingress.flags = SIRIUS_PARSER_FLAGS_INGRESS;
        parserInfo->ingress.segmentSel = (soc_mem_field32_get(unit,
                                                              FRAME_PARSINGm,
                                                              &ingressParser,
                                                              SEGMENT_SELf) +
                                          SIRIUS_QUEUE_MAP_BLOCK_OFFSET_INGRESS);
        parserInfo->ingress.cosProfile = (soc_mem_field32_get(unit,
                                                              FRAME_PARSINGm,
                                                              &ingressParser,
                                                              DEFAULT_COS_PROFILEf) +
                                          SIRIUS_COS_MAP_BLOCK_OFFSET_INGRESS);
        parserInfo->ingress.queue_byte0 = soc_mem_field32_get(unit,
                                                              FRAME_PARSINGm,
                                                              &ingressParser,
                                                              Q_BYTE_OFFSET0f);
        parserInfo->ingress.queue_bit0 = soc_mem_field32_get(unit,
                                                             FRAME_PARSINGm,
                                                             &ingressParser,
                                                             Q_BIT_OFFSET0f);
        parserInfo->ingress.queue_length0 = soc_mem_field32_get(unit,
                                                                FRAME_PARSINGm,
                                                                &ingressParser,
                                                                Q_LENGTH0f);
        parserInfo->ingress.queue_byte1 = soc_mem_field32_get(unit,
                                                              FRAME_PARSINGm,
                                                              &ingressParser,
                                                              Q_BYTE_OFFSET1f);
        parserInfo->ingress.queue_bit1 = soc_mem_field32_get(unit,
                                                             FRAME_PARSINGm,
                                                             &ingressParser,
                                                             Q_BIT_OFFSET1f);
        parserInfo->ingress.queue_length1 = soc_mem_field32_get(unit,
                                                                FRAME_PARSINGm,
                                                                &ingressParser,
                                                                Q_LENGTH1f);
        parserInfo->ingress.cos_byte = soc_mem_field32_get(unit,
                                                           FRAME_PARSINGm,
                                                           &ingressParser,
                                                           COS_BYTE_OFFSETf);
        parserInfo->ingress.cos_bit = soc_mem_field32_get(unit,
                                                          FRAME_PARSINGm,
                                                          &ingressParser,
                                                          COS_BIT_OFFSETf);
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_DPf)) {
            parserInfo->ingress.dp = soc_mem_field32_get(unit,
                                                         FRAME_PARSINGm,
                                                         &ingressParser,
                                                         DEFAULT_DPf);
        } else {
            parserInfo->ingress.dp = -1;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_ECNf)) {
            parserInfo->ingress.ecn = soc_mem_field32_get(unit,
                                                          FRAME_PARSINGm,
                                                          &ingressParser,
                                                          DEFAULT_ECNf);
        } else {
            parserInfo->ingress.ecn = -1;
        }
        parserInfo->ingress.stat_byte0 = soc_mem_field32_get(unit,
                                                             FRAME_PARSINGm,
                                                             &ingressParser,
                                                             SL_BYTE_OFFSET0f);
        parserInfo->ingress.stat_bit0 = soc_mem_field32_get(unit,
                                                            FRAME_PARSINGm,
                                                            &ingressParser,
                                                            SL_BIT_OFFSET0f);
        parserInfo->ingress.stat_length0 = soc_mem_field32_get(unit,
                                                               FRAME_PARSINGm,
                                                               &ingressParser,
                                                               SL_LENGTH0f);
        parserInfo->ingress.stat_byte1 = soc_mem_field32_get(unit,
                                                             FRAME_PARSINGm,
                                                             &ingressParser,
                                                             SL_BYTE_OFFSET1f);
        parserInfo->ingress.stat_bit1 = soc_mem_field32_get(unit,
                                                            FRAME_PARSINGm,
                                                            &ingressParser,
                                                            SL_BIT_OFFSET1f);
        parserInfo->ingress.stat_length1 = soc_mem_field32_get(unit,
                                                               FRAME_PARSINGm,
                                                               &ingressParser,
                                                               SL_LENGTH1f);
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_DEFAULT_INDEXf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_QUEUE_DEFAULT;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                COS_ENABLEf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_USE_COS_MAP;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                OFFSET_ENABLEf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_USE_TAG_OFFSET;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                OVERWRITE_DESTf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_OVERWRITE_DEST;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                USE_LEN_ADJ_IDXf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_LENGTH_ADJUST;
        }
        if (soc_mem_field32_get(unit,
                                FRAME_PARSINGm,
                                &ingressParser,
                                TEST_DISABLEf)) {
            parserInfo->ingress.flags |= SIRIUS_PARSER_FLAGS_CLEAR_TEST_BIT;
        }
    } else if ((SIRIUS_PARSER_OFFSET_EGRESS <= parserId) &&
               ((SIRIUS_PARSER_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > parserId)) {
        /* parser ID indicates egress */
        parserId -= SIRIUS_PARSER_OFFSET_EGRESS;
        sal_memset(&statsCfg, 0x00, sizeof(statsCfg));
        sal_memset(&egressParser, 0x00, sizeof(egressParser));
        result = soc_mem_read(unit,
                               EP_HDR_PARSING_CTRLm,
                               MEM_BLOCK_ALL,
                               parserId,
                               &egressParser);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to write unit %d ep_hdr_parsing_ctrl %d:"
                                   " %d (%s)\n"),
                       unit,
                       parserId,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        }
        result = soc_mem_read(unit,
                              EP_STATS_CTRLm,
                              MEM_BLOCK_ALL,
                              parserId,
                              &statsCfg);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to read unit %d statscfg %d:"
                                   " %d (%s)\n"),
                       unit,
                       parserId,
                       result,
                       _SHR_ERRMSG(result)));
            return result;
        }
        sal_memset(parserInfo, 0x00, sizeof(*parserInfo));
        parserInfo->egress.flags = SIRIUS_PARSER_FLAGS_EGRESS;
        parserInfo->egress.stat0_segment = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_SEGMENTf);
        parserInfo->egress.stat0_source0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_META0_SELf);
        parserInfo->egress.stat0_offset0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_OFFSET0f);
        parserInfo->egress.stat0_length0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_LENGTH0f);
        parserInfo->egress.stat0_source1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_META1_SELf);
        parserInfo->egress.stat0_offset1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_OFFSET1f);
        parserInfo->egress.stat0_length1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT0_META1_SELf);
        if (soc_mem_field32_get(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT0_PER_FRAME_ADJf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_STAT0_ADJ_PER_PACKET;
        }
        temp = soc_mem_field32_get(unit,
                                   EP_STATS_CTRLm,
                                   &statsCfg,
                                   STAT0_ADJUSTf);
        if (temp & 0x80) {
            parserInfo->egress.stat0_adjust = -(temp & 0x7F);
        } else {
            parserInfo->egress.stat0_adjust = temp & 0x7F;
        }
        parserInfo->egress.stat1_segment = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_SEGMENTf);
        parserInfo->egress.stat1_source0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_META0_SELf);
        parserInfo->egress.stat1_offset0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_OFFSET0f);
        parserInfo->egress.stat1_length0 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_LENGTH0f);
        parserInfo->egress.stat1_source1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_META1_SELf);
        parserInfo->egress.stat1_offset1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_OFFSET1f);
        parserInfo->egress.stat1_length1 = soc_mem_field32_get(unit,
                                                               EP_STATS_CTRLm,
                                                               &statsCfg,
                                                               STAT1_META1_SELf);
        if (soc_mem_field32_get(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                STAT1_PER_FRAME_ADJf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_STAT1_ADJ_PER_PACKET;
        }
        temp = soc_mem_field32_get(unit,
                                   EP_STATS_CTRLm,
                                   &statsCfg,
                                   STAT1_ADJUSTf);
        if (temp & 0x80) {
            parserInfo->egress.stat1_adjust = -(temp & 0x7F);
        } else {
            parserInfo->egress.stat1_adjust = temp & 0x7F;
        }
        if (soc_mem_field32_get(unit,
                                EP_STATS_CTRLm,
                                &statsCfg,
                                COMBINEf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_STAT_COMBINE;
        }
        parserInfo->egress.oi_write_byte = soc_mem_field32_get(unit,
                                                               EP_HDR_PARSING_CTRLm,
                                                               &egressParser,
                                                               OI_WR_OFFSETf);
        parserInfo->egress.oi_write_length = soc_mem_field32_get(unit,
                                                                 EP_HDR_PARSING_CTRLm,
                                                                 &egressParser,
                                                                 OI_WR_LENGTHf);
        parserInfo->egress.lengthAdj_nybble = soc_mem_field32_get(unit,
                                                                  EP_HDR_PARSING_CTRLm,
                                                                  &egressParser,
                                                                  LEN_ADJ_OFFSETf);
        parserInfo->egress.lengthAdj_length = soc_mem_field32_get(unit,
                                                                  EP_HDR_PARSING_CTRLm,
                                                                  &egressParser,
                                                                  LEN_ADJ_LENGTHf);
        parserInfo->egress.requeueSel = soc_mem_field32_get(unit,
                                                             EP_HDR_PARSING_CTRLm,
                                                             &egressParser,
                                                             REQ_OI_SELf);
        parserInfo->egress.oi_read_byte = soc_mem_field32_get(unit,
                                                              EP_HDR_PARSING_CTRLm,
                                                              &egressParser,
                                                              OI_RD_OFFSETf);
        parserInfo->egress.oi_read_length = soc_mem_field32_get(unit,
                                                                EP_HDR_PARSING_CTRLm,
                                                                &egressParser,
                                                                OI_RD_LENGTHf);
        parserInfo->egress.oi_index_offset = soc_mem_field32_get(unit,
                                                                 EP_HDR_PARSING_CTRLm,
                                                                 &egressParser,
                                                                 OI_INDEX_OFFSETf);
        parserInfo->egress.fcos_bit = soc_mem_field32_get(unit,
                                                          EP_HDR_PARSING_CTRLm,
                                                          &egressParser,
                                                          FCOS_OFFSETf);
        parserInfo->egress.fcos_length = soc_mem_field32_get(unit,
                                                             EP_HDR_PARSING_CTRLm,
                                                             &egressParser,
                                                             FCOS_LENGTHf);
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                EH_LENGTHf)) {
            parserInfo->egress.eh_bit = soc_mem_field32_get(unit,
                                                            EP_HDR_PARSING_CTRLm,
                                                            &egressParser,
                                                            EH_OFFSETf);
        } else {
            parserInfo->egress.eh_bit = -1;
        }
        parserInfo->egress.queue_write_byte = soc_mem_field32_get(unit,
                                                                  EP_HDR_PARSING_CTRLm,
                                                                  &egressParser,
                                                                  Q_WR_OFFSETf);
        parserInfo->egress.queue_write_length = soc_mem_field32_get(unit,
                                                                    EP_HDR_PARSING_CTRLm,
                                                                    &egressParser,
                                                                    Q_WR_LENGTHf);
        parserInfo->egress.hdrRemove_bytes = soc_mem_field32_get(unit,
                                                                 EP_HDR_PARSING_CTRLm,
                                                                 &egressParser,
                                                                 HDR_REMOVE_LENGTHf);
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                FOUR_BYTE_REMOVE_ENABLEf)) {
            parserInfo->egress.fourByteRemove_quadbyte = soc_mem_field32_get(unit,
                                                                             EP_HDR_PARSING_CTRLm,
                                                                             &egressParser,
                                                                             FOUR_BYTE_REMOVE_OFFSETf);
        } else {
            parserInfo->egress.fourByteRemove_quadbyte = -1;
        }
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                XGS_MP_CLEARf)) {
            parserInfo->egress.mp_bit = soc_mem_field32_get(unit,
                                                            EP_HDR_PARSING_CTRLm,
                                                            &egressParser,
                                                            MP_OFFSETf);
        } else {
            parserInfo->egress.mp_bit = -1;
        }
        parserInfo->egress.insertSel = ((soc_mem_field32_get(unit,
                                                             EP_HDR_PARSING_CTRLm,
                                                             &egressParser,
                                                             INSERT_2B_SELf) << 1) |
                                        soc_mem_field32_get(unit,
                                                            EP_HDR_PARSING_CTRLm,
                                                            &egressParser,
                                                            INSERT_2B_EXTENDf));
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                MC_TBL_LKUPf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_LOOKUP_ENCAPID;
        }
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                MC_CLEARf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_CLEAR_MC_BIT;
        }
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                LEN_ADJ_ON_SHAPINGf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_LEN_ADJ_ON_SHAPING;
        }
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                REQ_TBL_LKUPf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_LOOKUP_QUEUEID;
        }
        if (soc_mem_field32_get(unit,
                                EP_HDR_PARSING_CTRLm,
                                &egressParser,
                                XGS_MODEf)) {
            parserInfo->egress.flags |= SIRIUS_PARSER_FLAGS_XGS_MODE;
        }
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d parser ID %d is not valid\n"),
                   unit,
                   pid));
        return SOC_E_NOT_FOUND;
    }
    return SOC_E_NONE;
}


extern int
soc_sirius_parser_next(int unit,
                       unsigned int current,
                       unsigned int *next)
{
    int result = SOC_E_NOT_FOUND;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    do {
        /* figure out next predicate to examine */
        if (current >= ((SIRIUS_PARSER_OFFSET_EGRESS +
                         SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) * 2)) {
            /* very large number; go to first ingress predicate */
            current = SIRIUS_PARSER_OFFSET_INGRESS;
#if (0 != SIRIUS_PARSER_OFFSET_INGRESS)
        } else if (current < SIRIUS_PARSER_OFFSET_INGRESS) {
            /* below ingress; go to first ingress predicate */
            current = SIRIUS_PARSER_OFFSET_INGRESS;
#endif /* (0 != SIRIUS_PARSER_OFFSET_INGRESS) */
        } else if (
#if (0 != SIRIUS_PARSER_OFFSET_INGRESS)
                   (current >= SIRIUS_PARSER_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_PARSER_OFFSET_INGRESS) */
                   (current < ((SIRIUS_PARSER_OFFSET_INGRESS - 1) +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS))) {
            /* within ingress; look at next ingress */
            current++;
        } else if (current < SIRIUS_PARSER_OFFSET_EGRESS) {
            /* last ingress/between ingress and egress; go to first egress */
            current = SIRIUS_PARSER_OFFSET_EGRESS;
        } else if ((current >= SIRIUS_PARSER_OFFSET_EGRESS) &&
                   (current < ((SIRIUS_PARSER_OFFSET_EGRESS - 1) +
                               SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS))) {
            /* within egress; look at next egress */
            current++;
        } else {
            /* at/after end of egress but not large enough to wrap */
            break;
        }
        if (
#if (0 != SIRIUS_PARSER_OFFSET_INGRESS)
            (current >= SIRIUS_PARSER_OFFSET_INGRESS) &&
#endif /* (0 != SIRIUS_PARSER_OFFSET_INGRESS) */
            (current < (SIRIUS_PARSER_OFFSET_INGRESS +
                        SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS))) {
            /* check ingress  */
            if (SOC_SBX_SIRIUS_STATE(unit)->ingressParsers & (1 <<
                                                              (current -
                                                               SIRIUS_PARSER_OFFSET_INGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        } else  if ((current >= SIRIUS_PARSER_OFFSET_EGRESS) &&
                    (current < (SIRIUS_PARSER_OFFSET_EGRESS +
                                SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS))) {
            if (SOC_SBX_SIRIUS_STATE(unit)->egressParsers & (1 <<
                                                             (current -
                                                              SIRIUS_PARSER_OFFSET_EGRESS))) {
                /* this one is in use */
                result = SOC_E_NONE;
            }
        }
    } while ((SOC_E_NOT_FOUND == result));
    if (SOC_E_NONE == result) {
        *next = current;
    }
    return result;
}

/* clear all unused ingress parsers */
int
soc_sirius_parser_clear_unused_ingress(int unit)
{
    int idx;
    frame_parsing_entry_t fp_entry;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    sal_memset(&fp_entry, 0x00, sizeof(fp_entry));
    for (idx = 0;
         idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS;
         idx++) {
        if (0 == (SOC_SBX_SIRIUS_STATE(unit)->ingressParsers & (1 << idx))) {
            SOC_IF_ERROR_RETURN(soc_mem_write(unit,
                                              FRAME_PARSINGm,
                                              MEM_BLOCK_ALL,
                                              idx,
                                              &fp_entry));
        } /* if (this parser is not in use) */
    } /* for (all parsers) */
    return SOC_E_NONE;
}

/*
 *  Takes the 'tail' (lowest priority) entry in a predicate->parser mapping
 *  rule list, traversing toward the head (highest priority).  Builds the map
 *  into a buffer that can be used to program.  Note that this means it
 *  requires a pointer to an array of appropriate memory blocks and to know
 *  whether the ruleset is ingress or egress.
 *
 *  WARNING: this call is not reentrant, but nor are the resources in question.
 */
static int
_soc_sirius_update_parser_to_predicate_map(int unit,
                                           int ingress)
{
    static const unsigned int ingressField[16] = {TYPE0f, TYPE1f, TYPE2f, TYPE3f,
                                                  TYPE4f, TYPE5f, TYPE6f, TYPE7f,
                                                  TYPE8f, TYPE9f, TYPE10f, TYPE11f,
                                                  TYPE12f, TYPE13f, TYPE14f, TYPE15f};
    static const unsigned int egressField[16] = {VALUE0f, VALUE1f, VALUE2f, VALUE3f,
                                                 VALUE4f, VALUE5f, VALUE6f, VALUE7f,
                                                 VALUE8f, VALUE9f, VALUE10f, VALUE11f,
                                                 VALUE12f, VALUE13f, VALUE14f, VALUE15f};
    union {
        type_resolution_table_entry_t ingressBuffer[1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)];
        ep_class_resolution_entry_t egressBuffer[1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)];
    } u;
    
    static const uint8 _SIRIUS_DEFAULT_PARSER_ID = 15;
    const unsigned int *fields;
    uint8 *buffer;
    unsigned int mem;
    unsigned int index;
    unsigned int size;
    soc_sbx_sirius_predicate_parser_rule_t *rule;
    int result = SOC_E_NONE;

    if (ingress) {
        fields = &(ingressField[0]);
        mem = TYPE_RESOLUTION_TABLEm;
        size = sizeof(type_resolution_table_entry_t);
        buffer = (uint8*)(&(u.ingressBuffer[0]));
        rule = SOC_SBX_SIRIUS_STATE(unit)->ingressRuleTail;
    } else {
        fields = &(egressField[0]);
        mem = EP_CLASS_RESOLUTIONm;
        size = sizeof(ep_class_resolution_entry_t);
        buffer = (uint8*)(&(u.egressBuffer[0]));
        rule = SOC_SBX_SIRIUS_STATE(unit)->egressRuleTail;
    }
    for (index = 0;
         index < (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES);
         index++) {
        soc_mem_field32_set(unit,
                            mem,
                            &(buffer[size * (index >> 4)]),
                            fields[index & 0xF],
                            _SIRIUS_DEFAULT_PARSER_ID);
    } /* for (all possible predicate vector values) */
    while (rule) {
        SIR_EVERB((SIR_MSG1("unit %d rule %3d: %03X data, %03X mask -> parser %d\n"),
                   unit,
                   rule->ruleId,
                   rule->predState,
                   rule->predMask,
                   rule->parser));
        for (index = 0;
             index < (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES);
             index++) {
            if ((index & rule->predMask) == rule->predState) {
                soc_mem_field32_set(unit,
                                    mem,
                                    &(buffer[size * (index >> 4)]),
                                    fields[index & 0xF],
                                    rule->parser);
            } /* if (predicate vector meets rule requirements) */
        } /* for (all possible predicate vector values) */
        /* look at next higher priority rule */
        rule = rule->prev;
    } /* while (rules remain to evaluate) */
    
    for (index = 0;
          index < (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES);
          index++) {
        int k = soc_mem_field32_get(unit,
                                    mem,
                                    &(buffer[size * (index >> 4)]),
                                    fields[index & 0xF]);
        if (0xF != k) {
            SIR_EVERB(("%2d ", k));
        } else {
            SIR_EVERB(("-- "));
        }
        if (0x1F == (index & 0x01F)) {
            SIR_EVERB(("\n"));
        }
    }
    for (index = 0;
         (SOC_E_NONE == result) &&
         (index < (1 << (SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES - 4)));
         index++) {
        result = soc_mem_write(unit,
                               mem,
                               MEM_BLOCK_ALL,
                               index,
                               &(buffer[size * index]));
    } /* for (all rows in the memory) */
    if (SOC_E_NONE != result) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unable to write unit %d %s predicate->parser"
                               " map: %d (%s)\n"),
                   unit,
                   ingress?"ingress":"egress",
                   result,
                   _SHR_ERRMSG(result)));
    }
    if (BCM_E_NONE == result) {
        result = _soc_sirius_update_type_res_flags(unit, ingress);
    }
    return result;
}

/*
 *  NOTE: all fields are 'internal' representation for this function.
 */
static int
_soc_sirius_predicate_parser_rule_update(int unit,
                                         uint8 ruleId,
                                         soc_sirius_predicate_parser_rule_t *ruleInfo)
{
    soc_sbx_sirius_predicate_parser_rule_t *rule = NULL;
    soc_sbx_sirius_predicate_parser_rule_t *temp;
    soc_sbx_sirius_predicate_parser_rule_t **head;
    soc_sbx_sirius_predicate_parser_rule_t **tail;
    SHR_BITDCL *ruleIds;
    uint16 *predIds;
    uint16 *parserIds;
    int *predRefs;
    int *parserRefs;
    unsigned int idx;

    if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
        head = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleHead);
        tail = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleTail);
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
        predIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPreds);
        parserIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParsers);
        predRefs = &(SOC_SBX_SIRIUS_STATE(unit)->ingressPredRefs[0]);
        parserRefs = &(SOC_SBX_SIRIUS_STATE(unit)->ingressParserRefs[0]);
    } else if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS) {
        head = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleHead);
        tail = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleTail);
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
        predIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressPreds);
        parserIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressParsers);
        predRefs = &(SOC_SBX_SIRIUS_STATE(unit)->egressPredRefs[0]);
        parserRefs = &(SOC_SBX_SIRIUS_STATE(unit)->egressParserRefs[0]);
    } else {
        return SOC_E_PARAM;
    }
    /* make sure referenced resources exist */
    if (0 == (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_DELETE)) {
        for (idx = 0;
             idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES;
             idx++) {
            if (ruleInfo->predMask & (1 << idx)) {
                if (0 == ((*predIds) & (1 << idx))) {
                    LOG_ERROR(BSL_LS_SOC_COMMON,
                              (BSL_META_U(unit,
                                          "unit %d predicate %d is not in use\n"),
                               unit,
                               (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                               idx + SIRIUS_PREDICATE_OFFSET_INGRESS:
                               idx + SIRIUS_PREDICATE_OFFSET_INGRESS));
                    return SOC_E_CONFIG;
                }
            }
        }
        if ((ruleInfo->predMask & (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES)) ||
            (ruleInfo->predState & (1 << SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES))) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "an invalid predicate was used when configuring"
                                   " the provided rule\n")));
            return SOC_E_CONFIG;
        }
        if (0 == ((*parserIds) & (1 << ruleInfo->parser))) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d parser %d is not in use\n"),
                       unit,
                       (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       ruleInfo->parser + SIRIUS_PARSER_OFFSET_INGRESS:
                       ruleInfo->parser + SIRIUS_PARSER_OFFSET_EGRESS));
            return SOC_E_CONFIG;
        }
    }
    /* find the existing rule with this ID */
    rule = *head;
    while (NULL != rule) {
        if (ruleId == rule->ruleId) {
            /* this is the rule */
            break;
        }
        rule = rule->next;
    }
    if (ruleInfo->flags & (SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE |
                           SIRIUS_PREDICATE_PARSER_RULE_FLAG_DELETE)) {
        /* replacing or deleting; make sure we found it */
        if (!rule) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unable to find unit %d rule %d for replace\n"),
                       unit,
                       (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS:
                       ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS));
            return SOC_E_NOT_FOUND;
        }
        /* now delink it */
        if (rule->prev) {
            rule->prev->next = rule->next;
        } else {
            *head = rule->next;
        }
        if (rule->next) {
            rule->next->prev = rule->prev;
        } else {
            *tail = rule->prev;
        }
    } else { /* if (replace or delete) */
        /* not replacing or deleting; make sure we found nothing */
        if (rule) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d rule %d already exists\n"),
                       unit,
                       (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS:
                       ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS));
            return SOC_E_EXISTS;
        }
    } /* if (replace or delete) */
    /* remove references from the old rule */
    if (rule) {
        for (idx = 0;
             idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES;
             idx++) {
            if (rule->predMask & (1 << idx)) {
                predRefs[idx]--;
            }
        }
        parserRefs[rule->parser]--;
    }
    /* what to do with the new rule */
    if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_DELETE) {
        /* delete the old rule without replacement */
        SHR_BITCLR(ruleIds, ruleId);
        sal_free(rule);
    } else { /* if (deleting) */
        /* we do not want to delete the rule, so insert the new version */
        if (!(ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE)) {
            /* we need to add a new rule to the list */
            rule = sal_alloc(sizeof(*rule), "sirius parser/predicate map rule");
        }
        sal_memset(rule, 0x00, sizeof(*rule));
        /* make adjustments to the rule */
        rule->ruleId = ruleId;
        rule->priority = ruleInfo->priority;
        rule->predMask = ruleInfo->predMask;
        rule->predState = ruleInfo->predState;
        rule->parser = ruleInfo->parser;
        temp = *head;
        while ((NULL != temp) &&
               (temp->priority >= ruleInfo->priority)) {
            temp = temp->next;
        }
        if (NULL == temp) {
            /* fell off the end; add to tail */
            rule->prev = *tail;
            if (*tail) {
                (*tail)->next = rule;
            }
            *tail = rule;
            if (!(*head)) {
                /* nothing to fall off; head points here also */
                *head = rule;
            }
        } else { /* if (NULL == temp) */
            /* insert before 'temp' */
            rule->next = temp;
            rule->prev = temp->prev;
            if (temp->prev) {
                temp->prev->next = rule;
            } else {
                *head = rule;
            }
            temp->prev = rule;
        } /* if (NULL == temp) */
        /* account for new references */
        for (idx = 0;
             idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PREDICATES;
             idx++) {
            if (rule->predMask & (1 << idx)) {
                predRefs[idx]++;
            }
        }
        parserRefs[rule->parser]++;
        SHR_BITSET(ruleIds, ruleId);
    } /* if (deleting) */
    return SOC_E_NONE;
}

int
soc_sirius_predicate_parser_map_get(int unit,
                                    unsigned int ruleId,
                                    soc_sirius_predicate_parser_rule_t *ruleInfo)
{
    soc_sbx_sirius_predicate_parser_rule_t *rule;
    SHR_BITDCL *ruleIds;
    uint8 ruleTemp;
    uint8 flags;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!ruleInfo) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "outbound ruleInfo argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS <= ruleId) &&
        ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is ingress */
        rule = SOC_SBX_SIRIUS_STATE(unit)->ingressRuleHead;
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
    } else if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS <= ruleId) &&
               ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is egress */
        rule = SOC_SBX_SIRIUS_STATE(unit)->egressRuleHead;
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule ID %d is not valid\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    if (!SHR_BITGET(ruleIds, ruleTemp)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule %d is not in use\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    while (rule && (rule->ruleId != ruleTemp)) {
        rule = rule->next;
    }
    if (!rule) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule %d was not found\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    ruleInfo->predMask = rule->predMask;
    ruleInfo->predState = rule->predState;
    ruleInfo->priority = rule->priority;
    ruleInfo->parser = (rule->parser +
                        ((flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                         SIRIUS_PARSER_OFFSET_INGRESS:
                         SIRIUS_PARSER_OFFSET_EGRESS));
    ruleInfo->flags = flags;
    return SOC_E_NONE;
}

/*
 *  This has to look up the next rule not by the order in which they are
 *  stored, but by the actual rule ID.  If it did it by stored order, it would
 *  cause problems when traversing and updating rules, since the stored order
 *  is sorted by priority (with most recently added/updated at a given priority
 *  last of that priority).
 *
 *  It also means that we have to find the lowest rule ID when finding the
 *  first of a set, rather than just taking the head rule.
 */
int
soc_sirius_predicate_parser_map_get_next(int unit,
                                         unsigned int current,
                                         unsigned int *next,
                                         soc_sirius_predicate_parser_rule_t *ruleInfo)
{
    soc_sbx_sirius_predicate_parser_rule_t *rule;
    soc_sbx_sirius_predicate_parser_rule_t *best = NULL;
    uint8 flags;
    uint8 ruleBest = ~0;
    int nextItem = TRUE;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS <= current) &&
        ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > current)) {
        /* it is ingress */
        rule = SOC_SBX_SIRIUS_STATE(unit)->ingressRuleHead;
        current -= SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
    } else if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS <= current) &&
               ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > current)) {
        /* it is egress */
        rule = SOC_SBX_SIRIUS_STATE(unit)->egressRuleHead;
        current -= SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
    } else if (((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) <= current) &&
               (SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS > current)) {
        /* between ingress and egress, get first egress */
        nextItem = FALSE;
        rule = SOC_SBX_SIRIUS_STATE(unit)->egressRuleHead;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
    } else {
        /* between egress and ingress (wrapping), get first ingress */
        nextItem = FALSE;
        rule = SOC_SBX_SIRIUS_STATE(unit)->ingressRuleHead;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS;
    }

    if (nextItem) {
        /* need the rule whose ID most closely follows the current ID */
        while (rule) {
            if ((rule->ruleId > current) &&
                (rule->ruleId <= ruleBest)) {
                /* this one is closer to current but still above */
                best = rule;
                ruleBest = best->ruleId;
            }
            rule = rule->next;
        }
    } else { /* if (nextItem) */
        /* need the lowest rule ID we can find */
        while (rule) {
            if (rule->ruleId <= ruleBest) {
                /* this one is lower than seen so far */
                best = rule;
                ruleBest = best->ruleId;
            }
            rule = rule->next;
        }
    } /* if (nextItem) */

    if ((!best) && (flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)) {
        /* went past end of ingress; get first egress instead */
        rule = SOC_SBX_SIRIUS_STATE(unit)->egressRuleHead;
        flags = SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS;
        /* need the lowest rule ID that we can find */
        while (rule) {
            if (rule->ruleId <= ruleBest) {
                /* this one is lower than seen so far */
                best = rule;
                ruleBest = best->ruleId;
            }
            rule = rule->next;
        }
    }
    if (best) {
        if (ruleInfo) {
            ruleInfo->predMask = best->predMask;
            ruleInfo->predState = best->predState;
            ruleInfo->priority = best->priority;
            ruleInfo->parser = (best->parser +
                                ((flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                                 SIRIUS_PARSER_OFFSET_INGRESS:
                                 SIRIUS_PARSER_OFFSET_EGRESS));
            ruleInfo->flags = flags;
        }
    } else {
        /* fell off end of egress list */
        return SOC_E_NOT_FOUND;
    }
    if (flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
        *next = best->ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
    } else {
        *next = best->ruleId + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
    }
    return SOC_E_NONE;
}

int
soc_sirius_predicate_parser_map_delete(int unit,
                                       unsigned int ruleId)
{
    uint8 ruleTemp;
    soc_sirius_predicate_parser_rule_t ruleInfo;
    SHR_BITDCL *ruleIds;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS <= ruleId) &&
        ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is ingress */
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
        ruleInfo.flags = (SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                          SIRIUS_PREDICATE_PARSER_RULE_FLAG_DELETE);
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
    } else if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS <= ruleId) &&
               ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is egress */
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
        ruleInfo.flags = (SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS |
                          SIRIUS_PREDICATE_PARSER_RULE_FLAG_DELETE);
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule ID %d is not valid\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    if (!SHR_BITGET(ruleIds, ruleTemp)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule %d is not in use\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    result = _soc_sirius_predicate_parser_rule_update(unit,
                                                      ruleTemp,
                                                      &ruleInfo);
    if (SOC_E_NONE == result) {
        result = _soc_sirius_update_parser_to_predicate_map(unit,
                                                            ruleInfo.flags &
                                                            SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d %s predicate->parser map out of sync;"
                                   " will be restored next successful update\n"),
                       unit,
                       (ruleInfo.flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       "ingress":
                       "egress"));
        }
    }
    return result;
}

int
soc_sirius_predicate_parser_map_check(int unit,
                                      unsigned int ruleId)
{
    uint8 ruleTemp;
    SHR_BITDCL *ruleIds;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    /* coverity[unsigned_compare] */
    if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS <= ruleId) &&
        ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
          SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is ingress */
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
    } else if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS <= ruleId) &&
               ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS +
                 SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > ruleId)) {
        /* it is egress */
        ruleTemp = ruleId - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
        ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
    } else {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule ID %d is not valid\n"),
                   unit,
                   ruleId));
        return SOC_E_NOT_FOUND;
    }
    if (SHR_BITGET(ruleIds, ruleTemp)) {
        return SOC_E_FULL;
    } else {
        return SOC_E_EMPTY;
    }
}

int
soc_sirius_predicate_parser_map_add(int unit,
                                    const soc_sirius_predicate_parser_rule_t *ruleInfo,
                                    unsigned int *ruleId)
{
    uint8 ruleTemp;
    SHR_BITDCL *ruleIds;
    unsigned int idx;
    soc_sirius_predicate_parser_rule_t workingRule;
    int result;

    if (!SOC_SBX_SIRIUS_STATE(unit)) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d not initialised properly\n"),
                   unit));
        return SOC_E_INIT;
    }
    if (!ruleId) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "In/Out argument ruleId must not be NULL\n")));
        return SOC_E_PARAM;
    }
    if (!ruleInfo) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "The ruleInfo argument must not be NULL\n")));
        return SOC_E_PARAM;
    }
    if (255 < ruleInfo->priority) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "unit %d predicate->parser rule priority %d"
                               " not valid\n"),
                   unit,
                   ruleInfo->priority));
        return SOC_E_PARAM;
    }
    workingRule.flags = ruleInfo->flags;
    workingRule.priority = ruleInfo->priority;
    workingRule.predState = ruleInfo->predState;
    workingRule.predMask = ruleInfo->predMask;
    if (ruleInfo->flags & (~(SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                             SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS |
                             SIRIUS_PREDICATE_PARSER_RULE_FLAG_WITH_ID |
                             SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE))) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "flags %08X contains bits %08X  not supported"
                               " on unit %d\n"),
                   ruleInfo->flags,
                   ruleInfo->flags & (~(SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                   SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS |
                   SIRIUS_PREDICATE_PARSER_RULE_FLAG_WITH_ID |
                   SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE)),
                   unit));
        return SOC_E_PARAM;
    }
    if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_WITH_ID) {
        /* caller wants a specific ID */
        /* coverity[unsigned_compare] */
        if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS <= (*ruleId)) &&
            ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS +
              SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > (*ruleId))) {
            /* requested ID is ingress */
            ruleTemp = (*ruleId) - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
            ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
            if ((ruleInfo->flags & (SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                                    SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS)) !=
                SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
                /* but flags say otherwise */
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predictate->parser rule ID %d is"
                                       " ingress, but descriptor flags contradict\n"),
                           unit,
                           *ruleId));
                return SOC_E_PARAM;
            }
            if (/*(SIRIUS_PARSER_OFFSET_INGRESS <= ruleInfo->parser) && */
                ((SIRIUS_PARSER_OFFSET_INGRESS +
                  SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > ruleInfo->parser)) {
                workingRule.parser = (ruleInfo->parser -
                                      SIRIUS_PARSER_OFFSET_INGRESS);
            } else {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "parser ID %d is not valid for ingress on"
                                       " unit %d\n"),
                           ruleInfo->parser,
                           unit));
                return SOC_E_PARAM;
            }
        } else if ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS <= (*ruleId)) &&
                   ((SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS +
                     SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) > (*ruleId))) {
            /* requested ID is ingress */
            ruleTemp = (*ruleId) - SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
            ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
            if ((ruleInfo->flags & (SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                                    SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS)) !=
                SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS) {
                /* but flags say otherwise */
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predictate->parser rule ID %d is"
                                       " egress, but descriptor flags contradict\n"),
                           unit,
                           *ruleId));
                return SOC_E_PARAM;
            }
            if ((SIRIUS_PARSER_OFFSET_EGRESS <= ruleInfo->parser) &&
                ((SIRIUS_PARSER_OFFSET_EGRESS +
                  SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > ruleInfo->parser)) {
                workingRule.parser = (ruleInfo->parser -
                                      SIRIUS_PARSER_OFFSET_EGRESS);
            } else {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "parser ID %d is not valid for egress on"
                                       " unit %d\n"),
                           ruleInfo->parser,
                           unit));
                return SOC_E_PARAM;
            }
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d predicate->parser rule ID %d is"
                                   " not valid\n"),
                       unit,
                       *ruleId));
            return SOC_E_NOT_FOUND;
        }
        /* ID looks good; make sure it is as expected */
        if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE) {
            if (!SHR_BITGET(ruleIds, ruleTemp)) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predicate->parser rule %d is"
                                       " not in use; can not replace\n"),
                           unit,
                           *ruleId));
                return SOC_E_NOT_FOUND;
            }
        } else { /* if (replace mode) */
            if (SHR_BITGET(ruleIds, ruleTemp)) {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "unit %d predicate->parser rule %d is"
                                       " already in use; can not allocate\n"),
                           unit,
                           *ruleId));
                return SOC_E_EXISTS;
            }
        } /* if (replace mode) */
    } else { /* if (caller specified ID) */
        /* need to look for a free ID */
        if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_REPLACE) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d requires WITH_ID with REPLACE\n"),
                       unit));
            return SOC_E_PARAM;
        }
        if ((ruleInfo->flags & (SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                                SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS)) ==
            SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
            /* ingress rule */
            ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->ingressRuleIds[0]);
            if (/*(SIRIUS_PARSER_OFFSET_INGRESS <= ruleInfo->parser) && */
                ((SIRIUS_PARSER_OFFSET_INGRESS +
                  SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > ruleInfo->parser)) {
                workingRule.parser = (ruleInfo->parser -
                                      SIRIUS_PARSER_OFFSET_INGRESS);
            } else {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "parser ID %d is not valid for ingress on"
                                       " unit %d\n"),
                           ruleInfo->parser,
                           unit));
                return SOC_E_PARAM;
            }
        } else if ((ruleInfo->flags &
                    (SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS |
                     SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS)) ==
                   SIRIUS_PREDICATE_PARSER_RULE_FLAG_EGRESS) {
            /* egress rule */
            ruleIds = &(SOC_SBX_SIRIUS_STATE(unit)->egressRuleIds[0]);
            if ((SIRIUS_PARSER_OFFSET_EGRESS <= ruleInfo->parser) &&
                ((SIRIUS_PARSER_OFFSET_EGRESS +
                  SB_FAB_DEVICE_SIRIUS_CONFIG_PARSERS) > ruleInfo->parser)) {
                workingRule.parser = (ruleInfo->parser -
                                      SIRIUS_PARSER_OFFSET_EGRESS);
            } else {
                LOG_ERROR(BSL_LS_SOC_COMMON,
                          (BSL_META_U(unit,
                                      "parser ID %d is not valid for egress on"
                                       " unit %d\n"),
                           ruleInfo->parser,
                           unit));
                return SOC_E_PARAM;
            }
        } else {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d predicate->parser rules must be for"
                                   " either ingress or egress\n"),
                       unit));
            return SOC_E_PARAM;
        }
        for (idx = 0;
             idx < SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS;
             idx++) {
            if (!SHR_BITGET(ruleIds, idx)) {
                /* found an ID that is not in use */
                break;
            }
        }
        if (idx >= SB_FAB_DEVICE_SIRIUS_CONFIG_PRED_PARSER_MAPS) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d has no free %s predicate->parser"
                                   " rules\n"),
                       unit,
                       (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       "ingress":
                       "egress"));
            return SOC_E_RESOURCE;
        }
        ruleTemp = idx;
    } /* if (caller specified ID) */
    /* have now built new rule and decided upon ID; insert it */
    result = _soc_sirius_predicate_parser_rule_update(unit,
                                                      ruleTemp,
                                                      &workingRule);
    if (SOC_E_NONE == result) {
        if (ruleInfo->flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS) {
            *ruleId = ruleTemp + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_INGRESS;
        } else {
            *ruleId = ruleTemp + SIRIUS_PREDICATE_PARSER_RULE_OFFSET_EGRESS;
        }
        result = _soc_sirius_update_parser_to_predicate_map(unit,
                                                            workingRule.flags &
                                                            SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS);
        if (SOC_E_NONE != result) {
            LOG_ERROR(BSL_LS_SOC_COMMON,
                      (BSL_META_U(unit,
                                  "unit %d %s predicate->parser map out of sync;"
                                   " will be restored next successful update\n"),
                       unit,
                       (workingRule.flags & SIRIUS_PREDICATE_PARSER_RULE_FLAG_INGRESS)?
                       "ingress":
                       "egress"));
        }
    }
    return result;
}


int
soc_sirius_port_flush(int unit, int fifo)
{
    int  rv = SOC_E_INTERNAL;
    uint32 regval = 0, i = 0;

    SOC_IF_ERROR_RETURN(READ_FF_FLUSHr(unit, &regval));
    if (soc_reg_field_get(unit, FF_FLUSHr, regval, FLUSH_FIFO_DONEf) == 1) {
	soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_ENABLEf, 0);
	SOC_IF_ERROR_RETURN(WRITE_FF_FLUSHr(unit, regval));
	soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_DONEf, 1);
	SOC_IF_ERROR_RETURN(WRITE_FF_FLUSHr(unit, regval));
	SOC_IF_ERROR_RETURN(READ_FF_FLUSHr(unit, &regval));
    }
    if (soc_reg_field_get(unit, FF_FLUSHr, regval, FLUSH_FIFO_DONEf) == 0) {
	regval = 0;
	soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_NUMf, fifo);
	soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_ENABLEf, 1);
	SOC_IF_ERROR_RETURN(WRITE_FF_FLUSHr(unit, regval));
    }

    sal_usleep(SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_DELAY);
    for (i = 0; i < SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_COUNT; i++) {
	SOC_IF_ERROR_RETURN(READ_FF_FLUSHr(unit, &regval));
	if (soc_reg_field_get(unit, FF_FLUSHr, regval, FLUSH_FIFO_DONEf) == 1) {
	    soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_NUMf, 0x3ff);
	    rv = BCM_E_NONE;
            break;
	}

        sal_usleep(SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_DELAY);
    }

    soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_ENABLEf, 0);
    SOC_IF_ERROR_RETURN(WRITE_FF_FLUSHr(unit, regval));
    regval = 0;
    soc_reg_field_set(unit, FF_FLUSHr, &regval, FLUSH_FIFO_DONEf, 1);
    SOC_IF_ERROR_RETURN(WRITE_FF_FLUSHr(unit, regval));
    return (rv);
}


extern int
soc_sirius_fcd_empty(int unit, int fcd, int *is_empty)
{
    int rv = SOC_E_NONE;
    dc_mem_entry_t fcd_credits;
    int i = 0;


    (*is_empty) = FALSE;
    sal_usleep(100);

    for (i = 0; i < SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_COUNT; i++) {
	SOC_IF_ERROR_RETURN(READ_DC_MEMm(unit, MEM_BLOCK_ANY, fcd, &fcd_credits));

	if (soc_mem_field32_get(unit, DC_MEMm, &fcd_credits, COUNTf) == 0) 
            break;

        sal_usleep(100);
    }

    if (i >= SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_COUNT) {
        return(rv);
    }

    (*is_empty) = TRUE;
    
    return (rv);
}


extern int
soc_sirius_fifo_empty(int unit, int fifo, int *is_empty)
{
    eg_fd_fifo_count_entry_t count;
    int i = 0;

    (*is_empty) = FALSE;

    for (i = 0; i < SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_COUNT; i++) {
	SOC_IF_ERROR_RETURN(READ_EG_FD_FIFO_COUNTm(unit, MEM_BLOCK_ANY, fifo, &count));

	if (soc_mem_field32_get(unit, EG_FD_FIFO_COUNTm, &count, FIFO_COUNTf) == 0) {
	    (*is_empty) = TRUE;
	    return SOC_E_NONE;
	}

	sal_usleep(SB_FAB_DEVICE_SIRIUS_FIFO_EMPTY_ITER_DELAY);
    }
    return SOC_E_NONE;
}

extern int
soc_sirius_fifo_force_full_set(int unit, int fifo, int is_asserted)
{
    soc_sbx_sirius_config_t *sir = SOC_SBX_CFG_SIRIUS(unit);
    eg_fd_fifo_thresh_entry_t thresh;
    int thresh_val = 0;
    
    SOC_IF_ERROR_RETURN(READ_EG_FD_FIFO_THRESHm(unit, MEM_BLOCK_ANY, fifo, &thresh));

    /* update configuration */
    if (is_asserted == TRUE) {
	thresh_val = soc_mem_field32_get(unit, EG_FD_FIFO_THRESHm, &thresh, DYNAMICf) << 15;
	thresh_val |= soc_mem_field32_get(unit, EG_FD_FIFO_THRESHm, &thresh, FIFO_THRESHf);
	if (thresh_val != 0) {
	    sir->fifo_thresh[fifo] = thresh_val;
	    soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &thresh, DYNAMICf, 0);
	    soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &thresh, FIFO_THRESHf, 0);
	}
    } else {
	soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &thresh, DYNAMICf, sir->fifo_thresh[fifo] >> 15);
	soc_mem_field32_set(unit, EG_FD_FIFO_THRESHm, &thresh, FIFO_THRESHf, sir->fifo_thresh[fifo] & 0x7fff);
    }
    
    SOC_IF_ERROR_RETURN(WRITE_EG_FD_FIFO_THRESHm(unit, MEM_BLOCK_ANY, fifo, &thresh));
    return SOC_E_NONE;
}

int
soc_sirius_dt_mem_set(int unit, int fcd, int cosq, uint32 bytes_min, uint32 bytes_max)
{
    int  rv = SOC_E_NONE;
    dt_mem_entry_t dt_entry;
    int pages_min = 0, pages_max = 0;

    if (fcd/2 > SB_FAB_DEVICE_SIRIUS_MAX_PHYSICAL_PORTS ) {
	return SOC_E_PARAM;
    }

    /* Get current settings */
    SOC_IF_ERROR_RETURN(READ_DT_MEMm(unit, MEM_BLOCK_ANY, fcd/2, &dt_entry));

    pages_min = (bytes_min / 128) + (((bytes_min % 128) == 0) ? 0 : 1);
    pages_max = (bytes_max / 128) + (((bytes_max % 128) == 0) ? 0 : 1);

    if ((SOC_SBX_CFG(unit)->bEgressFifoIndependentFlowControl) || 	  	 
        (SOC_SBX_CFG(unit)->bEgressMulticastFifoIndependentFlowControl)) {
        soc_mem_field32_set(unit, DT_MEMm, &dt_entry, METHODf, 0);
        if (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == TRUE) {
            if ((fcd % 2) == 0 ) {
                soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD0f, pages_min);
                soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD1f, pages_max); 
            } else {
                soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD2f, pages_min);
                soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD3f, pages_max);
            }
        } else { 
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD0f, pages_min);
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD1f, pages_max);
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD2f, pages_min);
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD3f, pages_max);
        }
    } else {
        soc_mem_field32_set(unit, DT_MEMm, &dt_entry, METHODf, 1);
        /*
         * Base which threshold field to adjust based upon which half
         * (odd or even) of the fcd needs modification
         */
        if ((cosq == SOC_SBX_CFG_SIRIUS(unit)->ucast_ef_fifo) ||
            (cosq == SOC_SBX_CFG_SIRIUS(unit)->mcast_ef_fifo)) {
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD0f, pages_min);
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD1f, pages_max);
        } else {
            soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD2f, pages_min);
                soc_mem_field32_set(unit, DT_MEMm, &dt_entry, THRESHOLD3f, pages_max);
        }
    }
	
    /* Update entry and write back */
    SOC_IF_ERROR_RETURN(WRITE_DT_MEMm(unit, MEM_BLOCK_ANY, fcd/2, &dt_entry));
    return (rv);
}


int
soc_sirius_dt_mem_get(int unit, int fcd, int cosq, uint32 *bytes_min, uint32 *bytes_max)
{
    int  rv = SOC_E_NONE;
    dt_mem_entry_t dt_entry;
    int pages_min = 0, pages_max = 0;

    if ( fcd/2 > SB_FAB_DEVICE_SIRIUS_MAX_PHYSICAL_PORTS ) {
	return SOC_E_PARAM;
    }

    /* Get current settings */
    SOC_IF_ERROR_RETURN(READ_DT_MEMm(unit, MEM_BLOCK_ANY, fcd/2, &dt_entry));

    /* retreive current setting */
    if (soc_mem_field32_get(unit, DT_MEMm, &dt_entry, METHODf) == 0) {
        if (SOC_SBX_CFG_SIRIUS(unit)->bExtendedPortMode == TRUE) {
            if ((fcd % 2) == 0 ) {
                pages_min = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD0f);
                pages_max = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD1f); 
            } else {
                pages_min = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD2f);
                pages_max = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD3f);
            }
        } else { 
            pages_min = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD0f);
            pages_max = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD1f);
        }
    } else {
	/*
	 * Base which threshold field to adjust based upon which half
	 * (odd or even) of the fifo index needs modification
	 */
      if ((cosq == SOC_SBX_CFG_SIRIUS(unit)->ucast_ef_fifo) ||
	  (cosq == SOC_SBX_CFG_SIRIUS(unit)->mcast_ef_fifo)) {
	    pages_min = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD0f);
	    pages_max = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD1f);
	} else {
	    pages_min = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD2f);
	    pages_max = soc_mem_field32_get(unit, DT_MEMm, &dt_entry, THRESHOLD3f);
	}
    }

    (*bytes_min) = pages_min * 128;
    (*bytes_max) = pages_max * 128;
    return (rv);
}

int soc_sirius_dmt_mem_set(int unit, int sysport, int domain0, int domain1) 
{
    dmt_mem_entry_t dmt_entry;

    if (sysport > SOC_MEM_INFO(unit, DMT_MEMm).index_max) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, Sysport %d out of range, Unit(%d)\n"),
                   FUNCTION_NAME(), sysport, unit));
	return SOC_E_PARAM;
    }

    if (domain0 > 0x1ff) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, Domain0 %d out of range, Unit(%d)\n"),
                   FUNCTION_NAME(), domain0, unit));
	return SOC_E_PARAM;
    }

    if (domain1 > 0x1ff) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, Domain1 %d out of range, Unit(%d)\n"),
                   FUNCTION_NAME(), domain0, unit));
	return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_DMT_MEMm(unit, MEM_BLOCK_ANY, sysport, &dmt_entry));
    soc_mem_field32_set(unit, DMT_MEMm, &dmt_entry, DOMAIN_NUMBER0f, domain0);
    soc_mem_field32_set(unit, DMT_MEMm, &dmt_entry, DOMAIN_NUMBER1f, domain1);
    SOC_IF_ERROR_RETURN(WRITE_DMT_MEMm(unit, MEM_BLOCK_ANY, sysport, &dmt_entry));
    return SOC_E_NONE;
}

int soc_sirius_dmt_mem_get(int unit, int sysport, int *domain0, int *domain1) 
{
    dmt_mem_entry_t dmt_entry;

    if (sysport > SOC_MEM_INFO(unit, DMT_MEMm).index_max) {
        LOG_ERROR(BSL_LS_SOC_COMMON,
                  (BSL_META_U(unit,
                              "ERROR: %s, Sysport %d out of range, Unit(%d)\n"),
                   FUNCTION_NAME(), sysport, unit));
	return SOC_E_PARAM;
    }

    SOC_IF_ERROR_RETURN(READ_DMT_MEMm(unit, MEM_BLOCK_ANY, sysport, &dmt_entry));
    *domain0 = soc_mem_field32_get(unit, DMT_MEMm, &dmt_entry, DOMAIN_NUMBER0f);
    *domain1 = soc_mem_field32_get(unit, DMT_MEMm, &dmt_entry, DOMAIN_NUMBER1f);
    return SOC_E_NONE;
}

#endif /* BCM_SIRIUS_SUPPORT */
